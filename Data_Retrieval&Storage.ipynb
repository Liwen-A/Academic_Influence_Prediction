{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some Starter Code for Retrieving, and Analyzing Data Using API\n",
    "In this notebook I include a basic example of \n",
    "1. retrieving data using [SemanticScholar APIs](https://api.semanticscholar.org/graph/v1)\n",
    "2. store it in a pandas dataframe  \n",
    "3. write it to a .csv file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example, the following API performs a search by keyword and:\n",
    "1. Returns with total=639637, offset=0, next=100, and data is a list of 100 papers.\n",
    "2. Each paper has paperId, abstract, year, referenceCount, citationCount, influentialCitationCount and fieldsOfStudy \n",
    "\n",
    "Feel free to change the strings after 'query=' and 'fields='to specify what keyword you want to search and what fields, i.e. data, you want the API to return.  Add 'limit=' to specify how many data you want it to return.\n",
    "For more information on other APIs refer to [SemanticScholar APIs](https://api.semanticscholar.org/graph/v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get('https://api.semanticscholar.org/graph/v1/paper/search?&query=convex&fields=abstract,year,referenceCount,authors,citationCount,influentialCitationCount,fieldsOfStudy&offest=0&limit=100')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example of the paper instance returned by the above API call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total': 503042,\n",
       " 'offset': 0,\n",
       " 'next': 100,\n",
       " 'data': [{'paperId': '4f607f03272e4d62708f5b2441355f9e005cb452',\n",
       "   'abstract': 'Convex optimization problems arise frequently in many different fields. A comprehensive introduction to the subject, this book shows in detail how such problems can be solved numerically with great efficiency. The focus is on recognizing convex optimization problems and then finding the most appropriate technique for solving them. The text contains many worked examples and homework exercises and will appeal to students, researchers and practitioners in fields such as engineering, computer science, mathematics, statistics, finance, and economics.',\n",
       "   'year': 2006,\n",
       "   'referenceCount': 277,\n",
       "   'citationCount': 37959,\n",
       "   'influentialCitationCount': 3370,\n",
       "   'fieldsOfStudy': ['Mathematics', 'Computer Science'],\n",
       "   'authors': [{'authorId': '1843103', 'name': 'Stephen P. Boyd'},\n",
       "    {'authorId': '2014414', 'name': 'L. Vandenberghe'}]},\n",
       "  {'paperId': 'fc437af6204008647ea49f81058d5fdaddf75ead',\n",
       "   'abstract': 'Many meta-learning approaches for few-shot learning rely on simple base learners such as nearest-neighbor classifiers. However, even in the few-shot regime, discriminatively trained linear predictors can offer better generalization. We propose to use these predictors as base learners to learn representations for few-shot learning and show they offer better tradeoffs between feature size and performance across a range of few-shot recognition benchmarks. Our objective is to learn feature embeddings that generalize well under a linear classification rule for novel categories. To efficiently solve the objective, we exploit two properties of linear classifiers: implicit differentiation of the optimality conditions of the convex problem and the dual formulation of the optimization problem. This allows us to use high-dimensional embeddings with improved generalization at a modest increase in computational overhead. Our approach, named MetaOptNet, achieves state-of-the-art performance on miniImageNet, tieredImageNet, CIFAR-FS, and FC100 few-shot learning benchmarks.',\n",
       "   'year': 2019,\n",
       "   'referenceCount': 43,\n",
       "   'citationCount': 444,\n",
       "   'influentialCitationCount': 102,\n",
       "   'fieldsOfStudy': ['Computer Science'],\n",
       "   'authors': [{'authorId': '2668978', 'name': 'Kwonjoon Lee'},\n",
       "    {'authorId': '35208858', 'name': 'Subhransu Maji'},\n",
       "    {'authorId': '2529423', 'name': 'Avinash Ravichandran'},\n",
       "    {'authorId': '1715959', 'name': 'Stefano Soatto'}]},\n",
       "  {'paperId': '472e8257dca67af31539bc2bdc1479a4c43bca2f',\n",
       "   'abstract': 'In this paper we study a first-order primal-dual algorithm for non-smooth convex optimization problems with known saddle-point structure. We prove convergence to a saddle-point with rate O(1/N) in finite dimensions for the complete class of problems. We further show accelerations of the proposed algorithm to yield improved rates on problems with some degree of smoothness. In particular we show that we can achieve O(1/N2) convergence on problems, where the primal or the dual objective is uniformly convex, and we can show linear convergence, i.e. O(ωN) for some ω∈(0,1), on smooth problems. The wide applicability of the proposed algorithm is demonstrated on several imaging problems such as image denoising, image deconvolution, image inpainting, motion estimation and multi-label image segmentation.',\n",
       "   'year': 2010,\n",
       "   'referenceCount': 52,\n",
       "   'citationCount': 3443,\n",
       "   'influentialCitationCount': 507,\n",
       "   'fieldsOfStudy': ['Computer Science', 'Mathematics'],\n",
       "   'authors': [{'authorId': '1683740', 'name': 'A. Chambolle'},\n",
       "    {'authorId': '1730097', 'name': 'T. Pock'}]},\n",
       "  {'paperId': '8af74907c5d0b825c3e9419da64903f614aefd7c',\n",
       "   'abstract': 'This book provides a largely self-contained account of the main results of convex analysis and optimization in Hilbert space. A concise exposition of related constructive fixed point theory is presented, that allows for a wide range of algorithms to construct solutions to problems in optimization, equilibrium theory, monotone inclusions, variational inequalities, best approximation theory, and convex feasibility. The book is accessible to a broad audience, and reaches out in particular to applied scientists and engineers, to whom these tools have become indispensable.',\n",
       "   'year': 2011,\n",
       "   'referenceCount': 0,\n",
       "   'citationCount': 3247,\n",
       "   'influentialCitationCount': 311,\n",
       "   'fieldsOfStudy': ['Mathematics', 'Computer Science'],\n",
       "   'authors': [{'authorId': '1713257', 'name': 'Heinz H. Bauschke'},\n",
       "    {'authorId': '1783400', 'name': 'P. L. Combettes'}]},\n",
       "  {'paperId': 'dfb9e786b146f15951ed7343d45b3c75785ec5bc',\n",
       "   'abstract': 'Any solid object can be decomposed into a collection of convex polytopes (in short, convexes). When a small number of convexes are used, such a decomposition can be thought of as a piece-wise approximation of the geometry. This decomposition is fundamental in computer graphics, where it provides one of the most common ways to approximate geometry, for example, in real-time physics simulation. A convex object also has the property of being simultaneously an explicit and implicit representation: one can interpret it explicitly as a mesh derived by computing the vertices of a convex hull, or implicitly as the collection of half-space constraints or support functions. Their implicit representation makes them particularly well suited for neural network training, as they abstract away from the topology of the geometry they need to represent. However, at testing time, convexes can also generate explicit representations – polygonal meshes – which can then be used in any downstream application. We introduce a network architecture to represent a low dimensional family of convexes. This family is automatically derived via an auto-encoding process. We investigate the applications of this architecture including automatic convex decomposition, image to 3D reconstruction, and part-based shape retrieval.',\n",
       "   'year': 2020,\n",
       "   'referenceCount': 81,\n",
       "   'citationCount': 87,\n",
       "   'influentialCitationCount': 11,\n",
       "   'fieldsOfStudy': ['Computer Science'],\n",
       "   'authors': [{'authorId': '22257166', 'name': 'Boyang Deng'},\n",
       "    {'authorId': '32627314', 'name': 'Kyle Genova'},\n",
       "    {'authorId': '2720347', 'name': 'S. Yazdani'},\n",
       "    {'authorId': '35119991', 'name': 'Sofien Bouaziz'},\n",
       "    {'authorId': '1695689', 'name': 'Geoffrey E. Hinton'},\n",
       "    {'authorId': '1796480', 'name': 'A. Tagliasacchi'}]},\n",
       "  {'paperId': '040c161f21e0fa57ac192ac826310f55d60277b0',\n",
       "   'abstract': 'Suppose that one observes an incomplete subset of entries selected from a low-rank matrix. When is it possible to complete the matrix and recover the entries that have not been seen? We demonstrate that in very general settings, one can perfectly recover all of the missing entries from most sufficiently large subsets by solving a convex programming problem that finds the matrix with the minimum nuclear norm agreeing with the observed entries. The techniques used in this analysis draw upon parallels in the field of compressed sensing, demonstrating that objects other than signals and images can be perfectly reconstructed from very limited information.',\n",
       "   'year': 2012,\n",
       "   'referenceCount': 97,\n",
       "   'citationCount': 2390,\n",
       "   'influentialCitationCount': 249,\n",
       "   'fieldsOfStudy': ['Mathematics', 'Computer Science'],\n",
       "   'authors': [{'authorId': '2006869', 'name': 'E. Candès'},\n",
       "    {'authorId': '9229182', 'name': 'B. Recht'}]},\n",
       "  {'paperId': '4b23012689e0f17912fb38d4984775e567cff8d6',\n",
       "   'abstract': 'We propose a method to learn deep ReLU-based classifiers that are provably robust against norm-bounded adversarial perturbations (on the training data; for previously unseen examples, the approach will be guaranteed to detect all adversarial examples, though it may flag some non-adversarial examples as well). The basic idea of the approach is to consider a convex outer approximation of the set of activations reachable through a norm-bounded perturbation, and we develop a robust optimization procedure that minimizes the worst case loss over this outer region (via a linear program). Crucially, we show that the dual problem to this linear program can be represented itself as a deep network similar to the backpropagation network, leading to very efficient optimization approaches that produce guaranteed bounds on the robust loss. The end result is that by executing a few more forward and backward passes through a slightly modified version of the original network (though possibly with much larger batch sizes), we can learn a classifier that is provably robust to any norm-bounded adversarial attack. We illustrate the approach on a toy 2D robust classification task, and on a simple convolutional architecture applied to MNIST, where we produce a classifier that provably has less than 8.4% test error for any adversarial attack with bounded $\\\\ell_\\\\infty$ norm less than $\\\\epsilon = 0.1$. This represents the largest verified network that we are aware of, and we discuss future challenges in scaling the approach to much larger domains.',\n",
       "   'year': 2018,\n",
       "   'referenceCount': 34,\n",
       "   'citationCount': 890,\n",
       "   'influentialCitationCount': 117,\n",
       "   'fieldsOfStudy': ['Computer Science', 'Mathematics'],\n",
       "   'authors': [{'authorId': '145116464', 'name': 'J. Z. Kolter'},\n",
       "    {'authorId': '51026953', 'name': 'Eric Wong'}]},\n",
       "  {'paperId': '17d9f89ce7d4366f88cf87ad15f9c229f8578b66',\n",
       "   'abstract': 'The standard assumption for proving linear convergence of first order methods for smooth convex optimization is the strong convexity of the objective function, an assumption which does not hold for many practical applications. In this paper, we derive linear convergence rates of several first order methods for solving smooth non-strongly convex constrained optimization problems, i.e. involving an objective function with a Lipschitz continuous gradient that satisfies some relaxed strong convexity condition. In particular, in the case of smooth constrained convex optimization, we provide several relaxations of the strong convexity conditions and prove that they are sufficient for getting linear convergence for several first order methods such as projected gradient, fast gradient and feasible descent methods. We also provide examples of functional classes that satisfy our proposed relaxations of strong convexity conditions. Finally, we show that the proposed relaxed strong convexity conditions cover important applications ranging from solving linear systems, Linear Programming, and dual formulations of linearly constrained convex problems.',\n",
       "   'year': 2019,\n",
       "   'referenceCount': 25,\n",
       "   'citationCount': 183,\n",
       "   'influentialCitationCount': 26,\n",
       "   'fieldsOfStudy': ['Computer Science', 'Mathematics'],\n",
       "   'authors': [{'authorId': '2039290', 'name': 'I. Necoara'},\n",
       "    {'authorId': '143676697', 'name': 'Y. Nesterov'},\n",
       "    {'authorId': '2002957', 'name': 'F. Glineur'}]},\n",
       "  {'paperId': 'd0b0c3e5a1e768490bc9b759685930541957508b',\n",
       "   'abstract': 'It was in the middle of the 1980s, when the seminal paper by Kar markar opened a new epoch in nonlinear optimization. The importance of this paper, containing a new polynomial-time algorithm for linear op timization problems, was not only in its complexity bound. At that time, the most surprising feature of this algorithm was that the theoretical pre diction of its high efficiency was supported by excellent computational results. This unusual fact dramatically changed the style and direc tions of the research in nonlinear optimization. Thereafter it became more and more common that the new methods were provided with a complexity analysis, which was considered a better justification of their efficiency than computational experiments. In a new rapidly develop ing field, which got the name \"polynomial-time interior-point methods\", such a justification was obligatory. Afteralmost fifteen years of intensive research, the main results of this development started to appear in monographs [12, 14, 16, 17, 18, 19]. Approximately at that time the author was asked to prepare a new course on nonlinear optimization for graduate students. The idea was to create a course which would reflect the new developments in the field. Actually, this was a major challenge. At the time only the theory of interior-point methods for linear optimization was polished enough to be explained to students. The general theory of self-concordant functions had appeared in print only once in the form of research monograph [12].',\n",
       "   'year': 2004,\n",
       "   'referenceCount': 0,\n",
       "   'citationCount': 4560,\n",
       "   'influentialCitationCount': 689,\n",
       "   'fieldsOfStudy': ['Computer Science'],\n",
       "   'authors': [{'authorId': '143676697', 'name': 'Y. Nesterov'}]},\n",
       "  {'paperId': 'b272701e77ddb860741a193ac1701ca382853680',\n",
       "   'abstract': None,\n",
       "   'year': 1977,\n",
       "   'referenceCount': 8,\n",
       "   'citationCount': 6961,\n",
       "   'influentialCitationCount': 743,\n",
       "   'fieldsOfStudy': ['Mathematics'],\n",
       "   'authors': [{'authorId': '66418228', 'name': '丸山 徹'}]},\n",
       "  {'paperId': 'b9c975b0733f976276b620f21288ac5756a919ac',\n",
       "   'abstract': 'Preface to the classics edition Preface Part I. Fundamentals of Convex Analysis. I. Convex functions 2. Minimization of convex functions and variational inequalities 3. Duality in convex optimization Part II. Duality and Convex Variational Problems. 4. Applications of duality to the calculus of variations (I) 5. Applications of duality to the calculus of variations (II) 6. Duality by the minimax theorem 7. Other applications of duality Part III. Relaxation and Non-Convex Variational Problems. 8. Existence of solutions for variational problems 9. Relaxation of non-convex variational problems (I) 10. Relaxation of non-convex variational problems (II) Appendix I. An a priori estimate in non-convex programming Appendix II. Non-convex optimization problems depending on a parameter Comments Bibliography Index.',\n",
       "   'year': 1976,\n",
       "   'referenceCount': 0,\n",
       "   'citationCount': 4115,\n",
       "   'influentialCitationCount': 269,\n",
       "   'fieldsOfStudy': ['Mathematics'],\n",
       "   'authors': [{'authorId': '3189761', 'name': 'I. Ekeland'},\n",
       "    {'authorId': '101480945', 'name': 'R. Téman'}]},\n",
       "  {'paperId': '15d70874bed0c2cd2ddb2f225fd62f09e9c47617',\n",
       "   'abstract': \"Trying to find professional reading resources? We have lectures on convex optimization to read, not just read, however likewise download them and even read online. Locate this great book writtern by by now, just below, yeah just below. Obtain the data in the types of txt, zip, kindle, word, ppt, pdf, as well as rar. Once again, never miss out on to read online and also download this publication in our site here. Click the link. Are you looking to uncover lectures on convex optimization Digitalbook. Correct here it is possible to locate as well as download lectures on convex optimization Book. We've got ebooks for every single topic lectures on convex optimization accessible for download cost-free. Search the site also as find Jean Campbell eBook in layout. We also have a fantastic collection of information connected to this Digitalbook for you. As well because the best part is you could assessment as well as download for lectures on convex optimization eBook Our goal is always to offer you an assortment of cost-free ebooks too as aid resolve your troubles. We have got a considerable collection of totally free of expense Book for people from every single stroll of life. We have got tried our finest to gather a sizable library of preferred cost-free as well as paid files. GO TO THE TECHNICAL WRITING FOR AN EXPANDED TYPE OF THIS LECTURES ON CONVEX OPTIMIZATION, ALONG WITH A CORRECTLY FORMATTED VERSION OF THE INSTANCE MANUAL PAGE ABOVE.\",\n",
       "   'year': 2018,\n",
       "   'referenceCount': 0,\n",
       "   'citationCount': 417,\n",
       "   'influentialCitationCount': 58,\n",
       "   'fieldsOfStudy': ['Computer Science'],\n",
       "   'authors': [{'authorId': '143676697', 'name': 'Y. Nesterov'}]},\n",
       "  {'paperId': 'd479fbf514db0362e90d9d81f246318a6afb8004',\n",
       "   'abstract': 'Written for specialists working in optimization, mathematical programming, or control theory. The general theory of path-following and potential reduction interior point polynomial time methods, interior point methods, interior point methods for linear and quadratic programming, polynomial time methods for nonlinear convex programming, efficient computation methods for control problems and variational inequalities, and acceleration of path-following methods are covered. In this book, the authors describe the first unified theory of polynomial-time interior-point methods. Their approach provides a simple and elegant framework in which all known polynomial-time interior-point methods can be explained and analyzed; this approach yields polynomial-time interior-point methods for a wide variety of problems beyond the traditional linear and quadratic programs. The book contains new and important results in the general theory of convex programming, e.g., their \"conic\" problem formulation in which duality theory is completely symmetric. For each algorithm described, the authors carefully derive precise bounds on the computational effort required to solve a given family of problems to a given precision. In several cases they obtain better problem complexity estimates than were previously known. Several of the new algorithms described in this book, e.g., the projective method, have been implemented, tested on \"real world\" problems, and found to be extremely efficient in practice. Contents : Chapter 1: Self-Concordant Functions and Newton Method; Chapter 2: Path-Following Interior-Point Methods; Chapter 3: Potential Reduction Interior-Point Methods; Chapter 4: How to Construct Self- Concordant Barriers; Chapter 5: Applications in Convex Optimization; Chapter 6: Variational Inequalities with Monotone Operators; Chapter 7: Acceleration for Linear and Linearly Constrained Quadratic Problems',\n",
       "   'year': 1994,\n",
       "   'referenceCount': 0,\n",
       "   'citationCount': 3390,\n",
       "   'influentialCitationCount': 259,\n",
       "   'fieldsOfStudy': ['Mathematics', 'Computer Science'],\n",
       "   'authors': [{'authorId': '143676697', 'name': 'Y. Nesterov'},\n",
       "    {'authorId': '145853268', 'name': 'A. Nemirovski'}]},\n",
       "  {'paperId': '4e280ac44bba6310648638eb76312a81182c70f2',\n",
       "   'abstract': 'We consider an algorithm that successively samples and minimizes stochastic models of the objective function. We show that under weak-convexity and Lipschitz conditions, the algorithm drives the expected norm of the gradient of the Moreau envelope to zero at the rate $O(k^{-1/4})$. Our result yields new complexity guarantees for the stochastic proximal point algorithm on weakly convex problems and for the stochastic prox-linear algorithm for minimizing compositions of convex functions with smooth maps. Moreover, our result also recovers the recently obtained complexity estimate for the stochastic proximal subgradient method on weakly convex problems.',\n",
       "   'year': 2019,\n",
       "   'referenceCount': 86,\n",
       "   'citationCount': 152,\n",
       "   'influentialCitationCount': 24,\n",
       "   'fieldsOfStudy': ['Mathematics', 'Computer Science'],\n",
       "   'authors': [{'authorId': '40047103', 'name': 'Damek Davis'},\n",
       "    {'authorId': '2670852', 'name': 'D. Drusvyatskiy'}]},\n",
       "  {'paperId': '97884ff15e0a4e83f534b7b13979e519d1c50a54',\n",
       "   'abstract': 'Training large neural networks requires distributing learning across multiple workers, where the cost of communicating gradients can be a significant bottleneck. signSGD alleviates this problem by transmitting just the sign of each minibatch stochastic gradient. We prove that it can get the best of both worlds: compressed gradients and SGD-level convergence rate. signSGD can exploit mismatches between L1 and L2 geometry: when noise and curvature are much sparser than the gradients, signSGD is expected to converge at the same rate or faster than full-precision SGD. Measurements of the L1 versus L2 geometry of real networks support our theoretical claims, and we find that the momentum counterpart of signSGD is able to match the accuracy and convergence speed of Adam on deep Imagenet models. We extend our theory to the distributed setting, where the parameter server uses majority vote to aggregate gradient signs from each worker enabling 1-bit compression of worker-server communication in both directions. Using a theorem by Gauss, we prove that the non-convex convergence rate of majority vote matches that of distributed SGD. Thus, there is great promise for sign-based optimisation schemes to achieve both communication efficiency and high accuracy.',\n",
       "   'year': 2018,\n",
       "   'referenceCount': 50,\n",
       "   'citationCount': 392,\n",
       "   'influentialCitationCount': 79,\n",
       "   'fieldsOfStudy': ['Computer Science', 'Mathematics'],\n",
       "   'authors': [{'authorId': '2075339320', 'name': 'Jeremy Bernstein'},\n",
       "    {'authorId': '2040617', 'name': 'Yu-Xiang Wang'},\n",
       "    {'authorId': '3371922', 'name': 'K. Azizzadenesheli'},\n",
       "    {'authorId': '2047844', 'name': 'Anima Anandkumar'}]},\n",
       "  {'paperId': '60e58263e1acdc508ddd8df9e6490009cb35d2ee',\n",
       "   'abstract': None,\n",
       "   'year': 2018,\n",
       "   'referenceCount': 0,\n",
       "   'citationCount': 473,\n",
       "   'influentialCitationCount': 58,\n",
       "   'fieldsOfStudy': ['Mathematics'],\n",
       "   'authors': [{'authorId': '3146431', 'name': 'F. Liese'},\n",
       "    {'authorId': '1680998', 'name': 'I. Vajda'}]},\n",
       "  {'paperId': '4daec165c1f4aa1206b0d91c0b26f0287d1ef52d',\n",
       "   'abstract': 'In this work we introduce a new optimisation method called SAGA in the spirit of SAG, SDCA, MISO and SVRG, a set of recently proposed incremental gradient algorithms with fast linear convergence rates. SAGA improves on the theory behind SAG and SVRG, with better theoretical convergence rates, and has support for composite objectives where a proximal operator is used on the regulariser. Unlike SDCA, SAGA supports non-strongly convex problems directly, and is adaptive to any inherent strong convexity of the problem. We give experimental results showing the effectiveness of our method.',\n",
       "   'year': 2014,\n",
       "   'referenceCount': 15,\n",
       "   'citationCount': 1205,\n",
       "   'influentialCitationCount': 249,\n",
       "   'fieldsOfStudy': ['Computer Science', 'Mathematics'],\n",
       "   'authors': [{'authorId': '34597877', 'name': 'Aaron Defazio'},\n",
       "    {'authorId': '144570279', 'name': 'F. Bach'},\n",
       "    {'authorId': '1388317459', 'name': 'S. Lacoste-Julien'}]},\n",
       "  {'paperId': '21a0b0fbdde1aee56fe10e69e897decaf21f43a6',\n",
       "   'abstract': 'In this paper, we prove new complexity bounds for methods of convex optimization based only on computation of the function value. The search directions of our schemes are normally distributed random Gaussian vectors. It appears that such methods usually need at most n times more iterations than the standard gradient methods, where n is the dimension of the space of variables. This conclusion is true for both nonsmooth and smooth problems. For the latter class, we present also an accelerated scheme with the expected rate of convergence $$O\\\\Big ({n^2 \\\\over k^2}\\\\Big )$$O(n2k2), where k is the iteration counter. For stochastic optimization, we propose a zero-order scheme and justify its expected rate of convergence $$O\\\\Big ({n \\\\over k^{1/2}}\\\\Big )$$O(nk1/2). We give also some bounds for the rate of convergence of the random gradient-free methods to stationary points of nonconvex functions, for both smooth and nonsmooth cases. Our theoretical results are supported by preliminary computational experiments.',\n",
       "   'year': 2017,\n",
       "   'referenceCount': 62,\n",
       "   'citationCount': 499,\n",
       "   'influentialCitationCount': 118,\n",
       "   'fieldsOfStudy': ['Mathematics', 'Computer Science'],\n",
       "   'authors': [{'authorId': '143676697', 'name': 'Y. Nesterov'},\n",
       "    {'authorId': '145736253', 'name': 'V. Spokoiny'}]},\n",
       "  {'paperId': 'adb7c53c6928789cd5accf9ab5d0cec3fd32590d',\n",
       "   'abstract': 'The convex hull of a set of points is the smallest convex set that contains the points. This article presents a practical convex hull algorithm that combines the two-dimensional Quickhull algorithm with the general-dimension Beneath-Beyond Algorithm. It is similar to the randomized, incremental algorithms for convex hull and delaunay triangulation. We provide empirical evidence that the algorithm runs faster when the input contains nonextreme points and that it used less memory. computational geometry algorithms have traditionally assumed that input sets are well behaved. When an algorithm is implemented with floating-point arithmetic, this assumption can lead to serous errors. We briefly describe a solution to this problem when computing the convex hull in two, three, or four dimensions. The output is a set of “thick” facets that contain all possible exact convex hulls of the input. A variation is effective in five or more dimensions.',\n",
       "   'year': 1996,\n",
       "   'referenceCount': 74,\n",
       "   'citationCount': 4496,\n",
       "   'influentialCitationCount': 166,\n",
       "   'fieldsOfStudy': ['Mathematics', 'Computer Science'],\n",
       "   'authors': [{'authorId': '153942385', 'name': 'C. Barber'},\n",
       "    {'authorId': '1794954', 'name': 'D. Dobkin'},\n",
       "    {'authorId': '2474698', 'name': 'H. Huhdanpaa'}]},\n",
       "  {'paperId': 'd1dffca5c54287e7b498eb7469dc04207b24a6fa',\n",
       "   'abstract': None,\n",
       "   'year': 1970,\n",
       "   'referenceCount': 11,\n",
       "   'citationCount': 3890,\n",
       "   'influentialCitationCount': 446,\n",
       "   'fieldsOfStudy': ['Computer Science'],\n",
       "   'authors': [{'authorId': '2587310', 'name': 'R. Rockafellar'}]},\n",
       "  {'paperId': '88e83776313effc1564044d7bf19972981815e3c',\n",
       "   'abstract': 'Recent work has shown how to embed differentiable optimization problems (that is, problems whose solutions can be backpropagated through) as layers within deep learning architectures. This method provides a useful inductive bias for certain problems, but existing software for differentiable optimization layers is rigid and difficult to apply to new settings. In this paper, we propose an approach to differentiating through disciplined convex programs, a subclass of convex optimization problems used by domain-specific languages (DSLs) for convex optimization. We introduce disciplined parametrized programming, a subset of disciplined convex programming, and we show that every disciplined parametrized program can be represented as the composition of an affine map from parameters to problem data, a solver, and an affine map from the solver’s solution to a solution of the original problem (a new form we refer to as affine-solver-affine form). We then demonstrate how to efficiently differentiate through each of these components, allowing for end-to-end analytical differentiation through the entire convex program. We implement our methodology in version 1.1 of CVXPY, a popular Python-embedded DSL for convex optimization, and additionally implement differentiable layers for disciplined convex programs in PyTorch and TensorFlow 2.0. Our implementation significantly lowers the barrier to using convex optimization problems in differentiable programs. We present applications in linear machine learning models and in stochastic control, and we show that our layer is competitive (in execution time) compared to specialized differentiable solvers from past work.',\n",
       "   'year': 2019,\n",
       "   'referenceCount': 83,\n",
       "   'citationCount': 143,\n",
       "   'influentialCitationCount': 23,\n",
       "   'fieldsOfStudy': ['Computer Science', 'Mathematics'],\n",
       "   'authors': [{'authorId': '1945142', 'name': 'Akshay Agrawal'},\n",
       "    {'authorId': '1773498', 'name': 'Brandon Amos'},\n",
       "    {'authorId': '3379664', 'name': 'Shane T. Barratt'},\n",
       "    {'authorId': '1843103', 'name': 'Stephen P. Boyd'},\n",
       "    {'authorId': '2039713286', 'name': 'Steven Diamond'},\n",
       "    {'authorId': '145116464', 'name': 'J. Z. Kolter'}]},\n",
       "  {'paperId': '36632b6ea5ea553d7e48d5f342182650d58cc79d',\n",
       "   'abstract': 'We consider a problem of considerable practical interest: the recovery of a data matrix from a sampling of its entries. Suppose that we observe m entries selected uniformly at random from a matrix M. Can we complete the matrix and recover the entries that we have not seen?We show that one can perfectly recover most low-rank matrices from what appears to be an incomplete set of entries. We prove that if the number m of sampled entries obeys $$m\\\\ge C\\\\,n^{1.2}r\\\\log n$$ for some positive numerical constant C, then with very high probability, most n×n matrices of rank r can be perfectly recovered by solving a simple convex optimization program. This program finds the matrix with minimum nuclear norm that fits the data. The condition above assumes that the rank is not too large. However, if one replaces the 1.2 exponent with 1.25, then the result holds for all values of the rank. Similar results hold for arbitrary rectangular matrices as well. Our results are connected with the recent literature on compressed sensing, and show that objects other than signals and images can be perfectly reconstructed from very limited information.',\n",
       "   'year': 2009,\n",
       "   'referenceCount': 35,\n",
       "   'citationCount': 2710,\n",
       "   'influentialCitationCount': 273,\n",
       "   'fieldsOfStudy': ['Mathematics', 'Computer Science'],\n",
       "   'authors': [{'authorId': '2006869', 'name': 'E. Candès'},\n",
       "    {'authorId': '9229182', 'name': 'B. Recht'}]},\n",
       "  {'paperId': 'f9c2ece8262f9dcf4ec176799e88e51adb1fd052',\n",
       "   'abstract': 'We consider neural networks with a single hidden layer and non-decreasing homogeneous activa-tion functions like the rectified linear units. By letting the number of hidden units grow unbounded and using classical non-Euclidean regularization tools on the output weights, we provide a detailed theoretical analysis of their generalization performance, with a study of both the approximation and the estimation errors. We show in particular that they are adaptive to unknown underlying linear structures, such as the dependence on the projection of the input variables onto a low-dimensional subspace. Moreover, when using sparsity-inducing norms on the input weights, we show that high-dimensional non-linear variable selection may be achieved, without any strong assumption regarding the data and with a total number of variables potentially exponential in the number of ob-servations. In addition, we provide a simple geometric interpretation to the non-convex problem of addition of a new unit, which is the core potentially hard computational element in the framework of learning from continuously many basis functions. We provide simple conditions for convex relaxations to achieve the same generalization error bounds, even when constant-factor approxi-mations cannot be found (e.g., because it is NP-hard such as for the zero-homogeneous activation function). We were not able to find strong enough convex relaxations and leave open the existence or non-existence of polynomial-time algorithms.',\n",
       "   'year': 2017,\n",
       "   'referenceCount': 113,\n",
       "   'citationCount': 389,\n",
       "   'influentialCitationCount': 64,\n",
       "   'fieldsOfStudy': ['Computer Science', 'Mathematics'],\n",
       "   'authors': [{'authorId': '144570279', 'name': 'F. Bach'}]},\n",
       "  {'paperId': 'e177365c0dd642341469ba2f045405646c5dbb79',\n",
       "   'abstract': 'CVXPY is a domain-specific language for convex optimization embedded in Python. It allows the user to express convex optimization problems in a natural syntax that follows the math, rather than in the restrictive standard form required by solvers. CVXPY makes it easy to combine convex optimization with high-level features of Python such as parallelism and object-oriented design. CVXPY is available at http://www.cvxpy.org/ under the GPL license, along with documentation and examples.',\n",
       "   'year': 2016,\n",
       "   'referenceCount': 26,\n",
       "   'citationCount': 919,\n",
       "   'influentialCitationCount': 98,\n",
       "   'fieldsOfStudy': ['Computer Science', 'Mathematics', 'Medicine'],\n",
       "   'authors': [{'authorId': '2039713286', 'name': 'Steven Diamond'},\n",
       "    {'authorId': '1843103', 'name': 'Stephen P. Boyd'}]},\n",
       "  {'paperId': 'd4e61eb8656b6b1aedd8f32c7eef4ae807d162ed',\n",
       "   'abstract': 'This monograph portrays optimization as a process. In many practical applications the environment is so complex that it is infeasible to lay out a comprehensive theoretical model and use classical algorithmic theory and mathematical optimization. It is necessary as well as beneficial to take a robust approach, by applying an optimization method that learns as one goes along, learning from experience as more aspects of the problem are observed. This view of optimization as a process has become prominent in varied fields and has led to some spectacular success in modeling and systems that are now part of our daily lives.',\n",
       "   'year': 2016,\n",
       "   'referenceCount': 111,\n",
       "   'citationCount': 913,\n",
       "   'influentialCitationCount': 149,\n",
       "   'fieldsOfStudy': ['Computer Science', 'Mathematics'],\n",
       "   'authors': [{'authorId': '34840427', 'name': 'Elad Hazan'}]},\n",
       "  {'paperId': '8d3a318b62d2e970122da35b2a2e70a5d12cc16f',\n",
       "   'abstract': None,\n",
       "   'year': 1983,\n",
       "   'referenceCount': 0,\n",
       "   'citationCount': 2873,\n",
       "   'influentialCitationCount': 412,\n",
       "   'fieldsOfStudy': ['Biology'],\n",
       "   'authors': [{'authorId': '143676697', 'name': 'Y. Nesterov'}]},\n",
       "  {'paperId': '065c019bb27e23ed10492ca61b186eb9375dd5de',\n",
       "   'abstract': 'IX. Inner Construction of the Subdifferential.- X. Conjugacy in Convex Analysis.- XI. Approximate Subdifferentials of Convex Functions.- XII. Abstract Duality for Practitioners.- XIII. Methods of ?-Descent.- XIV. Dynamic Construction of Approximate Subdifferentials: Dual Form of Bundle Methods.- XV. Acceleration of the Cutting-Plane Algorithm: Primal Forms of Bundle Methods.- Bibliographical Comments.- References.',\n",
       "   'year': 1993,\n",
       "   'referenceCount': 0,\n",
       "   'citationCount': 2904,\n",
       "   'influentialCitationCount': 207,\n",
       "   'fieldsOfStudy': ['Mathematics'],\n",
       "   'authors': [{'authorId': '102835246', 'name': 'J. Hiriart-Urruty'},\n",
       "    {'authorId': '8773884', 'name': 'C. Lemaréchal'}]},\n",
       "  {'paperId': '4b4258c48d4ea4897b35671ee39538ca86848871',\n",
       "   'abstract': \"This monograph presents the main complexity theorems in convex optimization and their corresponding algorithms. Starting from the fundamental theory of black-box optimization, the material progresses towards recent advances in structural optimization and stochastic optimization. Our presentation of black-box optimization, strongly influenced by Nesterov's seminal book and Nemirovski's lecture notes, includes the analysis of cutting plane methods, as well as (accelerated) gradient descent schemes. We also pay special attention to non-Euclidean settings (relevant algorithms include Frank-Wolfe, mirror descent, and dual averaging) and discuss their relevance in machine learning. We provide a gentle introduction to structural optimization with FISTA (to optimize a sum of a smooth and a simple non-smooth term), saddle-point mirror prox (Nemirovski's alternative to Nesterov's smoothing), and a concise description of interior point methods. In stochastic optimization we discuss stochastic gradient descent, mini-batches, random coordinate descent, and sublinear algorithms. We also briefly touch upon convex relaxation of combinatorial problems and the use of randomness to round solutions, as well as random walks based methods.\",\n",
       "   'year': 2015,\n",
       "   'referenceCount': 93,\n",
       "   'citationCount': 1066,\n",
       "   'influentialCitationCount': 110,\n",
       "   'fieldsOfStudy': ['Computer Science', 'Mathematics'],\n",
       "   'authors': [{'authorId': '1815542', 'name': 'Sébastien Bubeck'}]},\n",
       "  {'paperId': 'b85be4c3b00302f43e647471e5d04fdba909acb7',\n",
       "   'abstract': 'We investigate the convex–concave procedure, a local heuristic that utilizes the tools of convex optimization to find local optima of difference of convex (DC) programming problems. The class of DC problems includes many difficult problems such as the traveling salesman problem. We extend the standard procedure in two major ways and describe several variations. First, we allow for the algorithm to be initialized without a feasible point. Second, we generalize the algorithm to include vector inequalities. We then present several examples to demonstrate these algorithms.',\n",
       "   'year': 2016,\n",
       "   'referenceCount': 140,\n",
       "   'citationCount': 376,\n",
       "   'influentialCitationCount': 76,\n",
       "   'fieldsOfStudy': ['Mathematics'],\n",
       "   'authors': [{'authorId': '153464383', 'name': 'Thomas Lipp'},\n",
       "    {'authorId': '1843103', 'name': 'Stephen P. Boyd'}]},\n",
       "  {'paperId': '961eabeaebd7035cd7668c9917fa9c39462e1113',\n",
       "   'abstract': 'We provide stronger and more general primal-dual convergence results for Frank-Wolfe-type algorithms (a.k.a. conditional gradient) for constrained convex optimization, enabled by a simple framework of duality gap certificates. Our analysis also holds if the linear subproblems are only solved approximately (as well as if the gradients are inexact), and is proven to be worst-case optimal in the sparsity of the obtained solutions. \\n \\nOn the application side, this allows us to unify a large variety of existing sparse greedy methods, in particular for optimization over convex hulls of an atomic set, even if those sets can only be approximated, including sparse (or structured sparse) vectors or matrices, low-rank matrices, permutation matrices, or max-norm bounded matrices. \\n \\nWe present a new general framework for convex optimization over matrix factorizations, where every Frank-Wolfe iteration will consist of a low-rank update, and discuss the broad application areas of this approach.',\n",
       "   'year': 2013,\n",
       "   'referenceCount': 59,\n",
       "   'citationCount': 918,\n",
       "   'influentialCitationCount': 175,\n",
       "   'fieldsOfStudy': ['Mathematics', 'Computer Science'],\n",
       "   'authors': [{'authorId': '2456863', 'name': 'Martin Jaggi'}]},\n",
       "  {'paperId': 'bcce96a2a074448953fc61a29a84afbdfc8db55a',\n",
       "   'abstract': 'Online learning is a well established learning paradigm which has both theoretical and practical appeals. The goal of online learning is to make a sequence of accurate predictions given knowledge of the correct answer to previous prediction tasks and possibly additional available information. Online learning has been studied in several research fields including game theory, information theory, and machine learning. It also became of great interest to practitioners due the recent emergence of large scale applications such as online advertisement placement and online web ranking. In this survey we provide a modern overview of online learning. Our goal is to give the reader a sense of some of the interesting ideas and in particular to underscore the centrality of convexity in deriving efficient online learning algorithms. We do not mean to be comprehensive but rather to give a high-level, rigorous yet easy to follow, survey.',\n",
       "   'year': 2012,\n",
       "   'referenceCount': 48,\n",
       "   'citationCount': 1429,\n",
       "   'influentialCitationCount': 180,\n",
       "   'fieldsOfStudy': ['Computer Science'],\n",
       "   'authors': [{'authorId': '1389955537', 'name': 'S. Shalev-Shwartz'}]},\n",
       "  {'paperId': 'be2f5d8a7e6b415f1e22cee7dfd9be56b1afd8be',\n",
       "   'abstract': 'Abstract: Several recent publications have proposed methods for mapping images into continuous semantic embedding spaces. In some cases the embedding space is trained jointly with the image transformation. In other cases the semantic embedding space is established by an independent natural language processing task, and then the image transformation into that space is learned in a second stage. Proponents of these image embedding systems have stressed their advantages over the traditional \\\\nway{} classification framing of image understanding, particularly in terms of the promise for zero-shot learning -- the ability to correctly annotate images of previously unseen object categories. In this paper, we propose a simple method for constructing an image embedding system from any existing \\\\nway{} image classifier and a semantic word embedding model, which contains the $\\\\n$ class labels in its vocabulary. Our method maps images into the semantic embedding space via convex combination of the class label embedding vectors, and requires no additional training. We show that this simple and direct method confers many of the advantages associated with more complex image embedding schemes, and indeed outperforms state of the art methods on the ImageNet zero-shot learning task.',\n",
       "   'year': 2014,\n",
       "   'referenceCount': 20,\n",
       "   'citationCount': 725,\n",
       "   'influentialCitationCount': 116,\n",
       "   'fieldsOfStudy': ['Computer Science'],\n",
       "   'authors': [{'authorId': '144739074', 'name': 'Mohammad Norouzi'},\n",
       "    {'authorId': '2047446108', 'name': 'Tomas Mikolov'},\n",
       "    {'authorId': '1751569', 'name': 'Samy Bengio'},\n",
       "    {'authorId': '1740765', 'name': 'Y. Singer'},\n",
       "    {'authorId': '1789737', 'name': 'Jonathon Shlens'},\n",
       "    {'authorId': '2279670', 'name': 'Andrea Frome'},\n",
       "    {'authorId': '32131713', 'name': 'G. Corrado'},\n",
       "    {'authorId': '49959210', 'name': 'J. Dean'}]},\n",
       "  {'paperId': '981ce6b655cc06416ff6bf7fac8c6c2076fd7fac',\n",
       "   'abstract': 'A central challenge to many fields of science and engineering involves minimizing non-convex error functions over continuous, high dimensional spaces. Gradient descent or quasi-Newton methods are almost ubiquitously used to perform such minimizations, and it is often thought that a main source of difficulty for these local methods to find the global minimum is the proliferation of local minima with much higher error than the global minimum. Here we argue, based on results from statistical physics, random matrix theory, neural network theory, and empirical evidence, that a deeper and more profound difficulty originates from the proliferation of saddle points, not local minima, especially in high dimensional problems of practical interest. Such saddle points are surrounded by high error plateaus that can dramatically slow down learning, and give the illusory impression of the existence of a local minimum. Motivated by these arguments, we propose a new approach to second-order optimization, the saddle-free Newton method, that can rapidly escape high dimensional saddle points, unlike gradient descent and quasi-Newton methods. We apply this algorithm to deep or recurrent neural network training, and provide numerical evidence for its superior optimization performance.',\n",
       "   'year': 2014,\n",
       "   'referenceCount': 34,\n",
       "   'citationCount': 991,\n",
       "   'influentialCitationCount': 66,\n",
       "   'fieldsOfStudy': ['Computer Science', 'Mathematics'],\n",
       "   'authors': [{'authorId': '2921469', 'name': 'Yann Dauphin'},\n",
       "    {'authorId': '1996134', 'name': 'Razvan Pascanu'},\n",
       "    {'authorId': '1854385', 'name': 'Çaglar Gülçehre'},\n",
       "    {'authorId': '1979489', 'name': 'Kyunghyun Cho'},\n",
       "    {'authorId': '25769960', 'name': 'S. Ganguli'},\n",
       "    {'authorId': '1751762', 'name': 'Yoshua Bengio'}]},\n",
       "  {'paperId': 'a0bcc10ad9afd8c6310917b355799358b632e464',\n",
       "   'abstract': 'We consider the fundamental problem in non-convex optimization of efficiently reaching a stationary point. In contrast to the convex case, in the long history of this basic problem, the only known theoretical results on first-order non-convex optimization remain to be full gradient descent that converges in $O(1/\\\\varepsilon)$ iterations for smooth objectives, and stochastic gradient descent that converges in $O(1/\\\\varepsilon^2)$ iterations for objectives that are sum of smooth functions. \\nWe provide the first improvement in this line of research. Our result is based on the variance reduction trick recently introduced to convex optimization, as well as a brand new analysis of variance reduction that is suitable for non-convex optimization. For objectives that are sum of smooth functions, our first-order minibatch stochastic method converges with an $O(1/\\\\varepsilon)$ rate, and is faster than full gradient descent by $\\\\Omega(n^{1/3})$. \\nWe demonstrate the effectiveness of our methods on empirical risk minimizations with non-convex loss functions and training neural nets.',\n",
       "   'year': 2016,\n",
       "   'referenceCount': 42,\n",
       "   'citationCount': 310,\n",
       "   'influentialCitationCount': 46,\n",
       "   'fieldsOfStudy': ['Mathematics', 'Computer Science'],\n",
       "   'authors': [{'authorId': '13319052', 'name': 'Z. Zhu'},\n",
       "    {'authorId': '34840427', 'name': 'Elad Hazan'}]},\n",
       "  {'paperId': '82c5d56fb0f4aef16766bdf99c4ad0d81aa86ccf',\n",
       "   'abstract': 'Automatic detection and segmentation of cells and nuclei in microscopy images is important for many biological applications. Recent successful learning-based approaches include per-pixel cell segmentation with subsequent pixel grouping, or localization of bounding boxes with subsequent shape refinement. In situations of crowded cells, these can be prone to segmentation errors, such as falsely merging bordering cells or suppressing valid cell instances due to the poor approximation with bounding boxes. To overcome these issues, we propose to localize cell nuclei via star-convex polygons, which are a much better shape representation as compared to bounding boxes and thus do not need shape refinement. To that end, we train a convolutional neural network that predicts for every pixel a polygon for the cell instance at that position. We demonstrate the merits of our approach on two synthetic datasets and one challenging dataset of diverse fluorescence microscopy images.',\n",
       "   'year': 2018,\n",
       "   'referenceCount': 21,\n",
       "   'citationCount': 185,\n",
       "   'influentialCitationCount': 23,\n",
       "   'fieldsOfStudy': ['Computer Science'],\n",
       "   'authors': [{'authorId': '152732433', 'name': 'Uwe Schmidt'},\n",
       "    {'authorId': '49233880', 'name': 'Martin Weigert'},\n",
       "    {'authorId': '31999740', 'name': 'Coleman Broaddus'},\n",
       "    {'authorId': '2145910', 'name': 'E. Myers'}]},\n",
       "  {'paperId': '7580ff1d8e57b6d41e16e2579e5f1fdff2358f76',\n",
       "   'abstract': '1. Basic convexity 2. Boundary structure 3. Minkowski addition 4. Curvature measure and quermass integrals 5. Mixed volumes 6. Inequalities for mixed volumes 7. Selected applications Appendix.',\n",
       "   'year': 1993,\n",
       "   'referenceCount': 825,\n",
       "   'citationCount': 2547,\n",
       "   'influentialCitationCount': 263,\n",
       "   'fieldsOfStudy': ['Mathematics'],\n",
       "   'authors': [{'authorId': '145371164', 'name': 'R. Schneider'}]},\n",
       "  {'paperId': 'f740bd6e5614f151cd1ad1f408c496963138a196',\n",
       "   'abstract': 'The alternating direction method of multipliers (ADMM) is now widely used in many fields, and its convergence was proved when two blocks of variables are alternatively updated. It is strongly desirable and practically valuable to extend the ADMM directly to the case of a multi-block convex minimization problem where its objective function is the sum of more than two separable convex functions. However, the convergence of this extension has been missing for a long time—neither an affirmative convergence proof nor an example showing its divergence is known in the literature. In this paper we give a negative answer to this long-standing open question: The direct extension of ADMM is not necessarily convergent. We present a sufficient condition to ensure the convergence of the direct extension of ADMM, and give an example to show its divergence.',\n",
       "   'year': 2016,\n",
       "   'referenceCount': 36,\n",
       "   'citationCount': 466,\n",
       "   'influentialCitationCount': 28,\n",
       "   'fieldsOfStudy': ['Mathematics', 'Computer Science'],\n",
       "   'authors': [{'authorId': '9191464', 'name': 'Caihua Chen'},\n",
       "    {'authorId': '120731519', 'name': 'B. He'},\n",
       "    {'authorId': '145185457', 'name': 'Y. Ye'},\n",
       "    {'authorId': '145802386', 'name': 'Xiaoming Yuan'}]},\n",
       "  {'paperId': '4894805f9d7bdb3ce39797ff483357613faddf1f',\n",
       "   'abstract': 'In applications throughout science and engineering one is often faced with the challenge of solving an ill-posed inverse problem, where the number of available measurements is smaller than the dimension of the model to be estimated. However in many practical situations of interest, models are constrained structurally so that they only have a few degrees of freedom relative to their ambient dimension. This paper provides a general framework to convert notions of simplicity into convex penalty functions, resulting in convex optimization solutions to linear, underdetermined inverse problems. The class of simple models considered includes those formed as the sum of a few atoms from some (possibly infinite) elementary atomic set; examples include well-studied cases from many technical fields such as sparse vectors (signal processing, statistics) and low-rank matrices (control, statistics), as well as several others including sums of a few permutation matrices (ranked elections, multiobject tracking), low-rank tensors (computer vision, neuroscience), orthogonal matrices (machine learning), and atomic measures (system identification). The convex programming formulation is based on minimizing the norm induced by the convex hull of the atomic set; this norm is referred to as the atomic norm. The facial structure of the atomic norm ball carries a number of favorable properties that are useful for recovering simple models, and an analysis of the underlying convex geometry provides sharp estimates of the number of generic measurements required for exact and robust recovery of models from partial information. These estimates are based on computing the Gaussian widths of tangent cones to the atomic norm ball. When the atomic set has algebraic structure the resulting optimization problems can be solved or approximated via semidefinite programming. The quality of these approximations affects the number of measurements required for recovery, and this tradeoff is characterized via some examples. Thus this work extends the catalog of simple models (beyond sparse vectors and low-rank matrices) that can be recovered from limited linear information via tractable convex programming.',\n",
       "   'year': 2012,\n",
       "   'referenceCount': 124,\n",
       "   'citationCount': 1149,\n",
       "   'influentialCitationCount': 140,\n",
       "   'fieldsOfStudy': ['Mathematics', 'Computer Science'],\n",
       "   'authors': [{'authorId': '1728994', 'name': 'V. Chandrasekaran'},\n",
       "    {'authorId': '9229182', 'name': 'B. Recht'},\n",
       "    {'authorId': '1731770', 'name': 'P. Parrilo'},\n",
       "    {'authorId': '1701607', 'name': 'A. Willsky'}]},\n",
       "  {'paperId': '749f3f9a40218c9daf4d3767c79e34a20e62da3c',\n",
       "   'abstract': 'This paper presents the input convex neural network architecture. These are scalar-valued (potentially deep) neural networks with constraints on the network parameters such that the output of the network is a convex function of (some of) the inputs. The networks allow for efficient inference via optimization over some inputs to the network given others, and can be applied to settings including structured prediction, data imputation, reinforcement learning, and others. In this paper we lay the basic groundwork for these models, proposing methods for inference, optimization and learning, and analyze their representational power. We show that many existing neural network architectures can be made input-convex with a minor modification, and develop specialized optimization algorithms tailored to this setting. Finally, we highlight the performance of the methods on multi-label prediction, image completion, and reinforcement learning problems, where we show improvement over the existing state of the art in many cases.',\n",
       "   'year': 2017,\n",
       "   'referenceCount': 56,\n",
       "   'citationCount': 148,\n",
       "   'influentialCitationCount': 40,\n",
       "   'fieldsOfStudy': ['Computer Science', 'Mathematics'],\n",
       "   'authors': [{'authorId': '1773498', 'name': 'Brandon Amos'},\n",
       "    {'authorId': '2112280294', 'name': 'Lei Xu'},\n",
       "    {'authorId': '145116464', 'name': 'J. Z. Kolter'}]},\n",
       "  {'paperId': '6d07eec4d28ba277cfca3949157c0bcd3587e813',\n",
       "   'abstract': 'We study convex optimization problems for which the data is not specified exactly and it is only known to belong to a given uncertainty set U, yet the constraints must hold for all possible values of the data from U. The ensuing optimization problem is called robust optimization. In this paper we lay the foundation of robust convex optimization. In the main part of the paper we show that if U is an ellipsoidal uncertainty set, then for some of the most important generic convex optimization problems (linear programming, quadratically constrained programming, semidefinite programming and others) the corresponding robust convex program is either exactly, or approximately, a tractable problem which lends itself to efficientalgorithms such as polynomial time interior point methods.',\n",
       "   'year': 1998,\n",
       "   'referenceCount': 21,\n",
       "   'citationCount': 2312,\n",
       "   'influentialCitationCount': 204,\n",
       "   'fieldsOfStudy': ['Mathematics', 'Computer Science'],\n",
       "   'authors': [{'authorId': '73484911', 'name': 'A. Ben-Tal'},\n",
       "    {'authorId': '145853268', 'name': 'A. Nemirovski'}]},\n",
       "  {'paperId': 'f1ffa948988c6c2a66796ec4033fa8a8188756c7',\n",
       "   'abstract': 'We describe graph implementations, a generic method for representing a convex function via its epigraph, described in a disciplined convex programming framework. This simple and natural idea allows a very wide variety of smooth and nonsmooth convex programs to be easily specified and efficiently solved, using interiorpoint methods for smooth or cone convex programs.',\n",
       "   'year': 2008,\n",
       "   'referenceCount': 31,\n",
       "   'citationCount': 2394,\n",
       "   'influentialCitationCount': 143,\n",
       "   'fieldsOfStudy': ['Mathematics', 'Computer Science'],\n",
       "   'authors': [{'authorId': '2057061460', 'name': 'Michael Grant'},\n",
       "    {'authorId': '1843103', 'name': 'Stephen P. Boyd'}]},\n",
       "  {'paperId': 'e46be7cb12666e6e161f2a176778b2d676750bbc',\n",
       "   'abstract': 'Whereas the upper bound lemma for matrix cross-product, introduced by Park (1999) and modified by Moon, Park, Kwon, and Lee (2001), plays a key role in guiding various delay-dependent criteria for delayed systems, the Jensen inequality has become an alternative as a way of reducing the number of decision variables. It directly relaxes the integral term of quadratic quantities into the quadratic term of the integral quantities, resulting in a linear combination of positive functions weighted by the inverses of convex parameters. This paper suggests the lower bound lemma for such a combination, which achieves performance behavior identical to approaches based on the integral inequality lemma but with much less decision variables, comparable to those based on the Jensen inequality lemma.',\n",
       "   'year': 2011,\n",
       "   'referenceCount': 11,\n",
       "   'citationCount': 1856,\n",
       "   'influentialCitationCount': 86,\n",
       "   'fieldsOfStudy': ['Computer Science', 'Mathematics'],\n",
       "   'authors': [{'authorId': '144548016', 'name': 'P. Park'},\n",
       "    {'authorId': '2902376', 'name': 'J. Ko'},\n",
       "    {'authorId': '2307322', 'name': 'C. Jeong'}]},\n",
       "  {'paperId': '492cc64f9dd578aa76d4ca5b14b45f2e85ae9f1c',\n",
       "   'abstract': 'This paper is concerned with stability of a linear system with a time-varying delay. First, an optimal reciprocally convex inequality is proposed. Compared with the extended reciprocally convex inequality recently reported, the optimal reciprocally convex inequality not only provides an optimal bound for the reciprocally convex combination, but also introduces less slack matrix variables. Second, a new Lyapunov-Krasovskii functional is tailored for the use of auxiliary function-based integral inequality. Third, based on the optimal reciprocally convex inequality and the new Lyapunov-Krasovskii functional, a stability criterion is derived for the system under study. Finally, two well-studied numerical examples are given to show that the obtained stability criterion can produce a larger upper bound of the time-varying delay than some existing methods.',\n",
       "   'year': 2017,\n",
       "   'referenceCount': 20,\n",
       "   'citationCount': 243,\n",
       "   'influentialCitationCount': 7,\n",
       "   'fieldsOfStudy': ['Mathematics', 'Computer Science'],\n",
       "   'authors': [{'authorId': '1731423', 'name': 'Xian-Ming Zhang'},\n",
       "    {'authorId': '145192086', 'name': 'Q. Han'},\n",
       "    {'authorId': '1746472', 'name': 'A. Seuret'},\n",
       "    {'authorId': '2404606', 'name': 'F. Gouaisbaut'}]},\n",
       "  {'paperId': 'e3c9a2b515f90e233d1474cf6666111fd9a2e735',\n",
       "   'abstract': 'Min-max saddle-point problems have broad applications in many tasks in machine learning, e.g., distributionally robust learning, learning with non-decomposable loss, or learning with uncertain data. Although convex-concave saddle-point problems have been broadly studied with efficient algorithms and solid theories available, it remains a challenge to design provably efficient algorithms for non-convex saddle-point problems, especially when the objective function involves an expectation or a large-scale finite sum. Motivated by recent literature on non-convex non-smooth minimization, this paper studies a family of non-convex min-max problems where the minimization component is non-convex (weakly convex) and the maximization component is concave. We propose a proximally guided stochastic subgradient method and a proximally guided stochastic variance-reduced method for expected and finite-sum saddle-point problems, respectively. We establish the computation complexities of both methods for finding a nearly stationary point of the corresponding minimization problem.',\n",
       "   'year': 2018,\n",
       "   'referenceCount': 47,\n",
       "   'citationCount': 118,\n",
       "   'influentialCitationCount': 11,\n",
       "   'fieldsOfStudy': ['Mathematics', 'Computer Science'],\n",
       "   'authors': [{'authorId': '34165881', 'name': 'Hassan Rafique'},\n",
       "    {'authorId': '14697929', 'name': 'Mingrui Liu'},\n",
       "    {'authorId': '39436683', 'name': 'Qihang Lin'},\n",
       "    {'authorId': '40381920', 'name': 'Tianbao Yang'}]},\n",
       "  {'paperId': 'e064fbf15b96ea5f6ce53e83a18bf571bcca8f75',\n",
       "   'abstract': 'This tutorial summarizes recent advances in the convex relaxation of the optimal power flow (OPF) problem, focusing on structural properties rather than algorithms. Part I presents two power flow models, formulates OPF and their relaxations in each model, and proves equivalence relationships among them. Part II presents sufficient conditions under which the convex relaxations are exact.',\n",
       "   'year': 2014,\n",
       "   'referenceCount': 138,\n",
       "   'citationCount': 623,\n",
       "   'influentialCitationCount': 34,\n",
       "   'fieldsOfStudy': ['Mathematics', 'Computer Science'],\n",
       "   'authors': [{'authorId': '36255406', 'name': 'S. Low'}]},\n",
       "  {'paperId': 'e1f153c6df86d1ca8ecb9561daddfe7a54f901e7',\n",
       "   'abstract': 'Convex programming involves a convex set F ⊆ Rn and a convex cost function c : F → R. The goal of convex programming is to find a point in F which minimizes c. In online convex programming, the convex set is known in advance, but in each step of some repeated optimization problem, one must select a point in F before seeing the cost function for that step. This can be used to model factory production, farm production, and many other industrial optimization problems where one is unaware of the value of the items produced until they have already been constructed. We introduce an algorithm for this domain. We also apply this algorithm to repeated games, and show that it is really a generalization of infinitesimal gradient ascent, and the results here imply that generalized infinitesimal gradient ascent (GIGA) is universally consistent.',\n",
       "   'year': 2003,\n",
       "   'referenceCount': 35,\n",
       "   'citationCount': 1818,\n",
       "   'influentialCitationCount': 314,\n",
       "   'fieldsOfStudy': ['Mathematics', 'Computer Science'],\n",
       "   'authors': [{'authorId': '8195063', 'name': 'Martin A. Zinkevich'}]},\n",
       "  {'paperId': '4bea655156a6d97f224995f55feb23e5e26dd92c',\n",
       "   'abstract': 'We present a new optimization-based approach for robotic motion planning among obstacles. Like CHOMP (Covariant Hamiltonian Optimization for Motion Planning), our algorithm can be used to find collision-free trajectories from naïve, straight-line initializations that might be in collision. At the core of our approach are (a) a sequential convex optimization procedure, which penalizes collisions with a hinge loss and increases the penalty coefficients in an outer loop as necessary, and (b) an efficient formulation of the no-collisions constraint that directly considers continuous-time safety Our algorithm is implemented in a software package called TrajOpt. We report results from a series of experiments comparing TrajOpt with CHOMP and randomized planners from OMPL, with regard to planning time and path quality. We consider motion planning for 7 DOF robot arms, 18 DOF full-body robots, statically stable walking motion for the 34 DOF Atlas humanoid robot, and physical experiments with the 18 DOF PR2. We also apply TrajOpt to plan curvature-constrained steerable needle trajectories in the SE(3) configuration space and multiple non-intersecting curved channels within 3D-printed implants for intracavitary brachytherapy. Details, videos, and source code are freely available at: http://rll.berkeley.edu/trajopt/ijrr.',\n",
       "   'year': 2014,\n",
       "   'referenceCount': 90,\n",
       "   'citationCount': 427,\n",
       "   'influentialCitationCount': 41,\n",
       "   'fieldsOfStudy': ['Mathematics', 'Computer Science'],\n",
       "   'authors': [{'authorId': '47971768', 'name': 'J. Schulman'},\n",
       "    {'authorId': '144581158', 'name': 'Yan Duan'},\n",
       "    {'authorId': '2126278', 'name': 'Jonathan Ho'},\n",
       "    {'authorId': '49250083', 'name': 'Alex X. Lee'},\n",
       "    {'authorId': '2895536', 'name': 'I. Awwal'},\n",
       "    {'authorId': '50168717', 'name': 'H. Bradlow'},\n",
       "    {'authorId': '143938045', 'name': 'Jia Pan'},\n",
       "    {'authorId': '144057564', 'name': 'S. Patil'},\n",
       "    {'authorId': '144344283', 'name': 'Ken Goldberg'},\n",
       "    {'authorId': '1689992', 'name': 'P. Abbeel'}]},\n",
       "  {'paperId': 'ef6008a4385e21aabda61daf7c5a1c075c08c860',\n",
       "   'abstract': 'c 2015 Dimitri P. Bertsekas All rights reserved. No part of this book may be reproduced in any form by any electronic or mechanical means (including photocopying, recording, or information storage and retrieval) without permission in writing from the publisher.',\n",
       "   'year': 2015,\n",
       "   'referenceCount': 12,\n",
       "   'citationCount': 475,\n",
       "   'influentialCitationCount': 41,\n",
       "   'fieldsOfStudy': ['Computer Science'],\n",
       "   'authors': [{'authorId': '1786249', 'name': 'D. Bertsekas'}]},\n",
       "  {'paperId': '013545b0ab886f6a9b47c19737e1c80273fda6b5',\n",
       "   'abstract': \"This is a book devoted to well-structured and thus efficiently solvable convex optimization problems, with emphasis on conic quadratic and semidefinite programming. The authors present the basic theory underlying these problems as well as their numerous applications in engineering, including synthesis of filters, Lyapunov stability analysis, and structural design. The authors also discuss the complexity issues and provide an overview of the basic theory of state-of-the-art polynomial time interior point methods for linear, conic quadratic, and semidefinite programming. The book's focus on well-structured convex problems in conic form allows for unified theoretical and algorithmical treatment of a wide spectrum of important optimization problems arising in applications.\",\n",
       "   'year': 2001,\n",
       "   'referenceCount': 18,\n",
       "   'citationCount': 2169,\n",
       "   'influentialCitationCount': 190,\n",
       "   'fieldsOfStudy': ['Computer Science', 'Mathematics'],\n",
       "   'authors': [{'authorId': '73484911', 'name': 'A. Ben-Tal'},\n",
       "    {'authorId': '145853268', 'name': 'A. Nemirovski'}]},\n",
       "  {'paperId': 'c369d9192c9754fb7a04529c68f2fb286f646df7',\n",
       "   'abstract': 'This paper is concerned with the problem of recovering an unknown matrix from a small fraction of its entries. This is known as the matrix completion problem, and comes up in a great number of applications, including the famous Netflix Prize and other similar questions in collaborative filtering. In general, accurate recovery of a matrix from a small number of entries is impossible, but the knowledge that the unknown matrix has low rank radically changes this premise, making the search for solutions meaningful. This paper presents optimality results quantifying the minimum number of entries needed to recover a matrix of rank r exactly by any method whatsoever (the information theoretic limit). More importantly, the paper shows that, under certain incoherence assumptions on the singular vectors of the matrix, recovery is possible by solving a convenient convex program as soon as the number of entries is on the order of the information theoretic limit (up to logarithmic factors). This convex program simply finds, among all matrices consistent with the observed entries, that with minimum nuclear norm. As an example, we show that on the order of nr log(n) samples are needed to recover a random n x n matrix of rank r by any method, and to be sure, nuclear norm minimization succeeds as soon as the number of entries is of the form nr polylog(n).',\n",
       "   'year': 2010,\n",
       "   'referenceCount': 33,\n",
       "   'citationCount': 1821,\n",
       "   'influentialCitationCount': 121,\n",
       "   'fieldsOfStudy': ['Mathematics', 'Computer Science'],\n",
       "   'authors': [{'authorId': '2006869', 'name': 'E. Candès'},\n",
       "    {'authorId': '50383069', 'name': 'T. Tao'}]},\n",
       "  {'paperId': '1e4095da22f608499c9b4d94df506cb4f0fa1224',\n",
       "   'abstract': 'This technical note studies the continuous-time distributed optimization of a sum of convex functions over directed graphs. Contrary to what is known in the consensus literature, where the same dynamics works for both undirected and directed scenarios, we show that the consensus-based dynamics that solves the continuous-time distributed optimization problem for undirected graphs fails to converge when transcribed to the directed setting. This study sets the basis for the design of an alternative distributed dynamics which we show is guaranteed to converge, on any strongly connected weight-balanced digraph, to the set of minimizers of a sum of convex differentiable functions with globally Lipschitz gradients. Our technical approach combines notions of invariance and cocoercivity with the positive definiteness properties of graph matrices to establish the results.',\n",
       "   'year': 2014,\n",
       "   'referenceCount': 50,\n",
       "   'citationCount': 451,\n",
       "   'influentialCitationCount': 32,\n",
       "   'fieldsOfStudy': ['Mathematics', 'Computer Science'],\n",
       "   'authors': [{'authorId': '3003034', 'name': 'B. Gharesifard'},\n",
       "    {'authorId': '145576411', 'name': 'J. Cortés'}]},\n",
       "  {'paperId': '635ec717dd165e8f3f8998db5bd8662de30cdaee',\n",
       "   'abstract': \"We describe a modular rewriting system for translating optimization problems written in a domain-specific language to forms compatible with low-level solver interfaces. Translation is facilitated by reductions, which accept a category of problems and transform instances of that category to equivalent instances of another category. Our system proceeds in two key phases: analysis, in which we attempt to find a suitable solver for a supplied problem, and canonicalization, in which we rewrite the problem in the selected solver's standard form. We implement the described system in version 1.0 of CVXPY, a domain-specific language for mathematical and especially convex optimization. By treating reductions as first-class objects, our method makes it easy to match problems to solvers well-suited for them and to support solvers with a wide variety of standard forms.\",\n",
       "   'year': 2017,\n",
       "   'referenceCount': 83,\n",
       "   'citationCount': 226,\n",
       "   'influentialCitationCount': 19,\n",
       "   'fieldsOfStudy': ['Computer Science', 'Mathematics'],\n",
       "   'authors': [{'authorId': '1945142', 'name': 'Akshay Agrawal'},\n",
       "    {'authorId': '50416929', 'name': 'Robin Verschueren'},\n",
       "    {'authorId': '2039713286', 'name': 'Steven Diamond'},\n",
       "    {'authorId': '1843103', 'name': 'Stephen P. Boyd'}]},\n",
       "  {'paperId': '43d1fe40167c5f2ed010c8e06c8e008c774fd22b',\n",
       "   'abstract': 'A vast majority of machine learning algorithms train their models and perform inference by solving optimization problems. In order to capture the learning and prediction problems accurately, structural constraints such as sparsity or low rank are frequently imposed or else the objective itself is designed to be a non-convex function. This is especially true of algorithms that operate in high-dimensional spaces or that train non-linear models such as tensor models and deep networks.  The freedom to express the learning problem as a non-convex optimization problem gives immense modeling power to the algorithm designer, but often such problems are NP-hard to solve.  A popular workaround to this has been to relax non-convex problems to convex ones and use traditional methods to solve the (convex) relaxed optimization problems. However this approach may be lossy and nevertheless presents significant challenges for large scale optimization.  On the other hand, direct approaches to non-convex optimization have met with resounding success in several domains and remain the methods of choice for the practitioner, as they frequently outperform relaxation-based techniques - popular heuristics include projected gradient descent and alternating minimization. However, these are often poorly understood in terms of their convergence and other properties.  This monograph presents a selection of recent advances that bridge a long-standing gap in our understanding of these heuristics. We hope that an insight into the inner workings of these methods will allow the reader to appreciate the unique marriage of task structure and generative models that allow these heuristic techniques to (provably) succeed. The monograph will lead the reader through several widely used non-convex optimization techniques, as well as applications thereof. The goal of this monograph is to both, introduce the rich literature in this area, as well as equip the reader with the tools and techniques needed to analyze these simple procedures for non-convex problems.',\n",
       "   'year': 2017,\n",
       "   'referenceCount': 136,\n",
       "   'citationCount': 222,\n",
       "   'influentialCitationCount': 8,\n",
       "   'fieldsOfStudy': ['Computer Science', 'Mathematics'],\n",
       "   'authors': [{'authorId': '48964143', 'name': 'Prateek Jain'},\n",
       "    {'authorId': '39746893', 'name': 'Purushottam Kar'}]},\n",
       "  {'paperId': '86d439ec4bb3e048c237281eb9754718c700c089',\n",
       "   'abstract': 'In this paper, a distributed optimization problem with general differentiable convex objective functions is studied for continuous-time multi-agent systems with single-integrator dynamics. The objective is for multiple agents to cooperatively optimize a team objective function formed by a sum of local objective functions with only local interaction and information while explicitly taking into account nonuniform gradient gains, finite-time convergence, and a common convex constraint set. First, a distributed nonsmooth algorithm is introduced for a special class of convex objective functions that have a quadratic-like form. It is shown that all agents reach a consensus in finite time while minimizing the team objective function asymptotically. Second, a distributed algorithm is presented for general differentiable convex objective functions, in which the interaction gains of each agent can be self-adjusted based on local states. A corresponding condition is then given to guarantee that all agents reach a consensus in finite time while minimizing the team objective function asymptotically. Third, a distributed optimization algorithm with state-dependent gradient gains is given for general differentiable convex objective functions. It is shown that the distributed continuous-time optimization problem can be solved even though the gradient gains are not identical. Fourth, a distributed tracking algorithm combined with a distributed estimation algorithm is given for general differentiable convex objective functions. It is shown that all agents reach a consensus while minimizing the team objective function in finite time. Fifth, as an extension of the previous results, a distributed constrained optimization algorithm with nonuniform gradient gains and a distributed constrained finite-time optimization algorithm are given. It is shown that both algorithms can be used to solve a distributed continuous-time optimization problem with a common convex constraint set. Numerical examples are included to illustrate the obtained theoretical results.',\n",
       "   'year': 2017,\n",
       "   'referenceCount': 24,\n",
       "   'citationCount': 167,\n",
       "   'influentialCitationCount': 8,\n",
       "   'fieldsOfStudy': ['Mathematics', 'Computer Science'],\n",
       "   'authors': [{'authorId': '145290798', 'name': 'Peng Lin'},\n",
       "    {'authorId': '145805552', 'name': 'W. Ren'},\n",
       "    {'authorId': '50743502', 'name': 'J. Farrell'}]},\n",
       "  {'paperId': '5e4f8d22fd2d7142846a1c4400b0e8a841931eeb',\n",
       "   'abstract': \"This paper proposes a novel class of distributed continuous-time coordination algorithms to solve network optimization problems whose cost function is a sum of local cost functions associated to the individual agents. We establish the exponential convergence of the proposed algorithm under (i) strongly connected and weight-balanced digraph topologies when the local costs are strongly convex with globally Lipschitz gradients, and (ii) connected graph topologies when the local costs are strongly convex with locally Lipschitz gradients. When the local cost functions are convex and the global cost function is strictly convex, we establish asymptotic convergence under connected graph topologies. We also characterize the algorithm's correctness under time-varying interaction topologies and study its privacy preservation properties. Motivated by practical considerations, we analyze the algorithm implementation with discrete-time communication. We provide an upper bound on the stepsize that guarantees exponential convergence over connected graphs for implementations with periodic communication. Building on this result, we design a provably-correct centralized event-triggered communication scheme that is free of Zeno behavior. Finally, we develop a distributed, asynchronous event-triggered communication scheme that is also free of Zeno with asymptotic convergence guarantees. Several simulations illustrate our results.\",\n",
       "   'year': 2015,\n",
       "   'referenceCount': 32,\n",
       "   'citationCount': 354,\n",
       "   'influentialCitationCount': 34,\n",
       "   'fieldsOfStudy': ['Mathematics', 'Computer Science'],\n",
       "   'authors': [{'authorId': '2881262', 'name': 'Solmaz S. Kia'},\n",
       "    {'authorId': '145576411', 'name': 'J. Cortés'},\n",
       "    {'authorId': '144448834', 'name': 'S. Martínez'}]},\n",
       "  {'paperId': 'f302f8422e2ad7cc231d231840bb3c9cbdd8e169',\n",
       "   'abstract': 'Abstract The reciprocally convex combination lemma (RCCL) is an important technique to develop stability criteria for the systems with a time-varying delay. This note develops an extended reciprocally convex matrix inequality, which reduces the estimation gap of the RCCL-based matrix inequality and reduces the number of decision variables of the recently proposed delay-dependent RCCL. A stability criterion of a linear time-delay system is established through the proposed matrix inequality. Finally, a numerical example is given to demonstrate the advantage of the proposed method.',\n",
       "   'year': 2017,\n",
       "   'referenceCount': 32,\n",
       "   'citationCount': 190,\n",
       "   'influentialCitationCount': 3,\n",
       "   'fieldsOfStudy': ['Mathematics', 'Computer Science'],\n",
       "   'authors': [{'authorId': '2659474', 'name': 'Chuan-Ke Zhang'},\n",
       "    {'authorId': '145475634', 'name': 'Yong He'},\n",
       "    {'authorId': '145650438', 'name': 'Lin Jiang'},\n",
       "    {'authorId': '26812561', 'name': 'Min Wu'},\n",
       "    {'authorId': '123451942', 'name': 'Qing-Guo Wang'}]},\n",
       "  {'paperId': '01c41a647cc44f372903be729848ea6d56342773',\n",
       "   'abstract': \"Distributionally robust optimization is a paradigm for decision making under uncertainty where the uncertain problem data are governed by a probability distribution that is itself subject to uncertainty. The distribution is then assumed to belong to an ambiguity set comprising all distributions that are compatible with the decision maker's prior information. In this paper, we propose a unifying framework for modeling and solving distributionally robust optimization problems. We introduce standardized ambiguity sets that contain all distributions with prescribed conic representable confidence sets and with mean values residing on an affine manifold. These ambiguity sets are highly expressive and encompass many ambiguity sets from the recent literature as special cases. They also allow us to characterize distributional families in terms of several classical and/or robust statistical indicators that have not yet been studied in the context of robust optimization. We determine conditions under which distributionally robust optimization problems based on our standardized ambiguity sets are computationally tractable. We also provide tractable conservative approximations for problems that violate these conditions.\",\n",
       "   'year': 2014,\n",
       "   'referenceCount': 76,\n",
       "   'citationCount': 549,\n",
       "   'influentialCitationCount': 31,\n",
       "   'fieldsOfStudy': ['Mathematics', 'Computer Science'],\n",
       "   'authors': [{'authorId': '7425260', 'name': 'W. Wiesemann'},\n",
       "    {'authorId': '2500534', 'name': 'D. Kuhn'},\n",
       "    {'authorId': '2397125', 'name': 'Melvyn Sim'}]},\n",
       "  {'paperId': '9a305c20c3e037604451d9e471a281f238b825e6',\n",
       "   'abstract': 'Thank you very much for reading fundamentals of convex analysis. As you may know, people have look hundreds times for their chosen novels like this fundamentals of convex analysis, but end up in infectious downloads. Rather than reading a good book with a cup of coffee in the afternoon, instead they cope with some harmful bugs inside their computer. fundamentals of convex analysis is available in our book collection an online access to it is set as public so you can get it instantly. Our book servers hosts in multiple countries, allowing you to get the most less latency time to download any of our books like this one. Kindly say, the fundamentals of convex analysis is universally compatible with any devices to read.',\n",
       "   'year': 2016,\n",
       "   'referenceCount': 1,\n",
       "   'citationCount': 285,\n",
       "   'influentialCitationCount': 26,\n",
       "   'fieldsOfStudy': ['Computer Science'],\n",
       "   'authors': [{'authorId': '52318286', 'name': 'Leon Hirsch'}]},\n",
       "  {'paperId': '37c040805d3123251f6e15eabc36b4a94d11a860',\n",
       "   'abstract': 'CVXGEN is a software tool that takes a high level description of a convex optimization problem family, and automatically generates custom C code that compiles into a reliable, high speed solver for the problem family. The current implementation targets problem families that can be transformed, using disciplined convex programming techniques, to convex quadratic programs of modest size. CVXGEN generates simple, flat, library-free code suitable for embedding in real-time applications. The generated code is almost branch free, and so has highly predictable run-time behavior. The combination of regularization (both static and dynamic) and iterative refinement in the search direction computation yields reliable performance, even with poor quality data. In this paper we describe how CVXGEN is implemented, and give some results on the speed and reliability of the automatically generated solvers.',\n",
       "   'year': 2012,\n",
       "   'referenceCount': 62,\n",
       "   'citationCount': 672,\n",
       "   'influentialCitationCount': 59,\n",
       "   'fieldsOfStudy': ['Mathematics'],\n",
       "   'authors': [{'authorId': '3026451', 'name': 'J. Mattingley'},\n",
       "    {'authorId': '1843103', 'name': 'Stephen P. Boyd'}]},\n",
       "  {'paperId': 'fe5759242914c814e0368a86af31b75a0bb4e2c3',\n",
       "   'abstract': 'We introduce the notion of inexact first-order oracle and analyze the behavior of several first-order methods of smooth convex optimization used with such an oracle. This notion of inexact oracle naturally appears in the context of smoothing techniques, Moreau–Yosida regularization, Augmented Lagrangians and many other situations. We derive complexity estimates for primal, dual and fast gradient methods, and study in particular their dependence on the accuracy of the oracle and the desired accuracy of the objective function. We observe that the superiority of fast gradient methods over the classical ones is no longer absolute when an inexact oracle is used. We prove that, contrary to simple gradient schemes, fast gradient methods must necessarily suffer from error accumulation. Finally, we show that the notion of inexact oracle allows the application of first-order methods of smooth convex optimization to solve non-smooth or weakly smooth convex problems.',\n",
       "   'year': 2014,\n",
       "   'referenceCount': 60,\n",
       "   'citationCount': 385,\n",
       "   'influentialCitationCount': 47,\n",
       "   'fieldsOfStudy': ['Mathematics', 'Computer Science'],\n",
       "   'authors': [{'authorId': '2530996', 'name': 'O. Devolder'},\n",
       "    {'authorId': '2002957', 'name': 'F. Glineur'},\n",
       "    {'authorId': '143676697', 'name': 'Y. Nesterov'}]},\n",
       "  {'paperId': 'e08f14111728901945f8c3b384b2f75746935e0d',\n",
       "   'abstract': 'Stochastic gradient descent (SGD) is a simple and popular method to solve stochastic optimization problems which arise in machine learning. For strongly convex problems, its convergence rate was known to be O(log(T)/T), by running SGD for T iterations and returning the average point. However, recent results showed that using a different algorithm, one can get an optimal O(1/T) rate. This might lead one to believe that standard SGD is suboptimal, and maybe should even be replaced as a method of choice. In this paper, we investigate the optimality of SGD in a stochastic setting. We show that for smooth problems, the algorithm attains the optimal O(1/T) rate. However, for non-smooth problems, the convergence rate with averaging might really be Ω(log(T)/T), and this is not just an artifact of the analysis. On the flip side, we show that a simple modification of the averaging step suffices to recover the O(1/T) rate, and no other change of the algorithm is necessary. We also present experimental results which support our findings, and point out open problems.',\n",
       "   'year': 2012,\n",
       "   'referenceCount': 17,\n",
       "   'citationCount': 519,\n",
       "   'influentialCitationCount': 60,\n",
       "   'fieldsOfStudy': ['Mathematics', 'Computer Science'],\n",
       "   'authors': [{'authorId': '1680046', 'name': 'A. Rakhlin'},\n",
       "    {'authorId': '1768909', 'name': 'O. Shamir'},\n",
       "    {'authorId': '37564609', 'name': 'Karthik Sridharan'}]},\n",
       "  {'paperId': '8b29797ee87243d601289b2d2d4701dd0baf6252',\n",
       "   'abstract': 'We consider the problem of recovering two unknown vectors, w and x, of length L from their circular convolution. We make the structural assumption that the two vectors are members of known subspaces, one with dimension N and the other with dimension K. Although the observed convolution is nonlinear in both w and x, it is linear in the rank-1 matrix formed by their outer product wx*. This observation allows us to recast the deconvolution problem as low-rank matrix recovery problem from linear measurements, whose natural convex relaxation is a nuclear norm minimization program. We prove the effectiveness of this relaxation by showing that, for “generic” signals, the program can deconvolve w and x exactly when the maximum of N and K is almost on the order of L. That is, we show that if x is drawn from a random subspace of dimension N, and w is a vector in a subspace of dimension K whose basis vectors are spread out in the frequency domain, then nuclear norm minimization recovers wx* without error. We discuss this result in the context of blind channel estimation in communications. If we have a message of length N, which we code using a random L x N coding matrix, and the encoded message travels through an unknown linear time-invariant channel of maximum length K, then the receiver can recover both the channel response and the message when L ≳ N + K, to within constant and log factors.',\n",
       "   'year': 2014,\n",
       "   'referenceCount': 55,\n",
       "   'citationCount': 347,\n",
       "   'influentialCitationCount': 52,\n",
       "   'fieldsOfStudy': ['Mathematics', 'Computer Science'],\n",
       "   'authors': [{'authorId': '104492197', 'name': 'Ali Ahmed'},\n",
       "    {'authorId': '9229182', 'name': 'B. Recht'},\n",
       "    {'authorId': '1735291', 'name': 'J. Romberg'}]},\n",
       "  {'paperId': '4360c0f7c650e671c6e6ba0e9ec443bd1462cbc9',\n",
       "   'abstract': \"We consider a general multi-agent convex optimization problem where the agents are to collectively minimize a global objective function subject to a global inequality constraint, a global equality constraint, and a global constraint set. The objective function is defined by a sum of local objective functions, while the global constraint set is produced by the intersection of local constraint sets. In particular, we study two cases: one where the equality constraint is absent, and the other where the local constraint sets are identical. We devise two distributed primal-dual subgradient algorithms based on the characterization of the primal-dual optimal solutions as the saddle points of the Lagrangian and penalty functions. These algorithms can be implemented over networks with dynamically changing topologies but satisfying a standard connectivity property, and allow the agents to asymptotically agree on optimal solutions and optimal values of the optimization problem under the Slater's condition.\",\n",
       "   'year': 2012,\n",
       "   'referenceCount': 77,\n",
       "   'citationCount': 582,\n",
       "   'influentialCitationCount': 37,\n",
       "   'fieldsOfStudy': ['Mathematics', 'Computer Science'],\n",
       "   'authors': [{'authorId': '1771269', 'name': 'Minghui Zhu'},\n",
       "    {'authorId': '144448834', 'name': 'S. Martínez'}]},\n",
       "  {'paperId': '436445b4cf3fe25e5778b5838eb623accad428e5',\n",
       "   'abstract': 'We consider the closely related problems of bandit convex optimization with two-point feedback, and zero-order stochastic convex optimization with two function evaluations per round. We provide a simple algorithm and analysis which is optimal for convex Lipschitz functions. This improves on \\\\cite{dujww13}, which only provides an optimal result for smooth functions; Moreover, the algorithm and analysis are simpler, and readily extend to non-Euclidean problems. The algorithm is based on a small but surprisingly powerful modification of the gradient estimator.',\n",
       "   'year': 2017,\n",
       "   'referenceCount': 16,\n",
       "   'citationCount': 112,\n",
       "   'influentialCitationCount': 17,\n",
       "   'fieldsOfStudy': ['Computer Science', 'Mathematics'],\n",
       "   'authors': [{'authorId': '1768909', 'name': 'O. Shamir'}]},\n",
       "  {'paperId': 'df092c64cf9992e000cb697daa248273966fab32',\n",
       "   'abstract': 'We introduce a flexible family of fairness regularizers for (linear and logistic) regression problems. These regularizers all enjoy convexity, permitting fast optimization, and they span the rang from notions of group fairness to strong individual fairness. By varying the weight on the fairness regularizer, we can compute the efficient frontier of the accuracy-fairness trade-off on any given dataset, and we measure the severity of this trade-off via a numerical quantity we call the Price of Fairness (PoF). The centerpiece of our results is an extensive comparative study of the PoF across six different datasets in which fairness is a primary consideration.',\n",
       "   'year': 2017,\n",
       "   'referenceCount': 37,\n",
       "   'citationCount': 157,\n",
       "   'influentialCitationCount': 13,\n",
       "   'fieldsOfStudy': ['Computer Science', 'Mathematics'],\n",
       "   'authors': [{'authorId': '50496565', 'name': 'R. Berk'},\n",
       "    {'authorId': '2253600', 'name': 'Hoda Heidari'},\n",
       "    {'authorId': '1775136', 'name': 'S. Jabbari'},\n",
       "    {'authorId': '144525693', 'name': 'Matthew Joseph'},\n",
       "    {'authorId': '81338045', 'name': 'M. Kearns'},\n",
       "    {'authorId': '144848816', 'name': 'Jamie H. Morgenstern'},\n",
       "    {'authorId': '5880154', 'name': 'Seth Neel'},\n",
       "    {'authorId': '1682008', 'name': 'Aaron Roth'}]},\n",
       "  {'paperId': 'b6d4f75fb0dbf48add4b361e91178372b01bd74d',\n",
       "   'abstract': 'This tutorial summarizes recent advances in the convex relaxation of the optimal power flow (OPF) problem, focusing on structural properties rather than algorithms. Part I presents two power flow models, formulates OPF and their relaxations in each model, and proves equivalence relations among them. Part II presents sufficient conditions under which the convex relaxations are exact.',\n",
       "   'year': 2014,\n",
       "   'referenceCount': 77,\n",
       "   'citationCount': 362,\n",
       "   'influentialCitationCount': 12,\n",
       "   'fieldsOfStudy': ['Mathematics', 'Computer Science'],\n",
       "   'authors': [{'authorId': '36255406', 'name': 'S. Low'}]},\n",
       "  {'paperId': '3d0b96767d7285b7ce8ecca9715aef9b020fafd9',\n",
       "   'abstract': 'Many classical algorithms are found until several years later to outlive the confines in which they were conceived, and continue to be relevant in unforeseen settings. In this paper, we show that SVRG is one such method: being originally designed for strongly convex objectives, it is also very robust in non-strongly convex or sum-of-non-convex settings. \\nMore precisely, we provide new analysis to improve the state-of-the-art running times in both settings by either applying SVRG or its novel variant. Since non-strongly convex objectives include important examples such as Lasso or logistic regression, and sum-of-non-convex objectives include famous examples such as stochastic PCA and is even believed to be related to training deep neural nets, our results also imply better performances in these applications.',\n",
       "   'year': 2016,\n",
       "   'referenceCount': 43,\n",
       "   'citationCount': 149,\n",
       "   'influentialCitationCount': 27,\n",
       "   'fieldsOfStudy': ['Computer Science', 'Mathematics'],\n",
       "   'authors': [{'authorId': '13319052', 'name': 'Z. Zhu'},\n",
       "    {'authorId': '145155436', 'name': 'Yang Yuan'}]},\n",
       "  {'paperId': 'e649adf3f157259caac9119b978769f9d24714c2',\n",
       "   'abstract': 'The objective of this work is to learn descriptors suitable for the sparse feature detectors used in viewpoint invariant matching. We make a number of novel contributions towards this goal. First, it is shown that learning the pooling regions for the descriptor can be formulated as a convex optimisation problem selecting the regions using sparsity. Second, it is shown that descriptor dimensionality reduction can also be formulated as a convex optimisation problem, using Mahalanobis matrix nuclear norm regularisation. Both formulations are based on discriminative large margin learning constraints. As the third contribution, we evaluate the performance of the compressed descriptors, obtained from the learnt real-valued descriptors by binarisation. Finally, we propose an extension of our learning formulations to a weakly supervised case, which allows us to learn the descriptors from unannotated image collections. It is demonstrated that the new learning methods improve over the state of the art in descriptor learning on the annotated local patches data set of Brown et al. and unannotated photo collections of Philbin et al. .',\n",
       "   'year': 2014,\n",
       "   'referenceCount': 42,\n",
       "   'citationCount': 303,\n",
       "   'influentialCitationCount': 37,\n",
       "   'fieldsOfStudy': ['Mathematics', 'Computer Science', 'Medicine'],\n",
       "   'authors': [{'authorId': '34838386', 'name': 'K. Simonyan'},\n",
       "    {'authorId': '1687524', 'name': 'A. Vedaldi'},\n",
       "    {'authorId': '1688869', 'name': 'Andrew Zisserman'}]},\n",
       "  {'paperId': 'ca074ee353c398b8de3bb6e1922691c2f02e635a',\n",
       "   'abstract': None,\n",
       "   'year': 1994,\n",
       "   'referenceCount': 0,\n",
       "   'citationCount': 1704,\n",
       "   'influentialCitationCount': 246,\n",
       "   'fieldsOfStudy': ['Mathematics'],\n",
       "   'authors': [{'authorId': '143806971', 'name': 'K. Ball'}]},\n",
       "  {'paperId': 'a0a2ad6d3225329f55766f0bf332c86a63f6e14e',\n",
       "   'abstract': 'Geodesic convexity generalizes the notion of (vector space) convexity to nonlinear metric spaces. But unlike convex optimization, geodesically convex (g-convex) optimization is much less developed. In this paper we contribute to the understanding of g-convex optimization by developing iteration complexity analysis for several first-order algorithms on Hadamard manifolds. Specifically, we prove upper bounds for the global complexity of deterministic and stochastic (sub)gradient methods for optimizing smooth and nonsmooth g-convex functions, both with and without strong g-convexity. Our analysis also reveals how the manifold geometry, especially \\\\emph{sectional curvature}, impacts convergence rates. To the best of our knowledge, our work is the first to provide global complexity analysis for first-order algorithms for general g-convex optimization.',\n",
       "   'year': 2016,\n",
       "   'referenceCount': 39,\n",
       "   'citationCount': 141,\n",
       "   'influentialCitationCount': 21,\n",
       "   'fieldsOfStudy': ['Mathematics', 'Computer Science'],\n",
       "   'authors': [{'authorId': '2108880169', 'name': 'Hongyi Zhang'},\n",
       "    {'authorId': '3072326', 'name': 'S. Sra'}]},\n",
       "  {'paperId': '52f7361f37a7f13185c9e4885cb6c26e61608616',\n",
       "   'abstract': \"We propose a new provable method for robust PCA, where the task is to recover a low-rank matrix, which is corrupted with sparse perturbations. Our method consists of simple alternating projections onto the set of low rank and sparse matrices with intermediate de-noising steps. We prove correct recovery of the low rank and sparse components under tight recovery conditions, which match those for the state-of-art convex relaxation techniques. Our method is extremely simple to implement and has low computational complexity. For a $m \\\\times n$ input matrix (say m \\\\geq n), our method has O(r^2 mn\\\\log(1/\\\\epsilon)) running time, where $r$ is the rank of the low-rank component and $\\\\epsilon$ is the accuracy. In contrast, the convex relaxation methods have a running time O(mn^2/\\\\epsilon), which is not scalable to large problem instances. Our running time nearly matches that of the usual PCA (i.e. non robust), which is O(rmn\\\\log (1/\\\\epsilon)). Thus, we achieve ``best of both the worlds'', viz low computational complexity and provable recovery for robust PCA. Our analysis represents one of the few instances of global convergence guarantees for non-convex methods.\",\n",
       "   'year': 2014,\n",
       "   'referenceCount': 26,\n",
       "   'citationCount': 229,\n",
       "   'influentialCitationCount': 51,\n",
       "   'fieldsOfStudy': ['Computer Science', 'Mathematics'],\n",
       "   'authors': [{'authorId': '1751626', 'name': 'Praneeth Netrapalli'},\n",
       "    {'authorId': '1877728', 'name': 'U. Niranjan'},\n",
       "    {'authorId': '1701677', 'name': 'S. Sanghavi'},\n",
       "    {'authorId': '2047844', 'name': 'Anima Anandkumar'},\n",
       "    {'authorId': '48964143', 'name': 'Prateek Jain'}]},\n",
       "  {'paperId': 'ee0ef3003597a86280bbbb5df4beb12f041831bf',\n",
       "   'abstract': 'Recent research indicates that many convex optimization problems with random constraints exhibit a \\nphase transition as the number of constraints increases. For example, this phenomenon emerges in the \\n l_1 minimization method for identifying a sparse vector from random linear measurements. Indeed, the \\n l_1 approach succeeds with high probability when the number of measurements exceeds a threshold that \\ndepends on the sparsity level; otherwise, it fails with high probability. This paper provides the first rigorous \\nanalysis that explains why phase transitions are ubiquitous in random convex optimization problems. \\nIt also describes tools for making reliable predictions about the quantitative aspects of the transition, \\nincluding the location and the width of the transition region. These techniques apply to regularized linear \\ninverse problems with random measurements, to demixing problems under a random incoherence model, \\nand also to cone programs with random affine constraints. The applied results depend on foundational \\nresearch in conic geometry. This paper introduces a summary parameter, called the statistical dimension, \\nthat canonically extends the dimension of a linear subspace to the class of convex cones. The main technical \\nresult demonstrates that the sequence of intrinsic volumes of a convex cone concentrates sharply \\naround the statistical dimension. This fact leads to accurate bounds on the probability that a randomly \\nrotated cone shares a ray with a fixed cone.',\n",
       "   'year': 2013,\n",
       "   'referenceCount': 152,\n",
       "   'citationCount': 406,\n",
       "   'influentialCitationCount': 56,\n",
       "   'fieldsOfStudy': ['Mathematics', 'Computer Science'],\n",
       "   'authors': [{'authorId': '3234551', 'name': 'Dennis Amelunxen'},\n",
       "    {'authorId': '143836001', 'name': 'Martin Lotz'},\n",
       "    {'authorId': '2057877220', 'name': 'Michael B. McCoy'},\n",
       "    {'authorId': '1788107', 'name': 'J. Tropp'}]},\n",
       "  {'paperId': '1d7ad0a7ae64bd8d78d09d03ca181e6e579bd6d8',\n",
       "   'abstract': 'This paper develops a general framework for solving a variety of convex cone problems that frequently arise in signal processing, machine learning, statistics, and other fields. The approach works as follows: first, determine a conic formulation of the problem; second, determine its dual; third, apply smoothing; and fourth, solve using an optimal first-order method. A merit of this approach is its flexibility: for example, all compressed sensing problems can be solved via this approach. These include models with objective functionals such as the total-variation norm, ||Wx||1 where W is arbitrary, or a combination thereof. In addition, the paper introduces a number of technical contributions such as a novel continuation scheme and a novel approach for controlling the step size, and applies results showing that the smooth and unsmoothed problems are sometimes formally equivalent. Combined with our framework, these lead to novel, stable and computationally efficient algorithms. For instance, our general implementation is competitive with state-of-the-art methods for solving intensively studied problems such as the LASSO. Further, numerical experiments show that one can solve the Dantzig selector problem, for which no efficient large-scale solvers exist, in a few hundred iterations. Finally, the paper is accompanied with a software release. This software is not a single, monolithic solver; rather, it is a suite of programs and routines designed to serve as building blocks for constructing complete algorithms.',\n",
       "   'year': 2011,\n",
       "   'referenceCount': 95,\n",
       "   'citationCount': 614,\n",
       "   'influentialCitationCount': 64,\n",
       "   'fieldsOfStudy': ['Mathematics', 'Computer Science'],\n",
       "   'authors': [{'authorId': '50333204', 'name': 'Stephen Becker'},\n",
       "    {'authorId': '2006869', 'name': 'E. Candès'},\n",
       "    {'authorId': '2057062180', 'name': 'Michael C. Grant'}]},\n",
       "  {'paperId': '1a8e11d93160148031b9aad6306ca9fbd4c66fec',\n",
       "   'abstract': 'This paper develops theoretical results regarding noisy 1-bit compressed sensing and sparse binomial regression. We demonstrate that a single convex program gives an accurate estimate of the signal, or coefficient vector, for both of these models. We show that an -sparse signal in can be accurately estimated from m = O(s log(n/s)) single-bit measurements using a simple convex program. This remains true even if each measurement bit is flipped with probability nearly 1/2. Worst-case (adversarial) noise can also be accounted for, and uniform results that hold for all sparse inputs are derived as well. In the terminology of sparse logistic regression, we show that O (s log (2n/s)) Bernoulli trials are sufficient to estimate a coefficient vector in which is approximately -sparse. Moreover, the same convex program works for virtually all generalized linear models, in which the link function may be unknown. To our knowledge, these are the first results that tie together the theory of sparse logistic regression to 1-bit compressed sensing. Our results apply to general signal structures aside from sparsity; one only needs to know the size of the set where signals reside. The size is given by the mean width of K, a computable quantity whose square serves as a robust extension of the dimension.',\n",
       "   'year': 2013,\n",
       "   'referenceCount': 45,\n",
       "   'citationCount': 391,\n",
       "   'influentialCitationCount': 46,\n",
       "   'fieldsOfStudy': ['Mathematics', 'Computer Science'],\n",
       "   'authors': [{'authorId': '1800179', 'name': 'Y. Plan'},\n",
       "    {'authorId': '1806615', 'name': 'R. Vershynin'}]},\n",
       "  {'paperId': 'f59019768cc6e198b73d52adcfaa0d26067a6e28',\n",
       "   'abstract': 'In this paper we consider sparsity on a tensor level, as given by the n-rank of a tensor. In an important sparse-vector approximation problem (compressed sensing) and the low-rank matrix recovery problem, using a convex relaxation technique proved to be a valuable solution strategy. Here, we will adapt these techniques to the tensor setting. We use the n-rank of a tensor as a sparsity measure and consider the low-n-rank tensor recovery problem, i.e. the problem of finding the tensor of the lowest n-rank that fulfills some linear constraints. We introduce a tractable convex relaxation of the n-rank and propose efficient algorithms to solve the low-n-rank tensor recovery problem numerically. The algorithms are based on the Douglas–Rachford splitting technique and its dual variant, the alternating direction method of multipliers.',\n",
       "   'year': 2011,\n",
       "   'referenceCount': 36,\n",
       "   'citationCount': 626,\n",
       "   'influentialCitationCount': 62,\n",
       "   'fieldsOfStudy': ['Mathematics'],\n",
       "   'authors': [{'authorId': '48372673', 'name': 'Silvia Gandy'},\n",
       "    {'authorId': '9229182', 'name': 'B. Recht'},\n",
       "    {'authorId': '145889563', 'name': 'I. Yamada'}]},\n",
       "  {'paperId': 'ccfaba27ca7bce5b95dde407e9df568e5902b218',\n",
       "   'abstract': 'Submodular functions are relevant to machine learning for at least two reasons: (1) some problems may be expressed directly as the optimization of submodular functions and (2) the Lovsz extension of submodular functions provides a useful set of regularization functions for supervised and unsupervised learning. In Learning with Submodular Functions: A Convex Optimization Perspective, the theory of submodular functions is presented in a self-contained way from a convex analysis perspective, presenting tight links between certain polyhedra, combinatorial optimization and convex optimization problems. In particular, it describes how submodular function minimization is equivalent to solving a wide variety of convex optimization problems. This allows the derivation of new efficient algorithms for approximate and exact submodular function minimization with theoretical guarantees and good practical performance. By listing many examples of submodular functions, it reviews various applications to machine learning, such as clustering, experimental design, sensor placement, graphical model structure learning or subset selection, as well as a family of structured sparsity-inducing norms that can be derived and used from submodular functions. Learning with Submodular Functions: A Convex Optimization Perspective is an ideal reference for researchers, scientists, or engineers with an interest in applying submodular functions to machine learning problems.',\n",
       "   'year': 2013,\n",
       "   'referenceCount': 246,\n",
       "   'citationCount': 365,\n",
       "   'influentialCitationCount': 51,\n",
       "   'fieldsOfStudy': ['Computer Science', 'Mathematics'],\n",
       "   'authors': [{'authorId': '144570279', 'name': 'F. Bach'}]},\n",
       "  {'paperId': '1e1d1c9a3cc9991bf64b075be899bff7440f895a',\n",
       "   'abstract': 'We present several new variations on the theme of nonnegative matrix factorization (NMF). Considering factorizations of the form X = FGT, we focus on algorithms in which G is restricted to containing nonnegative entries, but allowing the data matrix X to have mixed signs, thus extending the applicable range of NMF methods. We also consider algorithms in which the basis vectors of F are constrained to be convex combinations of the data points. This is used for a kernel extension of NMF. We provide algorithms for computing these new factorizations and we provide supporting theoretical analysis. We also analyze the relationships between our algorithms and clustering algorithms, and consider the implications for sparseness of solutions. Finally, we present experimental results that explore the properties of these new methods.',\n",
       "   'year': 2010,\n",
       "   'referenceCount': 59,\n",
       "   'citationCount': 1019,\n",
       "   'influentialCitationCount': 149,\n",
       "   'fieldsOfStudy': ['Mathematics', 'Computer Science', 'Medicine'],\n",
       "   'authors': [{'authorId': '1737469', 'name': 'C. Ding'},\n",
       "    {'authorId': None, 'name': 'Tao Li'},\n",
       "    {'authorId': '1694621', 'name': 'Michael I. Jordan'}]},\n",
       "  {'paperId': '25dc71902ad0323af1ce20eb5913bf178ae4d360',\n",
       "   'abstract': 'Clustering is a fundamental problem in many scientific applications. Standard methods such as k-means, Gaussian mixture models, and hierarchical clustering, however, are beset by local minima, which are sometimes drastically suboptimal. Recently introduced convex relaxations of k-means and hierarchical clustering shrink cluster centroids toward one another and ensure a unique global minimizer. In this work, we present two splitting methods for solving the convex clustering problem. The first is an instance of the alternating direction method of multipliers (ADMM); the second is an instance of the alternating minimization algorithm (AMA). In contrast to previously considered algorithms, our ADMM and AMA formulations provide simple and unified frameworks for solving the convex clustering problem under the previously studied norms and open the door to potentially novel norms. We demonstrate the performance of our algorithm on both simulated and real data examples. While the differences between the two algorithms appear to be minor on the surface, complexity analysis and numerical experiments show AMA to be significantly more efficient. This article has supplementary materials available online.',\n",
       "   'year': 2015,\n",
       "   'referenceCount': 87,\n",
       "   'citationCount': 188,\n",
       "   'influentialCitationCount': 36,\n",
       "   'fieldsOfStudy': ['Mathematics', 'Medicine'],\n",
       "   'authors': [{'authorId': '1721664', 'name': 'Eric C. Chi'},\n",
       "    {'authorId': '143953625', 'name': 'K. Lange'}]},\n",
       "  {'paperId': '093f08994e95ad84ad94a10cdb7631290f143d5a',\n",
       "   'abstract': 'Abstract In this paper, several types of L-convex spaces are introduced, including stratified L-convex spaces, convex-generated L-convex spaces, weakly induced L-convex spaces and induced L-convex spaces. Their relations are discussed category-theoretically. Firstly, it is shown that there is a Galois correspondence between the category SL-CS of stratified L-convex spaces (resp. the category WIL-CS of weakly induced L-convex spaces) and the category L-CS of L-convex spaces. In particular, SL-CS and WIL-CS are both coreflective subcategories of L-CS. Secondly, it is proved that there is a Galois correspondence between the category CS of convex spaces and the category SL-CS (resp. WIL-CS). Specially, CS can be embedded into SL-CS and WIL-CS as a coreflective subcategory. Finally, it is shown that the category CGL-CS of convex-generated L-convex spaces, the category IL-CS of induced L-convex spaces and CS are isomorphic.',\n",
       "   'year': 2017,\n",
       "   'referenceCount': 21,\n",
       "   'citationCount': 73,\n",
       "   'influentialCitationCount': 1,\n",
       "   'fieldsOfStudy': ['Computer Science', 'Mathematics'],\n",
       "   'authors': [{'authorId': '144865355', 'name': 'B. Pang'},\n",
       "    {'authorId': '37583169', 'name': 'F. Shi'}]},\n",
       "  {'paperId': '4ad915a10be9d443206e8ae707d64638be604f8a',\n",
       "   'abstract': 'We discuss binary classification from only positive and unlabeled data (PU classification), which is conceivable in various real-world machine learning problems. Since unlabeled data consists of both positive and negative data, simply separating positive and unlabeled data yields a biased solution. Recently, it was shown that the bias can be canceled by using a particular non-convex loss such as the ramp loss. However, classifier training with a non-convex loss is not straightforward in practice. In this paper, we discuss a convex formulation for PU classification that can still cancel the bias. The key idea is to use different loss functions for positive and unlabeled samples. However, in this setup, the hinge loss is not permissible. As an alternative, we propose the double hinge loss. Theoretically, we prove that the estimators converge to the optimal solutions at the optimal parametric rate. Experimentally, we demonstrate that PU classification with the double hinge loss performs as accurate as the non-convex method, with a much lower computational cost.',\n",
       "   'year': 2015,\n",
       "   'referenceCount': 27,\n",
       "   'citationCount': 168,\n",
       "   'influentialCitationCount': 31,\n",
       "   'fieldsOfStudy': ['Mathematics', 'Computer Science'],\n",
       "   'authors': [{'authorId': '3277454', 'name': 'M. Plessis'},\n",
       "    {'authorId': '47537639', 'name': 'Gang Niu'},\n",
       "    {'authorId': '67154907', 'name': 'Masashi Sugiyama'}]},\n",
       "  {'paperId': '44a6b76e5cbc61330663d0a9f393caf91a3a1be8',\n",
       "   'abstract': 'Abstract IN this paper we consider an iterative method of finding the common point of convex sets. This method can be regarded as a generalization of the methods discussed in [1–4]. Apart from problems which can be reduced to finding some point of the intersection of convex sets, the method considered can be applied to the approximate solution of problems in linear and convex programming.',\n",
       "   'year': 1967,\n",
       "   'referenceCount': 3,\n",
       "   'citationCount': 2331,\n",
       "   'influentialCitationCount': 179,\n",
       "   'fieldsOfStudy': ['Mathematics'],\n",
       "   'authors': [{'authorId': '35180576', 'name': 'L. Bregman'}]},\n",
       "  {'paperId': '9e7b0395d7b34e9d34cca779afd0c10da6e135b5',\n",
       "   'abstract': 'Abstract\\nWe present a method for learning sparse representations shared across multiple tasks. This method is a generalization of the well-known single-task 1-norm regularization. It is based on a novel non-convex regularizer which controls the number of learned features common across the tasks. We prove that the method is equivalent to solving a convex optimization problem for which there is an iterative algorithm which converges to an optimal solution. The algorithm has a simple interpretation: it alternately performs a supervised and an unsupervised step, where in the former step it learns task-specific functions and in the latter step it learns common-across-tasks sparse representations for these functions. We also provide an extension of the algorithm which learns sparse nonlinear representations using kernels. We report experiments on simulated and real data sets which demonstrate that the proposed method can both improve the performance relative to learning each task independently and lead to a few learned features common across related tasks. Our algorithm can also be used, as a special case, to simply select—not learn—a few common variables across the tasks.\\n',\n",
       "   'year': 2007,\n",
       "   'referenceCount': 60,\n",
       "   'citationCount': 1375,\n",
       "   'influentialCitationCount': 152,\n",
       "   'fieldsOfStudy': ['Mathematics', 'Computer Science'],\n",
       "   'authors': [{'authorId': '50033175', 'name': 'Andreas Argyriou'},\n",
       "    {'authorId': '1801089', 'name': 'T. Evgeniou'},\n",
       "    {'authorId': '1704699', 'name': 'M. Pontil'}]},\n",
       "  {'paperId': '50942b48eb4027acae9c77880d4fc9bdd973e4db',\n",
       "   'abstract': 'Quadratically constrained quadratic programs (QCQPs) have a wide range of applications in signal processing and wireless communications. Non-convex QCQPs are NP-hard in general. Existing approaches relax the non-convexity using semi-definite relaxation (SDR) or linearize the non-convex part and solve the resulting convex problem. However, these techniques are seldom successful in even obtaining a feasible solution when the QCQP matrices are indefinite. In this letter, a new feasible point pursuit successive convex approximation (FPP-SCA) algorithm is proposed for non-convex QCQPs. FPP-SCA linearizes the non-convex parts of the problem as conventional SCA does, but adds slack variables to sustain feasibility, and a penalty to ensure slacks are sparingly used. When FPP-SCA is successful in identifying a feasible point of the non-convex QCQP, convergence to a Karush-Kuhn-Tucker (KKT) point is thereafter ensured. Simulations show the effectiveness of our proposed algorithm in obtaining feasible and near-optimal solutions, significantly outperforming existing approaches.',\n",
       "   'year': 2015,\n",
       "   'referenceCount': 28,\n",
       "   'citationCount': 151,\n",
       "   'influentialCitationCount': 21,\n",
       "   'fieldsOfStudy': ['Mathematics', 'Computer Science'],\n",
       "   'authors': [{'authorId': '2924647', 'name': 'Omar Mehanna'},\n",
       "    {'authorId': '2349460', 'name': 'Kejun Huang'},\n",
       "    {'authorId': '1711511', 'name': 'B. Gopalakrishnan'},\n",
       "    {'authorId': '36086846', 'name': 'Aritra Konar'},\n",
       "    {'authorId': '73776482', 'name': 'N. Sidiropoulos'}]},\n",
       "  {'paperId': 'da2628755e4f72b212e8cefa187394cdaf585703',\n",
       "   'abstract': 'This paper is concerned with the alternating minimization (AM) method for solving convex minimization problems where the decision variables vector is split into two blocks. The objective function is a sum of a differentiable convex function and a separable (possibly) nonsmooth extended real-valued convex function, and consequently constraints can be incorporated. We analyze the convergence rate of the method and establish a nonasymptotic sublinear rate of convergence where the multiplicative constant depends on the minimal block Lipschitz constant. We then analyze the iteratively reweighted least squares (IRLS) method for solving convex problems involving sums of norms. Based on the results derived for the AM method, we establish a nonasymptotic sublinear rate of convergence of the IRLS method. In addition, we show an asymptotic rate of convergence whose efficiency estimate does not depend on the data of the problem. Finally, we study the convergence properties of a decomposition-based approach designed t...',\n",
       "   'year': 2015,\n",
       "   'referenceCount': 39,\n",
       "   'citationCount': 148,\n",
       "   'influentialCitationCount': 12,\n",
       "   'fieldsOfStudy': ['Mathematics', 'Computer Science'],\n",
       "   'authors': [{'authorId': '40204991', 'name': 'A. Beck'}]},\n",
       "  {'paperId': '3edae395b2a2e8a5a1796367cb7d1b0b206079d0',\n",
       "   'abstract': 'Non-convex sparsity-inducing penalties have recently received considerable attentions in sparse learning. Recent theoretical investigations have demonstrated their superiority over the convex counterparts in several sparse learning settings. However, solving the non-convex optimization problems associated with non-convex penalties remains a big challenge. A commonly used approach is the Multi-Stage (MS) convex relaxation (or DC programming), which relaxes the original non-convex problem to a sequence of convex problems. This approach is usually not very practical for large-scale problems because its computational cost is a multiple of solving a single convex problem. In this paper, we propose a General Iterative Shrinkage and Thresholding (GIST) algorithm to solve the nonconvex optimization problem for a large class of non-convex penalties. The GIST algorithm iteratively solves a proximal operator problem, which in turn has a closed-form solution for many commonly used penalties. At each outer iteration of the algorithm, we use a line search initialized by the Barzilai-Borwein (BB) rule that allows finding an appropriate step size quickly. The paper also presents a detailed convergence analysis of the GIST algorithm. The efficiency of the proposed algorithm is demonstrated by extensive experiments on large-scale data sets.',\n",
       "   'year': 2013,\n",
       "   'referenceCount': 36,\n",
       "   'citationCount': 273,\n",
       "   'influentialCitationCount': 47,\n",
       "   'fieldsOfStudy': ['Computer Science', 'Mathematics', 'Medicine'],\n",
       "   'authors': [{'authorId': '2925921', 'name': 'Pinghua Gong'},\n",
       "    {'authorId': '14966740', 'name': 'Changshui Zhang'},\n",
       "    {'authorId': '6201715', 'name': 'Zhaosong Lu'},\n",
       "    {'authorId': '1985263', 'name': 'Jianhua Z. Huang'},\n",
       "    {'authorId': '144030870', 'name': 'Jieping Ye'}]},\n",
       "  {'paperId': '7423e49f9cc4f03cdec9732e06c74e71629554ce',\n",
       "   'abstract': 'We study a nonlinear elliptic problem defined in a bounded domain involving fractional powers of the Laplacian operator together with a concave—convex term. We completely characterize the range of parameters for which solutions of the problem exist and prove a multiplicity result. We also prove an associated trace inequality and some Liouville-type results.',\n",
       "   'year': 2013,\n",
       "   'referenceCount': 54,\n",
       "   'citationCount': 371,\n",
       "   'influentialCitationCount': 13,\n",
       "   'fieldsOfStudy': ['Mathematics'],\n",
       "   'authors': [{'authorId': '38825176', 'name': 'C. Brändle'},\n",
       "    {'authorId': '78120055', 'name': 'E. Colorado'},\n",
       "    {'authorId': '1392822901', 'name': 'A. de Pablo'},\n",
       "    {'authorId': '145189973', 'name': 'U. Sanchez'}]},\n",
       "  {'paperId': '1bca7277d1b418a51f59fa7581f0416400105294',\n",
       "   'abstract': 'This book provides a self-contained, accessible introduction to the mathematical advances and challenges resulting from the use of semidefinite programming in polynomial optimization. This quickly evolving research area with contributions from the diverse fields of convex geometry, algebraic geometry, and optimization is known as convex algebraic geometry. Each chapter addresses a fundamental aspect of convex algebraic geometry. The book begins with an introduction to nonnegative polynomials and sums of squares and their connections to semidefinite programming and quickly advances to several areas at the forefront of current research. These include semidefinite representability of convex sets, duality theory from the point of view of algebraic geometry, and nontraditional topics such as sums of squares of complex forms and noncommutative sums of squares polynomials. Suitable for a class or seminar, with exercises aimed at teaching the topics to beginners, Semidefinite Optimization and Convex Algebraic Geometry serves as a point of entry into the subject for readers from multiple communities such as engineering, mathematics, and computer science. A guide to the necessary background material is available in the appendix. Audience This book can serve as a textbook for graduate-level courses presenting the basic mathematics behind convex algebraic geometry and semidefinite optimization. Readers conducting research in these areas will discover open problems and potential research directions. Contents: List of Notation; Chapter 1: What is Convex Algebraic Geometry?; Chapter 2: Semidefinite Optimization; Chapter 3: Polynomial Optimization, Sums of Squares, and Applications; Chapter 4: Nonnegative Polynomials and Sums of Squares; Chapter 5: Dualities; Chapter 6: Semidefinite Representability; Chapter 7: Convex Hulls of Algebraic Sets; Chapter 8: Free Convexity; Chapter 9: Sums of Hermitian Squares: Old and New; Appendix A: Background Material.',\n",
       "   'year': 2012,\n",
       "   'referenceCount': 0,\n",
       "   'citationCount': 453,\n",
       "   'influentialCitationCount': 24,\n",
       "   'fieldsOfStudy': ['Mathematics'],\n",
       "   'authors': [{'authorId': '2479013', 'name': 'Grigoriy Blekherman'},\n",
       "    {'authorId': '1731770', 'name': 'P. Parrilo'},\n",
       "    {'authorId': '1690660', 'name': 'Rekha R. Thomas'}]},\n",
       "  {'paperId': '11bc766fd0222d90334cfcb780dfc4fb5f2c586b',\n",
       "   'abstract': 'This paper considers a class of generalized convex games where each player is associated with a convex objective function, a convex inequality constraint and a convex constraint set. The players aim to compute a Nash equilibrium through communicating with neighboring players. The particular challenge we consider is that the component functions are unknown a priori to associated players. We study two distributed computation algorithms and analyze their convergence properties in the presence of data transmission delays and dynamic changes of network topologies. The algorithm performance is verified through demand response on the IEEE 30-bus Test System. Our technical tools integrate convex analysis, variational inequalities and simultaneous perturbation stochastic approximation.',\n",
       "   'year': 2016,\n",
       "   'referenceCount': 54,\n",
       "   'citationCount': 99,\n",
       "   'influentialCitationCount': 11,\n",
       "   'fieldsOfStudy': ['Computer Science', 'Mathematics'],\n",
       "   'authors': [{'authorId': '1771269', 'name': 'Minghui Zhu'},\n",
       "    {'authorId': '1777799', 'name': 'Emilio Frazzoli'}]},\n",
       "  {'paperId': 'a71dd894858ca684faa4a7b237513ece7a2ab089',\n",
       "   'abstract': 'This paper presents an algorithm to solve non-convex optimal control problems, where non-convexity can arise from nonlinear dynamics, and non-convex state and control constraints. This paper assumes that the state and control constraints are already convex or convexified, the proposed algorithm convexifies the nonlinear dynamics, via a linearization, in a successive manner. Thus at each succession, a convex optimal control subproblem is solved. Since the dynamics are linearized and other constraints are convex, after a discretization, the subproblem can be expressed as a finite dimensional convex programming subproblem. Since convex optimization problems can be solved very efficiently, especially with custom solvers, this subproblem can be solved in time-critical applications, such as real-time path planning for autonomous vehicles. Several safe-guarding techniques are incorporated into the algorithm, namely virtual control and trust regions, which add another layer of algorithmic robustness. A convergence analysis is presented in continuous-time setting. By doing so, our convergence results will be independent from any numerical schemes used for discretization. Numerical simulations are performed for an illustrative trajectory optimization example.',\n",
       "   'year': 2016,\n",
       "   'referenceCount': 48,\n",
       "   'citationCount': 100,\n",
       "   'influentialCitationCount': 8,\n",
       "   'fieldsOfStudy': ['Mathematics', 'Computer Science'],\n",
       "   'authors': [{'authorId': '8070908', 'name': 'Yuanqi Mao'},\n",
       "    {'authorId': '7808060', 'name': 'Michael Szmuk'},\n",
       "    {'authorId': '2991808', 'name': 'Behçet Açikmese'}]},\n",
       "  {'paperId': 'a2e0eb89cb6348c947d1035b9fb93676f18708da',\n",
       "   'abstract': 'Abstract. We introduce the notion of a convex measure of risk, an extension of the concept of a coherent risk measure defined in Artzner et al. (1999), and we prove a corresponding extension of the representation theorem in terms of probability measures on the underlying space of scenarios. As a case study, we consider convex measures of risk defined in terms of a robust notion of bounded shortfall risk. In the context of a financial market model, it turns out that the representation theorem is closely related to the superhedging duality under convex constraints.',\n",
       "   'year': 2002,\n",
       "   'referenceCount': 11,\n",
       "   'citationCount': 1374,\n",
       "   'influentialCitationCount': 212,\n",
       "   'fieldsOfStudy': ['Mathematics', 'Computer Science'],\n",
       "   'authors': [{'authorId': '35815328', 'name': 'H. Föllmer'},\n",
       "    {'authorId': '3318209', 'name': 'A. Schied'}]},\n",
       "  {'paperId': '0efd209954349807d921b22dcb1926ed1732cff2',\n",
       "   'abstract': 'Abstract A wide range of problems arising in practical applications can be formulated as Mixed-Integer Nonlinear Programs (MINLPs). For the case in which the objective and constraint functions are convex, some quite effective exact and heuristic algorithms are available. When non-convexities are present, however, things become much more difficult, since then even the continuous relaxation is a global optimization problem. We survey the literature on non-convex MINLPs, discussing applications, algorithms, and software. Special attention is paid to the case in which the objective and constraint functions are quadratic.',\n",
       "   'year': 2012,\n",
       "   'referenceCount': 215,\n",
       "   'citationCount': 376,\n",
       "   'influentialCitationCount': 19,\n",
       "   'fieldsOfStudy': ['Mathematics'],\n",
       "   'authors': [{'authorId': '1691727', 'name': 'S. Burer'},\n",
       "    {'authorId': '2145201', 'name': 'A. Letchford'}]},\n",
       "  {'paperId': '4c53bb5d40a2d4cc1afed0c8b91d07f6552ba216',\n",
       "   'abstract': 'This paper proposes a mixed-integer conic programming formulation for the minimum loss distribution network reconfiguration problem. This formulation has two features: first, it employs a convex representation of the network model which is based on the conic quadratic format of the power flow equations and second, it optimizes the exact value of the network losses. The use of a convex model in terms of the continuous variables is particularly important because it ensures that an optimal solution obtained by a branch-and-cut algorithm for mixed-integer conic programming is global. In addition, good quality solutions with a relaxed optimality gap can be very efficiently obtained. A polyhedral approximation which is amenable to solution via more widely available mixed-integer linear programming software is also presented. Numerical results on practical test networks including distributed generation show that mixed-integer convex optimization is an effective tool for network reconfiguration.',\n",
       "   'year': 2012,\n",
       "   'referenceCount': 33,\n",
       "   'citationCount': 340,\n",
       "   'influentialCitationCount': 34,\n",
       "   'fieldsOfStudy': ['Mathematics'],\n",
       "   'authors': [{'authorId': '2225982', 'name': 'R. Jabr'},\n",
       "    {'authorId': '144540651', 'name': 'R. Singh'},\n",
       "    {'authorId': '30679182', 'name': 'B. Pal'}]},\n",
       "  {'paperId': 'ef204ca3d888d27671ee40e5344a345e5dc302a6',\n",
       "   'abstract': \"Background from asymptotic convex geometry Isotropic log-concave measures Hyperplane conjecture and Bourgain's upper bound Partial answers L q -centroid bodies and concentration of mass Bodies with maximal isotropic constant Logarithmic Laplace transform and the isomorphic slicing problem Tail estimates for linear functionals M and M? *-estimates Approximating the covariance matrix Random polytopes in isotropic convex bodies Central limit problem and the thin shell conjecture The thin shell estimate Kannan-Lov sz-Simonovits conjecture Infimum convolution inequalities and concentration Information theory and the hyperplane conjecture Bibliography Subject index Author index\",\n",
       "   'year': 2014,\n",
       "   'referenceCount': 74,\n",
       "   'citationCount': 170,\n",
       "   'influentialCitationCount': 12,\n",
       "   'fieldsOfStudy': ['Mathematics'],\n",
       "   'authors': [{'authorId': '8804012', 'name': 'Silouanos Brazitikos'}]},\n",
       "  {'paperId': '366bd26a5a662012deefe4cb9416bcc2be450de8',\n",
       "   'abstract': 'This book gives a first systematic account on the subject of convex analysis and optimization in Hadamard spaces. It is primarily aimed at both graduate students and researchers in analysis and optimization.',\n",
       "   'year': 2014,\n",
       "   'referenceCount': 193,\n",
       "   'citationCount': 159,\n",
       "   'influentialCitationCount': 18,\n",
       "   'fieldsOfStudy': ['Mathematics'],\n",
       "   'authors': [{'authorId': '2224890', 'name': 'M. Bacák'}]},\n",
       "  {'paperId': 'c84f1f6549da0bdf41cf895bad6193daf6b24230',\n",
       "   'abstract': 'A method for estimating unknown node positions in a sensor network based exclusively on connectivity-induced constraints is described. Known peer-to-peer communication in the network is modeled as a set of geometric constraints on the node positions. The global solution of a feasibility problem for these constraints yields estimates for the unknown positions of the nodes in the network. Providing that the constraints are tight enough, simulation illustrates that this estimate becomes close to the actual node positions. Additionally, a method for placing rectangular bounds around the possible positions for all unknown nodes in the network is given. The area of the bounding rectangles decreases as additional or tighter constraints are included in the problem. Specific models are suggested and simulated for isotropic and directional communication, representative of broadcast-based and optical transmission respectively, though the methods presented are not limited to these simple cases.',\n",
       "   'year': 2001,\n",
       "   'referenceCount': 19,\n",
       "   'citationCount': 1775,\n",
       "   'influentialCitationCount': 67,\n",
       "   'fieldsOfStudy': ['Computer Science'],\n",
       "   'authors': [{'authorId': '33370351', 'name': 'L. Doherty'},\n",
       "    {'authorId': '143648343', 'name': 'K. Pister'},\n",
       "    {'authorId': '3570917', 'name': 'L. El Ghaoui'}]},\n",
       "  {'paperId': 'a6f5c8d82f27bd68eb4cc40bc3d0b00fccc5d469',\n",
       "   'abstract': 'This paper studies a difficult and fundamental problem that arises throughout electrical engineering, applied mathematics, and statistics. Suppose that one forms a short linear combination of elementary signals drawn from a large, fixed collection. Given an observation of the linear combination that has been contaminated with additive noise, the goal is to identify which elementary signals participated and to approximate their coefficients. Although many algorithms have been proposed, there is little theory which guarantees that these algorithms can accurately and efficiently solve the problem. This paper studies a method called convex relaxation, which attempts to recover the ideal sparse signal by solving a convex program. This approach is powerful because the optimization can be completed in polynomial time with standard scientific software. The paper provides general conditions which ensure that convex relaxation succeeds. As evidence of the broad impact of these results, the paper describes how convex relaxation can be used for several concrete signal recovery problems. It also describes applications to channel coding, linear regression, and numerical analysis',\n",
       "   'year': 2006,\n",
       "   'referenceCount': 98,\n",
       "   'citationCount': 1372,\n",
       "   'influentialCitationCount': 93,\n",
       "   'fieldsOfStudy': ['Mathematics', 'Computer Science'],\n",
       "   'authors': [{'authorId': '1788107', 'name': 'J. Tropp'}]},\n",
       "  {'paperId': '7b814e39159da8bef0a26308ddf3e4315c687675',\n",
       "   'abstract': 'In this paper we introduce disciplined convex-concave programming (DCCP), which combines the ideas of disciplined convex programming (DCP) with convex-concave programming (CCP). Convex-concave programming is an organized heuristic for solving nonconvex problems that involve objective and constraint functions that are a sum of a convex and a concave term. DCP is a structured way to define convex optimization problems, based on a family of basic convex and concave functions and a few rules for combining them. Problems expressed using DCP can be automatically converted to standard form and solved by a generic solver; widely used implementations include YALMIP, CVX, CVXPY, and Convex. jl. In this paper we propose a framework that combines the two ideas, and includes two improvements over previously published work on convex-concave programming, specifically the handling of domains of the functions, and the issue of subdifferentiability on the boundary of the domains. We describe a Python implementation called DCCP, which extends CVXPY, and give examples.',\n",
       "   'year': 2016,\n",
       "   'referenceCount': 74,\n",
       "   'citationCount': 68,\n",
       "   'influentialCitationCount': 13,\n",
       "   'fieldsOfStudy': ['Computer Science', 'Mathematics'],\n",
       "   'authors': [{'authorId': '2527436', 'name': 'Xinyue Shen'},\n",
       "    {'authorId': '2039713286', 'name': 'Steven Diamond'},\n",
       "    {'authorId': '2080215', 'name': 'Yuantao Gu'},\n",
       "    {'authorId': '1843103', 'name': 'Stephen P. Boyd'}]},\n",
       "  {'paperId': 'fb89da13e01e17052673c3a1a092092d3ef987d1',\n",
       "   'abstract': 'In many sparse coding based image restoration and image classification problems, using non-convex Ip-norm minimization (0 ≤ p <; 1) can often obtain better results than the convex l1-norm minimization. A number of algorithms, e.g., iteratively reweighted least squares (IRLS), iteratively thresholding method (ITM-Ip), and look-up table (LUT), have been proposed for non-convex Ip-norm sparse coding, while some analytic solutions have been suggested for some specific values of p. In this paper, by extending the popular soft-thresholding operator, we propose a generalized iterated shrinkage algorithm (GISA) for Ip-norm non-convex sparse coding. Unlike the analytic solutions, the proposed GISA algorithm is easy to implement, and can be adopted for solving non-convex sparse coding problems with arbitrary p values. Compared with LUT, GISA is more general and does not need to compute and store the look-up tables. Compared with IRLS and ITM-Ip, GISA is theoretically more solid and can achieve more accurate solutions. Experiments on image restoration and sparse coding based face recognition are conducted to validate the performance of GISA.',\n",
       "   'year': 2013,\n",
       "   'referenceCount': 52,\n",
       "   'citationCount': 222,\n",
       "   'influentialCitationCount': 28,\n",
       "   'fieldsOfStudy': ['Mathematics', 'Computer Science'],\n",
       "   'authors': [{'authorId': '1724520', 'name': 'W. Zuo'},\n",
       "    {'authorId': '1803714', 'name': 'Deyu Meng'},\n",
       "    {'authorId': '36685537', 'name': 'Lei Zhang'},\n",
       "    {'authorId': '2340559', 'name': 'Xiangchu Feng'},\n",
       "    {'authorId': '2109588826', 'name': 'David Zhang'}]},\n",
       "  {'paperId': '1980fe947e4622d555b592064592839d8cde46c7',\n",
       "   'abstract': 'Grobner basics The state polytope Variation of term orders Toric ideals Enumeration, sampling and integer programming Primitive partition identities Universal Grobner bases Regular triangulations The second hypersimplex $\\\\mathcal A$-graded algebras Canonical subalgebra bases Generators, Betti numbers and localizations Toric varieties in algebraic geometry Some specific Grobner bases Bibliography Index.',\n",
       "   'year': 1995,\n",
       "   'referenceCount': 0,\n",
       "   'citationCount': 1594,\n",
       "   'influentialCitationCount': 147,\n",
       "   'fieldsOfStudy': ['Mathematics'],\n",
       "   'authors': [{'authorId': '1760178', 'name': 'B. Sturmfels'}]},\n",
       "  {'paperId': '25e60172a650b3e7482732d65a1f1cc179dfca65',\n",
       "   'abstract': 'In many machine learning problems such as the dual form of SVM, the objective function to be minimized is convex but not strongly convex. This fact causes difficulties in obtaining the complexity of some commonly used optimization algorithms. In this paper, we proved the global linear convergence on a wide range of algorithms when they are applied to some non-strongly convex problems. In particular, we are the first to prove O(log(1/e)) time complexity of cyclic coordinate descent methods on dual problems of support vector classification and regression.',\n",
       "   'year': 2014,\n",
       "   'referenceCount': 37,\n",
       "   'citationCount': 128,\n",
       "   'influentialCitationCount': 21,\n",
       "   'fieldsOfStudy': ['Mathematics', 'Computer Science'],\n",
       "   'authors': [{'authorId': '145980559', 'name': 'Po-Wei Wang'},\n",
       "    {'authorId': '1711460', 'name': 'Chih-Jen Lin'}]}]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using api to access a author using authorID, and calculate the h-index of the specified author."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H-index of 1741103 is 19\n"
     ]
    }
   ],
   "source": [
    "def get_h_index(authorID):\n",
    "    \"\"\"given string authorID, calculate H-Index\"\"\"\n",
    "    response_author = requests.get('https://api.semanticscholar.org/graph/v1/author/{}?fields=name,papers,papers.citationCount'.format(authorID))\n",
    "    papers = response_author.json()['papers']\n",
    "\n",
    "    paper_citation = []\n",
    "    for i in papers:\n",
    "        paper_citation.append(i['citationCount'])\n",
    "    paper_citation.sort(key = lambda x: -x)\n",
    "    \n",
    "    h = 0\n",
    "    for i, c in enumerate(paper_citation):\n",
    "        if i + 1 > c:\n",
    "            h = i \n",
    "            break\n",
    "    return h\n",
    "\n",
    "\n",
    "exampleID = '1741103'\n",
    "print('H-index of {} is {}'.format(exampleID,get_h_index(exampleID)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The API only supports 100 resquests per 5 minutes. Here is an example of making 50 requests that retrieve the papers with keyword 'covid' and 'vaccination' and load them into a pandas dataframe       \n",
    "\n",
    "Note here the response.json() is a dictionary with keys 'total', 'offset','next', and 'data'. Here the value of the key 'data' is of our interest, and it is a list of dictionaries. Each dictionary stores the relevant data of a paper specified in your query. \n",
    "\n",
    "For demonstration purpose only [paperId\tyear,referenceCount,citationCount,influentialCitationCount,fieldsOfStudy] are collecrted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "num_requests = 33\n",
    "keywords = {\n",
    "    'Aeronautics': ['Aerospace','aircraft','fluid','aerodynamics', 'radar', 'orbital', 'combustion'],\n",
    "    'Mathematics':['Analysis', 'Algebraic', 'Arithmetic', 'Number', 'Vector', 'Set', 'Geometric'],\n",
    "    'Chemistry': ['Chemical', 'Thermodynamic', 'kinetics', 'electrochemistry', 'spectroscopy', 'molecular', 'geochemistry'],\n",
    "    'Computer science': ['Algorithm', 'Computation', 'Intelligent', 'System', 'Graphics', 'Visualization', 'Architecture'],\n",
    "    'Physics': ['Force', 'Newtonian', 'Mechanics', 'Relativity', 'Equilibrium', 'Quantum', 'Nuclear', 'Electromagnetic'],\n",
    "    'Material Science': ['Solids', 'metallurgy', 'mineralogy', 'nanotechnology', 'biomaterials', 'metallurgy', 'failure'],\n",
    "    'Civil Engineering': ['Geology', 'Soils', 'Environmental', 'Design', 'pavement', 'construction', 'residential', 'commercial'],\n",
    "    'Biology': ['natural science', 'organisms', 'physiology', 'anatomy', 'plants', 'animals', 'earth', 'ecosystem' ],\n",
    "    'Medicine': ['Cardiology', 'Cardiovascular Surgery', 'Dermatology', 'Dentistry', 'Emergency Medicine', 'Endocrinology', 'Gastroenterology', 'General Practice'],\n",
    "    'Economics':['Goods', 'services', 'production', 'consumption', 'macroeconomics', 'microeconomics', 'contract', 'econophysics', 'political economy']\n",
    "}\n",
    "\n",
    "for fields in keywords.keys():\n",
    "    data = []\n",
    "    for counter,q in enumerate(keywords[fields]):\n",
    "        for i in range(num_requests):\n",
    "            query = 'https://api.semanticscholar.org/graph/v1/paper/search?&query={}&fields=abstract,year,referenceCount,citationCount,influentialCitationCount,fieldsOfStudy,authors&offest={}&limit=100'.format(q,i*100)\n",
    "            response = requests.get(query)\n",
    "            data += response.json()['data']\n",
    "        if (counter + 1) % 3 == 0:\n",
    "            time.sleep(301) #sleep for 5 min\n",
    "    df = pd.DataFrame(data)\n",
    "    df = df[df['year'] < 2010]\n",
    "    df.to_csv(fields+'data.csv',index=False) # this writes a csv file to the current working directory "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell is a example of storing the retrived data into a pandas dataframe and write it into a csv file. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search by some keyword and then filter the data by year/discipline. Get 10k datapoints for 10 different disciplines each.   \n",
    "\n",
    "Potential disciplines to consider: [Math,Physics,Chemetry,Computer science, Aeronautics, Material Science, Civil Engineering, Biology, Medicine, scociology,economics]\n",
    "\n",
    "For each paper, get author ID, perform a search with author ID, get papers and citation count published by the author, calculate H-index.       \n",
    "\n",
    "\n",
    "train Models:        \n",
    "\n",
    "1.Linear Regression (with kernel)           \n",
    "2.NN: fully connected, 1st layer: D * 20, 2nd layer 20 * 1 , activation function: relu, loss: MSE  Try regularization. \n",
    "\n",
    "The following cells demonstrate how to define and train a simple regression model using Pytorch. We will use the data collecred above. The model will be a linear regression model that takes citationCount as input and predicts influentialCitationCount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "X_train = df['citationCount'].to_numpy(dtype=np.float32)\n",
    "y_train = df['influentialCitationCount'].to_numpy(dtype=np.float32)\n",
    "sc = MinMaxScaler() #scale the input so the gradient won't explode. \n",
    "X_train=sc.fit_transform(X_train.reshape(-1,1))\n",
    "y_train =y_train.reshape(-1,1)\n",
    "\n",
    "X_train = torch.from_numpy(X_train)\n",
    "y_train = torch.from_numpy(y_train)\n",
    "\n",
    "input_size,output_size = 1,1\n",
    "\n",
    "class LinearRegressionModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(LinearRegressionModel, self).__init__()\n",
    "        self.linear = torch.nn.Linear(input_size, output_size)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        y_pred = self.linear(x)\n",
    "        return y_pred\n",
    "\n",
    "model = LinearRegressionModel()\n",
    "learning_rate = 0.01\n",
    "l = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr =learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, loss 9078.8662109375\n",
      "epoch 1000, loss 2224.139404296875\n",
      "epoch 2000, loss 1482.6478271484375\n",
      "epoch 3000, loss 1100.35009765625\n",
      "epoch 4000, loss 903.2459716796875\n",
      "epoch 5000, loss 801.622314453125\n",
      "epoch 6000, loss 749.2279663085938\n",
      "epoch 7000, loss 722.2144775390625\n",
      "epoch 8000, loss 708.2868041992188\n",
      "epoch 9000, loss 701.106201171875\n",
      "epoch 10000, loss 697.4038696289062\n",
      "epoch 11000, loss 695.4951171875\n",
      "epoch 12000, loss 694.510986328125\n",
      "epoch 13000, loss 694.0035400390625\n",
      "epoch 14000, loss 693.741943359375\n",
      "epoch 15000, loss 693.6071166992188\n",
      "epoch 16000, loss 693.5374755859375\n",
      "epoch 17000, loss 693.501708984375\n",
      "epoch 18000, loss 693.483154296875\n",
      "epoch 19000, loss 693.4736938476562\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 20000\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "     #forward feed\n",
    "    y_pred = model(X_train.requires_grad_())\n",
    "\n",
    "    #calculate the loss\n",
    "    loss= l(y_pred, y_train)\n",
    "\n",
    "    #backward propagation: calculate gradients\n",
    "    loss.backward()\n",
    "\n",
    "    #update the weights\n",
    "    optimizer.step()\n",
    "\n",
    "    #clear out the gradients from the last step loss.backward()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    if epoch % 1000 == 0:\n",
    "     print('epoch {}, loss {}'.format(epoch, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[457.44882 ],\n",
       "       [325.22952 ],\n",
       "       [155.64798 ],\n",
       "       ...,\n",
       "       [ 33.368767],\n",
       "       [ 35.577686],\n",
       "       [ 29.992285]], dtype=float32)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.forward(X_train).detach().numpy() #make prediction"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8794517f13bcfee9fc9e64fa68815e36a23c0d95e014b70721951cbb766e370b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit (windows store)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
