paperId,abstract,year,referenceCount,citationCount,influentialCitationCount,year0_citation_count,year1_citation_count,year2_citation_count,year3_citation_count,year4_citation_count,year5_citation_count,year6_citation_count,year7_citation_count,year8_citation_count,year9_citation_count
24a931f2000cef230bfc88612223dce1f106f982,"Foreword Preface Acknowledgments List of Figures Units and Acronyms Introduction to UAV Systems Part 1 - The Design of Unmanned Air Vehicle (UAV) Systems Introduction to the Design and Selection of the System Aerodynamics and Airframe Configurations Characteristics of Aircraft Types Design Standards and Regulatory Aspects Aspects of Airframe Design Design for Stealth Payload Types Communications Control and Stability Navigation Launch and Recovery Control Stations Support Equipment Transportation Design for Reliability Part 2 - The Development of UAV Systems Introduction to System Development and Certification System Ground Testing System In-Flight Testing Part 3 - The Deployment of UAV Systems Operational Trials and Full Certification UAV Systems Deployment Army Roles Air Force Roles Civilian, Paramilitary, and Commercial Roles Part 4 - UAS Future Future Prospects and Challenges UAS Continuing Evolution Appendix A - UAS Organizations.",2010,0,537,39,0,14,21,26,42,54,60,70,73,79
05a41f829ffaea938f70518b3d71dadbd0267c01,"In this paper, the recent activity in conceptual design, prototype fabrication, and evaluation of shape morphing wing is concisely classified. Of special interest are concepts which include smart materials such as shape memory alloys (SMA), piezoelectric actuators (PZT), and shape memory polymers (SMP). We will also provide several concepts that have been developed and evaluated by the authors. Our work indicates that antagonistic SMA-actuated flexural structures form a possible enabling technology for wing morphing of small aircraft. The use of SMA-actuated structures in shape morphing wing designs reduces the weight penalty due to the actuation systems, because such SMA-actuated structures carry aerodynamic loads.",2010,56,498,9,9,11,32,48,41,55,55,49,54,48
24a931f2000cef230bfc88612223dce1f106f982,"Foreword Preface Acknowledgments List of Figures Units and Acronyms Introduction to UAV Systems Part 1 - The Design of Unmanned Air Vehicle (UAV) Systems Introduction to the Design and Selection of the System Aerodynamics and Airframe Configurations Characteristics of Aircraft Types Design Standards and Regulatory Aspects Aspects of Airframe Design Design for Stealth Payload Types Communications Control and Stability Navigation Launch and Recovery Control Stations Support Equipment Transportation Design for Reliability Part 2 - The Development of UAV Systems Introduction to System Development and Certification System Ground Testing System In-Flight Testing Part 3 - The Deployment of UAV Systems Operational Trials and Full Certification UAV Systems Deployment Army Roles Air Force Roles Civilian, Paramilitary, and Commercial Roles Part 4 - UAS Future Future Prospects and Challenges UAS Continuing Evolution Appendix A - UAS Organizations.",2010,0,537,39,0,14,21,26,42,54,60,70,73,79
05a41f829ffaea938f70518b3d71dadbd0267c01,"In this paper, the recent activity in conceptual design, prototype fabrication, and evaluation of shape morphing wing is concisely classified. Of special interest are concepts which include smart materials such as shape memory alloys (SMA), piezoelectric actuators (PZT), and shape memory polymers (SMP). We will also provide several concepts that have been developed and evaluated by the authors. Our work indicates that antagonistic SMA-actuated flexural structures form a possible enabling technology for wing morphing of small aircraft. The use of SMA-actuated structures in shape morphing wing designs reduces the weight penalty due to the actuation systems, because such SMA-actuated structures carry aerodynamic loads.",2010,56,498,9,9,11,32,48,41,55,55,49,54,48
24a931f2000cef230bfc88612223dce1f106f982,"Foreword Preface Acknowledgments List of Figures Units and Acronyms Introduction to UAV Systems Part 1 - The Design of Unmanned Air Vehicle (UAV) Systems Introduction to the Design and Selection of the System Aerodynamics and Airframe Configurations Characteristics of Aircraft Types Design Standards and Regulatory Aspects Aspects of Airframe Design Design for Stealth Payload Types Communications Control and Stability Navigation Launch and Recovery Control Stations Support Equipment Transportation Design for Reliability Part 2 - The Development of UAV Systems Introduction to System Development and Certification System Ground Testing System In-Flight Testing Part 3 - The Deployment of UAV Systems Operational Trials and Full Certification UAV Systems Deployment Army Roles Air Force Roles Civilian, Paramilitary, and Commercial Roles Part 4 - UAS Future Future Prospects and Challenges UAS Continuing Evolution Appendix A - UAS Organizations.",2010,0,537,39,0,14,21,26,42,54,60,70,73,79
05a41f829ffaea938f70518b3d71dadbd0267c01,"In this paper, the recent activity in conceptual design, prototype fabrication, and evaluation of shape morphing wing is concisely classified. Of special interest are concepts which include smart materials such as shape memory alloys (SMA), piezoelectric actuators (PZT), and shape memory polymers (SMP). We will also provide several concepts that have been developed and evaluated by the authors. Our work indicates that antagonistic SMA-actuated flexural structures form a possible enabling technology for wing morphing of small aircraft. The use of SMA-actuated structures in shape morphing wing designs reduces the weight penalty due to the actuation systems, because such SMA-actuated structures carry aerodynamic loads.",2010,56,498,9,9,11,32,48,41,55,55,49,54,48
24a931f2000cef230bfc88612223dce1f106f982,"Foreword Preface Acknowledgments List of Figures Units and Acronyms Introduction to UAV Systems Part 1 - The Design of Unmanned Air Vehicle (UAV) Systems Introduction to the Design and Selection of the System Aerodynamics and Airframe Configurations Characteristics of Aircraft Types Design Standards and Regulatory Aspects Aspects of Airframe Design Design for Stealth Payload Types Communications Control and Stability Navigation Launch and Recovery Control Stations Support Equipment Transportation Design for Reliability Part 2 - The Development of UAV Systems Introduction to System Development and Certification System Ground Testing System In-Flight Testing Part 3 - The Deployment of UAV Systems Operational Trials and Full Certification UAV Systems Deployment Army Roles Air Force Roles Civilian, Paramilitary, and Commercial Roles Part 4 - UAS Future Future Prospects and Challenges UAS Continuing Evolution Appendix A - UAS Organizations.",2010,0,537,39,0,14,21,26,42,54,60,70,73,79
05a41f829ffaea938f70518b3d71dadbd0267c01,"In this paper, the recent activity in conceptual design, prototype fabrication, and evaluation of shape morphing wing is concisely classified. Of special interest are concepts which include smart materials such as shape memory alloys (SMA), piezoelectric actuators (PZT), and shape memory polymers (SMP). We will also provide several concepts that have been developed and evaluated by the authors. Our work indicates that antagonistic SMA-actuated flexural structures form a possible enabling technology for wing morphing of small aircraft. The use of SMA-actuated structures in shape morphing wing designs reduces the weight penalty due to the actuation systems, because such SMA-actuated structures carry aerodynamic loads.",2010,56,498,9,9,11,32,48,41,55,55,49,54,48
24a931f2000cef230bfc88612223dce1f106f982,"Foreword Preface Acknowledgments List of Figures Units and Acronyms Introduction to UAV Systems Part 1 - The Design of Unmanned Air Vehicle (UAV) Systems Introduction to the Design and Selection of the System Aerodynamics and Airframe Configurations Characteristics of Aircraft Types Design Standards and Regulatory Aspects Aspects of Airframe Design Design for Stealth Payload Types Communications Control and Stability Navigation Launch and Recovery Control Stations Support Equipment Transportation Design for Reliability Part 2 - The Development of UAV Systems Introduction to System Development and Certification System Ground Testing System In-Flight Testing Part 3 - The Deployment of UAV Systems Operational Trials and Full Certification UAV Systems Deployment Army Roles Air Force Roles Civilian, Paramilitary, and Commercial Roles Part 4 - UAS Future Future Prospects and Challenges UAS Continuing Evolution Appendix A - UAS Organizations.",2010,0,537,39,0,14,21,26,42,54,60,70,73,79
05a41f829ffaea938f70518b3d71dadbd0267c01,"In this paper, the recent activity in conceptual design, prototype fabrication, and evaluation of shape morphing wing is concisely classified. Of special interest are concepts which include smart materials such as shape memory alloys (SMA), piezoelectric actuators (PZT), and shape memory polymers (SMP). We will also provide several concepts that have been developed and evaluated by the authors. Our work indicates that antagonistic SMA-actuated flexural structures form a possible enabling technology for wing morphing of small aircraft. The use of SMA-actuated structures in shape morphing wing designs reduces the weight penalty due to the actuation systems, because such SMA-actuated structures carry aerodynamic loads.",2010,56,498,9,9,11,32,48,41,55,55,49,54,48
24a931f2000cef230bfc88612223dce1f106f982,"Foreword Preface Acknowledgments List of Figures Units and Acronyms Introduction to UAV Systems Part 1 - The Design of Unmanned Air Vehicle (UAV) Systems Introduction to the Design and Selection of the System Aerodynamics and Airframe Configurations Characteristics of Aircraft Types Design Standards and Regulatory Aspects Aspects of Airframe Design Design for Stealth Payload Types Communications Control and Stability Navigation Launch and Recovery Control Stations Support Equipment Transportation Design for Reliability Part 2 - The Development of UAV Systems Introduction to System Development and Certification System Ground Testing System In-Flight Testing Part 3 - The Deployment of UAV Systems Operational Trials and Full Certification UAV Systems Deployment Army Roles Air Force Roles Civilian, Paramilitary, and Commercial Roles Part 4 - UAS Future Future Prospects and Challenges UAS Continuing Evolution Appendix A - UAS Organizations.",2010,0,537,39,0,14,21,26,42,54,60,70,73,79
05a41f829ffaea938f70518b3d71dadbd0267c01,"In this paper, the recent activity in conceptual design, prototype fabrication, and evaluation of shape morphing wing is concisely classified. Of special interest are concepts which include smart materials such as shape memory alloys (SMA), piezoelectric actuators (PZT), and shape memory polymers (SMP). We will also provide several concepts that have been developed and evaluated by the authors. Our work indicates that antagonistic SMA-actuated flexural structures form a possible enabling technology for wing morphing of small aircraft. The use of SMA-actuated structures in shape morphing wing designs reduces the weight penalty due to the actuation systems, because such SMA-actuated structures carry aerodynamic loads.",2010,56,498,9,9,11,32,48,41,55,55,49,54,48
24a931f2000cef230bfc88612223dce1f106f982,"Foreword Preface Acknowledgments List of Figures Units and Acronyms Introduction to UAV Systems Part 1 - The Design of Unmanned Air Vehicle (UAV) Systems Introduction to the Design and Selection of the System Aerodynamics and Airframe Configurations Characteristics of Aircraft Types Design Standards and Regulatory Aspects Aspects of Airframe Design Design for Stealth Payload Types Communications Control and Stability Navigation Launch and Recovery Control Stations Support Equipment Transportation Design for Reliability Part 2 - The Development of UAV Systems Introduction to System Development and Certification System Ground Testing System In-Flight Testing Part 3 - The Deployment of UAV Systems Operational Trials and Full Certification UAV Systems Deployment Army Roles Air Force Roles Civilian, Paramilitary, and Commercial Roles Part 4 - UAS Future Future Prospects and Challenges UAS Continuing Evolution Appendix A - UAS Organizations.",2010,0,537,39,0,14,21,26,42,54,60,70,73,79
24a931f2000cef230bfc88612223dce1f106f982,"Foreword Preface Acknowledgments List of Figures Units and Acronyms Introduction to UAV Systems Part 1 - The Design of Unmanned Air Vehicle (UAV) Systems Introduction to the Design and Selection of the System Aerodynamics and Airframe Configurations Characteristics of Aircraft Types Design Standards and Regulatory Aspects Aspects of Airframe Design Design for Stealth Payload Types Communications Control and Stability Navigation Launch and Recovery Control Stations Support Equipment Transportation Design for Reliability Part 2 - The Development of UAV Systems Introduction to System Development and Certification System Ground Testing System In-Flight Testing Part 3 - The Deployment of UAV Systems Operational Trials and Full Certification UAV Systems Deployment Army Roles Air Force Roles Civilian, Paramilitary, and Commercial Roles Part 4 - UAS Future Future Prospects and Challenges UAS Continuing Evolution Appendix A - UAS Organizations.",2010,0,537,39,0,14,21,26,42,54,60,70,73,79
05a41f829ffaea938f70518b3d71dadbd0267c01,"In this paper, the recent activity in conceptual design, prototype fabrication, and evaluation of shape morphing wing is concisely classified. Of special interest are concepts which include smart materials such as shape memory alloys (SMA), piezoelectric actuators (PZT), and shape memory polymers (SMP). We will also provide several concepts that have been developed and evaluated by the authors. Our work indicates that antagonistic SMA-actuated flexural structures form a possible enabling technology for wing morphing of small aircraft. The use of SMA-actuated structures in shape morphing wing designs reduces the weight penalty due to the actuation systems, because such SMA-actuated structures carry aerodynamic loads.",2010,56,498,9,9,11,32,48,41,55,55,49,54,48
24a931f2000cef230bfc88612223dce1f106f982,"Foreword Preface Acknowledgments List of Figures Units and Acronyms Introduction to UAV Systems Part 1 - The Design of Unmanned Air Vehicle (UAV) Systems Introduction to the Design and Selection of the System Aerodynamics and Airframe Configurations Characteristics of Aircraft Types Design Standards and Regulatory Aspects Aspects of Airframe Design Design for Stealth Payload Types Communications Control and Stability Navigation Launch and Recovery Control Stations Support Equipment Transportation Design for Reliability Part 2 - The Development of UAV Systems Introduction to System Development and Certification System Ground Testing System In-Flight Testing Part 3 - The Deployment of UAV Systems Operational Trials and Full Certification UAV Systems Deployment Army Roles Air Force Roles Civilian, Paramilitary, and Commercial Roles Part 4 - UAS Future Future Prospects and Challenges UAS Continuing Evolution Appendix A - UAS Organizations.",2010,0,537,39,0,14,21,26,42,54,60,70,73,79
05a41f829ffaea938f70518b3d71dadbd0267c01,"In this paper, the recent activity in conceptual design, prototype fabrication, and evaluation of shape morphing wing is concisely classified. Of special interest are concepts which include smart materials such as shape memory alloys (SMA), piezoelectric actuators (PZT), and shape memory polymers (SMP). We will also provide several concepts that have been developed and evaluated by the authors. Our work indicates that antagonistic SMA-actuated flexural structures form a possible enabling technology for wing morphing of small aircraft. The use of SMA-actuated structures in shape morphing wing designs reduces the weight penalty due to the actuation systems, because such SMA-actuated structures carry aerodynamic loads.",2010,56,498,9,9,11,32,48,41,55,55,49,54,48
24a931f2000cef230bfc88612223dce1f106f982,"Foreword Preface Acknowledgments List of Figures Units and Acronyms Introduction to UAV Systems Part 1 - The Design of Unmanned Air Vehicle (UAV) Systems Introduction to the Design and Selection of the System Aerodynamics and Airframe Configurations Characteristics of Aircraft Types Design Standards and Regulatory Aspects Aspects of Airframe Design Design for Stealth Payload Types Communications Control and Stability Navigation Launch and Recovery Control Stations Support Equipment Transportation Design for Reliability Part 2 - The Development of UAV Systems Introduction to System Development and Certification System Ground Testing System In-Flight Testing Part 3 - The Deployment of UAV Systems Operational Trials and Full Certification UAV Systems Deployment Army Roles Air Force Roles Civilian, Paramilitary, and Commercial Roles Part 4 - UAS Future Future Prospects and Challenges UAS Continuing Evolution Appendix A - UAS Organizations.",2010,0,537,39,0,14,21,26,42,54,60,70,73,79
05a41f829ffaea938f70518b3d71dadbd0267c01,"In this paper, the recent activity in conceptual design, prototype fabrication, and evaluation of shape morphing wing is concisely classified. Of special interest are concepts which include smart materials such as shape memory alloys (SMA), piezoelectric actuators (PZT), and shape memory polymers (SMP). We will also provide several concepts that have been developed and evaluated by the authors. Our work indicates that antagonistic SMA-actuated flexural structures form a possible enabling technology for wing morphing of small aircraft. The use of SMA-actuated structures in shape morphing wing designs reduces the weight penalty due to the actuation systems, because such SMA-actuated structures carry aerodynamic loads.",2010,56,498,9,9,11,32,48,41,55,55,49,54,48
08236a76e2355ee36c154f51b6b2159e054a3191,*Introduction. *Conservation Laws of Fluid Motion and Boundary Conditions. *Turbulence and its Modelling. *The Finite Volume Method for Diffusion Problems. *The Finite Volume Method for Convection-Diffusion Problems. *Solution Algorithms for Pressure-Velocity Coupling in Steady Flows. *Solution of Discretised Equations. *The Finite Volume Method for Unsteady Flows. *Implementation of Boundary Conditions. *Advanced topics and applications. Appendices. References. Index.,2007,0,7124,527,194,239,276,330,368,429,451,568,552,526
65afba3daff41d488f11e017bc02ba99854e52b7,"We present an overview of the lattice Boltzmann method (LBM), a parallel and efficient algorithm for simulating single-phase and multiphase fluid flows and for incorporating additional physical complexities. The LBM is especially useful for modeling complicated boundary conditions and multiphase interfaces. Recent extensions of this method are described, including simulations of fluid turbulence, suspension flows, and reaction diffusion systems.",2001,184,6063,218,62,109,118,114,142,211,241,226,290,295
e0069fc257328c8f362a5e4c37c59f19eb719523,,2003,0,3650,223,53,79,107,171,156,168,222,241,267,223
37491ed087839d86c9ba7783cb12ccc6c9918bf6,"Microfabricated integrated circuits revolutionized computation by vastly reducing the space, labor, and time required for calculations. Microfluidic systems hold similar promise for the large-scale automation of chemistry and biology, suggesting the possibility of numerous experiments performed rapidly and in parallel, while consuming little reagent. While it is too early to tell whether such a vision will be realized, significant progress has been achieved, and various applications of significant scientific and practical interest have been developed. Here a review of the physics of small volumes (nanoliters) of fluids is presented, as parametrized by a series of dimensionless numbers expressing the relative importance of various physical phenomena. Specifically, this review explores the Reynolds number Re, addressing inertial effects; the Peclet number Pe, which concerns convective and diffusive transport; the capillary number Ca expressing the importance of interfacial tension; the Deborah, Weissenberg, and elasticity numbers De, Wi, and El, describing elastic effects due to deformable microstructural elements like polymers; the Grashof and Rayleigh numbers Gr and Ra, describing density-driven flows; and the Knudsen number, describing the importance of noncontinuum molecular effects. Furthermore, the long-range nature of viscous flows and the small device dimensions inherent in microfluidics mean that the influence of boundaries is typically significant. A variety of strategies have been developed to manipulate fluids by exploiting boundary effects; among these are electrokinetic effects, acoustic streaming, and fluid-structure interactions. The goal is to describe the physics behind the rich variety of fluid phenomena occurring on the nanoliter scale using simple scaling arguments, with the hopes of developing an intuitive sense for this occasionally counterintuitive world.",2005,1080,3428,70,17,77,129,221,219,226,241,278,285,260
f14b8ef5a3edc5fdc9613a8a1c5545aa6cb626ad,"This Position Stand provides guidance on fluid replacement to sustain appropriate hydration of individuals performing physical activity. The goal of prehydrating is to start the activity euhydrated and with normal plasma electrolyte levels. Prehydrating with beverages, in addition to normal meals and fluid intake, should be initiated when needed at least several hours before the activity to enable fluid absorption and allow urine output to return to normal levels. The goal of drinking during exercise is to prevent excessive (>2% body weight loss from water deficit) dehydration and excessive changes in electrolyte balance to avert compromised performance. Because there is considerable variability in sweating rates and sweat electrolyte content between individuals, customized fluid replacement programs are recommended. Individual sweat rates can be estimated by measuring body weight before and after exercise. During exercise, consuming beverages containing electrolytes and carbohydrates can provide benefits over water alone under certain circumstances. After exercise, the goal is to replace any fluid electrolyte deficit. The speed with which rehydration is needed and the magnitude of fluid electrolyte deficits will determine if an aggressive replacement program is merited.",2007,10,1798,207,36,62,53,93,111,114,140,150,158,152
662ac20e8d8b980582c513b38dd964cc56b40e05,,2009,0,1648,162,94,74,105,117,140,138,140,120,110,149
c7342bc120397c23c3f777e7cfeb0d76b76637e5,"Intense multidisciplinary research has provided detailed knowledge of the molecular pathogenesis of Alzheimer disease (AD). This knowledge has been translated into new therapeutic strategies with putative disease-modifying effects. Several of the most promising approaches, such as amyloid-β immunotherapy and secretase inhibition, are now being tested in clinical trials. Disease-modifying treatments might be at their most effective when initiated very early in the course of AD, before amyloid plaques and neurodegeneration become too widespread. Thus, biomarkers are needed that can detect AD in the predementia phase or, ideally, in presymptomatic individuals. In this Review, we present the rationales behind and the diagnostic performances of the core cerebrospinal fluid (CSF) biomarkers for AD, namely total tau, phosphorylated tau and the 42 amino acid form of amyloid-β. These biomarkers reflect AD pathology, and are candidate markers for predicting future cognitive decline in healthy individuals and the progression to dementia in patients who are cognitively impaired. We also discuss emerging plasma and CSF biomarkers, and explore new proteomics-based strategies for identifying additional CSF markers. Furthermore, we outline the roles of CSF biomarkers in drug discovery and clinical trials, and provide perspectives on AD biomarker discovery and the validation of such markers for use in the clinic.",2010,198,1523,48,44,90,139,137,156,156,121,155,166,142
2e776c3af634ab4ff40a67e6295efcf3a3879848,"Fluid intelligence (Gf) refers to the ability to reason and to solve new problems independently of previously acquired knowledge. Gf is critical for a wide variety of cognitive tasks, and it is considered one of the most important factors in learning. Moreover, Gf is closely related to professional and educational success, especially in complex and demanding environments. Although performance on tests of Gf can be improved through direct practice on the tests themselves, there is no evidence that training on any other regimen yields increased Gf in adults. Furthermore, there is a long history of research into cognitive training showing that, although performance on trained tasks can increase dramatically, transfer of this learning to other tasks remains poor. Here, we present evidence for transfer from training on a demanding working memory task to measures of Gf. This transfer results even though the trained task is entirely different from the intelligence test itself. Furthermore, we demonstrate that the extent of gain in intelligence critically depends on the amount of training: the more training, the more improvement in Gf. That is, the training effect is dosage-dependent. Thus, in contrast to many previous studies, we conclude that it is possible to improve Gf without practicing the testing tasks themselves, opening a wide range of applications.",2008,58,1893,133,17,56,77,108,154,163,195,176,152,178
365bc7651a03fa1c1c02dbd72d800a1d97855484,Develop a cerebrospinal fluid biomarker signature for mild Alzheimer's disease (AD) in Alzheimer's Disease Neuroimaging Initiative (ADNI) subjects.,2009,34,1762,77,25,110,156,141,137,146,171,138,158,148
16373b46351bfeb596128a1c49249e44a47ee77e,"Fluid models of gas discharges require the input of transport coefficients and rate coefficients that depend on the electron energy distribution function. Such coefficients are usually calculated from collision cross-section data by solving the electron Boltzmann equation (BE). In this paper we present a new user-friendly BE solver developed especially for this purpose, freely available under the name BOLSIG+, which is more general and easier to use than most other BE solvers available. The solver provides steady-state solutions of the BE for electrons in a uniform electric field, using the classical two-term expansion, and is able to account for different growth models, quasi-stationary and oscillating fields, electron–neutral collisions and electron–electron collisions. We show that for the approximations we use, the BE takes the form of a convection-diffusion continuity-equation with a non-local source term in energy space. To solve this equation we use an exponential scheme commonly used for convection-diffusion problems. The calculated electron transport coefficients and rate coefficients are defined so as to ensure maximum consistency with the fluid equations. We discuss how these coefficients are best used in fluid models and illustrate the influence of some essential parameters and approximations.",2005,33,2086,92,4,11,26,27,49,56,80,93,114,160
48383c4b50853ff1afab6ecb9745c247a97ba6e1,"BACKGROUND
It remains uncertain whether the choice of resuscitation fluid for patients in intensive care units (ICUs) affects survival. We conducted a multicenter, randomized, double-blind trial to compare the effect of fluid resuscitation with albumin or saline on mortality in a heterogeneous population of patients in the ICU.


METHODS
We randomly assigned patients who had been admitted to the ICU to receive either 4 percent albumin or normal saline for intravascular-fluid resuscitation during the next 28 days. The primary outcome measure was death from any cause during the 28-day period after randomization.


RESULTS
Of the 6997 patients who underwent randomization, 3497 were assigned to receive albumin and 3500 to receive saline; the two groups had similar baseline characteristics. There were 726 deaths in the albumin group, as compared with 729 deaths in the saline group (relative risk of death, 0.99; 95 percent confidence interval, 0.91 to 1.09; P=0.87). The proportion of patients with new single-organ and multiple-organ failure was similar in the two groups (P=0.85). There were no significant differences between the groups in the mean (+/-SD) numbers of days spent in the ICU (6.5+/-6.6 in the albumin group and 6.2+/-6.2 in the saline group, P=0.44), days spent in the hospital (15.3+/-9.6 and 15.6+/-9.6, respectively; P=0.30), days of mechanical ventilation (4.5+/-6.1 and 4.3+/-5.7, respectively; P=0.74), or days of renal-replacement therapy (0.5+/-2.3 and 0.4+/-2.0, respectively; P=0.41).


CONCLUSIONS
In patients in the ICU, use of either 4 percent albumin or normal saline for fluid resuscitation results in similar outcomes at 28 days.",2004,28,2297,38,31,102,129,135,140,127,160,140,133,169
d26eccb48c61a051378678dfbb5b5943683fcaed,"Background Optimal fluid management in patients with acute lung injury is unknown. Diuresis or fluid restriction may improve lung function but could jeopardize extrapulmonary-organ perfusion. Methods In a randomized study, we compared a conservative and a liberal strategy of fluid management using explicit protocols applied for seven days in 1000 patients with acute lung injury. The primary end point was death at 60 days. Secondary end points included the number of ventilator-free days and organ-failure–free days and measures of lung physiology. Results The rate of death at 60 days was 25.5 percent in the conservative-strategy group and 28.4 percent in the liberal-strategy group (P=0.30; 95 percent confidence interval for the difference, −2.6 to 8.4 percent). The mean (±SE) cumulative fluid balance during the first seven days was –136±491 ml in the conservative-strategy group and 6992±502 ml in the liberal-strategy group (P<0.001). As compared with the liberal strategy, the conservative strategy improved ...",2009,32,1770,1,93,127,112,142,126,122,93,124,120,115
e28e5bd7634c45b775d915dbb39185d73ef58439,"Inkjet printing is viewed as a versatile manufacturing tool for applications in materials fabrication in addition to its traditional role in graphics output and marking. The unifying feature in all these applications is the dispensing and precise positioning of very small volumes of fluid (1–100 picoliters) on a substrate before transformation to a solid. The application of inkjet printing to the fabrication of structures for structural or functional materials applications requires an understanding as to how the physical processes that operate during inkjet printing interact with the properties of the fluid precursors used. Here we review the current state of understanding of the mechanisms of drop formation and how this defines the fluid properties that are required for a given liquid to be printable. The interactions between individual drops and the substrate as well as between adjacent drops are important in defining the resolution and accuracy of printed objects. Pattern resolution is limited by the extent to which a liquid drop spreads on a substrate and how spreading changes with the overlap of adjacent drops to form continuous features. There are clearly defined upper and lower bounds to the width of a printed continuous line, which can be defined in terms of materials and process variables. Finer-resolution features can be achieved through appropriate patterning and structuring of the substrate prior to printing, which is essential if polymeric semiconducting devices are to be fabricated. Low advancing and receding contact angles promote printed line stability but are also more prone to solute segregation or “coffee staining” on drying.",2010,56,1160,49,2,17,46,44,58,85,103,131,139,179
b721f6ba0e10507f1d25b76c3eb37380d16a31a2,This study develops analytical relationships and computations of power dissipation in magnetic fluid (ferrofluid) subjected to alternating magnetic field. The dissipation results from the orientational relaxation of particles having thermal fluctuations in a viscous medium.,2002,20,1779,95,2,5,8,13,23,28,36,68,81,92
6635fa7b37888f0f90c64afdfcb8ca09d3ae974f,"Many solid tumours show an increased interstitial fluid pressure (IFP), which forms a barrier to transcapillary transport. This barrier is an obstacle in tumour treatment, as it results in inefficient uptake of therapeutic agents. There are a number of factors that contribute to increased IFP in the tumour, such as vessel abnormalities, fibrosis and contraction of the interstitial matrix. Lowering the tumour IFP with specific signal-transduction antagonists might be a useful approach to improving anticancer drug efficacy.",2004,90,1642,63,0,18,37,44,48,50,69,81,97,123
179e0701b833052c3bdf4423c060ca2f68e7d891,"1. Kinematics, conservation equations, and boundary conditions for incompressible flow 2. Unidirectional flow 3. Hydraulic circuit analysis 4. Passive scalar transport: dispersion, patterning, and mixing 5. Electrostatics and electrodynamics 6. Electroosmosis 7. Potential fluid flow 8. Stikes flow 9. The diffuse structure of the electrical double layer 10. Zeta potential in microchannels 11. Species and charge transport 12. Microchip chemical separations 13. Particle electrophoresis 14. DNA transport and analysis 15. Nanofluidics: fluid and current flow in molecular-scale and thick-double-layer systems 16. AC electrokinetics and the dynamics of diffuse charge 17. Particle and droplet actuation: dielectrophoresis, magnetophoresis, and digital microfluidics Appendices: A. Units and fundamental constants B. Properties of electrolyte solutions C. Coordinate systems and vector calculus D. Governing equation reference E. Nondimensionalization and characteristic parameters F. Multipolar solutions to the Laplace and Stokes equations G. Complex functions H. Interaction potentials: atomistic modeling of solvents and solutes.",2010,1,860,45,5,37,57,88,97,100,91,85,90,94
e51ab939cf5a2faf79ae169f2b794bc27f31cfae,,2006,0,1249,190,3,4,27,30,57,72,76,93,73,105
66fbc867a7a5faf4773581ccb3a2918a0706e1db,"BACKGROUND
Optimal fluid management in patients with acute lung injury is unknown. Diuresis or fluid restriction may improve lung function but could jeopardize extrapulmonary-organ perfusion.


METHODS
In a randomized study, we compared a conservative and a liberal strategy of fluid management using explicit protocols applied for seven days in 1000 patients with acute lung injury. The primary end point was death at 60 days. Secondary end points included the number of ventilator-free days and organ-failure-free days and measures of lung physiology.


RESULTS
The rate of death at 60 days was 25.5 percent in the conservative-strategy group and 28.4 percent in the liberal-strategy group (P=0.30; 95 percent confidence interval for the difference, -2.6 to 8.4 percent). The mean (+/-SE) cumulative fluid balance during the first seven days was -136+/-491 ml in the conservative-strategy group and 6992+/-502 ml in the liberal-strategy group (P<0.001). As compared with the liberal strategy, the conservative strategy improved the oxygenation index ([mean airway pressure x the ratio of the fraction of inspired oxygen to the partial pressure of arterial oxygen]x100) and the lung injury score and increased the number of ventilator-free days (14.6+/-0.5 vs. 12.1+/-0.5, P<0.001) and days not spent in the intensive care unit (13.4+/-0.4 vs. 11.2+/-0.4, P<0.001) during the first 28 days but did not increase the incidence or prevalence of shock during the study or the use of dialysis during the first 60 days (10 percent vs. 14 percent, P=0.06).


CONCLUSIONS
Although there was no significant difference in the primary outcome of 60-day mortality, the conservative strategy of fluid management improved lung function and shortened the duration of mechanical ventilation and intensive care without increasing nonpulmonary-organ failures. These results support the use of a conservative strategy of fluid management in patients with acute lung injury. (ClinicalTrials.gov number, NCT00281268 [ClinicalTrials.gov].).",2006,59,1413,48,11,34,60,77,85,93,110,133,120,112
08236a76e2355ee36c154f51b6b2159e054a3191,*Introduction. *Conservation Laws of Fluid Motion and Boundary Conditions. *Turbulence and its Modelling. *The Finite Volume Method for Diffusion Problems. *The Finite Volume Method for Convection-Diffusion Problems. *Solution Algorithms for Pressure-Velocity Coupling in Steady Flows. *Solution of Discretised Equations. *The Finite Volume Method for Unsteady Flows. *Implementation of Boundary Conditions. *Advanced topics and applications. Appendices. References. Index.,2007,0,7124,527,194,239,276,330,368,429,451,568,552,526
65afba3daff41d488f11e017bc02ba99854e52b7,"We present an overview of the lattice Boltzmann method (LBM), a parallel and efficient algorithm for simulating single-phase and multiphase fluid flows and for incorporating additional physical complexities. The LBM is especially useful for modeling complicated boundary conditions and multiphase interfaces. Recent extensions of this method are described, including simulations of fluid turbulence, suspension flows, and reaction diffusion systems.",2001,184,6063,218,62,109,118,114,142,211,241,226,290,295
e0069fc257328c8f362a5e4c37c59f19eb719523,,2003,0,3650,223,53,79,107,171,156,168,222,241,267,223
37491ed087839d86c9ba7783cb12ccc6c9918bf6,"Microfabricated integrated circuits revolutionized computation by vastly reducing the space, labor, and time required for calculations. Microfluidic systems hold similar promise for the large-scale automation of chemistry and biology, suggesting the possibility of numerous experiments performed rapidly and in parallel, while consuming little reagent. While it is too early to tell whether such a vision will be realized, significant progress has been achieved, and various applications of significant scientific and practical interest have been developed. Here a review of the physics of small volumes (nanoliters) of fluids is presented, as parametrized by a series of dimensionless numbers expressing the relative importance of various physical phenomena. Specifically, this review explores the Reynolds number Re, addressing inertial effects; the Peclet number Pe, which concerns convective and diffusive transport; the capillary number Ca expressing the importance of interfacial tension; the Deborah, Weissenberg, and elasticity numbers De, Wi, and El, describing elastic effects due to deformable microstructural elements like polymers; the Grashof and Rayleigh numbers Gr and Ra, describing density-driven flows; and the Knudsen number, describing the importance of noncontinuum molecular effects. Furthermore, the long-range nature of viscous flows and the small device dimensions inherent in microfluidics mean that the influence of boundaries is typically significant. A variety of strategies have been developed to manipulate fluids by exploiting boundary effects; among these are electrokinetic effects, acoustic streaming, and fluid-structure interactions. The goal is to describe the physics behind the rich variety of fluid phenomena occurring on the nanoliter scale using simple scaling arguments, with the hopes of developing an intuitive sense for this occasionally counterintuitive world.",2005,1080,3428,70,17,77,129,221,219,226,241,278,285,260
f14b8ef5a3edc5fdc9613a8a1c5545aa6cb626ad,"This Position Stand provides guidance on fluid replacement to sustain appropriate hydration of individuals performing physical activity. The goal of prehydrating is to start the activity euhydrated and with normal plasma electrolyte levels. Prehydrating with beverages, in addition to normal meals and fluid intake, should be initiated when needed at least several hours before the activity to enable fluid absorption and allow urine output to return to normal levels. The goal of drinking during exercise is to prevent excessive (>2% body weight loss from water deficit) dehydration and excessive changes in electrolyte balance to avert compromised performance. Because there is considerable variability in sweating rates and sweat electrolyte content between individuals, customized fluid replacement programs are recommended. Individual sweat rates can be estimated by measuring body weight before and after exercise. During exercise, consuming beverages containing electrolytes and carbohydrates can provide benefits over water alone under certain circumstances. After exercise, the goal is to replace any fluid electrolyte deficit. The speed with which rehydration is needed and the magnitude of fluid electrolyte deficits will determine if an aggressive replacement program is merited.",2007,10,1798,207,36,62,53,93,111,114,140,150,158,152
662ac20e8d8b980582c513b38dd964cc56b40e05,,2009,0,1648,162,94,74,105,117,140,138,140,120,110,149
c7342bc120397c23c3f777e7cfeb0d76b76637e5,"Intense multidisciplinary research has provided detailed knowledge of the molecular pathogenesis of Alzheimer disease (AD). This knowledge has been translated into new therapeutic strategies with putative disease-modifying effects. Several of the most promising approaches, such as amyloid-β immunotherapy and secretase inhibition, are now being tested in clinical trials. Disease-modifying treatments might be at their most effective when initiated very early in the course of AD, before amyloid plaques and neurodegeneration become too widespread. Thus, biomarkers are needed that can detect AD in the predementia phase or, ideally, in presymptomatic individuals. In this Review, we present the rationales behind and the diagnostic performances of the core cerebrospinal fluid (CSF) biomarkers for AD, namely total tau, phosphorylated tau and the 42 amino acid form of amyloid-β. These biomarkers reflect AD pathology, and are candidate markers for predicting future cognitive decline in healthy individuals and the progression to dementia in patients who are cognitively impaired. We also discuss emerging plasma and CSF biomarkers, and explore new proteomics-based strategies for identifying additional CSF markers. Furthermore, we outline the roles of CSF biomarkers in drug discovery and clinical trials, and provide perspectives on AD biomarker discovery and the validation of such markers for use in the clinic.",2010,198,1523,48,44,90,139,137,156,156,121,155,166,142
2e776c3af634ab4ff40a67e6295efcf3a3879848,"Fluid intelligence (Gf) refers to the ability to reason and to solve new problems independently of previously acquired knowledge. Gf is critical for a wide variety of cognitive tasks, and it is considered one of the most important factors in learning. Moreover, Gf is closely related to professional and educational success, especially in complex and demanding environments. Although performance on tests of Gf can be improved through direct practice on the tests themselves, there is no evidence that training on any other regimen yields increased Gf in adults. Furthermore, there is a long history of research into cognitive training showing that, although performance on trained tasks can increase dramatically, transfer of this learning to other tasks remains poor. Here, we present evidence for transfer from training on a demanding working memory task to measures of Gf. This transfer results even though the trained task is entirely different from the intelligence test itself. Furthermore, we demonstrate that the extent of gain in intelligence critically depends on the amount of training: the more training, the more improvement in Gf. That is, the training effect is dosage-dependent. Thus, in contrast to many previous studies, we conclude that it is possible to improve Gf without practicing the testing tasks themselves, opening a wide range of applications.",2008,58,1893,133,17,56,77,108,154,163,195,176,152,178
365bc7651a03fa1c1c02dbd72d800a1d97855484,Develop a cerebrospinal fluid biomarker signature for mild Alzheimer's disease (AD) in Alzheimer's Disease Neuroimaging Initiative (ADNI) subjects.,2009,34,1762,77,25,110,156,141,137,146,171,138,158,148
16373b46351bfeb596128a1c49249e44a47ee77e,"Fluid models of gas discharges require the input of transport coefficients and rate coefficients that depend on the electron energy distribution function. Such coefficients are usually calculated from collision cross-section data by solving the electron Boltzmann equation (BE). In this paper we present a new user-friendly BE solver developed especially for this purpose, freely available under the name BOLSIG+, which is more general and easier to use than most other BE solvers available. The solver provides steady-state solutions of the BE for electrons in a uniform electric field, using the classical two-term expansion, and is able to account for different growth models, quasi-stationary and oscillating fields, electron–neutral collisions and electron–electron collisions. We show that for the approximations we use, the BE takes the form of a convection-diffusion continuity-equation with a non-local source term in energy space. To solve this equation we use an exponential scheme commonly used for convection-diffusion problems. The calculated electron transport coefficients and rate coefficients are defined so as to ensure maximum consistency with the fluid equations. We discuss how these coefficients are best used in fluid models and illustrate the influence of some essential parameters and approximations.",2005,33,2086,92,4,11,26,27,49,56,80,93,114,160
48383c4b50853ff1afab6ecb9745c247a97ba6e1,"BACKGROUND
It remains uncertain whether the choice of resuscitation fluid for patients in intensive care units (ICUs) affects survival. We conducted a multicenter, randomized, double-blind trial to compare the effect of fluid resuscitation with albumin or saline on mortality in a heterogeneous population of patients in the ICU.


METHODS
We randomly assigned patients who had been admitted to the ICU to receive either 4 percent albumin or normal saline for intravascular-fluid resuscitation during the next 28 days. The primary outcome measure was death from any cause during the 28-day period after randomization.


RESULTS
Of the 6997 patients who underwent randomization, 3497 were assigned to receive albumin and 3500 to receive saline; the two groups had similar baseline characteristics. There were 726 deaths in the albumin group, as compared with 729 deaths in the saline group (relative risk of death, 0.99; 95 percent confidence interval, 0.91 to 1.09; P=0.87). The proportion of patients with new single-organ and multiple-organ failure was similar in the two groups (P=0.85). There were no significant differences between the groups in the mean (+/-SD) numbers of days spent in the ICU (6.5+/-6.6 in the albumin group and 6.2+/-6.2 in the saline group, P=0.44), days spent in the hospital (15.3+/-9.6 and 15.6+/-9.6, respectively; P=0.30), days of mechanical ventilation (4.5+/-6.1 and 4.3+/-5.7, respectively; P=0.74), or days of renal-replacement therapy (0.5+/-2.3 and 0.4+/-2.0, respectively; P=0.41).


CONCLUSIONS
In patients in the ICU, use of either 4 percent albumin or normal saline for fluid resuscitation results in similar outcomes at 28 days.",2004,28,2297,38,31,102,129,135,140,127,160,140,133,169
d26eccb48c61a051378678dfbb5b5943683fcaed,"Background Optimal fluid management in patients with acute lung injury is unknown. Diuresis or fluid restriction may improve lung function but could jeopardize extrapulmonary-organ perfusion. Methods In a randomized study, we compared a conservative and a liberal strategy of fluid management using explicit protocols applied for seven days in 1000 patients with acute lung injury. The primary end point was death at 60 days. Secondary end points included the number of ventilator-free days and organ-failure–free days and measures of lung physiology. Results The rate of death at 60 days was 25.5 percent in the conservative-strategy group and 28.4 percent in the liberal-strategy group (P=0.30; 95 percent confidence interval for the difference, −2.6 to 8.4 percent). The mean (±SE) cumulative fluid balance during the first seven days was –136±491 ml in the conservative-strategy group and 6992±502 ml in the liberal-strategy group (P<0.001). As compared with the liberal strategy, the conservative strategy improved ...",2009,32,1770,1,93,127,112,142,126,122,93,124,120,115
e28e5bd7634c45b775d915dbb39185d73ef58439,"Inkjet printing is viewed as a versatile manufacturing tool for applications in materials fabrication in addition to its traditional role in graphics output and marking. The unifying feature in all these applications is the dispensing and precise positioning of very small volumes of fluid (1–100 picoliters) on a substrate before transformation to a solid. The application of inkjet printing to the fabrication of structures for structural or functional materials applications requires an understanding as to how the physical processes that operate during inkjet printing interact with the properties of the fluid precursors used. Here we review the current state of understanding of the mechanisms of drop formation and how this defines the fluid properties that are required for a given liquid to be printable. The interactions between individual drops and the substrate as well as between adjacent drops are important in defining the resolution and accuracy of printed objects. Pattern resolution is limited by the extent to which a liquid drop spreads on a substrate and how spreading changes with the overlap of adjacent drops to form continuous features. There are clearly defined upper and lower bounds to the width of a printed continuous line, which can be defined in terms of materials and process variables. Finer-resolution features can be achieved through appropriate patterning and structuring of the substrate prior to printing, which is essential if polymeric semiconducting devices are to be fabricated. Low advancing and receding contact angles promote printed line stability but are also more prone to solute segregation or “coffee staining” on drying.",2010,56,1160,49,2,17,46,44,58,85,103,131,139,179
b721f6ba0e10507f1d25b76c3eb37380d16a31a2,This study develops analytical relationships and computations of power dissipation in magnetic fluid (ferrofluid) subjected to alternating magnetic field. The dissipation results from the orientational relaxation of particles having thermal fluctuations in a viscous medium.,2002,20,1779,95,2,5,8,13,23,28,36,68,81,92
6635fa7b37888f0f90c64afdfcb8ca09d3ae974f,"Many solid tumours show an increased interstitial fluid pressure (IFP), which forms a barrier to transcapillary transport. This barrier is an obstacle in tumour treatment, as it results in inefficient uptake of therapeutic agents. There are a number of factors that contribute to increased IFP in the tumour, such as vessel abnormalities, fibrosis and contraction of the interstitial matrix. Lowering the tumour IFP with specific signal-transduction antagonists might be a useful approach to improving anticancer drug efficacy.",2004,90,1642,63,0,18,37,44,48,50,69,81,97,123
179e0701b833052c3bdf4423c060ca2f68e7d891,"1. Kinematics, conservation equations, and boundary conditions for incompressible flow 2. Unidirectional flow 3. Hydraulic circuit analysis 4. Passive scalar transport: dispersion, patterning, and mixing 5. Electrostatics and electrodynamics 6. Electroosmosis 7. Potential fluid flow 8. Stikes flow 9. The diffuse structure of the electrical double layer 10. Zeta potential in microchannels 11. Species and charge transport 12. Microchip chemical separations 13. Particle electrophoresis 14. DNA transport and analysis 15. Nanofluidics: fluid and current flow in molecular-scale and thick-double-layer systems 16. AC electrokinetics and the dynamics of diffuse charge 17. Particle and droplet actuation: dielectrophoresis, magnetophoresis, and digital microfluidics Appendices: A. Units and fundamental constants B. Properties of electrolyte solutions C. Coordinate systems and vector calculus D. Governing equation reference E. Nondimensionalization and characteristic parameters F. Multipolar solutions to the Laplace and Stokes equations G. Complex functions H. Interaction potentials: atomistic modeling of solvents and solutes.",2010,1,860,45,5,37,57,88,97,100,91,85,90,94
e51ab939cf5a2faf79ae169f2b794bc27f31cfae,,2006,0,1249,190,3,4,27,30,57,72,76,93,73,105
66fbc867a7a5faf4773581ccb3a2918a0706e1db,"BACKGROUND
Optimal fluid management in patients with acute lung injury is unknown. Diuresis or fluid restriction may improve lung function but could jeopardize extrapulmonary-organ perfusion.


METHODS
In a randomized study, we compared a conservative and a liberal strategy of fluid management using explicit protocols applied for seven days in 1000 patients with acute lung injury. The primary end point was death at 60 days. Secondary end points included the number of ventilator-free days and organ-failure-free days and measures of lung physiology.


RESULTS
The rate of death at 60 days was 25.5 percent in the conservative-strategy group and 28.4 percent in the liberal-strategy group (P=0.30; 95 percent confidence interval for the difference, -2.6 to 8.4 percent). The mean (+/-SE) cumulative fluid balance during the first seven days was -136+/-491 ml in the conservative-strategy group and 6992+/-502 ml in the liberal-strategy group (P<0.001). As compared with the liberal strategy, the conservative strategy improved the oxygenation index ([mean airway pressure x the ratio of the fraction of inspired oxygen to the partial pressure of arterial oxygen]x100) and the lung injury score and increased the number of ventilator-free days (14.6+/-0.5 vs. 12.1+/-0.5, P<0.001) and days not spent in the intensive care unit (13.4+/-0.4 vs. 11.2+/-0.4, P<0.001) during the first 28 days but did not increase the incidence or prevalence of shock during the study or the use of dialysis during the first 60 days (10 percent vs. 14 percent, P=0.06).


CONCLUSIONS
Although there was no significant difference in the primary outcome of 60-day mortality, the conservative strategy of fluid management improved lung function and shortened the duration of mechanical ventilation and intensive care without increasing nonpulmonary-organ failures. These results support the use of a conservative strategy of fluid management in patients with acute lung injury. (ClinicalTrials.gov number, NCT00281268 [ClinicalTrials.gov].).",2006,59,1413,48,11,34,60,77,85,93,110,133,120,112
f4dca1a08439ae0a13d44dba3774234c5c5b8cab,"Realistically animated fluids can add substantial realism to interactive applications such as virtual surgery simulators or computer games. In this paper we propose an interactive method based on Smoothed Particle Hydrodynamics (SPH) to simulate fluids with free surfaces. The method is an extension of the SPH-based technique by Desbrun to animate highly deformable bodies. We gear the method towards fluid simulation by deriving the force density fields directly from the Navier-Stokes equation and by adding a term to model surface tension effects. In contrast to Eulerian grid-based approaches, the particle-based approach makes mass conservation equations and convection terms dispensable which reduces the complexity of the simulation. In addition, the particles can directly be used to render the surface of the fluid. We propose methods to track and visualize the free surface using point splatting and marching cubes-based surface reconstruction. Our animation method is fast enough to be used in interactive systems and to allow for user interaction with models consisting of up to 5000 particles.",2003,25,1274,142,5,23,37,56,67,58,97,83,84,88
08236a76e2355ee36c154f51b6b2159e054a3191,*Introduction. *Conservation Laws of Fluid Motion and Boundary Conditions. *Turbulence and its Modelling. *The Finite Volume Method for Diffusion Problems. *The Finite Volume Method for Convection-Diffusion Problems. *Solution Algorithms for Pressure-Velocity Coupling in Steady Flows. *Solution of Discretised Equations. *The Finite Volume Method for Unsteady Flows. *Implementation of Boundary Conditions. *Advanced topics and applications. Appendices. References. Index.,2007,0,7124,527,194,239,276,330,368,429,451,568,552,526
65afba3daff41d488f11e017bc02ba99854e52b7,"We present an overview of the lattice Boltzmann method (LBM), a parallel and efficient algorithm for simulating single-phase and multiphase fluid flows and for incorporating additional physical complexities. The LBM is especially useful for modeling complicated boundary conditions and multiphase interfaces. Recent extensions of this method are described, including simulations of fluid turbulence, suspension flows, and reaction diffusion systems.",2001,184,6063,218,62,109,118,114,142,211,241,226,290,295
e0069fc257328c8f362a5e4c37c59f19eb719523,,2003,0,3650,223,53,79,107,171,156,168,222,241,267,223
37491ed087839d86c9ba7783cb12ccc6c9918bf6,"Microfabricated integrated circuits revolutionized computation by vastly reducing the space, labor, and time required for calculations. Microfluidic systems hold similar promise for the large-scale automation of chemistry and biology, suggesting the possibility of numerous experiments performed rapidly and in parallel, while consuming little reagent. While it is too early to tell whether such a vision will be realized, significant progress has been achieved, and various applications of significant scientific and practical interest have been developed. Here a review of the physics of small volumes (nanoliters) of fluids is presented, as parametrized by a series of dimensionless numbers expressing the relative importance of various physical phenomena. Specifically, this review explores the Reynolds number Re, addressing inertial effects; the Peclet number Pe, which concerns convective and diffusive transport; the capillary number Ca expressing the importance of interfacial tension; the Deborah, Weissenberg, and elasticity numbers De, Wi, and El, describing elastic effects due to deformable microstructural elements like polymers; the Grashof and Rayleigh numbers Gr and Ra, describing density-driven flows; and the Knudsen number, describing the importance of noncontinuum molecular effects. Furthermore, the long-range nature of viscous flows and the small device dimensions inherent in microfluidics mean that the influence of boundaries is typically significant. A variety of strategies have been developed to manipulate fluids by exploiting boundary effects; among these are electrokinetic effects, acoustic streaming, and fluid-structure interactions. The goal is to describe the physics behind the rich variety of fluid phenomena occurring on the nanoliter scale using simple scaling arguments, with the hopes of developing an intuitive sense for this occasionally counterintuitive world.",2005,1080,3428,70,17,77,129,221,219,226,241,278,285,260
f14b8ef5a3edc5fdc9613a8a1c5545aa6cb626ad,"This Position Stand provides guidance on fluid replacement to sustain appropriate hydration of individuals performing physical activity. The goal of prehydrating is to start the activity euhydrated and with normal plasma electrolyte levels. Prehydrating with beverages, in addition to normal meals and fluid intake, should be initiated when needed at least several hours before the activity to enable fluid absorption and allow urine output to return to normal levels. The goal of drinking during exercise is to prevent excessive (>2% body weight loss from water deficit) dehydration and excessive changes in electrolyte balance to avert compromised performance. Because there is considerable variability in sweating rates and sweat electrolyte content between individuals, customized fluid replacement programs are recommended. Individual sweat rates can be estimated by measuring body weight before and after exercise. During exercise, consuming beverages containing electrolytes and carbohydrates can provide benefits over water alone under certain circumstances. After exercise, the goal is to replace any fluid electrolyte deficit. The speed with which rehydration is needed and the magnitude of fluid electrolyte deficits will determine if an aggressive replacement program is merited.",2007,10,1798,207,36,62,53,93,111,114,140,150,158,152
662ac20e8d8b980582c513b38dd964cc56b40e05,,2009,0,1648,162,94,74,105,117,140,138,140,120,110,149
c7342bc120397c23c3f777e7cfeb0d76b76637e5,"Intense multidisciplinary research has provided detailed knowledge of the molecular pathogenesis of Alzheimer disease (AD). This knowledge has been translated into new therapeutic strategies with putative disease-modifying effects. Several of the most promising approaches, such as amyloid-β immunotherapy and secretase inhibition, are now being tested in clinical trials. Disease-modifying treatments might be at their most effective when initiated very early in the course of AD, before amyloid plaques and neurodegeneration become too widespread. Thus, biomarkers are needed that can detect AD in the predementia phase or, ideally, in presymptomatic individuals. In this Review, we present the rationales behind and the diagnostic performances of the core cerebrospinal fluid (CSF) biomarkers for AD, namely total tau, phosphorylated tau and the 42 amino acid form of amyloid-β. These biomarkers reflect AD pathology, and are candidate markers for predicting future cognitive decline in healthy individuals and the progression to dementia in patients who are cognitively impaired. We also discuss emerging plasma and CSF biomarkers, and explore new proteomics-based strategies for identifying additional CSF markers. Furthermore, we outline the roles of CSF biomarkers in drug discovery and clinical trials, and provide perspectives on AD biomarker discovery and the validation of such markers for use in the clinic.",2010,198,1523,48,44,90,139,137,156,156,121,155,166,142
2e776c3af634ab4ff40a67e6295efcf3a3879848,"Fluid intelligence (Gf) refers to the ability to reason and to solve new problems independently of previously acquired knowledge. Gf is critical for a wide variety of cognitive tasks, and it is considered one of the most important factors in learning. Moreover, Gf is closely related to professional and educational success, especially in complex and demanding environments. Although performance on tests of Gf can be improved through direct practice on the tests themselves, there is no evidence that training on any other regimen yields increased Gf in adults. Furthermore, there is a long history of research into cognitive training showing that, although performance on trained tasks can increase dramatically, transfer of this learning to other tasks remains poor. Here, we present evidence for transfer from training on a demanding working memory task to measures of Gf. This transfer results even though the trained task is entirely different from the intelligence test itself. Furthermore, we demonstrate that the extent of gain in intelligence critically depends on the amount of training: the more training, the more improvement in Gf. That is, the training effect is dosage-dependent. Thus, in contrast to many previous studies, we conclude that it is possible to improve Gf without practicing the testing tasks themselves, opening a wide range of applications.",2008,58,1893,133,17,56,77,108,154,163,195,176,152,178
365bc7651a03fa1c1c02dbd72d800a1d97855484,Develop a cerebrospinal fluid biomarker signature for mild Alzheimer's disease (AD) in Alzheimer's Disease Neuroimaging Initiative (ADNI) subjects.,2009,34,1762,77,25,110,156,141,137,146,171,138,158,148
16373b46351bfeb596128a1c49249e44a47ee77e,"Fluid models of gas discharges require the input of transport coefficients and rate coefficients that depend on the electron energy distribution function. Such coefficients are usually calculated from collision cross-section data by solving the electron Boltzmann equation (BE). In this paper we present a new user-friendly BE solver developed especially for this purpose, freely available under the name BOLSIG+, which is more general and easier to use than most other BE solvers available. The solver provides steady-state solutions of the BE for electrons in a uniform electric field, using the classical two-term expansion, and is able to account for different growth models, quasi-stationary and oscillating fields, electron–neutral collisions and electron–electron collisions. We show that for the approximations we use, the BE takes the form of a convection-diffusion continuity-equation with a non-local source term in energy space. To solve this equation we use an exponential scheme commonly used for convection-diffusion problems. The calculated electron transport coefficients and rate coefficients are defined so as to ensure maximum consistency with the fluid equations. We discuss how these coefficients are best used in fluid models and illustrate the influence of some essential parameters and approximations.",2005,33,2086,92,4,11,26,27,49,56,80,93,114,160
48383c4b50853ff1afab6ecb9745c247a97ba6e1,"BACKGROUND
It remains uncertain whether the choice of resuscitation fluid for patients in intensive care units (ICUs) affects survival. We conducted a multicenter, randomized, double-blind trial to compare the effect of fluid resuscitation with albumin or saline on mortality in a heterogeneous population of patients in the ICU.


METHODS
We randomly assigned patients who had been admitted to the ICU to receive either 4 percent albumin or normal saline for intravascular-fluid resuscitation during the next 28 days. The primary outcome measure was death from any cause during the 28-day period after randomization.


RESULTS
Of the 6997 patients who underwent randomization, 3497 were assigned to receive albumin and 3500 to receive saline; the two groups had similar baseline characteristics. There were 726 deaths in the albumin group, as compared with 729 deaths in the saline group (relative risk of death, 0.99; 95 percent confidence interval, 0.91 to 1.09; P=0.87). The proportion of patients with new single-organ and multiple-organ failure was similar in the two groups (P=0.85). There were no significant differences between the groups in the mean (+/-SD) numbers of days spent in the ICU (6.5+/-6.6 in the albumin group and 6.2+/-6.2 in the saline group, P=0.44), days spent in the hospital (15.3+/-9.6 and 15.6+/-9.6, respectively; P=0.30), days of mechanical ventilation (4.5+/-6.1 and 4.3+/-5.7, respectively; P=0.74), or days of renal-replacement therapy (0.5+/-2.3 and 0.4+/-2.0, respectively; P=0.41).


CONCLUSIONS
In patients in the ICU, use of either 4 percent albumin or normal saline for fluid resuscitation results in similar outcomes at 28 days.",2004,28,2297,38,31,102,129,135,140,127,160,140,133,169
d26eccb48c61a051378678dfbb5b5943683fcaed,"Background Optimal fluid management in patients with acute lung injury is unknown. Diuresis or fluid restriction may improve lung function but could jeopardize extrapulmonary-organ perfusion. Methods In a randomized study, we compared a conservative and a liberal strategy of fluid management using explicit protocols applied for seven days in 1000 patients with acute lung injury. The primary end point was death at 60 days. Secondary end points included the number of ventilator-free days and organ-failure–free days and measures of lung physiology. Results The rate of death at 60 days was 25.5 percent in the conservative-strategy group and 28.4 percent in the liberal-strategy group (P=0.30; 95 percent confidence interval for the difference, −2.6 to 8.4 percent). The mean (±SE) cumulative fluid balance during the first seven days was –136±491 ml in the conservative-strategy group and 6992±502 ml in the liberal-strategy group (P<0.001). As compared with the liberal strategy, the conservative strategy improved ...",2009,32,1770,1,93,127,112,142,126,122,93,124,120,115
e28e5bd7634c45b775d915dbb39185d73ef58439,"Inkjet printing is viewed as a versatile manufacturing tool for applications in materials fabrication in addition to its traditional role in graphics output and marking. The unifying feature in all these applications is the dispensing and precise positioning of very small volumes of fluid (1–100 picoliters) on a substrate before transformation to a solid. The application of inkjet printing to the fabrication of structures for structural or functional materials applications requires an understanding as to how the physical processes that operate during inkjet printing interact with the properties of the fluid precursors used. Here we review the current state of understanding of the mechanisms of drop formation and how this defines the fluid properties that are required for a given liquid to be printable. The interactions between individual drops and the substrate as well as between adjacent drops are important in defining the resolution and accuracy of printed objects. Pattern resolution is limited by the extent to which a liquid drop spreads on a substrate and how spreading changes with the overlap of adjacent drops to form continuous features. There are clearly defined upper and lower bounds to the width of a printed continuous line, which can be defined in terms of materials and process variables. Finer-resolution features can be achieved through appropriate patterning and structuring of the substrate prior to printing, which is essential if polymeric semiconducting devices are to be fabricated. Low advancing and receding contact angles promote printed line stability but are also more prone to solute segregation or “coffee staining” on drying.",2010,56,1160,49,2,17,46,44,58,85,103,131,139,179
b721f6ba0e10507f1d25b76c3eb37380d16a31a2,This study develops analytical relationships and computations of power dissipation in magnetic fluid (ferrofluid) subjected to alternating magnetic field. The dissipation results from the orientational relaxation of particles having thermal fluctuations in a viscous medium.,2002,20,1779,95,2,5,8,13,23,28,36,68,81,92
6635fa7b37888f0f90c64afdfcb8ca09d3ae974f,"Many solid tumours show an increased interstitial fluid pressure (IFP), which forms a barrier to transcapillary transport. This barrier is an obstacle in tumour treatment, as it results in inefficient uptake of therapeutic agents. There are a number of factors that contribute to increased IFP in the tumour, such as vessel abnormalities, fibrosis and contraction of the interstitial matrix. Lowering the tumour IFP with specific signal-transduction antagonists might be a useful approach to improving anticancer drug efficacy.",2004,90,1642,63,0,18,37,44,48,50,69,81,97,123
179e0701b833052c3bdf4423c060ca2f68e7d891,"1. Kinematics, conservation equations, and boundary conditions for incompressible flow 2. Unidirectional flow 3. Hydraulic circuit analysis 4. Passive scalar transport: dispersion, patterning, and mixing 5. Electrostatics and electrodynamics 6. Electroosmosis 7. Potential fluid flow 8. Stikes flow 9. The diffuse structure of the electrical double layer 10. Zeta potential in microchannels 11. Species and charge transport 12. Microchip chemical separations 13. Particle electrophoresis 14. DNA transport and analysis 15. Nanofluidics: fluid and current flow in molecular-scale and thick-double-layer systems 16. AC electrokinetics and the dynamics of diffuse charge 17. Particle and droplet actuation: dielectrophoresis, magnetophoresis, and digital microfluidics Appendices: A. Units and fundamental constants B. Properties of electrolyte solutions C. Coordinate systems and vector calculus D. Governing equation reference E. Nondimensionalization and characteristic parameters F. Multipolar solutions to the Laplace and Stokes equations G. Complex functions H. Interaction potentials: atomistic modeling of solvents and solutes.",2010,1,860,45,5,37,57,88,97,100,91,85,90,94
e51ab939cf5a2faf79ae169f2b794bc27f31cfae,,2006,0,1249,190,3,4,27,30,57,72,76,93,73,105
66fbc867a7a5faf4773581ccb3a2918a0706e1db,"BACKGROUND
Optimal fluid management in patients with acute lung injury is unknown. Diuresis or fluid restriction may improve lung function but could jeopardize extrapulmonary-organ perfusion.


METHODS
In a randomized study, we compared a conservative and a liberal strategy of fluid management using explicit protocols applied for seven days in 1000 patients with acute lung injury. The primary end point was death at 60 days. Secondary end points included the number of ventilator-free days and organ-failure-free days and measures of lung physiology.


RESULTS
The rate of death at 60 days was 25.5 percent in the conservative-strategy group and 28.4 percent in the liberal-strategy group (P=0.30; 95 percent confidence interval for the difference, -2.6 to 8.4 percent). The mean (+/-SE) cumulative fluid balance during the first seven days was -136+/-491 ml in the conservative-strategy group and 6992+/-502 ml in the liberal-strategy group (P<0.001). As compared with the liberal strategy, the conservative strategy improved the oxygenation index ([mean airway pressure x the ratio of the fraction of inspired oxygen to the partial pressure of arterial oxygen]x100) and the lung injury score and increased the number of ventilator-free days (14.6+/-0.5 vs. 12.1+/-0.5, P<0.001) and days not spent in the intensive care unit (13.4+/-0.4 vs. 11.2+/-0.4, P<0.001) during the first 28 days but did not increase the incidence or prevalence of shock during the study or the use of dialysis during the first 60 days (10 percent vs. 14 percent, P=0.06).


CONCLUSIONS
Although there was no significant difference in the primary outcome of 60-day mortality, the conservative strategy of fluid management improved lung function and shortened the duration of mechanical ventilation and intensive care without increasing nonpulmonary-organ failures. These results support the use of a conservative strategy of fluid management in patients with acute lung injury. (ClinicalTrials.gov number, NCT00281268 [ClinicalTrials.gov].).",2006,59,1413,48,11,34,60,77,85,93,110,133,120,112
f4dca1a08439ae0a13d44dba3774234c5c5b8cab,"Realistically animated fluids can add substantial realism to interactive applications such as virtual surgery simulators or computer games. In this paper we propose an interactive method based on Smoothed Particle Hydrodynamics (SPH) to simulate fluids with free surfaces. The method is an extension of the SPH-based technique by Desbrun to animate highly deformable bodies. We gear the method towards fluid simulation by deriving the force density fields directly from the Navier-Stokes equation and by adding a term to model surface tension effects. In contrast to Eulerian grid-based approaches, the particle-based approach makes mass conservation equations and convection terms dispensable which reduces the complexity of the simulation. In addition, the particles can directly be used to render the surface of the fluid. We propose methods to track and visualize the free surface using point splatting and marching cubes-based surface reconstruction. Our animation method is fast enough to be used in interactive systems and to allow for user interaction with models consisting of up to 5000 particles.",2003,25,1274,142,5,23,37,56,67,58,97,83,84,88
08236a76e2355ee36c154f51b6b2159e054a3191,*Introduction. *Conservation Laws of Fluid Motion and Boundary Conditions. *Turbulence and its Modelling. *The Finite Volume Method for Diffusion Problems. *The Finite Volume Method for Convection-Diffusion Problems. *Solution Algorithms for Pressure-Velocity Coupling in Steady Flows. *Solution of Discretised Equations. *The Finite Volume Method for Unsteady Flows. *Implementation of Boundary Conditions. *Advanced topics and applications. Appendices. References. Index.,2007,0,7124,527,194,239,276,330,368,429,451,568,552,526
65afba3daff41d488f11e017bc02ba99854e52b7,"We present an overview of the lattice Boltzmann method (LBM), a parallel and efficient algorithm for simulating single-phase and multiphase fluid flows and for incorporating additional physical complexities. The LBM is especially useful for modeling complicated boundary conditions and multiphase interfaces. Recent extensions of this method are described, including simulations of fluid turbulence, suspension flows, and reaction diffusion systems.",2001,184,6063,218,62,109,118,114,142,211,241,226,290,295
e0069fc257328c8f362a5e4c37c59f19eb719523,,2003,0,3650,223,53,79,107,171,156,168,222,241,267,223
37491ed087839d86c9ba7783cb12ccc6c9918bf6,"Microfabricated integrated circuits revolutionized computation by vastly reducing the space, labor, and time required for calculations. Microfluidic systems hold similar promise for the large-scale automation of chemistry and biology, suggesting the possibility of numerous experiments performed rapidly and in parallel, while consuming little reagent. While it is too early to tell whether such a vision will be realized, significant progress has been achieved, and various applications of significant scientific and practical interest have been developed. Here a review of the physics of small volumes (nanoliters) of fluids is presented, as parametrized by a series of dimensionless numbers expressing the relative importance of various physical phenomena. Specifically, this review explores the Reynolds number Re, addressing inertial effects; the Peclet number Pe, which concerns convective and diffusive transport; the capillary number Ca expressing the importance of interfacial tension; the Deborah, Weissenberg, and elasticity numbers De, Wi, and El, describing elastic effects due to deformable microstructural elements like polymers; the Grashof and Rayleigh numbers Gr and Ra, describing density-driven flows; and the Knudsen number, describing the importance of noncontinuum molecular effects. Furthermore, the long-range nature of viscous flows and the small device dimensions inherent in microfluidics mean that the influence of boundaries is typically significant. A variety of strategies have been developed to manipulate fluids by exploiting boundary effects; among these are electrokinetic effects, acoustic streaming, and fluid-structure interactions. The goal is to describe the physics behind the rich variety of fluid phenomena occurring on the nanoliter scale using simple scaling arguments, with the hopes of developing an intuitive sense for this occasionally counterintuitive world.",2005,1080,3428,70,17,77,129,221,219,226,241,278,285,260
f14b8ef5a3edc5fdc9613a8a1c5545aa6cb626ad,"This Position Stand provides guidance on fluid replacement to sustain appropriate hydration of individuals performing physical activity. The goal of prehydrating is to start the activity euhydrated and with normal plasma electrolyte levels. Prehydrating with beverages, in addition to normal meals and fluid intake, should be initiated when needed at least several hours before the activity to enable fluid absorption and allow urine output to return to normal levels. The goal of drinking during exercise is to prevent excessive (>2% body weight loss from water deficit) dehydration and excessive changes in electrolyte balance to avert compromised performance. Because there is considerable variability in sweating rates and sweat electrolyte content between individuals, customized fluid replacement programs are recommended. Individual sweat rates can be estimated by measuring body weight before and after exercise. During exercise, consuming beverages containing electrolytes and carbohydrates can provide benefits over water alone under certain circumstances. After exercise, the goal is to replace any fluid electrolyte deficit. The speed with which rehydration is needed and the magnitude of fluid electrolyte deficits will determine if an aggressive replacement program is merited.",2007,10,1798,207,36,62,53,93,111,114,140,150,158,152
662ac20e8d8b980582c513b38dd964cc56b40e05,,2009,0,1648,162,94,74,105,117,140,138,140,120,110,149
c7342bc120397c23c3f777e7cfeb0d76b76637e5,"Intense multidisciplinary research has provided detailed knowledge of the molecular pathogenesis of Alzheimer disease (AD). This knowledge has been translated into new therapeutic strategies with putative disease-modifying effects. Several of the most promising approaches, such as amyloid-β immunotherapy and secretase inhibition, are now being tested in clinical trials. Disease-modifying treatments might be at their most effective when initiated very early in the course of AD, before amyloid plaques and neurodegeneration become too widespread. Thus, biomarkers are needed that can detect AD in the predementia phase or, ideally, in presymptomatic individuals. In this Review, we present the rationales behind and the diagnostic performances of the core cerebrospinal fluid (CSF) biomarkers for AD, namely total tau, phosphorylated tau and the 42 amino acid form of amyloid-β. These biomarkers reflect AD pathology, and are candidate markers for predicting future cognitive decline in healthy individuals and the progression to dementia in patients who are cognitively impaired. We also discuss emerging plasma and CSF biomarkers, and explore new proteomics-based strategies for identifying additional CSF markers. Furthermore, we outline the roles of CSF biomarkers in drug discovery and clinical trials, and provide perspectives on AD biomarker discovery and the validation of such markers for use in the clinic.",2010,198,1523,48,44,90,139,137,156,156,121,155,166,142
2e776c3af634ab4ff40a67e6295efcf3a3879848,"Fluid intelligence (Gf) refers to the ability to reason and to solve new problems independently of previously acquired knowledge. Gf is critical for a wide variety of cognitive tasks, and it is considered one of the most important factors in learning. Moreover, Gf is closely related to professional and educational success, especially in complex and demanding environments. Although performance on tests of Gf can be improved through direct practice on the tests themselves, there is no evidence that training on any other regimen yields increased Gf in adults. Furthermore, there is a long history of research into cognitive training showing that, although performance on trained tasks can increase dramatically, transfer of this learning to other tasks remains poor. Here, we present evidence for transfer from training on a demanding working memory task to measures of Gf. This transfer results even though the trained task is entirely different from the intelligence test itself. Furthermore, we demonstrate that the extent of gain in intelligence critically depends on the amount of training: the more training, the more improvement in Gf. That is, the training effect is dosage-dependent. Thus, in contrast to many previous studies, we conclude that it is possible to improve Gf without practicing the testing tasks themselves, opening a wide range of applications.",2008,58,1893,133,17,56,77,108,154,163,195,176,152,178
365bc7651a03fa1c1c02dbd72d800a1d97855484,Develop a cerebrospinal fluid biomarker signature for mild Alzheimer's disease (AD) in Alzheimer's Disease Neuroimaging Initiative (ADNI) subjects.,2009,34,1762,77,25,110,156,141,137,146,171,138,158,148
16373b46351bfeb596128a1c49249e44a47ee77e,"Fluid models of gas discharges require the input of transport coefficients and rate coefficients that depend on the electron energy distribution function. Such coefficients are usually calculated from collision cross-section data by solving the electron Boltzmann equation (BE). In this paper we present a new user-friendly BE solver developed especially for this purpose, freely available under the name BOLSIG+, which is more general and easier to use than most other BE solvers available. The solver provides steady-state solutions of the BE for electrons in a uniform electric field, using the classical two-term expansion, and is able to account for different growth models, quasi-stationary and oscillating fields, electron–neutral collisions and electron–electron collisions. We show that for the approximations we use, the BE takes the form of a convection-diffusion continuity-equation with a non-local source term in energy space. To solve this equation we use an exponential scheme commonly used for convection-diffusion problems. The calculated electron transport coefficients and rate coefficients are defined so as to ensure maximum consistency with the fluid equations. We discuss how these coefficients are best used in fluid models and illustrate the influence of some essential parameters and approximations.",2005,33,2086,92,4,11,26,27,49,56,80,93,114,160
48383c4b50853ff1afab6ecb9745c247a97ba6e1,"BACKGROUND
It remains uncertain whether the choice of resuscitation fluid for patients in intensive care units (ICUs) affects survival. We conducted a multicenter, randomized, double-blind trial to compare the effect of fluid resuscitation with albumin or saline on mortality in a heterogeneous population of patients in the ICU.


METHODS
We randomly assigned patients who had been admitted to the ICU to receive either 4 percent albumin or normal saline for intravascular-fluid resuscitation during the next 28 days. The primary outcome measure was death from any cause during the 28-day period after randomization.


RESULTS
Of the 6997 patients who underwent randomization, 3497 were assigned to receive albumin and 3500 to receive saline; the two groups had similar baseline characteristics. There were 726 deaths in the albumin group, as compared with 729 deaths in the saline group (relative risk of death, 0.99; 95 percent confidence interval, 0.91 to 1.09; P=0.87). The proportion of patients with new single-organ and multiple-organ failure was similar in the two groups (P=0.85). There were no significant differences between the groups in the mean (+/-SD) numbers of days spent in the ICU (6.5+/-6.6 in the albumin group and 6.2+/-6.2 in the saline group, P=0.44), days spent in the hospital (15.3+/-9.6 and 15.6+/-9.6, respectively; P=0.30), days of mechanical ventilation (4.5+/-6.1 and 4.3+/-5.7, respectively; P=0.74), or days of renal-replacement therapy (0.5+/-2.3 and 0.4+/-2.0, respectively; P=0.41).


CONCLUSIONS
In patients in the ICU, use of either 4 percent albumin or normal saline for fluid resuscitation results in similar outcomes at 28 days.",2004,28,2297,38,31,102,129,135,140,127,160,140,133,169
d26eccb48c61a051378678dfbb5b5943683fcaed,"Background Optimal fluid management in patients with acute lung injury is unknown. Diuresis or fluid restriction may improve lung function but could jeopardize extrapulmonary-organ perfusion. Methods In a randomized study, we compared a conservative and a liberal strategy of fluid management using explicit protocols applied for seven days in 1000 patients with acute lung injury. The primary end point was death at 60 days. Secondary end points included the number of ventilator-free days and organ-failure–free days and measures of lung physiology. Results The rate of death at 60 days was 25.5 percent in the conservative-strategy group and 28.4 percent in the liberal-strategy group (P=0.30; 95 percent confidence interval for the difference, −2.6 to 8.4 percent). The mean (±SE) cumulative fluid balance during the first seven days was –136±491 ml in the conservative-strategy group and 6992±502 ml in the liberal-strategy group (P<0.001). As compared with the liberal strategy, the conservative strategy improved ...",2009,32,1770,1,93,127,112,142,126,122,93,124,120,115
e28e5bd7634c45b775d915dbb39185d73ef58439,"Inkjet printing is viewed as a versatile manufacturing tool for applications in materials fabrication in addition to its traditional role in graphics output and marking. The unifying feature in all these applications is the dispensing and precise positioning of very small volumes of fluid (1–100 picoliters) on a substrate before transformation to a solid. The application of inkjet printing to the fabrication of structures for structural or functional materials applications requires an understanding as to how the physical processes that operate during inkjet printing interact with the properties of the fluid precursors used. Here we review the current state of understanding of the mechanisms of drop formation and how this defines the fluid properties that are required for a given liquid to be printable. The interactions between individual drops and the substrate as well as between adjacent drops are important in defining the resolution and accuracy of printed objects. Pattern resolution is limited by the extent to which a liquid drop spreads on a substrate and how spreading changes with the overlap of adjacent drops to form continuous features. There are clearly defined upper and lower bounds to the width of a printed continuous line, which can be defined in terms of materials and process variables. Finer-resolution features can be achieved through appropriate patterning and structuring of the substrate prior to printing, which is essential if polymeric semiconducting devices are to be fabricated. Low advancing and receding contact angles promote printed line stability but are also more prone to solute segregation or “coffee staining” on drying.",2010,56,1160,49,2,17,46,44,58,85,103,131,139,179
b721f6ba0e10507f1d25b76c3eb37380d16a31a2,This study develops analytical relationships and computations of power dissipation in magnetic fluid (ferrofluid) subjected to alternating magnetic field. The dissipation results from the orientational relaxation of particles having thermal fluctuations in a viscous medium.,2002,20,1779,95,2,5,8,13,23,28,36,68,81,92
6635fa7b37888f0f90c64afdfcb8ca09d3ae974f,"Many solid tumours show an increased interstitial fluid pressure (IFP), which forms a barrier to transcapillary transport. This barrier is an obstacle in tumour treatment, as it results in inefficient uptake of therapeutic agents. There are a number of factors that contribute to increased IFP in the tumour, such as vessel abnormalities, fibrosis and contraction of the interstitial matrix. Lowering the tumour IFP with specific signal-transduction antagonists might be a useful approach to improving anticancer drug efficacy.",2004,90,1642,63,0,18,37,44,48,50,69,81,97,123
179e0701b833052c3bdf4423c060ca2f68e7d891,"1. Kinematics, conservation equations, and boundary conditions for incompressible flow 2. Unidirectional flow 3. Hydraulic circuit analysis 4. Passive scalar transport: dispersion, patterning, and mixing 5. Electrostatics and electrodynamics 6. Electroosmosis 7. Potential fluid flow 8. Stikes flow 9. The diffuse structure of the electrical double layer 10. Zeta potential in microchannels 11. Species and charge transport 12. Microchip chemical separations 13. Particle electrophoresis 14. DNA transport and analysis 15. Nanofluidics: fluid and current flow in molecular-scale and thick-double-layer systems 16. AC electrokinetics and the dynamics of diffuse charge 17. Particle and droplet actuation: dielectrophoresis, magnetophoresis, and digital microfluidics Appendices: A. Units and fundamental constants B. Properties of electrolyte solutions C. Coordinate systems and vector calculus D. Governing equation reference E. Nondimensionalization and characteristic parameters F. Multipolar solutions to the Laplace and Stokes equations G. Complex functions H. Interaction potentials: atomistic modeling of solvents and solutes.",2010,1,860,45,5,37,57,88,97,100,91,85,90,94
e51ab939cf5a2faf79ae169f2b794bc27f31cfae,,2006,0,1249,190,3,4,27,30,57,72,76,93,73,105
66fbc867a7a5faf4773581ccb3a2918a0706e1db,"BACKGROUND
Optimal fluid management in patients with acute lung injury is unknown. Diuresis or fluid restriction may improve lung function but could jeopardize extrapulmonary-organ perfusion.


METHODS
In a randomized study, we compared a conservative and a liberal strategy of fluid management using explicit protocols applied for seven days in 1000 patients with acute lung injury. The primary end point was death at 60 days. Secondary end points included the number of ventilator-free days and organ-failure-free days and measures of lung physiology.


RESULTS
The rate of death at 60 days was 25.5 percent in the conservative-strategy group and 28.4 percent in the liberal-strategy group (P=0.30; 95 percent confidence interval for the difference, -2.6 to 8.4 percent). The mean (+/-SE) cumulative fluid balance during the first seven days was -136+/-491 ml in the conservative-strategy group and 6992+/-502 ml in the liberal-strategy group (P<0.001). As compared with the liberal strategy, the conservative strategy improved the oxygenation index ([mean airway pressure x the ratio of the fraction of inspired oxygen to the partial pressure of arterial oxygen]x100) and the lung injury score and increased the number of ventilator-free days (14.6+/-0.5 vs. 12.1+/-0.5, P<0.001) and days not spent in the intensive care unit (13.4+/-0.4 vs. 11.2+/-0.4, P<0.001) during the first 28 days but did not increase the incidence or prevalence of shock during the study or the use of dialysis during the first 60 days (10 percent vs. 14 percent, P=0.06).


CONCLUSIONS
Although there was no significant difference in the primary outcome of 60-day mortality, the conservative strategy of fluid management improved lung function and shortened the duration of mechanical ventilation and intensive care without increasing nonpulmonary-organ failures. These results support the use of a conservative strategy of fluid management in patients with acute lung injury. (ClinicalTrials.gov number, NCT00281268 [ClinicalTrials.gov].).",2006,59,1413,48,11,34,60,77,85,93,110,133,120,112
f4dca1a08439ae0a13d44dba3774234c5c5b8cab,"Realistically animated fluids can add substantial realism to interactive applications such as virtual surgery simulators or computer games. In this paper we propose an interactive method based on Smoothed Particle Hydrodynamics (SPH) to simulate fluids with free surfaces. The method is an extension of the SPH-based technique by Desbrun to animate highly deformable bodies. We gear the method towards fluid simulation by deriving the force density fields directly from the Navier-Stokes equation and by adding a term to model surface tension effects. In contrast to Eulerian grid-based approaches, the particle-based approach makes mass conservation equations and convection terms dispensable which reduces the complexity of the simulation. In addition, the particles can directly be used to render the surface of the fluid. We propose methods to track and visualize the free surface using point splatting and marching cubes-based surface reconstruction. Our animation method is fast enough to be used in interactive systems and to allow for user interaction with models consisting of up to 5000 particles.",2003,25,1274,142,5,23,37,56,67,58,97,83,84,88
08236a76e2355ee36c154f51b6b2159e054a3191,*Introduction. *Conservation Laws of Fluid Motion and Boundary Conditions. *Turbulence and its Modelling. *The Finite Volume Method for Diffusion Problems. *The Finite Volume Method for Convection-Diffusion Problems. *Solution Algorithms for Pressure-Velocity Coupling in Steady Flows. *Solution of Discretised Equations. *The Finite Volume Method for Unsteady Flows. *Implementation of Boundary Conditions. *Advanced topics and applications. Appendices. References. Index.,2007,0,7124,527,194,239,276,330,368,429,451,568,552,526
65afba3daff41d488f11e017bc02ba99854e52b7,"We present an overview of the lattice Boltzmann method (LBM), a parallel and efficient algorithm for simulating single-phase and multiphase fluid flows and for incorporating additional physical complexities. The LBM is especially useful for modeling complicated boundary conditions and multiphase interfaces. Recent extensions of this method are described, including simulations of fluid turbulence, suspension flows, and reaction diffusion systems.",2001,184,6063,218,62,109,118,114,142,211,241,226,290,295
e0069fc257328c8f362a5e4c37c59f19eb719523,,2003,0,3650,223,53,79,107,171,156,168,222,241,267,223
37491ed087839d86c9ba7783cb12ccc6c9918bf6,"Microfabricated integrated circuits revolutionized computation by vastly reducing the space, labor, and time required for calculations. Microfluidic systems hold similar promise for the large-scale automation of chemistry and biology, suggesting the possibility of numerous experiments performed rapidly and in parallel, while consuming little reagent. While it is too early to tell whether such a vision will be realized, significant progress has been achieved, and various applications of significant scientific and practical interest have been developed. Here a review of the physics of small volumes (nanoliters) of fluids is presented, as parametrized by a series of dimensionless numbers expressing the relative importance of various physical phenomena. Specifically, this review explores the Reynolds number Re, addressing inertial effects; the Peclet number Pe, which concerns convective and diffusive transport; the capillary number Ca expressing the importance of interfacial tension; the Deborah, Weissenberg, and elasticity numbers De, Wi, and El, describing elastic effects due to deformable microstructural elements like polymers; the Grashof and Rayleigh numbers Gr and Ra, describing density-driven flows; and the Knudsen number, describing the importance of noncontinuum molecular effects. Furthermore, the long-range nature of viscous flows and the small device dimensions inherent in microfluidics mean that the influence of boundaries is typically significant. A variety of strategies have been developed to manipulate fluids by exploiting boundary effects; among these are electrokinetic effects, acoustic streaming, and fluid-structure interactions. The goal is to describe the physics behind the rich variety of fluid phenomena occurring on the nanoliter scale using simple scaling arguments, with the hopes of developing an intuitive sense for this occasionally counterintuitive world.",2005,1080,3428,70,17,77,129,221,219,226,241,278,285,260
f14b8ef5a3edc5fdc9613a8a1c5545aa6cb626ad,"This Position Stand provides guidance on fluid replacement to sustain appropriate hydration of individuals performing physical activity. The goal of prehydrating is to start the activity euhydrated and with normal plasma electrolyte levels. Prehydrating with beverages, in addition to normal meals and fluid intake, should be initiated when needed at least several hours before the activity to enable fluid absorption and allow urine output to return to normal levels. The goal of drinking during exercise is to prevent excessive (>2% body weight loss from water deficit) dehydration and excessive changes in electrolyte balance to avert compromised performance. Because there is considerable variability in sweating rates and sweat electrolyte content between individuals, customized fluid replacement programs are recommended. Individual sweat rates can be estimated by measuring body weight before and after exercise. During exercise, consuming beverages containing electrolytes and carbohydrates can provide benefits over water alone under certain circumstances. After exercise, the goal is to replace any fluid electrolyte deficit. The speed with which rehydration is needed and the magnitude of fluid electrolyte deficits will determine if an aggressive replacement program is merited.",2007,10,1798,207,36,62,53,93,111,114,140,150,158,152
662ac20e8d8b980582c513b38dd964cc56b40e05,,2009,0,1648,162,94,74,105,117,140,138,140,120,110,149
c7342bc120397c23c3f777e7cfeb0d76b76637e5,"Intense multidisciplinary research has provided detailed knowledge of the molecular pathogenesis of Alzheimer disease (AD). This knowledge has been translated into new therapeutic strategies with putative disease-modifying effects. Several of the most promising approaches, such as amyloid-β immunotherapy and secretase inhibition, are now being tested in clinical trials. Disease-modifying treatments might be at their most effective when initiated very early in the course of AD, before amyloid plaques and neurodegeneration become too widespread. Thus, biomarkers are needed that can detect AD in the predementia phase or, ideally, in presymptomatic individuals. In this Review, we present the rationales behind and the diagnostic performances of the core cerebrospinal fluid (CSF) biomarkers for AD, namely total tau, phosphorylated tau and the 42 amino acid form of amyloid-β. These biomarkers reflect AD pathology, and are candidate markers for predicting future cognitive decline in healthy individuals and the progression to dementia in patients who are cognitively impaired. We also discuss emerging plasma and CSF biomarkers, and explore new proteomics-based strategies for identifying additional CSF markers. Furthermore, we outline the roles of CSF biomarkers in drug discovery and clinical trials, and provide perspectives on AD biomarker discovery and the validation of such markers for use in the clinic.",2010,198,1523,48,44,90,139,137,156,156,121,155,166,142
2e776c3af634ab4ff40a67e6295efcf3a3879848,"Fluid intelligence (Gf) refers to the ability to reason and to solve new problems independently of previously acquired knowledge. Gf is critical for a wide variety of cognitive tasks, and it is considered one of the most important factors in learning. Moreover, Gf is closely related to professional and educational success, especially in complex and demanding environments. Although performance on tests of Gf can be improved through direct practice on the tests themselves, there is no evidence that training on any other regimen yields increased Gf in adults. Furthermore, there is a long history of research into cognitive training showing that, although performance on trained tasks can increase dramatically, transfer of this learning to other tasks remains poor. Here, we present evidence for transfer from training on a demanding working memory task to measures of Gf. This transfer results even though the trained task is entirely different from the intelligence test itself. Furthermore, we demonstrate that the extent of gain in intelligence critically depends on the amount of training: the more training, the more improvement in Gf. That is, the training effect is dosage-dependent. Thus, in contrast to many previous studies, we conclude that it is possible to improve Gf without practicing the testing tasks themselves, opening a wide range of applications.",2008,58,1893,133,17,56,77,108,154,163,195,176,152,178
365bc7651a03fa1c1c02dbd72d800a1d97855484,Develop a cerebrospinal fluid biomarker signature for mild Alzheimer's disease (AD) in Alzheimer's Disease Neuroimaging Initiative (ADNI) subjects.,2009,34,1762,77,25,110,156,141,137,146,171,138,158,148
16373b46351bfeb596128a1c49249e44a47ee77e,"Fluid models of gas discharges require the input of transport coefficients and rate coefficients that depend on the electron energy distribution function. Such coefficients are usually calculated from collision cross-section data by solving the electron Boltzmann equation (BE). In this paper we present a new user-friendly BE solver developed especially for this purpose, freely available under the name BOLSIG+, which is more general and easier to use than most other BE solvers available. The solver provides steady-state solutions of the BE for electrons in a uniform electric field, using the classical two-term expansion, and is able to account for different growth models, quasi-stationary and oscillating fields, electron–neutral collisions and electron–electron collisions. We show that for the approximations we use, the BE takes the form of a convection-diffusion continuity-equation with a non-local source term in energy space. To solve this equation we use an exponential scheme commonly used for convection-diffusion problems. The calculated electron transport coefficients and rate coefficients are defined so as to ensure maximum consistency with the fluid equations. We discuss how these coefficients are best used in fluid models and illustrate the influence of some essential parameters and approximations.",2005,33,2086,92,4,11,26,27,49,56,80,93,114,160
48383c4b50853ff1afab6ecb9745c247a97ba6e1,"BACKGROUND
It remains uncertain whether the choice of resuscitation fluid for patients in intensive care units (ICUs) affects survival. We conducted a multicenter, randomized, double-blind trial to compare the effect of fluid resuscitation with albumin or saline on mortality in a heterogeneous population of patients in the ICU.


METHODS
We randomly assigned patients who had been admitted to the ICU to receive either 4 percent albumin or normal saline for intravascular-fluid resuscitation during the next 28 days. The primary outcome measure was death from any cause during the 28-day period after randomization.


RESULTS
Of the 6997 patients who underwent randomization, 3497 were assigned to receive albumin and 3500 to receive saline; the two groups had similar baseline characteristics. There were 726 deaths in the albumin group, as compared with 729 deaths in the saline group (relative risk of death, 0.99; 95 percent confidence interval, 0.91 to 1.09; P=0.87). The proportion of patients with new single-organ and multiple-organ failure was similar in the two groups (P=0.85). There were no significant differences between the groups in the mean (+/-SD) numbers of days spent in the ICU (6.5+/-6.6 in the albumin group and 6.2+/-6.2 in the saline group, P=0.44), days spent in the hospital (15.3+/-9.6 and 15.6+/-9.6, respectively; P=0.30), days of mechanical ventilation (4.5+/-6.1 and 4.3+/-5.7, respectively; P=0.74), or days of renal-replacement therapy (0.5+/-2.3 and 0.4+/-2.0, respectively; P=0.41).


CONCLUSIONS
In patients in the ICU, use of either 4 percent albumin or normal saline for fluid resuscitation results in similar outcomes at 28 days.",2004,28,2297,38,31,102,129,135,140,127,160,140,133,169
d26eccb48c61a051378678dfbb5b5943683fcaed,"Background Optimal fluid management in patients with acute lung injury is unknown. Diuresis or fluid restriction may improve lung function but could jeopardize extrapulmonary-organ perfusion. Methods In a randomized study, we compared a conservative and a liberal strategy of fluid management using explicit protocols applied for seven days in 1000 patients with acute lung injury. The primary end point was death at 60 days. Secondary end points included the number of ventilator-free days and organ-failure–free days and measures of lung physiology. Results The rate of death at 60 days was 25.5 percent in the conservative-strategy group and 28.4 percent in the liberal-strategy group (P=0.30; 95 percent confidence interval for the difference, −2.6 to 8.4 percent). The mean (±SE) cumulative fluid balance during the first seven days was –136±491 ml in the conservative-strategy group and 6992±502 ml in the liberal-strategy group (P<0.001). As compared with the liberal strategy, the conservative strategy improved ...",2009,32,1770,1,93,127,112,142,126,122,93,124,120,115
b721f6ba0e10507f1d25b76c3eb37380d16a31a2,This study develops analytical relationships and computations of power dissipation in magnetic fluid (ferrofluid) subjected to alternating magnetic field. The dissipation results from the orientational relaxation of particles having thermal fluctuations in a viscous medium.,2002,20,1779,95,2,5,8,13,23,28,36,68,81,92
6635fa7b37888f0f90c64afdfcb8ca09d3ae974f,"Many solid tumours show an increased interstitial fluid pressure (IFP), which forms a barrier to transcapillary transport. This barrier is an obstacle in tumour treatment, as it results in inefficient uptake of therapeutic agents. There are a number of factors that contribute to increased IFP in the tumour, such as vessel abnormalities, fibrosis and contraction of the interstitial matrix. Lowering the tumour IFP with specific signal-transduction antagonists might be a useful approach to improving anticancer drug efficacy.",2004,90,1642,63,0,18,37,44,48,50,69,81,97,123
179e0701b833052c3bdf4423c060ca2f68e7d891,"1. Kinematics, conservation equations, and boundary conditions for incompressible flow 2. Unidirectional flow 3. Hydraulic circuit analysis 4. Passive scalar transport: dispersion, patterning, and mixing 5. Electrostatics and electrodynamics 6. Electroosmosis 7. Potential fluid flow 8. Stikes flow 9. The diffuse structure of the electrical double layer 10. Zeta potential in microchannels 11. Species and charge transport 12. Microchip chemical separations 13. Particle electrophoresis 14. DNA transport and analysis 15. Nanofluidics: fluid and current flow in molecular-scale and thick-double-layer systems 16. AC electrokinetics and the dynamics of diffuse charge 17. Particle and droplet actuation: dielectrophoresis, magnetophoresis, and digital microfluidics Appendices: A. Units and fundamental constants B. Properties of electrolyte solutions C. Coordinate systems and vector calculus D. Governing equation reference E. Nondimensionalization and characteristic parameters F. Multipolar solutions to the Laplace and Stokes equations G. Complex functions H. Interaction potentials: atomistic modeling of solvents and solutes.",2010,1,860,45,5,37,57,88,97,100,91,85,90,94
e51ab939cf5a2faf79ae169f2b794bc27f31cfae,,2006,0,1249,190,3,4,27,30,57,72,76,93,73,105
66fbc867a7a5faf4773581ccb3a2918a0706e1db,"BACKGROUND
Optimal fluid management in patients with acute lung injury is unknown. Diuresis or fluid restriction may improve lung function but could jeopardize extrapulmonary-organ perfusion.


METHODS
In a randomized study, we compared a conservative and a liberal strategy of fluid management using explicit protocols applied for seven days in 1000 patients with acute lung injury. The primary end point was death at 60 days. Secondary end points included the number of ventilator-free days and organ-failure-free days and measures of lung physiology.


RESULTS
The rate of death at 60 days was 25.5 percent in the conservative-strategy group and 28.4 percent in the liberal-strategy group (P=0.30; 95 percent confidence interval for the difference, -2.6 to 8.4 percent). The mean (+/-SE) cumulative fluid balance during the first seven days was -136+/-491 ml in the conservative-strategy group and 6992+/-502 ml in the liberal-strategy group (P<0.001). As compared with the liberal strategy, the conservative strategy improved the oxygenation index ([mean airway pressure x the ratio of the fraction of inspired oxygen to the partial pressure of arterial oxygen]x100) and the lung injury score and increased the number of ventilator-free days (14.6+/-0.5 vs. 12.1+/-0.5, P<0.001) and days not spent in the intensive care unit (13.4+/-0.4 vs. 11.2+/-0.4, P<0.001) during the first 28 days but did not increase the incidence or prevalence of shock during the study or the use of dialysis during the first 60 days (10 percent vs. 14 percent, P=0.06).


CONCLUSIONS
Although there was no significant difference in the primary outcome of 60-day mortality, the conservative strategy of fluid management improved lung function and shortened the duration of mechanical ventilation and intensive care without increasing nonpulmonary-organ failures. These results support the use of a conservative strategy of fluid management in patients with acute lung injury. (ClinicalTrials.gov number, NCT00281268 [ClinicalTrials.gov].).",2006,59,1413,48,11,34,60,77,85,93,110,133,120,112
f4dca1a08439ae0a13d44dba3774234c5c5b8cab,"Realistically animated fluids can add substantial realism to interactive applications such as virtual surgery simulators or computer games. In this paper we propose an interactive method based on Smoothed Particle Hydrodynamics (SPH) to simulate fluids with free surfaces. The method is an extension of the SPH-based technique by Desbrun to animate highly deformable bodies. We gear the method towards fluid simulation by deriving the force density fields directly from the Navier-Stokes equation and by adding a term to model surface tension effects. In contrast to Eulerian grid-based approaches, the particle-based approach makes mass conservation equations and convection terms dispensable which reduces the complexity of the simulation. In addition, the particles can directly be used to render the surface of the fluid. We propose methods to track and visualize the free surface using point splatting and marching cubes-based surface reconstruction. Our animation method is fast enough to be used in interactive systems and to allow for user interaction with models consisting of up to 5000 particles.",2003,25,1274,142,5,23,37,56,67,58,97,83,84,88
08236a76e2355ee36c154f51b6b2159e054a3191,*Introduction. *Conservation Laws of Fluid Motion and Boundary Conditions. *Turbulence and its Modelling. *The Finite Volume Method for Diffusion Problems. *The Finite Volume Method for Convection-Diffusion Problems. *Solution Algorithms for Pressure-Velocity Coupling in Steady Flows. *Solution of Discretised Equations. *The Finite Volume Method for Unsteady Flows. *Implementation of Boundary Conditions. *Advanced topics and applications. Appendices. References. Index.,2007,0,7124,527,194,239,276,330,368,429,451,568,552,526
65afba3daff41d488f11e017bc02ba99854e52b7,"We present an overview of the lattice Boltzmann method (LBM), a parallel and efficient algorithm for simulating single-phase and multiphase fluid flows and for incorporating additional physical complexities. The LBM is especially useful for modeling complicated boundary conditions and multiphase interfaces. Recent extensions of this method are described, including simulations of fluid turbulence, suspension flows, and reaction diffusion systems.",2001,184,6063,218,62,109,118,114,142,211,241,226,290,295
e0069fc257328c8f362a5e4c37c59f19eb719523,,2003,0,3650,223,53,79,107,171,156,168,222,241,267,223
37491ed087839d86c9ba7783cb12ccc6c9918bf6,"Microfabricated integrated circuits revolutionized computation by vastly reducing the space, labor, and time required for calculations. Microfluidic systems hold similar promise for the large-scale automation of chemistry and biology, suggesting the possibility of numerous experiments performed rapidly and in parallel, while consuming little reagent. While it is too early to tell whether such a vision will be realized, significant progress has been achieved, and various applications of significant scientific and practical interest have been developed. Here a review of the physics of small volumes (nanoliters) of fluids is presented, as parametrized by a series of dimensionless numbers expressing the relative importance of various physical phenomena. Specifically, this review explores the Reynolds number Re, addressing inertial effects; the Peclet number Pe, which concerns convective and diffusive transport; the capillary number Ca expressing the importance of interfacial tension; the Deborah, Weissenberg, and elasticity numbers De, Wi, and El, describing elastic effects due to deformable microstructural elements like polymers; the Grashof and Rayleigh numbers Gr and Ra, describing density-driven flows; and the Knudsen number, describing the importance of noncontinuum molecular effects. Furthermore, the long-range nature of viscous flows and the small device dimensions inherent in microfluidics mean that the influence of boundaries is typically significant. A variety of strategies have been developed to manipulate fluids by exploiting boundary effects; among these are electrokinetic effects, acoustic streaming, and fluid-structure interactions. The goal is to describe the physics behind the rich variety of fluid phenomena occurring on the nanoliter scale using simple scaling arguments, with the hopes of developing an intuitive sense for this occasionally counterintuitive world.",2005,1080,3428,70,17,77,129,221,219,226,241,278,285,260
f14b8ef5a3edc5fdc9613a8a1c5545aa6cb626ad,"This Position Stand provides guidance on fluid replacement to sustain appropriate hydration of individuals performing physical activity. The goal of prehydrating is to start the activity euhydrated and with normal plasma electrolyte levels. Prehydrating with beverages, in addition to normal meals and fluid intake, should be initiated when needed at least several hours before the activity to enable fluid absorption and allow urine output to return to normal levels. The goal of drinking during exercise is to prevent excessive (>2% body weight loss from water deficit) dehydration and excessive changes in electrolyte balance to avert compromised performance. Because there is considerable variability in sweating rates and sweat electrolyte content between individuals, customized fluid replacement programs are recommended. Individual sweat rates can be estimated by measuring body weight before and after exercise. During exercise, consuming beverages containing electrolytes and carbohydrates can provide benefits over water alone under certain circumstances. After exercise, the goal is to replace any fluid electrolyte deficit. The speed with which rehydration is needed and the magnitude of fluid electrolyte deficits will determine if an aggressive replacement program is merited.",2007,10,1798,207,36,62,53,93,111,114,140,150,158,152
662ac20e8d8b980582c513b38dd964cc56b40e05,,2009,0,1648,162,94,74,105,117,140,138,140,120,110,149
c7342bc120397c23c3f777e7cfeb0d76b76637e5,"Intense multidisciplinary research has provided detailed knowledge of the molecular pathogenesis of Alzheimer disease (AD). This knowledge has been translated into new therapeutic strategies with putative disease-modifying effects. Several of the most promising approaches, such as amyloid-β immunotherapy and secretase inhibition, are now being tested in clinical trials. Disease-modifying treatments might be at their most effective when initiated very early in the course of AD, before amyloid plaques and neurodegeneration become too widespread. Thus, biomarkers are needed that can detect AD in the predementia phase or, ideally, in presymptomatic individuals. In this Review, we present the rationales behind and the diagnostic performances of the core cerebrospinal fluid (CSF) biomarkers for AD, namely total tau, phosphorylated tau and the 42 amino acid form of amyloid-β. These biomarkers reflect AD pathology, and are candidate markers for predicting future cognitive decline in healthy individuals and the progression to dementia in patients who are cognitively impaired. We also discuss emerging plasma and CSF biomarkers, and explore new proteomics-based strategies for identifying additional CSF markers. Furthermore, we outline the roles of CSF biomarkers in drug discovery and clinical trials, and provide perspectives on AD biomarker discovery and the validation of such markers for use in the clinic.",2010,198,1523,48,44,90,139,137,156,156,121,155,166,142
2e776c3af634ab4ff40a67e6295efcf3a3879848,"Fluid intelligence (Gf) refers to the ability to reason and to solve new problems independently of previously acquired knowledge. Gf is critical for a wide variety of cognitive tasks, and it is considered one of the most important factors in learning. Moreover, Gf is closely related to professional and educational success, especially in complex and demanding environments. Although performance on tests of Gf can be improved through direct practice on the tests themselves, there is no evidence that training on any other regimen yields increased Gf in adults. Furthermore, there is a long history of research into cognitive training showing that, although performance on trained tasks can increase dramatically, transfer of this learning to other tasks remains poor. Here, we present evidence for transfer from training on a demanding working memory task to measures of Gf. This transfer results even though the trained task is entirely different from the intelligence test itself. Furthermore, we demonstrate that the extent of gain in intelligence critically depends on the amount of training: the more training, the more improvement in Gf. That is, the training effect is dosage-dependent. Thus, in contrast to many previous studies, we conclude that it is possible to improve Gf without practicing the testing tasks themselves, opening a wide range of applications.",2008,58,1893,133,17,56,77,108,154,163,195,176,152,178
365bc7651a03fa1c1c02dbd72d800a1d97855484,Develop a cerebrospinal fluid biomarker signature for mild Alzheimer's disease (AD) in Alzheimer's Disease Neuroimaging Initiative (ADNI) subjects.,2009,34,1762,77,25,110,156,141,137,146,171,138,158,148
16373b46351bfeb596128a1c49249e44a47ee77e,"Fluid models of gas discharges require the input of transport coefficients and rate coefficients that depend on the electron energy distribution function. Such coefficients are usually calculated from collision cross-section data by solving the electron Boltzmann equation (BE). In this paper we present a new user-friendly BE solver developed especially for this purpose, freely available under the name BOLSIG+, which is more general and easier to use than most other BE solvers available. The solver provides steady-state solutions of the BE for electrons in a uniform electric field, using the classical two-term expansion, and is able to account for different growth models, quasi-stationary and oscillating fields, electron–neutral collisions and electron–electron collisions. We show that for the approximations we use, the BE takes the form of a convection-diffusion continuity-equation with a non-local source term in energy space. To solve this equation we use an exponential scheme commonly used for convection-diffusion problems. The calculated electron transport coefficients and rate coefficients are defined so as to ensure maximum consistency with the fluid equations. We discuss how these coefficients are best used in fluid models and illustrate the influence of some essential parameters and approximations.",2005,33,2086,92,4,11,26,27,49,56,80,93,114,160
48383c4b50853ff1afab6ecb9745c247a97ba6e1,"BACKGROUND
It remains uncertain whether the choice of resuscitation fluid for patients in intensive care units (ICUs) affects survival. We conducted a multicenter, randomized, double-blind trial to compare the effect of fluid resuscitation with albumin or saline on mortality in a heterogeneous population of patients in the ICU.


METHODS
We randomly assigned patients who had been admitted to the ICU to receive either 4 percent albumin or normal saline for intravascular-fluid resuscitation during the next 28 days. The primary outcome measure was death from any cause during the 28-day period after randomization.


RESULTS
Of the 6997 patients who underwent randomization, 3497 were assigned to receive albumin and 3500 to receive saline; the two groups had similar baseline characteristics. There were 726 deaths in the albumin group, as compared with 729 deaths in the saline group (relative risk of death, 0.99; 95 percent confidence interval, 0.91 to 1.09; P=0.87). The proportion of patients with new single-organ and multiple-organ failure was similar in the two groups (P=0.85). There were no significant differences between the groups in the mean (+/-SD) numbers of days spent in the ICU (6.5+/-6.6 in the albumin group and 6.2+/-6.2 in the saline group, P=0.44), days spent in the hospital (15.3+/-9.6 and 15.6+/-9.6, respectively; P=0.30), days of mechanical ventilation (4.5+/-6.1 and 4.3+/-5.7, respectively; P=0.74), or days of renal-replacement therapy (0.5+/-2.3 and 0.4+/-2.0, respectively; P=0.41).


CONCLUSIONS
In patients in the ICU, use of either 4 percent albumin or normal saline for fluid resuscitation results in similar outcomes at 28 days.",2004,28,2297,38,31,102,129,135,140,127,160,140,133,169
d26eccb48c61a051378678dfbb5b5943683fcaed,"Background Optimal fluid management in patients with acute lung injury is unknown. Diuresis or fluid restriction may improve lung function but could jeopardize extrapulmonary-organ perfusion. Methods In a randomized study, we compared a conservative and a liberal strategy of fluid management using explicit protocols applied for seven days in 1000 patients with acute lung injury. The primary end point was death at 60 days. Secondary end points included the number of ventilator-free days and organ-failure–free days and measures of lung physiology. Results The rate of death at 60 days was 25.5 percent in the conservative-strategy group and 28.4 percent in the liberal-strategy group (P=0.30; 95 percent confidence interval for the difference, −2.6 to 8.4 percent). The mean (±SE) cumulative fluid balance during the first seven days was –136±491 ml in the conservative-strategy group and 6992±502 ml in the liberal-strategy group (P<0.001). As compared with the liberal strategy, the conservative strategy improved ...",2009,32,1770,1,93,127,112,142,126,122,93,124,120,115
b721f6ba0e10507f1d25b76c3eb37380d16a31a2,This study develops analytical relationships and computations of power dissipation in magnetic fluid (ferrofluid) subjected to alternating magnetic field. The dissipation results from the orientational relaxation of particles having thermal fluctuations in a viscous medium.,2002,20,1779,95,2,5,8,13,23,28,36,68,81,92
6635fa7b37888f0f90c64afdfcb8ca09d3ae974f,"Many solid tumours show an increased interstitial fluid pressure (IFP), which forms a barrier to transcapillary transport. This barrier is an obstacle in tumour treatment, as it results in inefficient uptake of therapeutic agents. There are a number of factors that contribute to increased IFP in the tumour, such as vessel abnormalities, fibrosis and contraction of the interstitial matrix. Lowering the tumour IFP with specific signal-transduction antagonists might be a useful approach to improving anticancer drug efficacy.",2004,90,1642,63,0,18,37,44,48,50,69,81,97,123
179e0701b833052c3bdf4423c060ca2f68e7d891,"1. Kinematics, conservation equations, and boundary conditions for incompressible flow 2. Unidirectional flow 3. Hydraulic circuit analysis 4. Passive scalar transport: dispersion, patterning, and mixing 5. Electrostatics and electrodynamics 6. Electroosmosis 7. Potential fluid flow 8. Stikes flow 9. The diffuse structure of the electrical double layer 10. Zeta potential in microchannels 11. Species and charge transport 12. Microchip chemical separations 13. Particle electrophoresis 14. DNA transport and analysis 15. Nanofluidics: fluid and current flow in molecular-scale and thick-double-layer systems 16. AC electrokinetics and the dynamics of diffuse charge 17. Particle and droplet actuation: dielectrophoresis, magnetophoresis, and digital microfluidics Appendices: A. Units and fundamental constants B. Properties of electrolyte solutions C. Coordinate systems and vector calculus D. Governing equation reference E. Nondimensionalization and characteristic parameters F. Multipolar solutions to the Laplace and Stokes equations G. Complex functions H. Interaction potentials: atomistic modeling of solvents and solutes.",2010,1,860,45,5,37,57,88,97,100,91,85,90,94
e51ab939cf5a2faf79ae169f2b794bc27f31cfae,,2006,0,1249,190,3,4,27,30,57,72,76,93,73,105
66fbc867a7a5faf4773581ccb3a2918a0706e1db,"BACKGROUND
Optimal fluid management in patients with acute lung injury is unknown. Diuresis or fluid restriction may improve lung function but could jeopardize extrapulmonary-organ perfusion.


METHODS
In a randomized study, we compared a conservative and a liberal strategy of fluid management using explicit protocols applied for seven days in 1000 patients with acute lung injury. The primary end point was death at 60 days. Secondary end points included the number of ventilator-free days and organ-failure-free days and measures of lung physiology.


RESULTS
The rate of death at 60 days was 25.5 percent in the conservative-strategy group and 28.4 percent in the liberal-strategy group (P=0.30; 95 percent confidence interval for the difference, -2.6 to 8.4 percent). The mean (+/-SE) cumulative fluid balance during the first seven days was -136+/-491 ml in the conservative-strategy group and 6992+/-502 ml in the liberal-strategy group (P<0.001). As compared with the liberal strategy, the conservative strategy improved the oxygenation index ([mean airway pressure x the ratio of the fraction of inspired oxygen to the partial pressure of arterial oxygen]x100) and the lung injury score and increased the number of ventilator-free days (14.6+/-0.5 vs. 12.1+/-0.5, P<0.001) and days not spent in the intensive care unit (13.4+/-0.4 vs. 11.2+/-0.4, P<0.001) during the first 28 days but did not increase the incidence or prevalence of shock during the study or the use of dialysis during the first 60 days (10 percent vs. 14 percent, P=0.06).


CONCLUSIONS
Although there was no significant difference in the primary outcome of 60-day mortality, the conservative strategy of fluid management improved lung function and shortened the duration of mechanical ventilation and intensive care without increasing nonpulmonary-organ failures. These results support the use of a conservative strategy of fluid management in patients with acute lung injury. (ClinicalTrials.gov number, NCT00281268 [ClinicalTrials.gov].).",2006,59,1413,48,11,34,60,77,85,93,110,133,120,112
f4dca1a08439ae0a13d44dba3774234c5c5b8cab,"Realistically animated fluids can add substantial realism to interactive applications such as virtual surgery simulators or computer games. In this paper we propose an interactive method based on Smoothed Particle Hydrodynamics (SPH) to simulate fluids with free surfaces. The method is an extension of the SPH-based technique by Desbrun to animate highly deformable bodies. We gear the method towards fluid simulation by deriving the force density fields directly from the Navier-Stokes equation and by adding a term to model surface tension effects. In contrast to Eulerian grid-based approaches, the particle-based approach makes mass conservation equations and convection terms dispensable which reduces the complexity of the simulation. In addition, the particles can directly be used to render the surface of the fluid. We propose methods to track and visualize the free surface using point splatting and marching cubes-based surface reconstruction. Our animation method is fast enough to be used in interactive systems and to allow for user interaction with models consisting of up to 5000 particles.",2003,25,1274,142,5,23,37,56,67,58,97,83,84,88
0d3549f769c37e59debe18cb185e85c70ba17c90,"To better understand the diversity of small silencing RNAs expressed in plants, we employed high-throughput pyrosequencing to obtain 887,000 reads corresponding to Arabidopsis thaliana small RNAs. They represented 340,000 unique sequences, a substantially greater diversity than previously obtained in any species. Most of the small RNAs had the properties of heterochromatic small interfering RNAs (siRNAs) associated with DNA silencing in that they were preferentially 24 nucleotides long and mapped to intergenic regions. Their density was greatest in the proximal and distal pericentromeric regions, with only a slightly preferential propensity to match repetitive elements. Also present were 38 newly identified microRNAs (miRNAs) and dozens of other plausible candidates. One miRNA mapped within an intron of DICER-LIKE 1 (DCL1), suggesting a second homeostatic autoregulatory mechanism for DCL1 expression; another defined the phase for siRNAs deriving from a newly identified trans-acting siRNA gene (TAS4); and two depended on DCL4 rather than DCL1 for their accumulation, indicating a second pathway for miRNA biogenesis in plants. More generally, our results revealed the existence of a layer of miRNA-based control beyond that found previously that is evolutionarily much more fluid, employing many newly emergent and diverse miRNAs, each expressed in specialized tissues or at low levels under standard growth conditions.",2006,71,1228,139,1,49,91,86,92,96,125,111,89,101
08236a76e2355ee36c154f51b6b2159e054a3191,*Introduction. *Conservation Laws of Fluid Motion and Boundary Conditions. *Turbulence and its Modelling. *The Finite Volume Method for Diffusion Problems. *The Finite Volume Method for Convection-Diffusion Problems. *Solution Algorithms for Pressure-Velocity Coupling in Steady Flows. *Solution of Discretised Equations. *The Finite Volume Method for Unsteady Flows. *Implementation of Boundary Conditions. *Advanced topics and applications. Appendices. References. Index.,2007,0,7124,527,194,239,276,330,368,429,451,568,552,526
65afba3daff41d488f11e017bc02ba99854e52b7,"We present an overview of the lattice Boltzmann method (LBM), a parallel and efficient algorithm for simulating single-phase and multiphase fluid flows and for incorporating additional physical complexities. The LBM is especially useful for modeling complicated boundary conditions and multiphase interfaces. Recent extensions of this method are described, including simulations of fluid turbulence, suspension flows, and reaction diffusion systems.",2001,184,6063,218,62,109,118,114,142,211,241,226,290,295
e0069fc257328c8f362a5e4c37c59f19eb719523,,2003,0,3650,223,53,79,107,171,156,168,222,241,267,223
37491ed087839d86c9ba7783cb12ccc6c9918bf6,"Microfabricated integrated circuits revolutionized computation by vastly reducing the space, labor, and time required for calculations. Microfluidic systems hold similar promise for the large-scale automation of chemistry and biology, suggesting the possibility of numerous experiments performed rapidly and in parallel, while consuming little reagent. While it is too early to tell whether such a vision will be realized, significant progress has been achieved, and various applications of significant scientific and practical interest have been developed. Here a review of the physics of small volumes (nanoliters) of fluids is presented, as parametrized by a series of dimensionless numbers expressing the relative importance of various physical phenomena. Specifically, this review explores the Reynolds number Re, addressing inertial effects; the Peclet number Pe, which concerns convective and diffusive transport; the capillary number Ca expressing the importance of interfacial tension; the Deborah, Weissenberg, and elasticity numbers De, Wi, and El, describing elastic effects due to deformable microstructural elements like polymers; the Grashof and Rayleigh numbers Gr and Ra, describing density-driven flows; and the Knudsen number, describing the importance of noncontinuum molecular effects. Furthermore, the long-range nature of viscous flows and the small device dimensions inherent in microfluidics mean that the influence of boundaries is typically significant. A variety of strategies have been developed to manipulate fluids by exploiting boundary effects; among these are electrokinetic effects, acoustic streaming, and fluid-structure interactions. The goal is to describe the physics behind the rich variety of fluid phenomena occurring on the nanoliter scale using simple scaling arguments, with the hopes of developing an intuitive sense for this occasionally counterintuitive world.",2005,1080,3428,70,17,77,129,221,219,226,241,278,285,260
f14b8ef5a3edc5fdc9613a8a1c5545aa6cb626ad,"This Position Stand provides guidance on fluid replacement to sustain appropriate hydration of individuals performing physical activity. The goal of prehydrating is to start the activity euhydrated and with normal plasma electrolyte levels. Prehydrating with beverages, in addition to normal meals and fluid intake, should be initiated when needed at least several hours before the activity to enable fluid absorption and allow urine output to return to normal levels. The goal of drinking during exercise is to prevent excessive (>2% body weight loss from water deficit) dehydration and excessive changes in electrolyte balance to avert compromised performance. Because there is considerable variability in sweating rates and sweat electrolyte content between individuals, customized fluid replacement programs are recommended. Individual sweat rates can be estimated by measuring body weight before and after exercise. During exercise, consuming beverages containing electrolytes and carbohydrates can provide benefits over water alone under certain circumstances. After exercise, the goal is to replace any fluid electrolyte deficit. The speed with which rehydration is needed and the magnitude of fluid electrolyte deficits will determine if an aggressive replacement program is merited.",2007,10,1798,207,36,62,53,93,111,114,140,150,158,152
662ac20e8d8b980582c513b38dd964cc56b40e05,,2009,0,1648,162,94,74,105,117,140,138,140,120,110,149
c7342bc120397c23c3f777e7cfeb0d76b76637e5,"Intense multidisciplinary research has provided detailed knowledge of the molecular pathogenesis of Alzheimer disease (AD). This knowledge has been translated into new therapeutic strategies with putative disease-modifying effects. Several of the most promising approaches, such as amyloid-β immunotherapy and secretase inhibition, are now being tested in clinical trials. Disease-modifying treatments might be at their most effective when initiated very early in the course of AD, before amyloid plaques and neurodegeneration become too widespread. Thus, biomarkers are needed that can detect AD in the predementia phase or, ideally, in presymptomatic individuals. In this Review, we present the rationales behind and the diagnostic performances of the core cerebrospinal fluid (CSF) biomarkers for AD, namely total tau, phosphorylated tau and the 42 amino acid form of amyloid-β. These biomarkers reflect AD pathology, and are candidate markers for predicting future cognitive decline in healthy individuals and the progression to dementia in patients who are cognitively impaired. We also discuss emerging plasma and CSF biomarkers, and explore new proteomics-based strategies for identifying additional CSF markers. Furthermore, we outline the roles of CSF biomarkers in drug discovery and clinical trials, and provide perspectives on AD biomarker discovery and the validation of such markers for use in the clinic.",2010,198,1523,48,44,90,139,137,156,156,121,155,166,142
2e776c3af634ab4ff40a67e6295efcf3a3879848,"Fluid intelligence (Gf) refers to the ability to reason and to solve new problems independently of previously acquired knowledge. Gf is critical for a wide variety of cognitive tasks, and it is considered one of the most important factors in learning. Moreover, Gf is closely related to professional and educational success, especially in complex and demanding environments. Although performance on tests of Gf can be improved through direct practice on the tests themselves, there is no evidence that training on any other regimen yields increased Gf in adults. Furthermore, there is a long history of research into cognitive training showing that, although performance on trained tasks can increase dramatically, transfer of this learning to other tasks remains poor. Here, we present evidence for transfer from training on a demanding working memory task to measures of Gf. This transfer results even though the trained task is entirely different from the intelligence test itself. Furthermore, we demonstrate that the extent of gain in intelligence critically depends on the amount of training: the more training, the more improvement in Gf. That is, the training effect is dosage-dependent. Thus, in contrast to many previous studies, we conclude that it is possible to improve Gf without practicing the testing tasks themselves, opening a wide range of applications.",2008,58,1893,133,17,56,77,108,154,163,195,176,152,178
365bc7651a03fa1c1c02dbd72d800a1d97855484,Develop a cerebrospinal fluid biomarker signature for mild Alzheimer's disease (AD) in Alzheimer's Disease Neuroimaging Initiative (ADNI) subjects.,2009,34,1762,77,25,110,156,141,137,146,171,138,158,148
16373b46351bfeb596128a1c49249e44a47ee77e,"Fluid models of gas discharges require the input of transport coefficients and rate coefficients that depend on the electron energy distribution function. Such coefficients are usually calculated from collision cross-section data by solving the electron Boltzmann equation (BE). In this paper we present a new user-friendly BE solver developed especially for this purpose, freely available under the name BOLSIG+, which is more general and easier to use than most other BE solvers available. The solver provides steady-state solutions of the BE for electrons in a uniform electric field, using the classical two-term expansion, and is able to account for different growth models, quasi-stationary and oscillating fields, electron–neutral collisions and electron–electron collisions. We show that for the approximations we use, the BE takes the form of a convection-diffusion continuity-equation with a non-local source term in energy space. To solve this equation we use an exponential scheme commonly used for convection-diffusion problems. The calculated electron transport coefficients and rate coefficients are defined so as to ensure maximum consistency with the fluid equations. We discuss how these coefficients are best used in fluid models and illustrate the influence of some essential parameters and approximations.",2005,33,2086,92,4,11,26,27,49,56,80,93,114,160
48383c4b50853ff1afab6ecb9745c247a97ba6e1,"BACKGROUND
It remains uncertain whether the choice of resuscitation fluid for patients in intensive care units (ICUs) affects survival. We conducted a multicenter, randomized, double-blind trial to compare the effect of fluid resuscitation with albumin or saline on mortality in a heterogeneous population of patients in the ICU.


METHODS
We randomly assigned patients who had been admitted to the ICU to receive either 4 percent albumin or normal saline for intravascular-fluid resuscitation during the next 28 days. The primary outcome measure was death from any cause during the 28-day period after randomization.


RESULTS
Of the 6997 patients who underwent randomization, 3497 were assigned to receive albumin and 3500 to receive saline; the two groups had similar baseline characteristics. There were 726 deaths in the albumin group, as compared with 729 deaths in the saline group (relative risk of death, 0.99; 95 percent confidence interval, 0.91 to 1.09; P=0.87). The proportion of patients with new single-organ and multiple-organ failure was similar in the two groups (P=0.85). There were no significant differences between the groups in the mean (+/-SD) numbers of days spent in the ICU (6.5+/-6.6 in the albumin group and 6.2+/-6.2 in the saline group, P=0.44), days spent in the hospital (15.3+/-9.6 and 15.6+/-9.6, respectively; P=0.30), days of mechanical ventilation (4.5+/-6.1 and 4.3+/-5.7, respectively; P=0.74), or days of renal-replacement therapy (0.5+/-2.3 and 0.4+/-2.0, respectively; P=0.41).


CONCLUSIONS
In patients in the ICU, use of either 4 percent albumin or normal saline for fluid resuscitation results in similar outcomes at 28 days.",2004,28,2297,38,31,102,129,135,140,127,160,140,133,169
d26eccb48c61a051378678dfbb5b5943683fcaed,"Background Optimal fluid management in patients with acute lung injury is unknown. Diuresis or fluid restriction may improve lung function but could jeopardize extrapulmonary-organ perfusion. Methods In a randomized study, we compared a conservative and a liberal strategy of fluid management using explicit protocols applied for seven days in 1000 patients with acute lung injury. The primary end point was death at 60 days. Secondary end points included the number of ventilator-free days and organ-failure–free days and measures of lung physiology. Results The rate of death at 60 days was 25.5 percent in the conservative-strategy group and 28.4 percent in the liberal-strategy group (P=0.30; 95 percent confidence interval for the difference, −2.6 to 8.4 percent). The mean (±SE) cumulative fluid balance during the first seven days was –136±491 ml in the conservative-strategy group and 6992±502 ml in the liberal-strategy group (P<0.001). As compared with the liberal strategy, the conservative strategy improved ...",2009,32,1770,1,93,127,112,142,126,122,93,124,120,115
e28e5bd7634c45b775d915dbb39185d73ef58439,"Inkjet printing is viewed as a versatile manufacturing tool for applications in materials fabrication in addition to its traditional role in graphics output and marking. The unifying feature in all these applications is the dispensing and precise positioning of very small volumes of fluid (1–100 picoliters) on a substrate before transformation to a solid. The application of inkjet printing to the fabrication of structures for structural or functional materials applications requires an understanding as to how the physical processes that operate during inkjet printing interact with the properties of the fluid precursors used. Here we review the current state of understanding of the mechanisms of drop formation and how this defines the fluid properties that are required for a given liquid to be printable. The interactions between individual drops and the substrate as well as between adjacent drops are important in defining the resolution and accuracy of printed objects. Pattern resolution is limited by the extent to which a liquid drop spreads on a substrate and how spreading changes with the overlap of adjacent drops to form continuous features. There are clearly defined upper and lower bounds to the width of a printed continuous line, which can be defined in terms of materials and process variables. Finer-resolution features can be achieved through appropriate patterning and structuring of the substrate prior to printing, which is essential if polymeric semiconducting devices are to be fabricated. Low advancing and receding contact angles promote printed line stability but are also more prone to solute segregation or “coffee staining” on drying.",2010,56,1160,49,2,17,46,44,58,85,103,131,139,179
b721f6ba0e10507f1d25b76c3eb37380d16a31a2,This study develops analytical relationships and computations of power dissipation in magnetic fluid (ferrofluid) subjected to alternating magnetic field. The dissipation results from the orientational relaxation of particles having thermal fluctuations in a viscous medium.,2002,20,1779,95,2,5,8,13,23,28,36,68,81,92
6635fa7b37888f0f90c64afdfcb8ca09d3ae974f,"Many solid tumours show an increased interstitial fluid pressure (IFP), which forms a barrier to transcapillary transport. This barrier is an obstacle in tumour treatment, as it results in inefficient uptake of therapeutic agents. There are a number of factors that contribute to increased IFP in the tumour, such as vessel abnormalities, fibrosis and contraction of the interstitial matrix. Lowering the tumour IFP with specific signal-transduction antagonists might be a useful approach to improving anticancer drug efficacy.",2004,90,1642,63,0,18,37,44,48,50,69,81,97,123
179e0701b833052c3bdf4423c060ca2f68e7d891,"1. Kinematics, conservation equations, and boundary conditions for incompressible flow 2. Unidirectional flow 3. Hydraulic circuit analysis 4. Passive scalar transport: dispersion, patterning, and mixing 5. Electrostatics and electrodynamics 6. Electroosmosis 7. Potential fluid flow 8. Stikes flow 9. The diffuse structure of the electrical double layer 10. Zeta potential in microchannels 11. Species and charge transport 12. Microchip chemical separations 13. Particle electrophoresis 14. DNA transport and analysis 15. Nanofluidics: fluid and current flow in molecular-scale and thick-double-layer systems 16. AC electrokinetics and the dynamics of diffuse charge 17. Particle and droplet actuation: dielectrophoresis, magnetophoresis, and digital microfluidics Appendices: A. Units and fundamental constants B. Properties of electrolyte solutions C. Coordinate systems and vector calculus D. Governing equation reference E. Nondimensionalization and characteristic parameters F. Multipolar solutions to the Laplace and Stokes equations G. Complex functions H. Interaction potentials: atomistic modeling of solvents and solutes.",2010,1,860,45,5,37,57,88,97,100,91,85,90,94
e51ab939cf5a2faf79ae169f2b794bc27f31cfae,,2006,0,1249,190,3,4,27,30,57,72,76,93,73,105
66fbc867a7a5faf4773581ccb3a2918a0706e1db,"BACKGROUND
Optimal fluid management in patients with acute lung injury is unknown. Diuresis or fluid restriction may improve lung function but could jeopardize extrapulmonary-organ perfusion.


METHODS
In a randomized study, we compared a conservative and a liberal strategy of fluid management using explicit protocols applied for seven days in 1000 patients with acute lung injury. The primary end point was death at 60 days. Secondary end points included the number of ventilator-free days and organ-failure-free days and measures of lung physiology.


RESULTS
The rate of death at 60 days was 25.5 percent in the conservative-strategy group and 28.4 percent in the liberal-strategy group (P=0.30; 95 percent confidence interval for the difference, -2.6 to 8.4 percent). The mean (+/-SE) cumulative fluid balance during the first seven days was -136+/-491 ml in the conservative-strategy group and 6992+/-502 ml in the liberal-strategy group (P<0.001). As compared with the liberal strategy, the conservative strategy improved the oxygenation index ([mean airway pressure x the ratio of the fraction of inspired oxygen to the partial pressure of arterial oxygen]x100) and the lung injury score and increased the number of ventilator-free days (14.6+/-0.5 vs. 12.1+/-0.5, P<0.001) and days not spent in the intensive care unit (13.4+/-0.4 vs. 11.2+/-0.4, P<0.001) during the first 28 days but did not increase the incidence or prevalence of shock during the study or the use of dialysis during the first 60 days (10 percent vs. 14 percent, P=0.06).


CONCLUSIONS
Although there was no significant difference in the primary outcome of 60-day mortality, the conservative strategy of fluid management improved lung function and shortened the duration of mechanical ventilation and intensive care without increasing nonpulmonary-organ failures. These results support the use of a conservative strategy of fluid management in patients with acute lung injury. (ClinicalTrials.gov number, NCT00281268 [ClinicalTrials.gov].).",2006,59,1413,48,11,34,60,77,85,93,110,133,120,112
08236a76e2355ee36c154f51b6b2159e054a3191,*Introduction. *Conservation Laws of Fluid Motion and Boundary Conditions. *Turbulence and its Modelling. *The Finite Volume Method for Diffusion Problems. *The Finite Volume Method for Convection-Diffusion Problems. *Solution Algorithms for Pressure-Velocity Coupling in Steady Flows. *Solution of Discretised Equations. *The Finite Volume Method for Unsteady Flows. *Implementation of Boundary Conditions. *Advanced topics and applications. Appendices. References. Index.,2007,0,7124,527,194,239,276,330,368,429,451,568,552,526
65afba3daff41d488f11e017bc02ba99854e52b7,"We present an overview of the lattice Boltzmann method (LBM), a parallel and efficient algorithm for simulating single-phase and multiphase fluid flows and for incorporating additional physical complexities. The LBM is especially useful for modeling complicated boundary conditions and multiphase interfaces. Recent extensions of this method are described, including simulations of fluid turbulence, suspension flows, and reaction diffusion systems.",2001,184,6063,218,62,109,118,114,142,211,241,226,290,295
e0069fc257328c8f362a5e4c37c59f19eb719523,,2003,0,3650,223,53,79,107,171,156,168,222,241,267,223
37491ed087839d86c9ba7783cb12ccc6c9918bf6,"Microfabricated integrated circuits revolutionized computation by vastly reducing the space, labor, and time required for calculations. Microfluidic systems hold similar promise for the large-scale automation of chemistry and biology, suggesting the possibility of numerous experiments performed rapidly and in parallel, while consuming little reagent. While it is too early to tell whether such a vision will be realized, significant progress has been achieved, and various applications of significant scientific and practical interest have been developed. Here a review of the physics of small volumes (nanoliters) of fluids is presented, as parametrized by a series of dimensionless numbers expressing the relative importance of various physical phenomena. Specifically, this review explores the Reynolds number Re, addressing inertial effects; the Peclet number Pe, which concerns convective and diffusive transport; the capillary number Ca expressing the importance of interfacial tension; the Deborah, Weissenberg, and elasticity numbers De, Wi, and El, describing elastic effects due to deformable microstructural elements like polymers; the Grashof and Rayleigh numbers Gr and Ra, describing density-driven flows; and the Knudsen number, describing the importance of noncontinuum molecular effects. Furthermore, the long-range nature of viscous flows and the small device dimensions inherent in microfluidics mean that the influence of boundaries is typically significant. A variety of strategies have been developed to manipulate fluids by exploiting boundary effects; among these are electrokinetic effects, acoustic streaming, and fluid-structure interactions. The goal is to describe the physics behind the rich variety of fluid phenomena occurring on the nanoliter scale using simple scaling arguments, with the hopes of developing an intuitive sense for this occasionally counterintuitive world.",2005,1080,3428,70,17,77,129,221,219,226,241,278,285,260
f14b8ef5a3edc5fdc9613a8a1c5545aa6cb626ad,"This Position Stand provides guidance on fluid replacement to sustain appropriate hydration of individuals performing physical activity. The goal of prehydrating is to start the activity euhydrated and with normal plasma electrolyte levels. Prehydrating with beverages, in addition to normal meals and fluid intake, should be initiated when needed at least several hours before the activity to enable fluid absorption and allow urine output to return to normal levels. The goal of drinking during exercise is to prevent excessive (>2% body weight loss from water deficit) dehydration and excessive changes in electrolyte balance to avert compromised performance. Because there is considerable variability in sweating rates and sweat electrolyte content between individuals, customized fluid replacement programs are recommended. Individual sweat rates can be estimated by measuring body weight before and after exercise. During exercise, consuming beverages containing electrolytes and carbohydrates can provide benefits over water alone under certain circumstances. After exercise, the goal is to replace any fluid electrolyte deficit. The speed with which rehydration is needed and the magnitude of fluid electrolyte deficits will determine if an aggressive replacement program is merited.",2007,10,1798,207,36,62,53,93,111,114,140,150,158,152
662ac20e8d8b980582c513b38dd964cc56b40e05,,2009,0,1648,162,94,74,105,117,140,138,140,120,110,149
c7342bc120397c23c3f777e7cfeb0d76b76637e5,"Intense multidisciplinary research has provided detailed knowledge of the molecular pathogenesis of Alzheimer disease (AD). This knowledge has been translated into new therapeutic strategies with putative disease-modifying effects. Several of the most promising approaches, such as amyloid-β immunotherapy and secretase inhibition, are now being tested in clinical trials. Disease-modifying treatments might be at their most effective when initiated very early in the course of AD, before amyloid plaques and neurodegeneration become too widespread. Thus, biomarkers are needed that can detect AD in the predementia phase or, ideally, in presymptomatic individuals. In this Review, we present the rationales behind and the diagnostic performances of the core cerebrospinal fluid (CSF) biomarkers for AD, namely total tau, phosphorylated tau and the 42 amino acid form of amyloid-β. These biomarkers reflect AD pathology, and are candidate markers for predicting future cognitive decline in healthy individuals and the progression to dementia in patients who are cognitively impaired. We also discuss emerging plasma and CSF biomarkers, and explore new proteomics-based strategies for identifying additional CSF markers. Furthermore, we outline the roles of CSF biomarkers in drug discovery and clinical trials, and provide perspectives on AD biomarker discovery and the validation of such markers for use in the clinic.",2010,198,1523,48,44,90,139,137,156,156,121,155,166,142
2e776c3af634ab4ff40a67e6295efcf3a3879848,"Fluid intelligence (Gf) refers to the ability to reason and to solve new problems independently of previously acquired knowledge. Gf is critical for a wide variety of cognitive tasks, and it is considered one of the most important factors in learning. Moreover, Gf is closely related to professional and educational success, especially in complex and demanding environments. Although performance on tests of Gf can be improved through direct practice on the tests themselves, there is no evidence that training on any other regimen yields increased Gf in adults. Furthermore, there is a long history of research into cognitive training showing that, although performance on trained tasks can increase dramatically, transfer of this learning to other tasks remains poor. Here, we present evidence for transfer from training on a demanding working memory task to measures of Gf. This transfer results even though the trained task is entirely different from the intelligence test itself. Furthermore, we demonstrate that the extent of gain in intelligence critically depends on the amount of training: the more training, the more improvement in Gf. That is, the training effect is dosage-dependent. Thus, in contrast to many previous studies, we conclude that it is possible to improve Gf without practicing the testing tasks themselves, opening a wide range of applications.",2008,58,1893,133,17,56,77,108,154,163,195,176,152,178
365bc7651a03fa1c1c02dbd72d800a1d97855484,Develop a cerebrospinal fluid biomarker signature for mild Alzheimer's disease (AD) in Alzheimer's Disease Neuroimaging Initiative (ADNI) subjects.,2009,34,1762,77,25,110,156,141,137,146,171,138,158,148
16373b46351bfeb596128a1c49249e44a47ee77e,"Fluid models of gas discharges require the input of transport coefficients and rate coefficients that depend on the electron energy distribution function. Such coefficients are usually calculated from collision cross-section data by solving the electron Boltzmann equation (BE). In this paper we present a new user-friendly BE solver developed especially for this purpose, freely available under the name BOLSIG+, which is more general and easier to use than most other BE solvers available. The solver provides steady-state solutions of the BE for electrons in a uniform electric field, using the classical two-term expansion, and is able to account for different growth models, quasi-stationary and oscillating fields, electron–neutral collisions and electron–electron collisions. We show that for the approximations we use, the BE takes the form of a convection-diffusion continuity-equation with a non-local source term in energy space. To solve this equation we use an exponential scheme commonly used for convection-diffusion problems. The calculated electron transport coefficients and rate coefficients are defined so as to ensure maximum consistency with the fluid equations. We discuss how these coefficients are best used in fluid models and illustrate the influence of some essential parameters and approximations.",2005,33,2086,92,4,11,26,27,49,56,80,93,114,160
48383c4b50853ff1afab6ecb9745c247a97ba6e1,"BACKGROUND
It remains uncertain whether the choice of resuscitation fluid for patients in intensive care units (ICUs) affects survival. We conducted a multicenter, randomized, double-blind trial to compare the effect of fluid resuscitation with albumin or saline on mortality in a heterogeneous population of patients in the ICU.


METHODS
We randomly assigned patients who had been admitted to the ICU to receive either 4 percent albumin or normal saline for intravascular-fluid resuscitation during the next 28 days. The primary outcome measure was death from any cause during the 28-day period after randomization.


RESULTS
Of the 6997 patients who underwent randomization, 3497 were assigned to receive albumin and 3500 to receive saline; the two groups had similar baseline characteristics. There were 726 deaths in the albumin group, as compared with 729 deaths in the saline group (relative risk of death, 0.99; 95 percent confidence interval, 0.91 to 1.09; P=0.87). The proportion of patients with new single-organ and multiple-organ failure was similar in the two groups (P=0.85). There were no significant differences between the groups in the mean (+/-SD) numbers of days spent in the ICU (6.5+/-6.6 in the albumin group and 6.2+/-6.2 in the saline group, P=0.44), days spent in the hospital (15.3+/-9.6 and 15.6+/-9.6, respectively; P=0.30), days of mechanical ventilation (4.5+/-6.1 and 4.3+/-5.7, respectively; P=0.74), or days of renal-replacement therapy (0.5+/-2.3 and 0.4+/-2.0, respectively; P=0.41).


CONCLUSIONS
In patients in the ICU, use of either 4 percent albumin or normal saline for fluid resuscitation results in similar outcomes at 28 days.",2004,28,2297,38,31,102,129,135,140,127,160,140,133,169
d26eccb48c61a051378678dfbb5b5943683fcaed,"Background Optimal fluid management in patients with acute lung injury is unknown. Diuresis or fluid restriction may improve lung function but could jeopardize extrapulmonary-organ perfusion. Methods In a randomized study, we compared a conservative and a liberal strategy of fluid management using explicit protocols applied for seven days in 1000 patients with acute lung injury. The primary end point was death at 60 days. Secondary end points included the number of ventilator-free days and organ-failure–free days and measures of lung physiology. Results The rate of death at 60 days was 25.5 percent in the conservative-strategy group and 28.4 percent in the liberal-strategy group (P=0.30; 95 percent confidence interval for the difference, −2.6 to 8.4 percent). The mean (±SE) cumulative fluid balance during the first seven days was –136±491 ml in the conservative-strategy group and 6992±502 ml in the liberal-strategy group (P<0.001). As compared with the liberal strategy, the conservative strategy improved ...",2009,32,1770,1,93,127,112,142,126,122,93,124,120,115
b721f6ba0e10507f1d25b76c3eb37380d16a31a2,This study develops analytical relationships and computations of power dissipation in magnetic fluid (ferrofluid) subjected to alternating magnetic field. The dissipation results from the orientational relaxation of particles having thermal fluctuations in a viscous medium.,2002,20,1779,95,2,5,8,13,23,28,36,68,81,92
6635fa7b37888f0f90c64afdfcb8ca09d3ae974f,"Many solid tumours show an increased interstitial fluid pressure (IFP), which forms a barrier to transcapillary transport. This barrier is an obstacle in tumour treatment, as it results in inefficient uptake of therapeutic agents. There are a number of factors that contribute to increased IFP in the tumour, such as vessel abnormalities, fibrosis and contraction of the interstitial matrix. Lowering the tumour IFP with specific signal-transduction antagonists might be a useful approach to improving anticancer drug efficacy.",2004,90,1642,63,0,18,37,44,48,50,69,81,97,123
179e0701b833052c3bdf4423c060ca2f68e7d891,"1. Kinematics, conservation equations, and boundary conditions for incompressible flow 2. Unidirectional flow 3. Hydraulic circuit analysis 4. Passive scalar transport: dispersion, patterning, and mixing 5. Electrostatics and electrodynamics 6. Electroosmosis 7. Potential fluid flow 8. Stikes flow 9. The diffuse structure of the electrical double layer 10. Zeta potential in microchannels 11. Species and charge transport 12. Microchip chemical separations 13. Particle electrophoresis 14. DNA transport and analysis 15. Nanofluidics: fluid and current flow in molecular-scale and thick-double-layer systems 16. AC electrokinetics and the dynamics of diffuse charge 17. Particle and droplet actuation: dielectrophoresis, magnetophoresis, and digital microfluidics Appendices: A. Units and fundamental constants B. Properties of electrolyte solutions C. Coordinate systems and vector calculus D. Governing equation reference E. Nondimensionalization and characteristic parameters F. Multipolar solutions to the Laplace and Stokes equations G. Complex functions H. Interaction potentials: atomistic modeling of solvents and solutes.",2010,1,860,45,5,37,57,88,97,100,91,85,90,94
e51ab939cf5a2faf79ae169f2b794bc27f31cfae,,2006,0,1249,190,3,4,27,30,57,72,76,93,73,105
66fbc867a7a5faf4773581ccb3a2918a0706e1db,"BACKGROUND
Optimal fluid management in patients with acute lung injury is unknown. Diuresis or fluid restriction may improve lung function but could jeopardize extrapulmonary-organ perfusion.


METHODS
In a randomized study, we compared a conservative and a liberal strategy of fluid management using explicit protocols applied for seven days in 1000 patients with acute lung injury. The primary end point was death at 60 days. Secondary end points included the number of ventilator-free days and organ-failure-free days and measures of lung physiology.


RESULTS
The rate of death at 60 days was 25.5 percent in the conservative-strategy group and 28.4 percent in the liberal-strategy group (P=0.30; 95 percent confidence interval for the difference, -2.6 to 8.4 percent). The mean (+/-SE) cumulative fluid balance during the first seven days was -136+/-491 ml in the conservative-strategy group and 6992+/-502 ml in the liberal-strategy group (P<0.001). As compared with the liberal strategy, the conservative strategy improved the oxygenation index ([mean airway pressure x the ratio of the fraction of inspired oxygen to the partial pressure of arterial oxygen]x100) and the lung injury score and increased the number of ventilator-free days (14.6+/-0.5 vs. 12.1+/-0.5, P<0.001) and days not spent in the intensive care unit (13.4+/-0.4 vs. 11.2+/-0.4, P<0.001) during the first 28 days but did not increase the incidence or prevalence of shock during the study or the use of dialysis during the first 60 days (10 percent vs. 14 percent, P=0.06).


CONCLUSIONS
Although there was no significant difference in the primary outcome of 60-day mortality, the conservative strategy of fluid management improved lung function and shortened the duration of mechanical ventilation and intensive care without increasing nonpulmonary-organ failures. These results support the use of a conservative strategy of fluid management in patients with acute lung injury. (ClinicalTrials.gov number, NCT00281268 [ClinicalTrials.gov].).",2006,59,1413,48,11,34,60,77,85,93,110,133,120,112
f4dca1a08439ae0a13d44dba3774234c5c5b8cab,"Realistically animated fluids can add substantial realism to interactive applications such as virtual surgery simulators or computer games. In this paper we propose an interactive method based on Smoothed Particle Hydrodynamics (SPH) to simulate fluids with free surfaces. The method is an extension of the SPH-based technique by Desbrun to animate highly deformable bodies. We gear the method towards fluid simulation by deriving the force density fields directly from the Navier-Stokes equation and by adding a term to model surface tension effects. In contrast to Eulerian grid-based approaches, the particle-based approach makes mass conservation equations and convection terms dispensable which reduces the complexity of the simulation. In addition, the particles can directly be used to render the surface of the fluid. We propose methods to track and visualize the free surface using point splatting and marching cubes-based surface reconstruction. Our animation method is fast enough to be used in interactive systems and to allow for user interaction with models consisting of up to 5000 particles.",2003,25,1274,142,5,23,37,56,67,58,97,83,84,88
0d3549f769c37e59debe18cb185e85c70ba17c90,"To better understand the diversity of small silencing RNAs expressed in plants, we employed high-throughput pyrosequencing to obtain 887,000 reads corresponding to Arabidopsis thaliana small RNAs. They represented 340,000 unique sequences, a substantially greater diversity than previously obtained in any species. Most of the small RNAs had the properties of heterochromatic small interfering RNAs (siRNAs) associated with DNA silencing in that they were preferentially 24 nucleotides long and mapped to intergenic regions. Their density was greatest in the proximal and distal pericentromeric regions, with only a slightly preferential propensity to match repetitive elements. Also present were 38 newly identified microRNAs (miRNAs) and dozens of other plausible candidates. One miRNA mapped within an intron of DICER-LIKE 1 (DCL1), suggesting a second homeostatic autoregulatory mechanism for DCL1 expression; another defined the phase for siRNAs deriving from a newly identified trans-acting siRNA gene (TAS4); and two depended on DCL4 rather than DCL1 for their accumulation, indicating a second pathway for miRNA biogenesis in plants. More generally, our results revealed the existence of a layer of miRNA-based control beyond that found previously that is evolutionarily much more fluid, employing many newly emergent and diverse miRNAs, each expressed in specialized tissues or at low levels under standard growth conditions.",2006,71,1228,139,1,49,91,86,92,96,125,111,89,101
08236a76e2355ee36c154f51b6b2159e054a3191,*Introduction. *Conservation Laws of Fluid Motion and Boundary Conditions. *Turbulence and its Modelling. *The Finite Volume Method for Diffusion Problems. *The Finite Volume Method for Convection-Diffusion Problems. *Solution Algorithms for Pressure-Velocity Coupling in Steady Flows. *Solution of Discretised Equations. *The Finite Volume Method for Unsteady Flows. *Implementation of Boundary Conditions. *Advanced topics and applications. Appendices. References. Index.,2007,0,7124,527,194,239,276,330,368,429,451,568,552,526
65afba3daff41d488f11e017bc02ba99854e52b7,"We present an overview of the lattice Boltzmann method (LBM), a parallel and efficient algorithm for simulating single-phase and multiphase fluid flows and for incorporating additional physical complexities. The LBM is especially useful for modeling complicated boundary conditions and multiphase interfaces. Recent extensions of this method are described, including simulations of fluid turbulence, suspension flows, and reaction diffusion systems.",2001,184,6063,218,62,109,118,114,142,211,241,226,290,295
e0069fc257328c8f362a5e4c37c59f19eb719523,,2003,0,3650,223,53,79,107,171,156,168,222,241,267,223
37491ed087839d86c9ba7783cb12ccc6c9918bf6,"Microfabricated integrated circuits revolutionized computation by vastly reducing the space, labor, and time required for calculations. Microfluidic systems hold similar promise for the large-scale automation of chemistry and biology, suggesting the possibility of numerous experiments performed rapidly and in parallel, while consuming little reagent. While it is too early to tell whether such a vision will be realized, significant progress has been achieved, and various applications of significant scientific and practical interest have been developed. Here a review of the physics of small volumes (nanoliters) of fluids is presented, as parametrized by a series of dimensionless numbers expressing the relative importance of various physical phenomena. Specifically, this review explores the Reynolds number Re, addressing inertial effects; the Peclet number Pe, which concerns convective and diffusive transport; the capillary number Ca expressing the importance of interfacial tension; the Deborah, Weissenberg, and elasticity numbers De, Wi, and El, describing elastic effects due to deformable microstructural elements like polymers; the Grashof and Rayleigh numbers Gr and Ra, describing density-driven flows; and the Knudsen number, describing the importance of noncontinuum molecular effects. Furthermore, the long-range nature of viscous flows and the small device dimensions inherent in microfluidics mean that the influence of boundaries is typically significant. A variety of strategies have been developed to manipulate fluids by exploiting boundary effects; among these are electrokinetic effects, acoustic streaming, and fluid-structure interactions. The goal is to describe the physics behind the rich variety of fluid phenomena occurring on the nanoliter scale using simple scaling arguments, with the hopes of developing an intuitive sense for this occasionally counterintuitive world.",2005,1080,3428,70,17,77,129,221,219,226,241,278,285,260
f14b8ef5a3edc5fdc9613a8a1c5545aa6cb626ad,"This Position Stand provides guidance on fluid replacement to sustain appropriate hydration of individuals performing physical activity. The goal of prehydrating is to start the activity euhydrated and with normal plasma electrolyte levels. Prehydrating with beverages, in addition to normal meals and fluid intake, should be initiated when needed at least several hours before the activity to enable fluid absorption and allow urine output to return to normal levels. The goal of drinking during exercise is to prevent excessive (>2% body weight loss from water deficit) dehydration and excessive changes in electrolyte balance to avert compromised performance. Because there is considerable variability in sweating rates and sweat electrolyte content between individuals, customized fluid replacement programs are recommended. Individual sweat rates can be estimated by measuring body weight before and after exercise. During exercise, consuming beverages containing electrolytes and carbohydrates can provide benefits over water alone under certain circumstances. After exercise, the goal is to replace any fluid electrolyte deficit. The speed with which rehydration is needed and the magnitude of fluid electrolyte deficits will determine if an aggressive replacement program is merited.",2007,10,1798,207,36,62,53,93,111,114,140,150,158,152
662ac20e8d8b980582c513b38dd964cc56b40e05,,2009,0,1648,162,94,74,105,117,140,138,140,120,110,149
c7342bc120397c23c3f777e7cfeb0d76b76637e5,"Intense multidisciplinary research has provided detailed knowledge of the molecular pathogenesis of Alzheimer disease (AD). This knowledge has been translated into new therapeutic strategies with putative disease-modifying effects. Several of the most promising approaches, such as amyloid-β immunotherapy and secretase inhibition, are now being tested in clinical trials. Disease-modifying treatments might be at their most effective when initiated very early in the course of AD, before amyloid plaques and neurodegeneration become too widespread. Thus, biomarkers are needed that can detect AD in the predementia phase or, ideally, in presymptomatic individuals. In this Review, we present the rationales behind and the diagnostic performances of the core cerebrospinal fluid (CSF) biomarkers for AD, namely total tau, phosphorylated tau and the 42 amino acid form of amyloid-β. These biomarkers reflect AD pathology, and are candidate markers for predicting future cognitive decline in healthy individuals and the progression to dementia in patients who are cognitively impaired. We also discuss emerging plasma and CSF biomarkers, and explore new proteomics-based strategies for identifying additional CSF markers. Furthermore, we outline the roles of CSF biomarkers in drug discovery and clinical trials, and provide perspectives on AD biomarker discovery and the validation of such markers for use in the clinic.",2010,198,1523,48,44,90,139,137,156,156,121,155,166,142
2e776c3af634ab4ff40a67e6295efcf3a3879848,"Fluid intelligence (Gf) refers to the ability to reason and to solve new problems independently of previously acquired knowledge. Gf is critical for a wide variety of cognitive tasks, and it is considered one of the most important factors in learning. Moreover, Gf is closely related to professional and educational success, especially in complex and demanding environments. Although performance on tests of Gf can be improved through direct practice on the tests themselves, there is no evidence that training on any other regimen yields increased Gf in adults. Furthermore, there is a long history of research into cognitive training showing that, although performance on trained tasks can increase dramatically, transfer of this learning to other tasks remains poor. Here, we present evidence for transfer from training on a demanding working memory task to measures of Gf. This transfer results even though the trained task is entirely different from the intelligence test itself. Furthermore, we demonstrate that the extent of gain in intelligence critically depends on the amount of training: the more training, the more improvement in Gf. That is, the training effect is dosage-dependent. Thus, in contrast to many previous studies, we conclude that it is possible to improve Gf without practicing the testing tasks themselves, opening a wide range of applications.",2008,58,1893,133,17,56,77,108,154,163,195,176,152,178
365bc7651a03fa1c1c02dbd72d800a1d97855484,Develop a cerebrospinal fluid biomarker signature for mild Alzheimer's disease (AD) in Alzheimer's Disease Neuroimaging Initiative (ADNI) subjects.,2009,34,1762,77,25,110,156,141,137,146,171,138,158,148
16373b46351bfeb596128a1c49249e44a47ee77e,"Fluid models of gas discharges require the input of transport coefficients and rate coefficients that depend on the electron energy distribution function. Such coefficients are usually calculated from collision cross-section data by solving the electron Boltzmann equation (BE). In this paper we present a new user-friendly BE solver developed especially for this purpose, freely available under the name BOLSIG+, which is more general and easier to use than most other BE solvers available. The solver provides steady-state solutions of the BE for electrons in a uniform electric field, using the classical two-term expansion, and is able to account for different growth models, quasi-stationary and oscillating fields, electron–neutral collisions and electron–electron collisions. We show that for the approximations we use, the BE takes the form of a convection-diffusion continuity-equation with a non-local source term in energy space. To solve this equation we use an exponential scheme commonly used for convection-diffusion problems. The calculated electron transport coefficients and rate coefficients are defined so as to ensure maximum consistency with the fluid equations. We discuss how these coefficients are best used in fluid models and illustrate the influence of some essential parameters and approximations.",2005,33,2086,92,4,11,26,27,49,56,80,93,114,160
48383c4b50853ff1afab6ecb9745c247a97ba6e1,"BACKGROUND
It remains uncertain whether the choice of resuscitation fluid for patients in intensive care units (ICUs) affects survival. We conducted a multicenter, randomized, double-blind trial to compare the effect of fluid resuscitation with albumin or saline on mortality in a heterogeneous population of patients in the ICU.


METHODS
We randomly assigned patients who had been admitted to the ICU to receive either 4 percent albumin or normal saline for intravascular-fluid resuscitation during the next 28 days. The primary outcome measure was death from any cause during the 28-day period after randomization.


RESULTS
Of the 6997 patients who underwent randomization, 3497 were assigned to receive albumin and 3500 to receive saline; the two groups had similar baseline characteristics. There were 726 deaths in the albumin group, as compared with 729 deaths in the saline group (relative risk of death, 0.99; 95 percent confidence interval, 0.91 to 1.09; P=0.87). The proportion of patients with new single-organ and multiple-organ failure was similar in the two groups (P=0.85). There were no significant differences between the groups in the mean (+/-SD) numbers of days spent in the ICU (6.5+/-6.6 in the albumin group and 6.2+/-6.2 in the saline group, P=0.44), days spent in the hospital (15.3+/-9.6 and 15.6+/-9.6, respectively; P=0.30), days of mechanical ventilation (4.5+/-6.1 and 4.3+/-5.7, respectively; P=0.74), or days of renal-replacement therapy (0.5+/-2.3 and 0.4+/-2.0, respectively; P=0.41).


CONCLUSIONS
In patients in the ICU, use of either 4 percent albumin or normal saline for fluid resuscitation results in similar outcomes at 28 days.",2004,28,2297,38,31,102,129,135,140,127,160,140,133,169
d26eccb48c61a051378678dfbb5b5943683fcaed,"Background Optimal fluid management in patients with acute lung injury is unknown. Diuresis or fluid restriction may improve lung function but could jeopardize extrapulmonary-organ perfusion. Methods In a randomized study, we compared a conservative and a liberal strategy of fluid management using explicit protocols applied for seven days in 1000 patients with acute lung injury. The primary end point was death at 60 days. Secondary end points included the number of ventilator-free days and organ-failure–free days and measures of lung physiology. Results The rate of death at 60 days was 25.5 percent in the conservative-strategy group and 28.4 percent in the liberal-strategy group (P=0.30; 95 percent confidence interval for the difference, −2.6 to 8.4 percent). The mean (±SE) cumulative fluid balance during the first seven days was –136±491 ml in the conservative-strategy group and 6992±502 ml in the liberal-strategy group (P<0.001). As compared with the liberal strategy, the conservative strategy improved ...",2009,32,1770,1,93,127,112,142,126,122,93,124,120,115
b721f6ba0e10507f1d25b76c3eb37380d16a31a2,This study develops analytical relationships and computations of power dissipation in magnetic fluid (ferrofluid) subjected to alternating magnetic field. The dissipation results from the orientational relaxation of particles having thermal fluctuations in a viscous medium.,2002,20,1779,95,2,5,8,13,23,28,36,68,81,92
6635fa7b37888f0f90c64afdfcb8ca09d3ae974f,"Many solid tumours show an increased interstitial fluid pressure (IFP), which forms a barrier to transcapillary transport. This barrier is an obstacle in tumour treatment, as it results in inefficient uptake of therapeutic agents. There are a number of factors that contribute to increased IFP in the tumour, such as vessel abnormalities, fibrosis and contraction of the interstitial matrix. Lowering the tumour IFP with specific signal-transduction antagonists might be a useful approach to improving anticancer drug efficacy.",2004,90,1642,63,0,18,37,44,48,50,69,81,97,123
179e0701b833052c3bdf4423c060ca2f68e7d891,"1. Kinematics, conservation equations, and boundary conditions for incompressible flow 2. Unidirectional flow 3. Hydraulic circuit analysis 4. Passive scalar transport: dispersion, patterning, and mixing 5. Electrostatics and electrodynamics 6. Electroosmosis 7. Potential fluid flow 8. Stikes flow 9. The diffuse structure of the electrical double layer 10. Zeta potential in microchannels 11. Species and charge transport 12. Microchip chemical separations 13. Particle electrophoresis 14. DNA transport and analysis 15. Nanofluidics: fluid and current flow in molecular-scale and thick-double-layer systems 16. AC electrokinetics and the dynamics of diffuse charge 17. Particle and droplet actuation: dielectrophoresis, magnetophoresis, and digital microfluidics Appendices: A. Units and fundamental constants B. Properties of electrolyte solutions C. Coordinate systems and vector calculus D. Governing equation reference E. Nondimensionalization and characteristic parameters F. Multipolar solutions to the Laplace and Stokes equations G. Complex functions H. Interaction potentials: atomistic modeling of solvents and solutes.",2010,1,860,45,5,37,57,88,97,100,91,85,90,94
e51ab939cf5a2faf79ae169f2b794bc27f31cfae,,2006,0,1249,190,3,4,27,30,57,72,76,93,73,105
66fbc867a7a5faf4773581ccb3a2918a0706e1db,"BACKGROUND
Optimal fluid management in patients with acute lung injury is unknown. Diuresis or fluid restriction may improve lung function but could jeopardize extrapulmonary-organ perfusion.


METHODS
In a randomized study, we compared a conservative and a liberal strategy of fluid management using explicit protocols applied for seven days in 1000 patients with acute lung injury. The primary end point was death at 60 days. Secondary end points included the number of ventilator-free days and organ-failure-free days and measures of lung physiology.


RESULTS
The rate of death at 60 days was 25.5 percent in the conservative-strategy group and 28.4 percent in the liberal-strategy group (P=0.30; 95 percent confidence interval for the difference, -2.6 to 8.4 percent). The mean (+/-SE) cumulative fluid balance during the first seven days was -136+/-491 ml in the conservative-strategy group and 6992+/-502 ml in the liberal-strategy group (P<0.001). As compared with the liberal strategy, the conservative strategy improved the oxygenation index ([mean airway pressure x the ratio of the fraction of inspired oxygen to the partial pressure of arterial oxygen]x100) and the lung injury score and increased the number of ventilator-free days (14.6+/-0.5 vs. 12.1+/-0.5, P<0.001) and days not spent in the intensive care unit (13.4+/-0.4 vs. 11.2+/-0.4, P<0.001) during the first 28 days but did not increase the incidence or prevalence of shock during the study or the use of dialysis during the first 60 days (10 percent vs. 14 percent, P=0.06).


CONCLUSIONS
Although there was no significant difference in the primary outcome of 60-day mortality, the conservative strategy of fluid management improved lung function and shortened the duration of mechanical ventilation and intensive care without increasing nonpulmonary-organ failures. These results support the use of a conservative strategy of fluid management in patients with acute lung injury. (ClinicalTrials.gov number, NCT00281268 [ClinicalTrials.gov].).",2006,59,1413,48,11,34,60,77,85,93,110,133,120,112
f4dca1a08439ae0a13d44dba3774234c5c5b8cab,"Realistically animated fluids can add substantial realism to interactive applications such as virtual surgery simulators or computer games. In this paper we propose an interactive method based on Smoothed Particle Hydrodynamics (SPH) to simulate fluids with free surfaces. The method is an extension of the SPH-based technique by Desbrun to animate highly deformable bodies. We gear the method towards fluid simulation by deriving the force density fields directly from the Navier-Stokes equation and by adding a term to model surface tension effects. In contrast to Eulerian grid-based approaches, the particle-based approach makes mass conservation equations and convection terms dispensable which reduces the complexity of the simulation. In addition, the particles can directly be used to render the surface of the fluid. We propose methods to track and visualize the free surface using point splatting and marching cubes-based surface reconstruction. Our animation method is fast enough to be used in interactive systems and to allow for user interaction with models consisting of up to 5000 particles.",2003,25,1274,142,5,23,37,56,67,58,97,83,84,88
0d3549f769c37e59debe18cb185e85c70ba17c90,"To better understand the diversity of small silencing RNAs expressed in plants, we employed high-throughput pyrosequencing to obtain 887,000 reads corresponding to Arabidopsis thaliana small RNAs. They represented 340,000 unique sequences, a substantially greater diversity than previously obtained in any species. Most of the small RNAs had the properties of heterochromatic small interfering RNAs (siRNAs) associated with DNA silencing in that they were preferentially 24 nucleotides long and mapped to intergenic regions. Their density was greatest in the proximal and distal pericentromeric regions, with only a slightly preferential propensity to match repetitive elements. Also present were 38 newly identified microRNAs (miRNAs) and dozens of other plausible candidates. One miRNA mapped within an intron of DICER-LIKE 1 (DCL1), suggesting a second homeostatic autoregulatory mechanism for DCL1 expression; another defined the phase for siRNAs deriving from a newly identified trans-acting siRNA gene (TAS4); and two depended on DCL4 rather than DCL1 for their accumulation, indicating a second pathway for miRNA biogenesis in plants. More generally, our results revealed the existence of a layer of miRNA-based control beyond that found previously that is evolutionarily much more fluid, employing many newly emergent and diverse miRNAs, each expressed in specialized tissues or at low levels under standard growth conditions.",2006,71,1228,139,1,49,91,86,92,96,125,111,89,101
08236a76e2355ee36c154f51b6b2159e054a3191,*Introduction. *Conservation Laws of Fluid Motion and Boundary Conditions. *Turbulence and its Modelling. *The Finite Volume Method for Diffusion Problems. *The Finite Volume Method for Convection-Diffusion Problems. *Solution Algorithms for Pressure-Velocity Coupling in Steady Flows. *Solution of Discretised Equations. *The Finite Volume Method for Unsteady Flows. *Implementation of Boundary Conditions. *Advanced topics and applications. Appendices. References. Index.,2007,0,7124,527,194,239,276,330,368,429,451,568,552,526
65afba3daff41d488f11e017bc02ba99854e52b7,"We present an overview of the lattice Boltzmann method (LBM), a parallel and efficient algorithm for simulating single-phase and multiphase fluid flows and for incorporating additional physical complexities. The LBM is especially useful for modeling complicated boundary conditions and multiphase interfaces. Recent extensions of this method are described, including simulations of fluid turbulence, suspension flows, and reaction diffusion systems.",2001,184,6063,218,62,109,118,114,142,211,241,226,290,295
e0069fc257328c8f362a5e4c37c59f19eb719523,,2003,0,3650,223,53,79,107,171,156,168,222,241,267,223
37491ed087839d86c9ba7783cb12ccc6c9918bf6,"Microfabricated integrated circuits revolutionized computation by vastly reducing the space, labor, and time required for calculations. Microfluidic systems hold similar promise for the large-scale automation of chemistry and biology, suggesting the possibility of numerous experiments performed rapidly and in parallel, while consuming little reagent. While it is too early to tell whether such a vision will be realized, significant progress has been achieved, and various applications of significant scientific and practical interest have been developed. Here a review of the physics of small volumes (nanoliters) of fluids is presented, as parametrized by a series of dimensionless numbers expressing the relative importance of various physical phenomena. Specifically, this review explores the Reynolds number Re, addressing inertial effects; the Peclet number Pe, which concerns convective and diffusive transport; the capillary number Ca expressing the importance of interfacial tension; the Deborah, Weissenberg, and elasticity numbers De, Wi, and El, describing elastic effects due to deformable microstructural elements like polymers; the Grashof and Rayleigh numbers Gr and Ra, describing density-driven flows; and the Knudsen number, describing the importance of noncontinuum molecular effects. Furthermore, the long-range nature of viscous flows and the small device dimensions inherent in microfluidics mean that the influence of boundaries is typically significant. A variety of strategies have been developed to manipulate fluids by exploiting boundary effects; among these are electrokinetic effects, acoustic streaming, and fluid-structure interactions. The goal is to describe the physics behind the rich variety of fluid phenomena occurring on the nanoliter scale using simple scaling arguments, with the hopes of developing an intuitive sense for this occasionally counterintuitive world.",2005,1080,3428,70,17,77,129,221,219,226,241,278,285,260
f14b8ef5a3edc5fdc9613a8a1c5545aa6cb626ad,"This Position Stand provides guidance on fluid replacement to sustain appropriate hydration of individuals performing physical activity. The goal of prehydrating is to start the activity euhydrated and with normal plasma electrolyte levels. Prehydrating with beverages, in addition to normal meals and fluid intake, should be initiated when needed at least several hours before the activity to enable fluid absorption and allow urine output to return to normal levels. The goal of drinking during exercise is to prevent excessive (>2% body weight loss from water deficit) dehydration and excessive changes in electrolyte balance to avert compromised performance. Because there is considerable variability in sweating rates and sweat electrolyte content between individuals, customized fluid replacement programs are recommended. Individual sweat rates can be estimated by measuring body weight before and after exercise. During exercise, consuming beverages containing electrolytes and carbohydrates can provide benefits over water alone under certain circumstances. After exercise, the goal is to replace any fluid electrolyte deficit. The speed with which rehydration is needed and the magnitude of fluid electrolyte deficits will determine if an aggressive replacement program is merited.",2007,10,1798,207,36,62,53,93,111,114,140,150,158,152
662ac20e8d8b980582c513b38dd964cc56b40e05,,2009,0,1648,162,94,74,105,117,140,138,140,120,110,149
c7342bc120397c23c3f777e7cfeb0d76b76637e5,"Intense multidisciplinary research has provided detailed knowledge of the molecular pathogenesis of Alzheimer disease (AD). This knowledge has been translated into new therapeutic strategies with putative disease-modifying effects. Several of the most promising approaches, such as amyloid-β immunotherapy and secretase inhibition, are now being tested in clinical trials. Disease-modifying treatments might be at their most effective when initiated very early in the course of AD, before amyloid plaques and neurodegeneration become too widespread. Thus, biomarkers are needed that can detect AD in the predementia phase or, ideally, in presymptomatic individuals. In this Review, we present the rationales behind and the diagnostic performances of the core cerebrospinal fluid (CSF) biomarkers for AD, namely total tau, phosphorylated tau and the 42 amino acid form of amyloid-β. These biomarkers reflect AD pathology, and are candidate markers for predicting future cognitive decline in healthy individuals and the progression to dementia in patients who are cognitively impaired. We also discuss emerging plasma and CSF biomarkers, and explore new proteomics-based strategies for identifying additional CSF markers. Furthermore, we outline the roles of CSF biomarkers in drug discovery and clinical trials, and provide perspectives on AD biomarker discovery and the validation of such markers for use in the clinic.",2010,198,1523,48,44,90,139,137,156,156,121,155,166,142
2e776c3af634ab4ff40a67e6295efcf3a3879848,"Fluid intelligence (Gf) refers to the ability to reason and to solve new problems independently of previously acquired knowledge. Gf is critical for a wide variety of cognitive tasks, and it is considered one of the most important factors in learning. Moreover, Gf is closely related to professional and educational success, especially in complex and demanding environments. Although performance on tests of Gf can be improved through direct practice on the tests themselves, there is no evidence that training on any other regimen yields increased Gf in adults. Furthermore, there is a long history of research into cognitive training showing that, although performance on trained tasks can increase dramatically, transfer of this learning to other tasks remains poor. Here, we present evidence for transfer from training on a demanding working memory task to measures of Gf. This transfer results even though the trained task is entirely different from the intelligence test itself. Furthermore, we demonstrate that the extent of gain in intelligence critically depends on the amount of training: the more training, the more improvement in Gf. That is, the training effect is dosage-dependent. Thus, in contrast to many previous studies, we conclude that it is possible to improve Gf without practicing the testing tasks themselves, opening a wide range of applications.",2008,58,1893,133,17,56,77,108,154,163,195,176,152,178
365bc7651a03fa1c1c02dbd72d800a1d97855484,Develop a cerebrospinal fluid biomarker signature for mild Alzheimer's disease (AD) in Alzheimer's Disease Neuroimaging Initiative (ADNI) subjects.,2009,34,1762,77,25,110,156,141,137,146,171,138,158,148
16373b46351bfeb596128a1c49249e44a47ee77e,"Fluid models of gas discharges require the input of transport coefficients and rate coefficients that depend on the electron energy distribution function. Such coefficients are usually calculated from collision cross-section data by solving the electron Boltzmann equation (BE). In this paper we present a new user-friendly BE solver developed especially for this purpose, freely available under the name BOLSIG+, which is more general and easier to use than most other BE solvers available. The solver provides steady-state solutions of the BE for electrons in a uniform electric field, using the classical two-term expansion, and is able to account for different growth models, quasi-stationary and oscillating fields, electron–neutral collisions and electron–electron collisions. We show that for the approximations we use, the BE takes the form of a convection-diffusion continuity-equation with a non-local source term in energy space. To solve this equation we use an exponential scheme commonly used for convection-diffusion problems. The calculated electron transport coefficients and rate coefficients are defined so as to ensure maximum consistency with the fluid equations. We discuss how these coefficients are best used in fluid models and illustrate the influence of some essential parameters and approximations.",2005,33,2086,92,4,11,26,27,49,56,80,93,114,160
48383c4b50853ff1afab6ecb9745c247a97ba6e1,"BACKGROUND
It remains uncertain whether the choice of resuscitation fluid for patients in intensive care units (ICUs) affects survival. We conducted a multicenter, randomized, double-blind trial to compare the effect of fluid resuscitation with albumin or saline on mortality in a heterogeneous population of patients in the ICU.


METHODS
We randomly assigned patients who had been admitted to the ICU to receive either 4 percent albumin or normal saline for intravascular-fluid resuscitation during the next 28 days. The primary outcome measure was death from any cause during the 28-day period after randomization.


RESULTS
Of the 6997 patients who underwent randomization, 3497 were assigned to receive albumin and 3500 to receive saline; the two groups had similar baseline characteristics. There were 726 deaths in the albumin group, as compared with 729 deaths in the saline group (relative risk of death, 0.99; 95 percent confidence interval, 0.91 to 1.09; P=0.87). The proportion of patients with new single-organ and multiple-organ failure was similar in the two groups (P=0.85). There were no significant differences between the groups in the mean (+/-SD) numbers of days spent in the ICU (6.5+/-6.6 in the albumin group and 6.2+/-6.2 in the saline group, P=0.44), days spent in the hospital (15.3+/-9.6 and 15.6+/-9.6, respectively; P=0.30), days of mechanical ventilation (4.5+/-6.1 and 4.3+/-5.7, respectively; P=0.74), or days of renal-replacement therapy (0.5+/-2.3 and 0.4+/-2.0, respectively; P=0.41).


CONCLUSIONS
In patients in the ICU, use of either 4 percent albumin or normal saline for fluid resuscitation results in similar outcomes at 28 days.",2004,28,2297,38,31,102,129,135,140,127,160,140,133,169
d26eccb48c61a051378678dfbb5b5943683fcaed,"Background Optimal fluid management in patients with acute lung injury is unknown. Diuresis or fluid restriction may improve lung function but could jeopardize extrapulmonary-organ perfusion. Methods In a randomized study, we compared a conservative and a liberal strategy of fluid management using explicit protocols applied for seven days in 1000 patients with acute lung injury. The primary end point was death at 60 days. Secondary end points included the number of ventilator-free days and organ-failure–free days and measures of lung physiology. Results The rate of death at 60 days was 25.5 percent in the conservative-strategy group and 28.4 percent in the liberal-strategy group (P=0.30; 95 percent confidence interval for the difference, −2.6 to 8.4 percent). The mean (±SE) cumulative fluid balance during the first seven days was –136±491 ml in the conservative-strategy group and 6992±502 ml in the liberal-strategy group (P<0.001). As compared with the liberal strategy, the conservative strategy improved ...",2009,32,1770,1,93,127,112,142,126,122,93,124,120,115
b721f6ba0e10507f1d25b76c3eb37380d16a31a2,This study develops analytical relationships and computations of power dissipation in magnetic fluid (ferrofluid) subjected to alternating magnetic field. The dissipation results from the orientational relaxation of particles having thermal fluctuations in a viscous medium.,2002,20,1779,95,2,5,8,13,23,28,36,68,81,92
6635fa7b37888f0f90c64afdfcb8ca09d3ae974f,"Many solid tumours show an increased interstitial fluid pressure (IFP), which forms a barrier to transcapillary transport. This barrier is an obstacle in tumour treatment, as it results in inefficient uptake of therapeutic agents. There are a number of factors that contribute to increased IFP in the tumour, such as vessel abnormalities, fibrosis and contraction of the interstitial matrix. Lowering the tumour IFP with specific signal-transduction antagonists might be a useful approach to improving anticancer drug efficacy.",2004,90,1642,63,0,18,37,44,48,50,69,81,97,123
179e0701b833052c3bdf4423c060ca2f68e7d891,"1. Kinematics, conservation equations, and boundary conditions for incompressible flow 2. Unidirectional flow 3. Hydraulic circuit analysis 4. Passive scalar transport: dispersion, patterning, and mixing 5. Electrostatics and electrodynamics 6. Electroosmosis 7. Potential fluid flow 8. Stikes flow 9. The diffuse structure of the electrical double layer 10. Zeta potential in microchannels 11. Species and charge transport 12. Microchip chemical separations 13. Particle electrophoresis 14. DNA transport and analysis 15. Nanofluidics: fluid and current flow in molecular-scale and thick-double-layer systems 16. AC electrokinetics and the dynamics of diffuse charge 17. Particle and droplet actuation: dielectrophoresis, magnetophoresis, and digital microfluidics Appendices: A. Units and fundamental constants B. Properties of electrolyte solutions C. Coordinate systems and vector calculus D. Governing equation reference E. Nondimensionalization and characteristic parameters F. Multipolar solutions to the Laplace and Stokes equations G. Complex functions H. Interaction potentials: atomistic modeling of solvents and solutes.",2010,1,860,45,5,37,57,88,97,100,91,85,90,94
e51ab939cf5a2faf79ae169f2b794bc27f31cfae,,2006,0,1249,190,3,4,27,30,57,72,76,93,73,105
66fbc867a7a5faf4773581ccb3a2918a0706e1db,"BACKGROUND
Optimal fluid management in patients with acute lung injury is unknown. Diuresis or fluid restriction may improve lung function but could jeopardize extrapulmonary-organ perfusion.


METHODS
In a randomized study, we compared a conservative and a liberal strategy of fluid management using explicit protocols applied for seven days in 1000 patients with acute lung injury. The primary end point was death at 60 days. Secondary end points included the number of ventilator-free days and organ-failure-free days and measures of lung physiology.


RESULTS
The rate of death at 60 days was 25.5 percent in the conservative-strategy group and 28.4 percent in the liberal-strategy group (P=0.30; 95 percent confidence interval for the difference, -2.6 to 8.4 percent). The mean (+/-SE) cumulative fluid balance during the first seven days was -136+/-491 ml in the conservative-strategy group and 6992+/-502 ml in the liberal-strategy group (P<0.001). As compared with the liberal strategy, the conservative strategy improved the oxygenation index ([mean airway pressure x the ratio of the fraction of inspired oxygen to the partial pressure of arterial oxygen]x100) and the lung injury score and increased the number of ventilator-free days (14.6+/-0.5 vs. 12.1+/-0.5, P<0.001) and days not spent in the intensive care unit (13.4+/-0.4 vs. 11.2+/-0.4, P<0.001) during the first 28 days but did not increase the incidence or prevalence of shock during the study or the use of dialysis during the first 60 days (10 percent vs. 14 percent, P=0.06).


CONCLUSIONS
Although there was no significant difference in the primary outcome of 60-day mortality, the conservative strategy of fluid management improved lung function and shortened the duration of mechanical ventilation and intensive care without increasing nonpulmonary-organ failures. These results support the use of a conservative strategy of fluid management in patients with acute lung injury. (ClinicalTrials.gov number, NCT00281268 [ClinicalTrials.gov].).",2006,59,1413,48,11,34,60,77,85,93,110,133,120,112
f4dca1a08439ae0a13d44dba3774234c5c5b8cab,"Realistically animated fluids can add substantial realism to interactive applications such as virtual surgery simulators or computer games. In this paper we propose an interactive method based on Smoothed Particle Hydrodynamics (SPH) to simulate fluids with free surfaces. The method is an extension of the SPH-based technique by Desbrun to animate highly deformable bodies. We gear the method towards fluid simulation by deriving the force density fields directly from the Navier-Stokes equation and by adding a term to model surface tension effects. In contrast to Eulerian grid-based approaches, the particle-based approach makes mass conservation equations and convection terms dispensable which reduces the complexity of the simulation. In addition, the particles can directly be used to render the surface of the fluid. We propose methods to track and visualize the free surface using point splatting and marching cubes-based surface reconstruction. Our animation method is fast enough to be used in interactive systems and to allow for user interaction with models consisting of up to 5000 particles.",2003,25,1274,142,5,23,37,56,67,58,97,83,84,88
0d3549f769c37e59debe18cb185e85c70ba17c90,"To better understand the diversity of small silencing RNAs expressed in plants, we employed high-throughput pyrosequencing to obtain 887,000 reads corresponding to Arabidopsis thaliana small RNAs. They represented 340,000 unique sequences, a substantially greater diversity than previously obtained in any species. Most of the small RNAs had the properties of heterochromatic small interfering RNAs (siRNAs) associated with DNA silencing in that they were preferentially 24 nucleotides long and mapped to intergenic regions. Their density was greatest in the proximal and distal pericentromeric regions, with only a slightly preferential propensity to match repetitive elements. Also present were 38 newly identified microRNAs (miRNAs) and dozens of other plausible candidates. One miRNA mapped within an intron of DICER-LIKE 1 (DCL1), suggesting a second homeostatic autoregulatory mechanism for DCL1 expression; another defined the phase for siRNAs deriving from a newly identified trans-acting siRNA gene (TAS4); and two depended on DCL4 rather than DCL1 for their accumulation, indicating a second pathway for miRNA biogenesis in plants. More generally, our results revealed the existence of a layer of miRNA-based control beyond that found previously that is evolutionarily much more fluid, employing many newly emergent and diverse miRNAs, each expressed in specialized tissues or at low levels under standard growth conditions.",2006,71,1228,139,1,49,91,86,92,96,125,111,89,101
3c21e68088b176d521d127a4dc358f6fa6d41fca,Preface to the second edition Preface to the first edition Acknowledgements List of main symbols 1. Introduction: a history of helicopter flight 2. Fundamentals of rotor aerodynamics 3. Blade element analysis 4. Rotating blade motion 5. Helicopter performance 6. Aerodynamics design of helicopters 7. Aerodynamics of rotor airfoils 8. Unsteady airfoil behavior 9. Dynamic stall 10. Rotor wakes and blade tip vortices 11. Rotor-airframe interaction aerodynamics 12. Autogiros and gyroplanes 13. Aerodynamics of wind turbines 14. Computational methods for helicopter aerodynamics Appendix Index.,2000,4,2084,255,1,9,21,30,35,48,55,67,64,83
403230929184e8580ed76a41902738153156e86b,"Abstract Micro air vehicles (MAVs) have the potential to revolutionize our sensing and information gathering capabilities in areas such as environmental monitoring and homeland security. Flapping wings with suitable wing kinematics, wing shapes, and flexible structures can enhance lift as well as thrust by exploiting large-scale vortical flow structures under various conditions. However, the scaling invariance of both fluid dynamics and structural dynamics as the size changes is fundamentally difficult. The focus of this review is to assess the recent progress in flapping wing aerodynamics and aeroelasticity. It is realized that a variation of the Reynolds number (wing sizing, flapping frequency, etc.) leads to a change in the leading edge vortex (LEV) and spanwise flow structures, which impacts the aerodynamic force generation. While in classical stationary wing theory, the tip vortices (TiVs) are seen as wasted energy, in flapping flight, they can interact with the LEV to enhance lift without increasing the power requirements. Surrogate modeling techniques can assess the aerodynamic outcomes between two- and three-dimensional wing. The combined effect of the TiVs, the LEV, and jet can improve the aerodynamics of a flapping wing. Regarding aeroelasticity, chordwise flexibility in the forward flight can substantially adjust the projected area normal to the flight trajectory via shape deformation, hence redistributing thrust and lift. Spanwise flexibility in the forward flight creates shape deformation from the wing root to the wing tip resulting in varied phase shift and effective angle of attack distribution along the wing span. Numerous open issues in flapping wing aerodynamics are highlighted.",2010,287,790,18,14,45,58,72,80,82,78,77,71,72
ad5873d1b208c6d5bed72bf533a918c870d664f1,"Saving energy and enhancing performance are secular preoccupations shared by both nature and human beings. In animal locomotion, flapping flyers or swimmers rely on the flexibility of their wings or body to passively increase their efficiency using an appropriate cycle of storing and releasing elastic energy. Despite the convergence of many observations pointing out this feature, the underlying mechanisms explaining how the elastic nature of the wings is related to propulsive efficiency remain unclear. Here we use an experiment with a self-propelled simplified insect model allowing to show how wing compliance governs the performance of flapping flyers. Reducing the description of the flapping wing to a forced oscillator model, we pinpoint different nonlinear effects that can account for the observed behavior—in particular a set of cubic nonlinearities coming from the clamped-free beam equation used to model the wing and a quadratic damping term representing the fluid drag associated to the fast flapping motion. In contrast to what has been repeatedly suggested in the literature, we show that flapping flyers optimize their performance not by especially looking for resonance to achieve larger flapping amplitudes with less effort, but by tuning the temporal evolution of the wing shape (i.e., the phase dynamics in the oscillator model) to optimize the aerodynamics.",2010,34,191,14,0,2,7,22,28,19,20,22,24,13
bf30ff4b4569719b8663c728184c440de36bcebf,"SUMMARY The flight of insects has fascinated physicists and biologists for more than a century. Yet, until recently, researchers were unable to rigorously quantify the complex wing motions of flapping insects or measure the forces and flows around their wings. However, recent developments in high-speed videography and tools for computational and mechanical modeling have allowed researchers to make rapid progress in advancing our understanding of insect flight. These mechanical and computational fluid dynamic models, combined with modern flow visualization techniques, have revealed that the fluid dynamic phenomena underlying flapping flight are different from those of non-flapping, 2-D wings on which most previous models were based. In particular, even at high angles of attack, a prominent leading edge vortex remains stably attached on the insect wing and does not shed into an unsteady wake, as would be expected from non-flapping 2-D wings. Its presence greatly enhances the forces generated by the wing, thus enabling insects to hover or maneuver. In addition, flight forces are further enhanced by other mechanisms acting during changes in angle of attack, especially at stroke reversal, the mutual interaction of the two wings at dorsal stroke reversal or wing–wake interactions following stroke reversal. This progress has enabled the development of simple analytical and empirical models that allow us to calculate the instantaneous forces on flapping insect wings more accurately than was previously possible. It also promises to foster new and exciting multi-disciplinary collaborations between physicists who seek to explain the phenomenology, biologists who seek to understand its relevance to insect physiology and evolution, and engineers who are inspired to build micro-robotic insects using these principles. This review covers the basic physical principles underlying flapping flight in insects, results of recent experiments concerning the aerodynamics of insect flight, as well as the different approaches used to model these phenomena.",2003,124,1060,56,0,6,22,29,29,41,59,68,60,69
3c21e68088b176d521d127a4dc358f6fa6d41fca,Preface to the second edition Preface to the first edition Acknowledgements List of main symbols 1. Introduction: a history of helicopter flight 2. Fundamentals of rotor aerodynamics 3. Blade element analysis 4. Rotating blade motion 5. Helicopter performance 6. Aerodynamics design of helicopters 7. Aerodynamics of rotor airfoils 8. Unsteady airfoil behavior 9. Dynamic stall 10. Rotor wakes and blade tip vortices 11. Rotor-airframe interaction aerodynamics 12. Autogiros and gyroplanes 13. Aerodynamics of wind turbines 14. Computational methods for helicopter aerodynamics Appendix Index.,2000,4,2084,255,1,9,21,30,35,48,55,67,64,83
403230929184e8580ed76a41902738153156e86b,"Abstract Micro air vehicles (MAVs) have the potential to revolutionize our sensing and information gathering capabilities in areas such as environmental monitoring and homeland security. Flapping wings with suitable wing kinematics, wing shapes, and flexible structures can enhance lift as well as thrust by exploiting large-scale vortical flow structures under various conditions. However, the scaling invariance of both fluid dynamics and structural dynamics as the size changes is fundamentally difficult. The focus of this review is to assess the recent progress in flapping wing aerodynamics and aeroelasticity. It is realized that a variation of the Reynolds number (wing sizing, flapping frequency, etc.) leads to a change in the leading edge vortex (LEV) and spanwise flow structures, which impacts the aerodynamic force generation. While in classical stationary wing theory, the tip vortices (TiVs) are seen as wasted energy, in flapping flight, they can interact with the LEV to enhance lift without increasing the power requirements. Surrogate modeling techniques can assess the aerodynamic outcomes between two- and three-dimensional wing. The combined effect of the TiVs, the LEV, and jet can improve the aerodynamics of a flapping wing. Regarding aeroelasticity, chordwise flexibility in the forward flight can substantially adjust the projected area normal to the flight trajectory via shape deformation, hence redistributing thrust and lift. Spanwise flexibility in the forward flight creates shape deformation from the wing root to the wing tip resulting in varied phase shift and effective angle of attack distribution along the wing span. Numerous open issues in flapping wing aerodynamics are highlighted.",2010,287,790,18,14,45,58,72,80,82,78,77,71,72
ad5873d1b208c6d5bed72bf533a918c870d664f1,"Saving energy and enhancing performance are secular preoccupations shared by both nature and human beings. In animal locomotion, flapping flyers or swimmers rely on the flexibility of their wings or body to passively increase their efficiency using an appropriate cycle of storing and releasing elastic energy. Despite the convergence of many observations pointing out this feature, the underlying mechanisms explaining how the elastic nature of the wings is related to propulsive efficiency remain unclear. Here we use an experiment with a self-propelled simplified insect model allowing to show how wing compliance governs the performance of flapping flyers. Reducing the description of the flapping wing to a forced oscillator model, we pinpoint different nonlinear effects that can account for the observed behavior—in particular a set of cubic nonlinearities coming from the clamped-free beam equation used to model the wing and a quadratic damping term representing the fluid drag associated to the fast flapping motion. In contrast to what has been repeatedly suggested in the literature, we show that flapping flyers optimize their performance not by especially looking for resonance to achieve larger flapping amplitudes with less effort, but by tuning the temporal evolution of the wing shape (i.e., the phase dynamics in the oscillator model) to optimize the aerodynamics.",2010,34,191,14,0,2,7,22,28,19,20,22,24,13
bf30ff4b4569719b8663c728184c440de36bcebf,"SUMMARY The flight of insects has fascinated physicists and biologists for more than a century. Yet, until recently, researchers were unable to rigorously quantify the complex wing motions of flapping insects or measure the forces and flows around their wings. However, recent developments in high-speed videography and tools for computational and mechanical modeling have allowed researchers to make rapid progress in advancing our understanding of insect flight. These mechanical and computational fluid dynamic models, combined with modern flow visualization techniques, have revealed that the fluid dynamic phenomena underlying flapping flight are different from those of non-flapping, 2-D wings on which most previous models were based. In particular, even at high angles of attack, a prominent leading edge vortex remains stably attached on the insect wing and does not shed into an unsteady wake, as would be expected from non-flapping 2-D wings. Its presence greatly enhances the forces generated by the wing, thus enabling insects to hover or maneuver. In addition, flight forces are further enhanced by other mechanisms acting during changes in angle of attack, especially at stroke reversal, the mutual interaction of the two wings at dorsal stroke reversal or wing–wake interactions following stroke reversal. This progress has enabled the development of simple analytical and empirical models that allow us to calculate the instantaneous forces on flapping insect wings more accurately than was previously possible. It also promises to foster new and exciting multi-disciplinary collaborations between physicists who seek to explain the phenomenology, biologists who seek to understand its relevance to insect physiology and evolution, and engineers who are inspired to build micro-robotic insects using these principles. This review covers the basic physical principles underlying flapping flight in insects, results of recent experiments concerning the aerodynamics of insect flight, as well as the different approaches used to model these phenomena.",2003,124,1060,56,0,6,22,29,29,41,59,68,60,69
3c21e68088b176d521d127a4dc358f6fa6d41fca,Preface to the second edition Preface to the first edition Acknowledgements List of main symbols 1. Introduction: a history of helicopter flight 2. Fundamentals of rotor aerodynamics 3. Blade element analysis 4. Rotating blade motion 5. Helicopter performance 6. Aerodynamics design of helicopters 7. Aerodynamics of rotor airfoils 8. Unsteady airfoil behavior 9. Dynamic stall 10. Rotor wakes and blade tip vortices 11. Rotor-airframe interaction aerodynamics 12. Autogiros and gyroplanes 13. Aerodynamics of wind turbines 14. Computational methods for helicopter aerodynamics Appendix Index.,2000,4,2084,255,1,9,21,30,35,48,55,67,64,83
403230929184e8580ed76a41902738153156e86b,"Abstract Micro air vehicles (MAVs) have the potential to revolutionize our sensing and information gathering capabilities in areas such as environmental monitoring and homeland security. Flapping wings with suitable wing kinematics, wing shapes, and flexible structures can enhance lift as well as thrust by exploiting large-scale vortical flow structures under various conditions. However, the scaling invariance of both fluid dynamics and structural dynamics as the size changes is fundamentally difficult. The focus of this review is to assess the recent progress in flapping wing aerodynamics and aeroelasticity. It is realized that a variation of the Reynolds number (wing sizing, flapping frequency, etc.) leads to a change in the leading edge vortex (LEV) and spanwise flow structures, which impacts the aerodynamic force generation. While in classical stationary wing theory, the tip vortices (TiVs) are seen as wasted energy, in flapping flight, they can interact with the LEV to enhance lift without increasing the power requirements. Surrogate modeling techniques can assess the aerodynamic outcomes between two- and three-dimensional wing. The combined effect of the TiVs, the LEV, and jet can improve the aerodynamics of a flapping wing. Regarding aeroelasticity, chordwise flexibility in the forward flight can substantially adjust the projected area normal to the flight trajectory via shape deformation, hence redistributing thrust and lift. Spanwise flexibility in the forward flight creates shape deformation from the wing root to the wing tip resulting in varied phase shift and effective angle of attack distribution along the wing span. Numerous open issues in flapping wing aerodynamics are highlighted.",2010,287,790,18,14,45,58,72,80,82,78,77,71,72
ad5873d1b208c6d5bed72bf533a918c870d664f1,"Saving energy and enhancing performance are secular preoccupations shared by both nature and human beings. In animal locomotion, flapping flyers or swimmers rely on the flexibility of their wings or body to passively increase their efficiency using an appropriate cycle of storing and releasing elastic energy. Despite the convergence of many observations pointing out this feature, the underlying mechanisms explaining how the elastic nature of the wings is related to propulsive efficiency remain unclear. Here we use an experiment with a self-propelled simplified insect model allowing to show how wing compliance governs the performance of flapping flyers. Reducing the description of the flapping wing to a forced oscillator model, we pinpoint different nonlinear effects that can account for the observed behavior—in particular a set of cubic nonlinearities coming from the clamped-free beam equation used to model the wing and a quadratic damping term representing the fluid drag associated to the fast flapping motion. In contrast to what has been repeatedly suggested in the literature, we show that flapping flyers optimize their performance not by especially looking for resonance to achieve larger flapping amplitudes with less effort, but by tuning the temporal evolution of the wing shape (i.e., the phase dynamics in the oscillator model) to optimize the aerodynamics.",2010,34,191,14,0,2,7,22,28,19,20,22,24,13
bf30ff4b4569719b8663c728184c440de36bcebf,"SUMMARY The flight of insects has fascinated physicists and biologists for more than a century. Yet, until recently, researchers were unable to rigorously quantify the complex wing motions of flapping insects or measure the forces and flows around their wings. However, recent developments in high-speed videography and tools for computational and mechanical modeling have allowed researchers to make rapid progress in advancing our understanding of insect flight. These mechanical and computational fluid dynamic models, combined with modern flow visualization techniques, have revealed that the fluid dynamic phenomena underlying flapping flight are different from those of non-flapping, 2-D wings on which most previous models were based. In particular, even at high angles of attack, a prominent leading edge vortex remains stably attached on the insect wing and does not shed into an unsteady wake, as would be expected from non-flapping 2-D wings. Its presence greatly enhances the forces generated by the wing, thus enabling insects to hover or maneuver. In addition, flight forces are further enhanced by other mechanisms acting during changes in angle of attack, especially at stroke reversal, the mutual interaction of the two wings at dorsal stroke reversal or wing–wake interactions following stroke reversal. This progress has enabled the development of simple analytical and empirical models that allow us to calculate the instantaneous forces on flapping insect wings more accurately than was previously possible. It also promises to foster new and exciting multi-disciplinary collaborations between physicists who seek to explain the phenomenology, biologists who seek to understand its relevance to insect physiology and evolution, and engineers who are inspired to build micro-robotic insects using these principles. This review covers the basic physical principles underlying flapping flight in insects, results of recent experiments concerning the aerodynamics of insect flight, as well as the different approaches used to model these phenomena.",2003,124,1060,56,0,6,22,29,29,41,59,68,60,69
3c21e68088b176d521d127a4dc358f6fa6d41fca,Preface to the second edition Preface to the first edition Acknowledgements List of main symbols 1. Introduction: a history of helicopter flight 2. Fundamentals of rotor aerodynamics 3. Blade element analysis 4. Rotating blade motion 5. Helicopter performance 6. Aerodynamics design of helicopters 7. Aerodynamics of rotor airfoils 8. Unsteady airfoil behavior 9. Dynamic stall 10. Rotor wakes and blade tip vortices 11. Rotor-airframe interaction aerodynamics 12. Autogiros and gyroplanes 13. Aerodynamics of wind turbines 14. Computational methods for helicopter aerodynamics Appendix Index.,2000,4,2084,255,1,9,21,30,35,48,55,67,64,83
403230929184e8580ed76a41902738153156e86b,"Abstract Micro air vehicles (MAVs) have the potential to revolutionize our sensing and information gathering capabilities in areas such as environmental monitoring and homeland security. Flapping wings with suitable wing kinematics, wing shapes, and flexible structures can enhance lift as well as thrust by exploiting large-scale vortical flow structures under various conditions. However, the scaling invariance of both fluid dynamics and structural dynamics as the size changes is fundamentally difficult. The focus of this review is to assess the recent progress in flapping wing aerodynamics and aeroelasticity. It is realized that a variation of the Reynolds number (wing sizing, flapping frequency, etc.) leads to a change in the leading edge vortex (LEV) and spanwise flow structures, which impacts the aerodynamic force generation. While in classical stationary wing theory, the tip vortices (TiVs) are seen as wasted energy, in flapping flight, they can interact with the LEV to enhance lift without increasing the power requirements. Surrogate modeling techniques can assess the aerodynamic outcomes between two- and three-dimensional wing. The combined effect of the TiVs, the LEV, and jet can improve the aerodynamics of a flapping wing. Regarding aeroelasticity, chordwise flexibility in the forward flight can substantially adjust the projected area normal to the flight trajectory via shape deformation, hence redistributing thrust and lift. Spanwise flexibility in the forward flight creates shape deformation from the wing root to the wing tip resulting in varied phase shift and effective angle of attack distribution along the wing span. Numerous open issues in flapping wing aerodynamics are highlighted.",2010,287,790,18,14,45,58,72,80,82,78,77,71,72
ad5873d1b208c6d5bed72bf533a918c870d664f1,"Saving energy and enhancing performance are secular preoccupations shared by both nature and human beings. In animal locomotion, flapping flyers or swimmers rely on the flexibility of their wings or body to passively increase their efficiency using an appropriate cycle of storing and releasing elastic energy. Despite the convergence of many observations pointing out this feature, the underlying mechanisms explaining how the elastic nature of the wings is related to propulsive efficiency remain unclear. Here we use an experiment with a self-propelled simplified insect model allowing to show how wing compliance governs the performance of flapping flyers. Reducing the description of the flapping wing to a forced oscillator model, we pinpoint different nonlinear effects that can account for the observed behavior—in particular a set of cubic nonlinearities coming from the clamped-free beam equation used to model the wing and a quadratic damping term representing the fluid drag associated to the fast flapping motion. In contrast to what has been repeatedly suggested in the literature, we show that flapping flyers optimize their performance not by especially looking for resonance to achieve larger flapping amplitudes with less effort, but by tuning the temporal evolution of the wing shape (i.e., the phase dynamics in the oscillator model) to optimize the aerodynamics.",2010,34,191,14,0,2,7,22,28,19,20,22,24,13
3c21e68088b176d521d127a4dc358f6fa6d41fca,Preface to the second edition Preface to the first edition Acknowledgements List of main symbols 1. Introduction: a history of helicopter flight 2. Fundamentals of rotor aerodynamics 3. Blade element analysis 4. Rotating blade motion 5. Helicopter performance 6. Aerodynamics design of helicopters 7. Aerodynamics of rotor airfoils 8. Unsteady airfoil behavior 9. Dynamic stall 10. Rotor wakes and blade tip vortices 11. Rotor-airframe interaction aerodynamics 12. Autogiros and gyroplanes 13. Aerodynamics of wind turbines 14. Computational methods for helicopter aerodynamics Appendix Index.,2000,4,2084,255,1,9,21,30,35,48,55,67,64,83
403230929184e8580ed76a41902738153156e86b,"Abstract Micro air vehicles (MAVs) have the potential to revolutionize our sensing and information gathering capabilities in areas such as environmental monitoring and homeland security. Flapping wings with suitable wing kinematics, wing shapes, and flexible structures can enhance lift as well as thrust by exploiting large-scale vortical flow structures under various conditions. However, the scaling invariance of both fluid dynamics and structural dynamics as the size changes is fundamentally difficult. The focus of this review is to assess the recent progress in flapping wing aerodynamics and aeroelasticity. It is realized that a variation of the Reynolds number (wing sizing, flapping frequency, etc.) leads to a change in the leading edge vortex (LEV) and spanwise flow structures, which impacts the aerodynamic force generation. While in classical stationary wing theory, the tip vortices (TiVs) are seen as wasted energy, in flapping flight, they can interact with the LEV to enhance lift without increasing the power requirements. Surrogate modeling techniques can assess the aerodynamic outcomes between two- and three-dimensional wing. The combined effect of the TiVs, the LEV, and jet can improve the aerodynamics of a flapping wing. Regarding aeroelasticity, chordwise flexibility in the forward flight can substantially adjust the projected area normal to the flight trajectory via shape deformation, hence redistributing thrust and lift. Spanwise flexibility in the forward flight creates shape deformation from the wing root to the wing tip resulting in varied phase shift and effective angle of attack distribution along the wing span. Numerous open issues in flapping wing aerodynamics are highlighted.",2010,287,790,18,14,45,58,72,80,82,78,77,71,72
ad5873d1b208c6d5bed72bf533a918c870d664f1,"Saving energy and enhancing performance are secular preoccupations shared by both nature and human beings. In animal locomotion, flapping flyers or swimmers rely on the flexibility of their wings or body to passively increase their efficiency using an appropriate cycle of storing and releasing elastic energy. Despite the convergence of many observations pointing out this feature, the underlying mechanisms explaining how the elastic nature of the wings is related to propulsive efficiency remain unclear. Here we use an experiment with a self-propelled simplified insect model allowing to show how wing compliance governs the performance of flapping flyers. Reducing the description of the flapping wing to a forced oscillator model, we pinpoint different nonlinear effects that can account for the observed behavior—in particular a set of cubic nonlinearities coming from the clamped-free beam equation used to model the wing and a quadratic damping term representing the fluid drag associated to the fast flapping motion. In contrast to what has been repeatedly suggested in the literature, we show that flapping flyers optimize their performance not by especially looking for resonance to achieve larger flapping amplitudes with less effort, but by tuning the temporal evolution of the wing shape (i.e., the phase dynamics in the oscillator model) to optimize the aerodynamics.",2010,34,191,14,0,2,7,22,28,19,20,22,24,13
bf30ff4b4569719b8663c728184c440de36bcebf,"SUMMARY The flight of insects has fascinated physicists and biologists for more than a century. Yet, until recently, researchers were unable to rigorously quantify the complex wing motions of flapping insects or measure the forces and flows around their wings. However, recent developments in high-speed videography and tools for computational and mechanical modeling have allowed researchers to make rapid progress in advancing our understanding of insect flight. These mechanical and computational fluid dynamic models, combined with modern flow visualization techniques, have revealed that the fluid dynamic phenomena underlying flapping flight are different from those of non-flapping, 2-D wings on which most previous models were based. In particular, even at high angles of attack, a prominent leading edge vortex remains stably attached on the insect wing and does not shed into an unsteady wake, as would be expected from non-flapping 2-D wings. Its presence greatly enhances the forces generated by the wing, thus enabling insects to hover or maneuver. In addition, flight forces are further enhanced by other mechanisms acting during changes in angle of attack, especially at stroke reversal, the mutual interaction of the two wings at dorsal stroke reversal or wing–wake interactions following stroke reversal. This progress has enabled the development of simple analytical and empirical models that allow us to calculate the instantaneous forces on flapping insect wings more accurately than was previously possible. It also promises to foster new and exciting multi-disciplinary collaborations between physicists who seek to explain the phenomenology, biologists who seek to understand its relevance to insect physiology and evolution, and engineers who are inspired to build micro-robotic insects using these principles. This review covers the basic physical principles underlying flapping flight in insects, results of recent experiments concerning the aerodynamics of insect flight, as well as the different approaches used to model these phenomena.",2003,124,1060,56,0,6,22,29,29,41,59,68,60,69
3c21e68088b176d521d127a4dc358f6fa6d41fca,Preface to the second edition Preface to the first edition Acknowledgements List of main symbols 1. Introduction: a history of helicopter flight 2. Fundamentals of rotor aerodynamics 3. Blade element analysis 4. Rotating blade motion 5. Helicopter performance 6. Aerodynamics design of helicopters 7. Aerodynamics of rotor airfoils 8. Unsteady airfoil behavior 9. Dynamic stall 10. Rotor wakes and blade tip vortices 11. Rotor-airframe interaction aerodynamics 12. Autogiros and gyroplanes 13. Aerodynamics of wind turbines 14. Computational methods for helicopter aerodynamics Appendix Index.,2000,4,2084,255,1,9,21,30,35,48,55,67,64,83
403230929184e8580ed76a41902738153156e86b,"Abstract Micro air vehicles (MAVs) have the potential to revolutionize our sensing and information gathering capabilities in areas such as environmental monitoring and homeland security. Flapping wings with suitable wing kinematics, wing shapes, and flexible structures can enhance lift as well as thrust by exploiting large-scale vortical flow structures under various conditions. However, the scaling invariance of both fluid dynamics and structural dynamics as the size changes is fundamentally difficult. The focus of this review is to assess the recent progress in flapping wing aerodynamics and aeroelasticity. It is realized that a variation of the Reynolds number (wing sizing, flapping frequency, etc.) leads to a change in the leading edge vortex (LEV) and spanwise flow structures, which impacts the aerodynamic force generation. While in classical stationary wing theory, the tip vortices (TiVs) are seen as wasted energy, in flapping flight, they can interact with the LEV to enhance lift without increasing the power requirements. Surrogate modeling techniques can assess the aerodynamic outcomes between two- and three-dimensional wing. The combined effect of the TiVs, the LEV, and jet can improve the aerodynamics of a flapping wing. Regarding aeroelasticity, chordwise flexibility in the forward flight can substantially adjust the projected area normal to the flight trajectory via shape deformation, hence redistributing thrust and lift. Spanwise flexibility in the forward flight creates shape deformation from the wing root to the wing tip resulting in varied phase shift and effective angle of attack distribution along the wing span. Numerous open issues in flapping wing aerodynamics are highlighted.",2010,287,790,18,14,45,58,72,80,82,78,77,71,72
ad5873d1b208c6d5bed72bf533a918c870d664f1,"Saving energy and enhancing performance are secular preoccupations shared by both nature and human beings. In animal locomotion, flapping flyers or swimmers rely on the flexibility of their wings or body to passively increase their efficiency using an appropriate cycle of storing and releasing elastic energy. Despite the convergence of many observations pointing out this feature, the underlying mechanisms explaining how the elastic nature of the wings is related to propulsive efficiency remain unclear. Here we use an experiment with a self-propelled simplified insect model allowing to show how wing compliance governs the performance of flapping flyers. Reducing the description of the flapping wing to a forced oscillator model, we pinpoint different nonlinear effects that can account for the observed behavior—in particular a set of cubic nonlinearities coming from the clamped-free beam equation used to model the wing and a quadratic damping term representing the fluid drag associated to the fast flapping motion. In contrast to what has been repeatedly suggested in the literature, we show that flapping flyers optimize their performance not by especially looking for resonance to achieve larger flapping amplitudes with less effort, but by tuning the temporal evolution of the wing shape (i.e., the phase dynamics in the oscillator model) to optimize the aerodynamics.",2010,34,191,14,0,2,7,22,28,19,20,22,24,13
bf30ff4b4569719b8663c728184c440de36bcebf,"SUMMARY The flight of insects has fascinated physicists and biologists for more than a century. Yet, until recently, researchers were unable to rigorously quantify the complex wing motions of flapping insects or measure the forces and flows around their wings. However, recent developments in high-speed videography and tools for computational and mechanical modeling have allowed researchers to make rapid progress in advancing our understanding of insect flight. These mechanical and computational fluid dynamic models, combined with modern flow visualization techniques, have revealed that the fluid dynamic phenomena underlying flapping flight are different from those of non-flapping, 2-D wings on which most previous models were based. In particular, even at high angles of attack, a prominent leading edge vortex remains stably attached on the insect wing and does not shed into an unsteady wake, as would be expected from non-flapping 2-D wings. Its presence greatly enhances the forces generated by the wing, thus enabling insects to hover or maneuver. In addition, flight forces are further enhanced by other mechanisms acting during changes in angle of attack, especially at stroke reversal, the mutual interaction of the two wings at dorsal stroke reversal or wing–wake interactions following stroke reversal. This progress has enabled the development of simple analytical and empirical models that allow us to calculate the instantaneous forces on flapping insect wings more accurately than was previously possible. It also promises to foster new and exciting multi-disciplinary collaborations between physicists who seek to explain the phenomenology, biologists who seek to understand its relevance to insect physiology and evolution, and engineers who are inspired to build micro-robotic insects using these principles. This review covers the basic physical principles underlying flapping flight in insects, results of recent experiments concerning the aerodynamics of insect flight, as well as the different approaches used to model these phenomena.",2003,124,1060,56,0,6,22,29,29,41,59,68,60,69
3c21e68088b176d521d127a4dc358f6fa6d41fca,Preface to the second edition Preface to the first edition Acknowledgements List of main symbols 1. Introduction: a history of helicopter flight 2. Fundamentals of rotor aerodynamics 3. Blade element analysis 4. Rotating blade motion 5. Helicopter performance 6. Aerodynamics design of helicopters 7. Aerodynamics of rotor airfoils 8. Unsteady airfoil behavior 9. Dynamic stall 10. Rotor wakes and blade tip vortices 11. Rotor-airframe interaction aerodynamics 12. Autogiros and gyroplanes 13. Aerodynamics of wind turbines 14. Computational methods for helicopter aerodynamics Appendix Index.,2000,4,2084,255,1,9,21,30,35,48,55,67,64,83
403230929184e8580ed76a41902738153156e86b,"Abstract Micro air vehicles (MAVs) have the potential to revolutionize our sensing and information gathering capabilities in areas such as environmental monitoring and homeland security. Flapping wings with suitable wing kinematics, wing shapes, and flexible structures can enhance lift as well as thrust by exploiting large-scale vortical flow structures under various conditions. However, the scaling invariance of both fluid dynamics and structural dynamics as the size changes is fundamentally difficult. The focus of this review is to assess the recent progress in flapping wing aerodynamics and aeroelasticity. It is realized that a variation of the Reynolds number (wing sizing, flapping frequency, etc.) leads to a change in the leading edge vortex (LEV) and spanwise flow structures, which impacts the aerodynamic force generation. While in classical stationary wing theory, the tip vortices (TiVs) are seen as wasted energy, in flapping flight, they can interact with the LEV to enhance lift without increasing the power requirements. Surrogate modeling techniques can assess the aerodynamic outcomes between two- and three-dimensional wing. The combined effect of the TiVs, the LEV, and jet can improve the aerodynamics of a flapping wing. Regarding aeroelasticity, chordwise flexibility in the forward flight can substantially adjust the projected area normal to the flight trajectory via shape deformation, hence redistributing thrust and lift. Spanwise flexibility in the forward flight creates shape deformation from the wing root to the wing tip resulting in varied phase shift and effective angle of attack distribution along the wing span. Numerous open issues in flapping wing aerodynamics are highlighted.",2010,287,790,18,14,45,58,72,80,82,78,77,71,72
ad5873d1b208c6d5bed72bf533a918c870d664f1,"Saving energy and enhancing performance are secular preoccupations shared by both nature and human beings. In animal locomotion, flapping flyers or swimmers rely on the flexibility of their wings or body to passively increase their efficiency using an appropriate cycle of storing and releasing elastic energy. Despite the convergence of many observations pointing out this feature, the underlying mechanisms explaining how the elastic nature of the wings is related to propulsive efficiency remain unclear. Here we use an experiment with a self-propelled simplified insect model allowing to show how wing compliance governs the performance of flapping flyers. Reducing the description of the flapping wing to a forced oscillator model, we pinpoint different nonlinear effects that can account for the observed behavior—in particular a set of cubic nonlinearities coming from the clamped-free beam equation used to model the wing and a quadratic damping term representing the fluid drag associated to the fast flapping motion. In contrast to what has been repeatedly suggested in the literature, we show that flapping flyers optimize their performance not by especially looking for resonance to achieve larger flapping amplitudes with less effort, but by tuning the temporal evolution of the wing shape (i.e., the phase dynamics in the oscillator model) to optimize the aerodynamics.",2010,34,191,14,0,2,7,22,28,19,20,22,24,13
bf30ff4b4569719b8663c728184c440de36bcebf,"SUMMARY The flight of insects has fascinated physicists and biologists for more than a century. Yet, until recently, researchers were unable to rigorously quantify the complex wing motions of flapping insects or measure the forces and flows around their wings. However, recent developments in high-speed videography and tools for computational and mechanical modeling have allowed researchers to make rapid progress in advancing our understanding of insect flight. These mechanical and computational fluid dynamic models, combined with modern flow visualization techniques, have revealed that the fluid dynamic phenomena underlying flapping flight are different from those of non-flapping, 2-D wings on which most previous models were based. In particular, even at high angles of attack, a prominent leading edge vortex remains stably attached on the insect wing and does not shed into an unsteady wake, as would be expected from non-flapping 2-D wings. Its presence greatly enhances the forces generated by the wing, thus enabling insects to hover or maneuver. In addition, flight forces are further enhanced by other mechanisms acting during changes in angle of attack, especially at stroke reversal, the mutual interaction of the two wings at dorsal stroke reversal or wing–wake interactions following stroke reversal. This progress has enabled the development of simple analytical and empirical models that allow us to calculate the instantaneous forces on flapping insect wings more accurately than was previously possible. It also promises to foster new and exciting multi-disciplinary collaborations between physicists who seek to explain the phenomenology, biologists who seek to understand its relevance to insect physiology and evolution, and engineers who are inspired to build micro-robotic insects using these principles. This review covers the basic physical principles underlying flapping flight in insects, results of recent experiments concerning the aerodynamics of insect flight, as well as the different approaches used to model these phenomena.",2003,124,1060,56,0,6,22,29,29,41,59,68,60,69
3c21e68088b176d521d127a4dc358f6fa6d41fca,Preface to the second edition Preface to the first edition Acknowledgements List of main symbols 1. Introduction: a history of helicopter flight 2. Fundamentals of rotor aerodynamics 3. Blade element analysis 4. Rotating blade motion 5. Helicopter performance 6. Aerodynamics design of helicopters 7. Aerodynamics of rotor airfoils 8. Unsteady airfoil behavior 9. Dynamic stall 10. Rotor wakes and blade tip vortices 11. Rotor-airframe interaction aerodynamics 12. Autogiros and gyroplanes 13. Aerodynamics of wind turbines 14. Computational methods for helicopter aerodynamics Appendix Index.,2000,4,2084,255,1,9,21,30,35,48,55,67,64,83
403230929184e8580ed76a41902738153156e86b,"Abstract Micro air vehicles (MAVs) have the potential to revolutionize our sensing and information gathering capabilities in areas such as environmental monitoring and homeland security. Flapping wings with suitable wing kinematics, wing shapes, and flexible structures can enhance lift as well as thrust by exploiting large-scale vortical flow structures under various conditions. However, the scaling invariance of both fluid dynamics and structural dynamics as the size changes is fundamentally difficult. The focus of this review is to assess the recent progress in flapping wing aerodynamics and aeroelasticity. It is realized that a variation of the Reynolds number (wing sizing, flapping frequency, etc.) leads to a change in the leading edge vortex (LEV) and spanwise flow structures, which impacts the aerodynamic force generation. While in classical stationary wing theory, the tip vortices (TiVs) are seen as wasted energy, in flapping flight, they can interact with the LEV to enhance lift without increasing the power requirements. Surrogate modeling techniques can assess the aerodynamic outcomes between two- and three-dimensional wing. The combined effect of the TiVs, the LEV, and jet can improve the aerodynamics of a flapping wing. Regarding aeroelasticity, chordwise flexibility in the forward flight can substantially adjust the projected area normal to the flight trajectory via shape deformation, hence redistributing thrust and lift. Spanwise flexibility in the forward flight creates shape deformation from the wing root to the wing tip resulting in varied phase shift and effective angle of attack distribution along the wing span. Numerous open issues in flapping wing aerodynamics are highlighted.",2010,287,790,18,14,45,58,72,80,82,78,77,71,72
ad5873d1b208c6d5bed72bf533a918c870d664f1,"Saving energy and enhancing performance are secular preoccupations shared by both nature and human beings. In animal locomotion, flapping flyers or swimmers rely on the flexibility of their wings or body to passively increase their efficiency using an appropriate cycle of storing and releasing elastic energy. Despite the convergence of many observations pointing out this feature, the underlying mechanisms explaining how the elastic nature of the wings is related to propulsive efficiency remain unclear. Here we use an experiment with a self-propelled simplified insect model allowing to show how wing compliance governs the performance of flapping flyers. Reducing the description of the flapping wing to a forced oscillator model, we pinpoint different nonlinear effects that can account for the observed behavior—in particular a set of cubic nonlinearities coming from the clamped-free beam equation used to model the wing and a quadratic damping term representing the fluid drag associated to the fast flapping motion. In contrast to what has been repeatedly suggested in the literature, we show that flapping flyers optimize their performance not by especially looking for resonance to achieve larger flapping amplitudes with less effort, but by tuning the temporal evolution of the wing shape (i.e., the phase dynamics in the oscillator model) to optimize the aerodynamics.",2010,34,191,14,0,2,7,22,28,19,20,22,24,13
3c21e68088b176d521d127a4dc358f6fa6d41fca,Preface to the second edition Preface to the first edition Acknowledgements List of main symbols 1. Introduction: a history of helicopter flight 2. Fundamentals of rotor aerodynamics 3. Blade element analysis 4. Rotating blade motion 5. Helicopter performance 6. Aerodynamics design of helicopters 7. Aerodynamics of rotor airfoils 8. Unsteady airfoil behavior 9. Dynamic stall 10. Rotor wakes and blade tip vortices 11. Rotor-airframe interaction aerodynamics 12. Autogiros and gyroplanes 13. Aerodynamics of wind turbines 14. Computational methods for helicopter aerodynamics Appendix Index.,2000,4,2084,255,1,9,21,30,35,48,55,67,64,83
403230929184e8580ed76a41902738153156e86b,"Abstract Micro air vehicles (MAVs) have the potential to revolutionize our sensing and information gathering capabilities in areas such as environmental monitoring and homeland security. Flapping wings with suitable wing kinematics, wing shapes, and flexible structures can enhance lift as well as thrust by exploiting large-scale vortical flow structures under various conditions. However, the scaling invariance of both fluid dynamics and structural dynamics as the size changes is fundamentally difficult. The focus of this review is to assess the recent progress in flapping wing aerodynamics and aeroelasticity. It is realized that a variation of the Reynolds number (wing sizing, flapping frequency, etc.) leads to a change in the leading edge vortex (LEV) and spanwise flow structures, which impacts the aerodynamic force generation. While in classical stationary wing theory, the tip vortices (TiVs) are seen as wasted energy, in flapping flight, they can interact with the LEV to enhance lift without increasing the power requirements. Surrogate modeling techniques can assess the aerodynamic outcomes between two- and three-dimensional wing. The combined effect of the TiVs, the LEV, and jet can improve the aerodynamics of a flapping wing. Regarding aeroelasticity, chordwise flexibility in the forward flight can substantially adjust the projected area normal to the flight trajectory via shape deformation, hence redistributing thrust and lift. Spanwise flexibility in the forward flight creates shape deformation from the wing root to the wing tip resulting in varied phase shift and effective angle of attack distribution along the wing span. Numerous open issues in flapping wing aerodynamics are highlighted.",2010,287,790,18,14,45,58,72,80,82,78,77,71,72
ad5873d1b208c6d5bed72bf533a918c870d664f1,"Saving energy and enhancing performance are secular preoccupations shared by both nature and human beings. In animal locomotion, flapping flyers or swimmers rely on the flexibility of their wings or body to passively increase their efficiency using an appropriate cycle of storing and releasing elastic energy. Despite the convergence of many observations pointing out this feature, the underlying mechanisms explaining how the elastic nature of the wings is related to propulsive efficiency remain unclear. Here we use an experiment with a self-propelled simplified insect model allowing to show how wing compliance governs the performance of flapping flyers. Reducing the description of the flapping wing to a forced oscillator model, we pinpoint different nonlinear effects that can account for the observed behavior—in particular a set of cubic nonlinearities coming from the clamped-free beam equation used to model the wing and a quadratic damping term representing the fluid drag associated to the fast flapping motion. In contrast to what has been repeatedly suggested in the literature, we show that flapping flyers optimize their performance not by especially looking for resonance to achieve larger flapping amplitudes with less effort, but by tuning the temporal evolution of the wing shape (i.e., the phase dynamics in the oscillator model) to optimize the aerodynamics.",2010,34,191,14,0,2,7,22,28,19,20,22,24,13
bf30ff4b4569719b8663c728184c440de36bcebf,"SUMMARY The flight of insects has fascinated physicists and biologists for more than a century. Yet, until recently, researchers were unable to rigorously quantify the complex wing motions of flapping insects or measure the forces and flows around their wings. However, recent developments in high-speed videography and tools for computational and mechanical modeling have allowed researchers to make rapid progress in advancing our understanding of insect flight. These mechanical and computational fluid dynamic models, combined with modern flow visualization techniques, have revealed that the fluid dynamic phenomena underlying flapping flight are different from those of non-flapping, 2-D wings on which most previous models were based. In particular, even at high angles of attack, a prominent leading edge vortex remains stably attached on the insect wing and does not shed into an unsteady wake, as would be expected from non-flapping 2-D wings. Its presence greatly enhances the forces generated by the wing, thus enabling insects to hover or maneuver. In addition, flight forces are further enhanced by other mechanisms acting during changes in angle of attack, especially at stroke reversal, the mutual interaction of the two wings at dorsal stroke reversal or wing–wake interactions following stroke reversal. This progress has enabled the development of simple analytical and empirical models that allow us to calculate the instantaneous forces on flapping insect wings more accurately than was previously possible. It also promises to foster new and exciting multi-disciplinary collaborations between physicists who seek to explain the phenomenology, biologists who seek to understand its relevance to insect physiology and evolution, and engineers who are inspired to build micro-robotic insects using these principles. This review covers the basic physical principles underlying flapping flight in insects, results of recent experiments concerning the aerodynamics of insect flight, as well as the different approaches used to model these phenomena.",2003,124,1060,56,0,6,22,29,29,41,59,68,60,69
3c21e68088b176d521d127a4dc358f6fa6d41fca,Preface to the second edition Preface to the first edition Acknowledgements List of main symbols 1. Introduction: a history of helicopter flight 2. Fundamentals of rotor aerodynamics 3. Blade element analysis 4. Rotating blade motion 5. Helicopter performance 6. Aerodynamics design of helicopters 7. Aerodynamics of rotor airfoils 8. Unsteady airfoil behavior 9. Dynamic stall 10. Rotor wakes and blade tip vortices 11. Rotor-airframe interaction aerodynamics 12. Autogiros and gyroplanes 13. Aerodynamics of wind turbines 14. Computational methods for helicopter aerodynamics Appendix Index.,2000,4,2084,255,1,9,21,30,35,48,55,67,64,83
403230929184e8580ed76a41902738153156e86b,"Abstract Micro air vehicles (MAVs) have the potential to revolutionize our sensing and information gathering capabilities in areas such as environmental monitoring and homeland security. Flapping wings with suitable wing kinematics, wing shapes, and flexible structures can enhance lift as well as thrust by exploiting large-scale vortical flow structures under various conditions. However, the scaling invariance of both fluid dynamics and structural dynamics as the size changes is fundamentally difficult. The focus of this review is to assess the recent progress in flapping wing aerodynamics and aeroelasticity. It is realized that a variation of the Reynolds number (wing sizing, flapping frequency, etc.) leads to a change in the leading edge vortex (LEV) and spanwise flow structures, which impacts the aerodynamic force generation. While in classical stationary wing theory, the tip vortices (TiVs) are seen as wasted energy, in flapping flight, they can interact with the LEV to enhance lift without increasing the power requirements. Surrogate modeling techniques can assess the aerodynamic outcomes between two- and three-dimensional wing. The combined effect of the TiVs, the LEV, and jet can improve the aerodynamics of a flapping wing. Regarding aeroelasticity, chordwise flexibility in the forward flight can substantially adjust the projected area normal to the flight trajectory via shape deformation, hence redistributing thrust and lift. Spanwise flexibility in the forward flight creates shape deformation from the wing root to the wing tip resulting in varied phase shift and effective angle of attack distribution along the wing span. Numerous open issues in flapping wing aerodynamics are highlighted.",2010,287,790,18,14,45,58,72,80,82,78,77,71,72
ad5873d1b208c6d5bed72bf533a918c870d664f1,"Saving energy and enhancing performance are secular preoccupations shared by both nature and human beings. In animal locomotion, flapping flyers or swimmers rely on the flexibility of their wings or body to passively increase their efficiency using an appropriate cycle of storing and releasing elastic energy. Despite the convergence of many observations pointing out this feature, the underlying mechanisms explaining how the elastic nature of the wings is related to propulsive efficiency remain unclear. Here we use an experiment with a self-propelled simplified insect model allowing to show how wing compliance governs the performance of flapping flyers. Reducing the description of the flapping wing to a forced oscillator model, we pinpoint different nonlinear effects that can account for the observed behavior—in particular a set of cubic nonlinearities coming from the clamped-free beam equation used to model the wing and a quadratic damping term representing the fluid drag associated to the fast flapping motion. In contrast to what has been repeatedly suggested in the literature, we show that flapping flyers optimize their performance not by especially looking for resonance to achieve larger flapping amplitudes with less effort, but by tuning the temporal evolution of the wing shape (i.e., the phase dynamics in the oscillator model) to optimize the aerodynamics.",2010,34,191,14,0,2,7,22,28,19,20,22,24,13
bf30ff4b4569719b8663c728184c440de36bcebf,"SUMMARY The flight of insects has fascinated physicists and biologists for more than a century. Yet, until recently, researchers were unable to rigorously quantify the complex wing motions of flapping insects or measure the forces and flows around their wings. However, recent developments in high-speed videography and tools for computational and mechanical modeling have allowed researchers to make rapid progress in advancing our understanding of insect flight. These mechanical and computational fluid dynamic models, combined with modern flow visualization techniques, have revealed that the fluid dynamic phenomena underlying flapping flight are different from those of non-flapping, 2-D wings on which most previous models were based. In particular, even at high angles of attack, a prominent leading edge vortex remains stably attached on the insect wing and does not shed into an unsteady wake, as would be expected from non-flapping 2-D wings. Its presence greatly enhances the forces generated by the wing, thus enabling insects to hover or maneuver. In addition, flight forces are further enhanced by other mechanisms acting during changes in angle of attack, especially at stroke reversal, the mutual interaction of the two wings at dorsal stroke reversal or wing–wake interactions following stroke reversal. This progress has enabled the development of simple analytical and empirical models that allow us to calculate the instantaneous forces on flapping insect wings more accurately than was previously possible. It also promises to foster new and exciting multi-disciplinary collaborations between physicists who seek to explain the phenomenology, biologists who seek to understand its relevance to insect physiology and evolution, and engineers who are inspired to build micro-robotic insects using these principles. This review covers the basic physical principles underlying flapping flight in insects, results of recent experiments concerning the aerodynamics of insect flight, as well as the different approaches used to model these phenomena.",2003,124,1060,56,0,6,22,29,29,41,59,68,60,69
bb01353f818ca226b53433163893efc56c3df32d,"The proliferation of mobile computing devices and local-area wireless networks has fostered a growing interest in location-aware systems and services. In this paper we present RADAR, a radio-frequency (RF)-based system for locating and tracking users inside buildings. RADAR operates by recording and processing signal strength information at multiple base stations positioned to provide overlapping coverage in the area of interest. It combines empirical measurements with signal propagation modeling to determine user location and thereby enable location-aware services and applications. We present experimental results that demonstrate the ability of RADAR to estimate user location with a high degree of accuracy.",2000,36,8417,939,18,41,70,138,237,348,377,446,474,558
1e71e22a3012080f9d6d115080e3f4678e39f0b9,"[1] The Shuttle Radar Topography Mission produced the most complete, highest-resolution digital elevation model of the Earth. The project was a joint endeavor of NASA, the National Geospatial-Intelligence Agency, and the German and Italian Space Agencies and flew in February 2000. It used dual radar antennas to acquire interferometric radar data, processed to digital topographic data at 1 arc sec resolution. Details of the development, flight operations, data processing, and products are provided for users of this revolutionary data set.",2000,52,3523,186,2,5,1,2,1,6,13,14,54,95
a0abeeaef200e83a6d4538423c826a522f4e8b71,"Synthetic aperture radar interferometry is an imaging technique for measuring the topography of a surface, its changes over time, and other changes in the detailed characteristic of the surface. By exploiting the phase of the coherent radar signal, interferometry has transformed radar remote sensing from a largely interpretive science to a quantitative tool, with applications in cartography, geodesy, land cover characterization, and natural hazards. This paper reviews the techniques of interferometry, systems and limitations, and applications in a rapidly growing area of science and engineering.",2000,216,2887,220,23,38,65,78,79,93,114,122,104,141
ce9c55ed58d056b9c0723d048ecd8564fb0c4a16,Overview of Polarimetric Radar Imaging Brief History of Polarimetric Radar Imaging SAR Image Formation: Summary Airborne and Space-Borne PolSAR Systems Description of the Remaining Chapters Electromagnetic Vector Wave and Polarization Descriptors Monochromatic Electromagnetic Plane Wave Polarization Ellipse Jones Vector Stokes Vector Wave Covariance Matrix Electromagnetic Vector Scattering Operators Polarimetric Back Scattering Sinclair S Matrix Scattering Target Vectors k and Omega Polarimetric Coherency T and Covariance C Matrices Polarimetric Mueller M and Kennaugh K Matrices Change of Polarimetric Basis Target Polarimetric Characterization PolSAR Speckle Statistics Fundamental Property of Speckle in SAR Images Speckle Statistics for Multilook-Processed SAR Images Texture Model and K Distribution Effect of Speckle Spatial Correlation Polarimetric and Interferometric SAR Speckle Statistics Phase Difference Distributions of Single-Look and Multilook PolSAR Data Multilook Product Distribution Joint Distribution of Multilook Si2 and Sj2 Multilook Intensity and Amplitude Ratio Distributions Verifications of Multilook PDFs K Distribution for Multilook Polarimetric Data Summary Appendices PolSAR Speckle Filtering Introduction to Speckle Filtering of SAR Imagery Filtering of Single Polarization SAR Data Review of Multipolarization Speckle Filtering Algorithms PolSAR Speckle Filtering Scattering Model-Based PolSAR Speckle Filter Introduction to the Polarimetric Target Decomposition Concept Introduction Dichotomy of the Kennaugh Matrix K Eigenvector-Based Decompositions Model-Based Decompositions Coherent Decompositions The H/A/a Polarimetric Decomposition Theorem Introduction Pure Target Case Probabilistic Model for Random Media Scattering Roll Invariance Property Polarimetric Scattering a Parameter Polarimetric Scattering Entropy (H) Polarimetric Scattering Anisotropy (A) Three-Dimensional H/A/a Classification Space New Eigenvalue-Based Parameters Speckle Filtering Effects on H/A/a PolSAR Terrain and Land-Use Classification Introduction Maximum Likelihood Classifier Based on Complex Gaussian Distribution Complex Wishart Classifier for Multilook PolSAR Data Characteristics of Wishart Distance Measure Supervised Classification Using Wishart Distance Measure Unsupervised Classification Based on Scattering Mechanisms and Wishart Classifier Scattering Model-Based Unsupervised Classification Quantitative Comparison of Classification Capability: Fully PolSAR versus Dual- and Single-Polarization SAR Pol-InSAR Forest Mapping and Classification Introduction Pol-InSAR Scattering Descriptors Forest Mapping and Forest Classification Appendix Selected PolSAR Applications Polarimetric Signature Analysis of Manmade Structures Polarization Orientation Angle Estimation and Applications Ocean Surface Remote Sensing with PolSAR Ionosphere Faraday Rotation Estimation PolSAR Interferometry for Forest Height Estimation Nonstationary Natural Media Analysis from PolSAR Data Using a Two-Dimensional Time-Frequency Approach Appendix A: Eigen Characteristics of Hermitian Matrix Appendix B: PolSARpro Software: The Polariemtric SAR Data Processing and Educational Toolbox Index,2009,0,1800,298,16,47,90,130,125,139,172,197,195,207
a2fd9b9b59646626b5104f781b16ce239c20f03b,Preface. Summary. Nomenclature. 1. Introduction. 2. Radar system theory and interferometric processing. 3. Functional model for radar interferometry. 4. Stochastic model for radar interferometry. 5. Data analysis and interpretation for deformation monitoring. 6. Atmospheric monitoring. 7. Conclusions and recommendations. A. Comparison neutral delay GPS and InSAR. B. Structure function and power spectrum. Bibliography. About the Author. Index.,2001,0,1970,298,4,15,37,37,49,49,71,61,94,118
23eb33af4f0495edff01402ec8eb019e80717897,Foreword. Introduction. Signal Processing Fundamentals. Pulse Compression. Synthetic Aperture Concepts. SAR Signal Properties. The Range Doppler Algorithm. The Chirp Scaling Algorithm. The Omega-K Algorithm. The SPECAN Algorithm. Processing ScanSAR Data. Doppler Parameter Estimation. Comparison of Algorithms. References.,2005,0,1674,246,6,10,16,41,43,79,117,132,127,145
98ec941f07556008c3c3226fd755d7c42ea21b3e,"This detailed guide clearly and concisely presents radar digital signal processing for both practicing engineers and engineering students. This revised edition of Fundamentals of Radar Signal Processing provides in-depth coverage of radar digital signal processing (DSP) fundamentals and applications. It has been updated to include coverage of measurement accuracy and target tracking. Additionally, to make it more useful as a teaching tool, it now includes end-of-chapter problems and a solutions manual. New to this Edition: New chapter on Measurement Accuracy and Target Tracking Two new appendices--Important Digital Signal Processing Facts; Important Probability Density Function and Their Relationships Addition of 20 to 30 problems to ends of chapters Solutions manual",2005,0,1534,178,2,16,20,31,49,85,73,84,114,125
8308e7b39d1f556e4041b4630a41aa8435fe1a49,"MIMO (multiple-input multiple-output) radar refers to an architecture that employs multiple, spatially distributed transmitters and receivers. While, in a general sense, MIMO radar can be viewed as a type of multistatic radar, the separate nomenclature suggests unique features that set MIMO radar apart from the multistatic radar literature and that have a close relation to MIMO communications. This article reviews some recent work on MIMO radar with widely separated antennas. Widely separated transmit/receive antennas capture the spatial diversity of the target's radar cross section (RCS). Unique features of MIMO radar are explained and illustrated by examples. It is shown that with noncoherent processing, a target's RCS spatial variations can be exploited to obtain a diversity gain for target detection and for estimation of various parameters, such as angle of arrival and Doppler. For target location, it is shown that coherent processing can provide a resolution far exceeding that supported by the radar's waveform.",2008,44,1641,72,20,71,104,118,127,118,146,146,155,155
26f825b4ae30b08241df7031a900892761c0f9c0,"We have provided a review of some recent results on the emerging technology of MIMO radar with colocated antennas. We have shown that the waveform diversity offered by such a MIMO radar system enables significant superiority over its phased-array counterpart, including much improved parameter identifiability, direct applicability of adaptive techniques for parameter estimation, as well as superior flexibility of transmit beampattern designs. We hope that this overview of our recent results on the MIMO radar, along with the related results obtained by our colleagues, will stimulate the interest deserved by this topic in both academia and government agencies as well as industry.",2007,32,1722,39,1,27,56,98,103,112,104,145,161,163
aafb36d70d896fad4e68ffceafb5ad53197f22c3,"For 11 days in February 2000, the Shuttle Radar Topography Mission (SRTM) successfully recorded by interferometric synthetic aperture radar (InSAR) data of the entire land mass of the earth between 60°N and 57°S. The data acquired in C- and X-bands are processed into the first global digital elevation models (DEMs) at 1 arc sec resolution, by NASA-JPL and German aerospace center (DLR), respectively. From the perspective of the SRTM-X system, we give in this paper an overview of the mission and the DEM production, as well as an evaluation of the DEM product quality. Special emphasis is on challenges and peculiarities of the processing that arose from the unique design of the SRTM system, which has been the first single-pass interferometer in space.",2003,31,1542,118,6,29,50,58,86,78,107,90,86,91
b064bb54e7d367513067982b7d97cf0697418ec0,"Elevation data is vital to successful mission planning, operations and readiness. Traditional methods for producing elevation data are very expensive and time consuming; major cloud belts would never be completed with existing methods. The Shuttle Radar Topography Mission (SRTM) was selected in 1995 as the best means of supplying nearly global, accurate elevation data. The SRTM is an interferometric SAR system that flew during 11-22 February 2000 aboard NASA's Space Shuttle Endeavour and collected highly specialized data that will allow the generation of Digital Terrain Elevation Data Level 2(DTED® 2). The result of the SRTM will increase the United States Government's coverage of vital and detailed DTED® 2from less than 5% to 80% of the Earth's landmass. This paper describes the shuttle mission and its deliverables.",2001,97,1496,152,3,1,5,4,7,5,9,27,41,64
201dea99707c04e1b659932bb2d46c3e37a6435e,"A stylized compressed sensing radar is proposed in which the time-frequency plane is discretized into an N times N grid. Assuming the number of targets K is small (i.e., K Lt N2), then we can transmit a sufficiently ldquoincoherentrdquo pulse and employ the techniques of compressed sensing to reconstruct the target scene. A theoretical upper bound on the sparsity K is presented. Numerical simulations verify that even better performance can be achieved in practice. This novel-compressed sensing approach offers great potential for better resolution over classical radar.",2008,52,985,28,9,31,43,85,105,120,102,105,94,83
ba841b3c6236793f084f3e056c858abbd05fe6a7,"It has recently been shown that multiple-input multiple-output (MIMO) antenna systems have the potential to improve dramatically the performance of communication systems over single antenna systems. Unlike beamforming, which presumes a high correlation between signals either transmitted or received by an array, the MIMO concept exploits the independence between signals at the array elements. In conventional radar, target scintillations are regarded as a nuisance parameter that degrades radar performance. The novelty of MIMO radar is that it takes the opposite view; namely, it capitalizes on target scintillations to improve the radar's performance. We introduce the MIMO concept for radar. The MIMO radar system under consideration consists of a transmit array with widely-spaced elements such that each views a different aspect of the target. The array at the receiver is a conventional array used for direction finding (DF). The system performance analysis is carried out in terms of the Cramer-Rao bound of the mean-square error in estimating the target direction. It is shown that MIMO radar leads to significant performance improvement in DF accuracy.",2004,20,1283,45,3,7,30,41,71,67,108,93,75,90
bb01353f818ca226b53433163893efc56c3df32d,"The proliferation of mobile computing devices and local-area wireless networks has fostered a growing interest in location-aware systems and services. In this paper we present RADAR, a radio-frequency (RF)-based system for locating and tracking users inside buildings. RADAR operates by recording and processing signal strength information at multiple base stations positioned to provide overlapping coverage in the area of interest. It combines empirical measurements with signal propagation modeling to determine user location and thereby enable location-aware services and applications. We present experimental results that demonstrate the ability of RADAR to estimate user location with a high degree of accuracy.",2000,36,8417,939,18,41,70,138,237,348,377,446,474,558
1e71e22a3012080f9d6d115080e3f4678e39f0b9,"[1] The Shuttle Radar Topography Mission produced the most complete, highest-resolution digital elevation model of the Earth. The project was a joint endeavor of NASA, the National Geospatial-Intelligence Agency, and the German and Italian Space Agencies and flew in February 2000. It used dual radar antennas to acquire interferometric radar data, processed to digital topographic data at 1 arc sec resolution. Details of the development, flight operations, data processing, and products are provided for users of this revolutionary data set.",2000,52,3523,186,2,5,1,2,1,6,13,14,54,95
a0abeeaef200e83a6d4538423c826a522f4e8b71,"Synthetic aperture radar interferometry is an imaging technique for measuring the topography of a surface, its changes over time, and other changes in the detailed characteristic of the surface. By exploiting the phase of the coherent radar signal, interferometry has transformed radar remote sensing from a largely interpretive science to a quantitative tool, with applications in cartography, geodesy, land cover characterization, and natural hazards. This paper reviews the techniques of interferometry, systems and limitations, and applications in a rapidly growing area of science and engineering.",2000,216,2887,220,23,38,65,78,79,93,114,122,104,141
ce9c55ed58d056b9c0723d048ecd8564fb0c4a16,Overview of Polarimetric Radar Imaging Brief History of Polarimetric Radar Imaging SAR Image Formation: Summary Airborne and Space-Borne PolSAR Systems Description of the Remaining Chapters Electromagnetic Vector Wave and Polarization Descriptors Monochromatic Electromagnetic Plane Wave Polarization Ellipse Jones Vector Stokes Vector Wave Covariance Matrix Electromagnetic Vector Scattering Operators Polarimetric Back Scattering Sinclair S Matrix Scattering Target Vectors k and Omega Polarimetric Coherency T and Covariance C Matrices Polarimetric Mueller M and Kennaugh K Matrices Change of Polarimetric Basis Target Polarimetric Characterization PolSAR Speckle Statistics Fundamental Property of Speckle in SAR Images Speckle Statistics for Multilook-Processed SAR Images Texture Model and K Distribution Effect of Speckle Spatial Correlation Polarimetric and Interferometric SAR Speckle Statistics Phase Difference Distributions of Single-Look and Multilook PolSAR Data Multilook Product Distribution Joint Distribution of Multilook Si2 and Sj2 Multilook Intensity and Amplitude Ratio Distributions Verifications of Multilook PDFs K Distribution for Multilook Polarimetric Data Summary Appendices PolSAR Speckle Filtering Introduction to Speckle Filtering of SAR Imagery Filtering of Single Polarization SAR Data Review of Multipolarization Speckle Filtering Algorithms PolSAR Speckle Filtering Scattering Model-Based PolSAR Speckle Filter Introduction to the Polarimetric Target Decomposition Concept Introduction Dichotomy of the Kennaugh Matrix K Eigenvector-Based Decompositions Model-Based Decompositions Coherent Decompositions The H/A/a Polarimetric Decomposition Theorem Introduction Pure Target Case Probabilistic Model for Random Media Scattering Roll Invariance Property Polarimetric Scattering a Parameter Polarimetric Scattering Entropy (H) Polarimetric Scattering Anisotropy (A) Three-Dimensional H/A/a Classification Space New Eigenvalue-Based Parameters Speckle Filtering Effects on H/A/a PolSAR Terrain and Land-Use Classification Introduction Maximum Likelihood Classifier Based on Complex Gaussian Distribution Complex Wishart Classifier for Multilook PolSAR Data Characteristics of Wishart Distance Measure Supervised Classification Using Wishart Distance Measure Unsupervised Classification Based on Scattering Mechanisms and Wishart Classifier Scattering Model-Based Unsupervised Classification Quantitative Comparison of Classification Capability: Fully PolSAR versus Dual- and Single-Polarization SAR Pol-InSAR Forest Mapping and Classification Introduction Pol-InSAR Scattering Descriptors Forest Mapping and Forest Classification Appendix Selected PolSAR Applications Polarimetric Signature Analysis of Manmade Structures Polarization Orientation Angle Estimation and Applications Ocean Surface Remote Sensing with PolSAR Ionosphere Faraday Rotation Estimation PolSAR Interferometry for Forest Height Estimation Nonstationary Natural Media Analysis from PolSAR Data Using a Two-Dimensional Time-Frequency Approach Appendix A: Eigen Characteristics of Hermitian Matrix Appendix B: PolSARpro Software: The Polariemtric SAR Data Processing and Educational Toolbox Index,2009,0,1800,298,16,47,90,130,125,139,172,197,195,207
a2fd9b9b59646626b5104f781b16ce239c20f03b,Preface. Summary. Nomenclature. 1. Introduction. 2. Radar system theory and interferometric processing. 3. Functional model for radar interferometry. 4. Stochastic model for radar interferometry. 5. Data analysis and interpretation for deformation monitoring. 6. Atmospheric monitoring. 7. Conclusions and recommendations. A. Comparison neutral delay GPS and InSAR. B. Structure function and power spectrum. Bibliography. About the Author. Index.,2001,0,1970,298,4,15,37,37,49,49,71,61,94,118
23eb33af4f0495edff01402ec8eb019e80717897,Foreword. Introduction. Signal Processing Fundamentals. Pulse Compression. Synthetic Aperture Concepts. SAR Signal Properties. The Range Doppler Algorithm. The Chirp Scaling Algorithm. The Omega-K Algorithm. The SPECAN Algorithm. Processing ScanSAR Data. Doppler Parameter Estimation. Comparison of Algorithms. References.,2005,0,1674,246,6,10,16,41,43,79,117,132,127,145
98ec941f07556008c3c3226fd755d7c42ea21b3e,"This detailed guide clearly and concisely presents radar digital signal processing for both practicing engineers and engineering students. This revised edition of Fundamentals of Radar Signal Processing provides in-depth coverage of radar digital signal processing (DSP) fundamentals and applications. It has been updated to include coverage of measurement accuracy and target tracking. Additionally, to make it more useful as a teaching tool, it now includes end-of-chapter problems and a solutions manual. New to this Edition: New chapter on Measurement Accuracy and Target Tracking Two new appendices--Important Digital Signal Processing Facts; Important Probability Density Function and Their Relationships Addition of 20 to 30 problems to ends of chapters Solutions manual",2005,0,1534,178,2,16,20,31,49,85,73,84,114,125
8308e7b39d1f556e4041b4630a41aa8435fe1a49,"MIMO (multiple-input multiple-output) radar refers to an architecture that employs multiple, spatially distributed transmitters and receivers. While, in a general sense, MIMO radar can be viewed as a type of multistatic radar, the separate nomenclature suggests unique features that set MIMO radar apart from the multistatic radar literature and that have a close relation to MIMO communications. This article reviews some recent work on MIMO radar with widely separated antennas. Widely separated transmit/receive antennas capture the spatial diversity of the target's radar cross section (RCS). Unique features of MIMO radar are explained and illustrated by examples. It is shown that with noncoherent processing, a target's RCS spatial variations can be exploited to obtain a diversity gain for target detection and for estimation of various parameters, such as angle of arrival and Doppler. For target location, it is shown that coherent processing can provide a resolution far exceeding that supported by the radar's waveform.",2008,44,1641,72,20,71,104,118,127,118,146,146,155,155
26f825b4ae30b08241df7031a900892761c0f9c0,"We have provided a review of some recent results on the emerging technology of MIMO radar with colocated antennas. We have shown that the waveform diversity offered by such a MIMO radar system enables significant superiority over its phased-array counterpart, including much improved parameter identifiability, direct applicability of adaptive techniques for parameter estimation, as well as superior flexibility of transmit beampattern designs. We hope that this overview of our recent results on the MIMO radar, along with the related results obtained by our colleagues, will stimulate the interest deserved by this topic in both academia and government agencies as well as industry.",2007,32,1722,39,1,27,56,98,103,112,104,145,161,163
aafb36d70d896fad4e68ffceafb5ad53197f22c3,"For 11 days in February 2000, the Shuttle Radar Topography Mission (SRTM) successfully recorded by interferometric synthetic aperture radar (InSAR) data of the entire land mass of the earth between 60°N and 57°S. The data acquired in C- and X-bands are processed into the first global digital elevation models (DEMs) at 1 arc sec resolution, by NASA-JPL and German aerospace center (DLR), respectively. From the perspective of the SRTM-X system, we give in this paper an overview of the mission and the DEM production, as well as an evaluation of the DEM product quality. Special emphasis is on challenges and peculiarities of the processing that arose from the unique design of the SRTM system, which has been the first single-pass interferometer in space.",2003,31,1542,118,6,29,50,58,86,78,107,90,86,91
b064bb54e7d367513067982b7d97cf0697418ec0,"Elevation data is vital to successful mission planning, operations and readiness. Traditional methods for producing elevation data are very expensive and time consuming; major cloud belts would never be completed with existing methods. The Shuttle Radar Topography Mission (SRTM) was selected in 1995 as the best means of supplying nearly global, accurate elevation data. The SRTM is an interferometric SAR system that flew during 11-22 February 2000 aboard NASA's Space Shuttle Endeavour and collected highly specialized data that will allow the generation of Digital Terrain Elevation Data Level 2(DTED® 2). The result of the SRTM will increase the United States Government's coverage of vital and detailed DTED® 2from less than 5% to 80% of the Earth's landmass. This paper describes the shuttle mission and its deliverables.",2001,97,1496,152,3,1,5,4,7,5,9,27,41,64
201dea99707c04e1b659932bb2d46c3e37a6435e,"A stylized compressed sensing radar is proposed in which the time-frequency plane is discretized into an N times N grid. Assuming the number of targets K is small (i.e., K Lt N2), then we can transmit a sufficiently ldquoincoherentrdquo pulse and employ the techniques of compressed sensing to reconstruct the target scene. A theoretical upper bound on the sparsity K is presented. Numerical simulations verify that even better performance can be achieved in practice. This novel-compressed sensing approach offers great potential for better resolution over classical radar.",2008,52,985,28,9,31,43,85,105,120,102,105,94,83
ba841b3c6236793f084f3e056c858abbd05fe6a7,"It has recently been shown that multiple-input multiple-output (MIMO) antenna systems have the potential to improve dramatically the performance of communication systems over single antenna systems. Unlike beamforming, which presumes a high correlation between signals either transmitted or received by an array, the MIMO concept exploits the independence between signals at the array elements. In conventional radar, target scintillations are regarded as a nuisance parameter that degrades radar performance. The novelty of MIMO radar is that it takes the opposite view; namely, it capitalizes on target scintillations to improve the radar's performance. We introduce the MIMO concept for radar. The MIMO radar system under consideration consists of a transmit array with widely-spaced elements such that each views a different aspect of the target. The array at the receiver is a conventional array used for direction finding (DF). The system performance analysis is carried out in terms of the Cramer-Rao bound of the mean-square error in estimating the target direction. It is shown that MIMO radar leads to significant performance improvement in DF accuracy.",2004,20,1283,45,3,7,30,41,71,67,108,93,75,90
bb01353f818ca226b53433163893efc56c3df32d,"The proliferation of mobile computing devices and local-area wireless networks has fostered a growing interest in location-aware systems and services. In this paper we present RADAR, a radio-frequency (RF)-based system for locating and tracking users inside buildings. RADAR operates by recording and processing signal strength information at multiple base stations positioned to provide overlapping coverage in the area of interest. It combines empirical measurements with signal propagation modeling to determine user location and thereby enable location-aware services and applications. We present experimental results that demonstrate the ability of RADAR to estimate user location with a high degree of accuracy.",2000,36,8417,939,18,41,70,138,237,348,377,446,474,558
1e71e22a3012080f9d6d115080e3f4678e39f0b9,"[1] The Shuttle Radar Topography Mission produced the most complete, highest-resolution digital elevation model of the Earth. The project was a joint endeavor of NASA, the National Geospatial-Intelligence Agency, and the German and Italian Space Agencies and flew in February 2000. It used dual radar antennas to acquire interferometric radar data, processed to digital topographic data at 1 arc sec resolution. Details of the development, flight operations, data processing, and products are provided for users of this revolutionary data set.",2000,52,3523,186,2,5,1,2,1,6,13,14,54,95
a0abeeaef200e83a6d4538423c826a522f4e8b71,"Synthetic aperture radar interferometry is an imaging technique for measuring the topography of a surface, its changes over time, and other changes in the detailed characteristic of the surface. By exploiting the phase of the coherent radar signal, interferometry has transformed radar remote sensing from a largely interpretive science to a quantitative tool, with applications in cartography, geodesy, land cover characterization, and natural hazards. This paper reviews the techniques of interferometry, systems and limitations, and applications in a rapidly growing area of science and engineering.",2000,216,2887,220,23,38,65,78,79,93,114,122,104,141
ce9c55ed58d056b9c0723d048ecd8564fb0c4a16,Overview of Polarimetric Radar Imaging Brief History of Polarimetric Radar Imaging SAR Image Formation: Summary Airborne and Space-Borne PolSAR Systems Description of the Remaining Chapters Electromagnetic Vector Wave and Polarization Descriptors Monochromatic Electromagnetic Plane Wave Polarization Ellipse Jones Vector Stokes Vector Wave Covariance Matrix Electromagnetic Vector Scattering Operators Polarimetric Back Scattering Sinclair S Matrix Scattering Target Vectors k and Omega Polarimetric Coherency T and Covariance C Matrices Polarimetric Mueller M and Kennaugh K Matrices Change of Polarimetric Basis Target Polarimetric Characterization PolSAR Speckle Statistics Fundamental Property of Speckle in SAR Images Speckle Statistics for Multilook-Processed SAR Images Texture Model and K Distribution Effect of Speckle Spatial Correlation Polarimetric and Interferometric SAR Speckle Statistics Phase Difference Distributions of Single-Look and Multilook PolSAR Data Multilook Product Distribution Joint Distribution of Multilook Si2 and Sj2 Multilook Intensity and Amplitude Ratio Distributions Verifications of Multilook PDFs K Distribution for Multilook Polarimetric Data Summary Appendices PolSAR Speckle Filtering Introduction to Speckle Filtering of SAR Imagery Filtering of Single Polarization SAR Data Review of Multipolarization Speckle Filtering Algorithms PolSAR Speckle Filtering Scattering Model-Based PolSAR Speckle Filter Introduction to the Polarimetric Target Decomposition Concept Introduction Dichotomy of the Kennaugh Matrix K Eigenvector-Based Decompositions Model-Based Decompositions Coherent Decompositions The H/A/a Polarimetric Decomposition Theorem Introduction Pure Target Case Probabilistic Model for Random Media Scattering Roll Invariance Property Polarimetric Scattering a Parameter Polarimetric Scattering Entropy (H) Polarimetric Scattering Anisotropy (A) Three-Dimensional H/A/a Classification Space New Eigenvalue-Based Parameters Speckle Filtering Effects on H/A/a PolSAR Terrain and Land-Use Classification Introduction Maximum Likelihood Classifier Based on Complex Gaussian Distribution Complex Wishart Classifier for Multilook PolSAR Data Characteristics of Wishart Distance Measure Supervised Classification Using Wishart Distance Measure Unsupervised Classification Based on Scattering Mechanisms and Wishart Classifier Scattering Model-Based Unsupervised Classification Quantitative Comparison of Classification Capability: Fully PolSAR versus Dual- and Single-Polarization SAR Pol-InSAR Forest Mapping and Classification Introduction Pol-InSAR Scattering Descriptors Forest Mapping and Forest Classification Appendix Selected PolSAR Applications Polarimetric Signature Analysis of Manmade Structures Polarization Orientation Angle Estimation and Applications Ocean Surface Remote Sensing with PolSAR Ionosphere Faraday Rotation Estimation PolSAR Interferometry for Forest Height Estimation Nonstationary Natural Media Analysis from PolSAR Data Using a Two-Dimensional Time-Frequency Approach Appendix A: Eigen Characteristics of Hermitian Matrix Appendix B: PolSARpro Software: The Polariemtric SAR Data Processing and Educational Toolbox Index,2009,0,1800,298,16,47,90,130,125,139,172,197,195,207
a2fd9b9b59646626b5104f781b16ce239c20f03b,Preface. Summary. Nomenclature. 1. Introduction. 2. Radar system theory and interferometric processing. 3. Functional model for radar interferometry. 4. Stochastic model for radar interferometry. 5. Data analysis and interpretation for deformation monitoring. 6. Atmospheric monitoring. 7. Conclusions and recommendations. A. Comparison neutral delay GPS and InSAR. B. Structure function and power spectrum. Bibliography. About the Author. Index.,2001,0,1970,298,4,15,37,37,49,49,71,61,94,118
23eb33af4f0495edff01402ec8eb019e80717897,Foreword. Introduction. Signal Processing Fundamentals. Pulse Compression. Synthetic Aperture Concepts. SAR Signal Properties. The Range Doppler Algorithm. The Chirp Scaling Algorithm. The Omega-K Algorithm. The SPECAN Algorithm. Processing ScanSAR Data. Doppler Parameter Estimation. Comparison of Algorithms. References.,2005,0,1674,246,6,10,16,41,43,79,117,132,127,145
98ec941f07556008c3c3226fd755d7c42ea21b3e,"This detailed guide clearly and concisely presents radar digital signal processing for both practicing engineers and engineering students. This revised edition of Fundamentals of Radar Signal Processing provides in-depth coverage of radar digital signal processing (DSP) fundamentals and applications. It has been updated to include coverage of measurement accuracy and target tracking. Additionally, to make it more useful as a teaching tool, it now includes end-of-chapter problems and a solutions manual. New to this Edition: New chapter on Measurement Accuracy and Target Tracking Two new appendices--Important Digital Signal Processing Facts; Important Probability Density Function and Their Relationships Addition of 20 to 30 problems to ends of chapters Solutions manual",2005,0,1534,178,2,16,20,31,49,85,73,84,114,125
8308e7b39d1f556e4041b4630a41aa8435fe1a49,"MIMO (multiple-input multiple-output) radar refers to an architecture that employs multiple, spatially distributed transmitters and receivers. While, in a general sense, MIMO radar can be viewed as a type of multistatic radar, the separate nomenclature suggests unique features that set MIMO radar apart from the multistatic radar literature and that have a close relation to MIMO communications. This article reviews some recent work on MIMO radar with widely separated antennas. Widely separated transmit/receive antennas capture the spatial diversity of the target's radar cross section (RCS). Unique features of MIMO radar are explained and illustrated by examples. It is shown that with noncoherent processing, a target's RCS spatial variations can be exploited to obtain a diversity gain for target detection and for estimation of various parameters, such as angle of arrival and Doppler. For target location, it is shown that coherent processing can provide a resolution far exceeding that supported by the radar's waveform.",2008,44,1641,72,20,71,104,118,127,118,146,146,155,155
26f825b4ae30b08241df7031a900892761c0f9c0,"We have provided a review of some recent results on the emerging technology of MIMO radar with colocated antennas. We have shown that the waveform diversity offered by such a MIMO radar system enables significant superiority over its phased-array counterpart, including much improved parameter identifiability, direct applicability of adaptive techniques for parameter estimation, as well as superior flexibility of transmit beampattern designs. We hope that this overview of our recent results on the MIMO radar, along with the related results obtained by our colleagues, will stimulate the interest deserved by this topic in both academia and government agencies as well as industry.",2007,32,1722,39,1,27,56,98,103,112,104,145,161,163
aafb36d70d896fad4e68ffceafb5ad53197f22c3,"For 11 days in February 2000, the Shuttle Radar Topography Mission (SRTM) successfully recorded by interferometric synthetic aperture radar (InSAR) data of the entire land mass of the earth between 60°N and 57°S. The data acquired in C- and X-bands are processed into the first global digital elevation models (DEMs) at 1 arc sec resolution, by NASA-JPL and German aerospace center (DLR), respectively. From the perspective of the SRTM-X system, we give in this paper an overview of the mission and the DEM production, as well as an evaluation of the DEM product quality. Special emphasis is on challenges and peculiarities of the processing that arose from the unique design of the SRTM system, which has been the first single-pass interferometer in space.",2003,31,1542,118,6,29,50,58,86,78,107,90,86,91
b064bb54e7d367513067982b7d97cf0697418ec0,"Elevation data is vital to successful mission planning, operations and readiness. Traditional methods for producing elevation data are very expensive and time consuming; major cloud belts would never be completed with existing methods. The Shuttle Radar Topography Mission (SRTM) was selected in 1995 as the best means of supplying nearly global, accurate elevation data. The SRTM is an interferometric SAR system that flew during 11-22 February 2000 aboard NASA's Space Shuttle Endeavour and collected highly specialized data that will allow the generation of Digital Terrain Elevation Data Level 2(DTED® 2). The result of the SRTM will increase the United States Government's coverage of vital and detailed DTED® 2from less than 5% to 80% of the Earth's landmass. This paper describes the shuttle mission and its deliverables.",2001,97,1496,152,3,1,5,4,7,5,9,27,41,64
201dea99707c04e1b659932bb2d46c3e37a6435e,"A stylized compressed sensing radar is proposed in which the time-frequency plane is discretized into an N times N grid. Assuming the number of targets K is small (i.e., K Lt N2), then we can transmit a sufficiently ldquoincoherentrdquo pulse and employ the techniques of compressed sensing to reconstruct the target scene. A theoretical upper bound on the sparsity K is presented. Numerical simulations verify that even better performance can be achieved in practice. This novel-compressed sensing approach offers great potential for better resolution over classical radar.",2008,52,985,28,9,31,43,85,105,120,102,105,94,83
ba841b3c6236793f084f3e056c858abbd05fe6a7,"It has recently been shown that multiple-input multiple-output (MIMO) antenna systems have the potential to improve dramatically the performance of communication systems over single antenna systems. Unlike beamforming, which presumes a high correlation between signals either transmitted or received by an array, the MIMO concept exploits the independence between signals at the array elements. In conventional radar, target scintillations are regarded as a nuisance parameter that degrades radar performance. The novelty of MIMO radar is that it takes the opposite view; namely, it capitalizes on target scintillations to improve the radar's performance. We introduce the MIMO concept for radar. The MIMO radar system under consideration consists of a transmit array with widely-spaced elements such that each views a different aspect of the target. The array at the receiver is a conventional array used for direction finding (DF). The system performance analysis is carried out in terms of the Cramer-Rao bound of the mean-square error in estimating the target direction. It is shown that MIMO radar leads to significant performance improvement in DF accuracy.",2004,20,1283,45,3,7,30,41,71,67,108,93,75,90
bb01353f818ca226b53433163893efc56c3df32d,"The proliferation of mobile computing devices and local-area wireless networks has fostered a growing interest in location-aware systems and services. In this paper we present RADAR, a radio-frequency (RF)-based system for locating and tracking users inside buildings. RADAR operates by recording and processing signal strength information at multiple base stations positioned to provide overlapping coverage in the area of interest. It combines empirical measurements with signal propagation modeling to determine user location and thereby enable location-aware services and applications. We present experimental results that demonstrate the ability of RADAR to estimate user location with a high degree of accuracy.",2000,36,8417,939,18,41,70,138,237,348,377,446,474,558
1e71e22a3012080f9d6d115080e3f4678e39f0b9,"[1] The Shuttle Radar Topography Mission produced the most complete, highest-resolution digital elevation model of the Earth. The project was a joint endeavor of NASA, the National Geospatial-Intelligence Agency, and the German and Italian Space Agencies and flew in February 2000. It used dual radar antennas to acquire interferometric radar data, processed to digital topographic data at 1 arc sec resolution. Details of the development, flight operations, data processing, and products are provided for users of this revolutionary data set.",2000,52,3523,186,2,5,1,2,1,6,13,14,54,95
a0abeeaef200e83a6d4538423c826a522f4e8b71,"Synthetic aperture radar interferometry is an imaging technique for measuring the topography of a surface, its changes over time, and other changes in the detailed characteristic of the surface. By exploiting the phase of the coherent radar signal, interferometry has transformed radar remote sensing from a largely interpretive science to a quantitative tool, with applications in cartography, geodesy, land cover characterization, and natural hazards. This paper reviews the techniques of interferometry, systems and limitations, and applications in a rapidly growing area of science and engineering.",2000,216,2887,220,23,38,65,78,79,93,114,122,104,141
ce9c55ed58d056b9c0723d048ecd8564fb0c4a16,Overview of Polarimetric Radar Imaging Brief History of Polarimetric Radar Imaging SAR Image Formation: Summary Airborne and Space-Borne PolSAR Systems Description of the Remaining Chapters Electromagnetic Vector Wave and Polarization Descriptors Monochromatic Electromagnetic Plane Wave Polarization Ellipse Jones Vector Stokes Vector Wave Covariance Matrix Electromagnetic Vector Scattering Operators Polarimetric Back Scattering Sinclair S Matrix Scattering Target Vectors k and Omega Polarimetric Coherency T and Covariance C Matrices Polarimetric Mueller M and Kennaugh K Matrices Change of Polarimetric Basis Target Polarimetric Characterization PolSAR Speckle Statistics Fundamental Property of Speckle in SAR Images Speckle Statistics for Multilook-Processed SAR Images Texture Model and K Distribution Effect of Speckle Spatial Correlation Polarimetric and Interferometric SAR Speckle Statistics Phase Difference Distributions of Single-Look and Multilook PolSAR Data Multilook Product Distribution Joint Distribution of Multilook Si2 and Sj2 Multilook Intensity and Amplitude Ratio Distributions Verifications of Multilook PDFs K Distribution for Multilook Polarimetric Data Summary Appendices PolSAR Speckle Filtering Introduction to Speckle Filtering of SAR Imagery Filtering of Single Polarization SAR Data Review of Multipolarization Speckle Filtering Algorithms PolSAR Speckle Filtering Scattering Model-Based PolSAR Speckle Filter Introduction to the Polarimetric Target Decomposition Concept Introduction Dichotomy of the Kennaugh Matrix K Eigenvector-Based Decompositions Model-Based Decompositions Coherent Decompositions The H/A/a Polarimetric Decomposition Theorem Introduction Pure Target Case Probabilistic Model for Random Media Scattering Roll Invariance Property Polarimetric Scattering a Parameter Polarimetric Scattering Entropy (H) Polarimetric Scattering Anisotropy (A) Three-Dimensional H/A/a Classification Space New Eigenvalue-Based Parameters Speckle Filtering Effects on H/A/a PolSAR Terrain and Land-Use Classification Introduction Maximum Likelihood Classifier Based on Complex Gaussian Distribution Complex Wishart Classifier for Multilook PolSAR Data Characteristics of Wishart Distance Measure Supervised Classification Using Wishart Distance Measure Unsupervised Classification Based on Scattering Mechanisms and Wishart Classifier Scattering Model-Based Unsupervised Classification Quantitative Comparison of Classification Capability: Fully PolSAR versus Dual- and Single-Polarization SAR Pol-InSAR Forest Mapping and Classification Introduction Pol-InSAR Scattering Descriptors Forest Mapping and Forest Classification Appendix Selected PolSAR Applications Polarimetric Signature Analysis of Manmade Structures Polarization Orientation Angle Estimation and Applications Ocean Surface Remote Sensing with PolSAR Ionosphere Faraday Rotation Estimation PolSAR Interferometry for Forest Height Estimation Nonstationary Natural Media Analysis from PolSAR Data Using a Two-Dimensional Time-Frequency Approach Appendix A: Eigen Characteristics of Hermitian Matrix Appendix B: PolSARpro Software: The Polariemtric SAR Data Processing and Educational Toolbox Index,2009,0,1800,298,16,47,90,130,125,139,172,197,195,207
a2fd9b9b59646626b5104f781b16ce239c20f03b,Preface. Summary. Nomenclature. 1. Introduction. 2. Radar system theory and interferometric processing. 3. Functional model for radar interferometry. 4. Stochastic model for radar interferometry. 5. Data analysis and interpretation for deformation monitoring. 6. Atmospheric monitoring. 7. Conclusions and recommendations. A. Comparison neutral delay GPS and InSAR. B. Structure function and power spectrum. Bibliography. About the Author. Index.,2001,0,1970,298,4,15,37,37,49,49,71,61,94,118
23eb33af4f0495edff01402ec8eb019e80717897,Foreword. Introduction. Signal Processing Fundamentals. Pulse Compression. Synthetic Aperture Concepts. SAR Signal Properties. The Range Doppler Algorithm. The Chirp Scaling Algorithm. The Omega-K Algorithm. The SPECAN Algorithm. Processing ScanSAR Data. Doppler Parameter Estimation. Comparison of Algorithms. References.,2005,0,1674,246,6,10,16,41,43,79,117,132,127,145
98ec941f07556008c3c3226fd755d7c42ea21b3e,"This detailed guide clearly and concisely presents radar digital signal processing for both practicing engineers and engineering students. This revised edition of Fundamentals of Radar Signal Processing provides in-depth coverage of radar digital signal processing (DSP) fundamentals and applications. It has been updated to include coverage of measurement accuracy and target tracking. Additionally, to make it more useful as a teaching tool, it now includes end-of-chapter problems and a solutions manual. New to this Edition: New chapter on Measurement Accuracy and Target Tracking Two new appendices--Important Digital Signal Processing Facts; Important Probability Density Function and Their Relationships Addition of 20 to 30 problems to ends of chapters Solutions manual",2005,0,1534,178,2,16,20,31,49,85,73,84,114,125
8308e7b39d1f556e4041b4630a41aa8435fe1a49,"MIMO (multiple-input multiple-output) radar refers to an architecture that employs multiple, spatially distributed transmitters and receivers. While, in a general sense, MIMO radar can be viewed as a type of multistatic radar, the separate nomenclature suggests unique features that set MIMO radar apart from the multistatic radar literature and that have a close relation to MIMO communications. This article reviews some recent work on MIMO radar with widely separated antennas. Widely separated transmit/receive antennas capture the spatial diversity of the target's radar cross section (RCS). Unique features of MIMO radar are explained and illustrated by examples. It is shown that with noncoherent processing, a target's RCS spatial variations can be exploited to obtain a diversity gain for target detection and for estimation of various parameters, such as angle of arrival and Doppler. For target location, it is shown that coherent processing can provide a resolution far exceeding that supported by the radar's waveform.",2008,44,1641,72,20,71,104,118,127,118,146,146,155,155
26f825b4ae30b08241df7031a900892761c0f9c0,"We have provided a review of some recent results on the emerging technology of MIMO radar with colocated antennas. We have shown that the waveform diversity offered by such a MIMO radar system enables significant superiority over its phased-array counterpart, including much improved parameter identifiability, direct applicability of adaptive techniques for parameter estimation, as well as superior flexibility of transmit beampattern designs. We hope that this overview of our recent results on the MIMO radar, along with the related results obtained by our colleagues, will stimulate the interest deserved by this topic in both academia and government agencies as well as industry.",2007,32,1722,39,1,27,56,98,103,112,104,145,161,163
aafb36d70d896fad4e68ffceafb5ad53197f22c3,"For 11 days in February 2000, the Shuttle Radar Topography Mission (SRTM) successfully recorded by interferometric synthetic aperture radar (InSAR) data of the entire land mass of the earth between 60°N and 57°S. The data acquired in C- and X-bands are processed into the first global digital elevation models (DEMs) at 1 arc sec resolution, by NASA-JPL and German aerospace center (DLR), respectively. From the perspective of the SRTM-X system, we give in this paper an overview of the mission and the DEM production, as well as an evaluation of the DEM product quality. Special emphasis is on challenges and peculiarities of the processing that arose from the unique design of the SRTM system, which has been the first single-pass interferometer in space.",2003,31,1542,118,6,29,50,58,86,78,107,90,86,91
b064bb54e7d367513067982b7d97cf0697418ec0,"Elevation data is vital to successful mission planning, operations and readiness. Traditional methods for producing elevation data are very expensive and time consuming; major cloud belts would never be completed with existing methods. The Shuttle Radar Topography Mission (SRTM) was selected in 1995 as the best means of supplying nearly global, accurate elevation data. The SRTM is an interferometric SAR system that flew during 11-22 February 2000 aboard NASA's Space Shuttle Endeavour and collected highly specialized data that will allow the generation of Digital Terrain Elevation Data Level 2(DTED® 2). The result of the SRTM will increase the United States Government's coverage of vital and detailed DTED® 2from less than 5% to 80% of the Earth's landmass. This paper describes the shuttle mission and its deliverables.",2001,97,1496,152,3,1,5,4,7,5,9,27,41,64
201dea99707c04e1b659932bb2d46c3e37a6435e,"A stylized compressed sensing radar is proposed in which the time-frequency plane is discretized into an N times N grid. Assuming the number of targets K is small (i.e., K Lt N2), then we can transmit a sufficiently ldquoincoherentrdquo pulse and employ the techniques of compressed sensing to reconstruct the target scene. A theoretical upper bound on the sparsity K is presented. Numerical simulations verify that even better performance can be achieved in practice. This novel-compressed sensing approach offers great potential for better resolution over classical radar.",2008,52,985,28,9,31,43,85,105,120,102,105,94,83
ba841b3c6236793f084f3e056c858abbd05fe6a7,"It has recently been shown that multiple-input multiple-output (MIMO) antenna systems have the potential to improve dramatically the performance of communication systems over single antenna systems. Unlike beamforming, which presumes a high correlation between signals either transmitted or received by an array, the MIMO concept exploits the independence between signals at the array elements. In conventional radar, target scintillations are regarded as a nuisance parameter that degrades radar performance. The novelty of MIMO radar is that it takes the opposite view; namely, it capitalizes on target scintillations to improve the radar's performance. We introduce the MIMO concept for radar. The MIMO radar system under consideration consists of a transmit array with widely-spaced elements such that each views a different aspect of the target. The array at the receiver is a conventional array used for direction finding (DF). The system performance analysis is carried out in terms of the Cramer-Rao bound of the mean-square error in estimating the target direction. It is shown that MIMO radar leads to significant performance improvement in DF accuracy.",2004,20,1283,45,3,7,30,41,71,67,108,93,75,90
bb01353f818ca226b53433163893efc56c3df32d,"The proliferation of mobile computing devices and local-area wireless networks has fostered a growing interest in location-aware systems and services. In this paper we present RADAR, a radio-frequency (RF)-based system for locating and tracking users inside buildings. RADAR operates by recording and processing signal strength information at multiple base stations positioned to provide overlapping coverage in the area of interest. It combines empirical measurements with signal propagation modeling to determine user location and thereby enable location-aware services and applications. We present experimental results that demonstrate the ability of RADAR to estimate user location with a high degree of accuracy.",2000,36,8417,939,18,41,70,138,237,348,377,446,474,558
1e71e22a3012080f9d6d115080e3f4678e39f0b9,"[1] The Shuttle Radar Topography Mission produced the most complete, highest-resolution digital elevation model of the Earth. The project was a joint endeavor of NASA, the National Geospatial-Intelligence Agency, and the German and Italian Space Agencies and flew in February 2000. It used dual radar antennas to acquire interferometric radar data, processed to digital topographic data at 1 arc sec resolution. Details of the development, flight operations, data processing, and products are provided for users of this revolutionary data set.",2000,52,3523,186,2,5,1,2,1,6,13,14,54,95
a0abeeaef200e83a6d4538423c826a522f4e8b71,"Synthetic aperture radar interferometry is an imaging technique for measuring the topography of a surface, its changes over time, and other changes in the detailed characteristic of the surface. By exploiting the phase of the coherent radar signal, interferometry has transformed radar remote sensing from a largely interpretive science to a quantitative tool, with applications in cartography, geodesy, land cover characterization, and natural hazards. This paper reviews the techniques of interferometry, systems and limitations, and applications in a rapidly growing area of science and engineering.",2000,216,2887,220,23,38,65,78,79,93,114,122,104,141
ce9c55ed58d056b9c0723d048ecd8564fb0c4a16,Overview of Polarimetric Radar Imaging Brief History of Polarimetric Radar Imaging SAR Image Formation: Summary Airborne and Space-Borne PolSAR Systems Description of the Remaining Chapters Electromagnetic Vector Wave and Polarization Descriptors Monochromatic Electromagnetic Plane Wave Polarization Ellipse Jones Vector Stokes Vector Wave Covariance Matrix Electromagnetic Vector Scattering Operators Polarimetric Back Scattering Sinclair S Matrix Scattering Target Vectors k and Omega Polarimetric Coherency T and Covariance C Matrices Polarimetric Mueller M and Kennaugh K Matrices Change of Polarimetric Basis Target Polarimetric Characterization PolSAR Speckle Statistics Fundamental Property of Speckle in SAR Images Speckle Statistics for Multilook-Processed SAR Images Texture Model and K Distribution Effect of Speckle Spatial Correlation Polarimetric and Interferometric SAR Speckle Statistics Phase Difference Distributions of Single-Look and Multilook PolSAR Data Multilook Product Distribution Joint Distribution of Multilook Si2 and Sj2 Multilook Intensity and Amplitude Ratio Distributions Verifications of Multilook PDFs K Distribution for Multilook Polarimetric Data Summary Appendices PolSAR Speckle Filtering Introduction to Speckle Filtering of SAR Imagery Filtering of Single Polarization SAR Data Review of Multipolarization Speckle Filtering Algorithms PolSAR Speckle Filtering Scattering Model-Based PolSAR Speckle Filter Introduction to the Polarimetric Target Decomposition Concept Introduction Dichotomy of the Kennaugh Matrix K Eigenvector-Based Decompositions Model-Based Decompositions Coherent Decompositions The H/A/a Polarimetric Decomposition Theorem Introduction Pure Target Case Probabilistic Model for Random Media Scattering Roll Invariance Property Polarimetric Scattering a Parameter Polarimetric Scattering Entropy (H) Polarimetric Scattering Anisotropy (A) Three-Dimensional H/A/a Classification Space New Eigenvalue-Based Parameters Speckle Filtering Effects on H/A/a PolSAR Terrain and Land-Use Classification Introduction Maximum Likelihood Classifier Based on Complex Gaussian Distribution Complex Wishart Classifier for Multilook PolSAR Data Characteristics of Wishart Distance Measure Supervised Classification Using Wishart Distance Measure Unsupervised Classification Based on Scattering Mechanisms and Wishart Classifier Scattering Model-Based Unsupervised Classification Quantitative Comparison of Classification Capability: Fully PolSAR versus Dual- and Single-Polarization SAR Pol-InSAR Forest Mapping and Classification Introduction Pol-InSAR Scattering Descriptors Forest Mapping and Forest Classification Appendix Selected PolSAR Applications Polarimetric Signature Analysis of Manmade Structures Polarization Orientation Angle Estimation and Applications Ocean Surface Remote Sensing with PolSAR Ionosphere Faraday Rotation Estimation PolSAR Interferometry for Forest Height Estimation Nonstationary Natural Media Analysis from PolSAR Data Using a Two-Dimensional Time-Frequency Approach Appendix A: Eigen Characteristics of Hermitian Matrix Appendix B: PolSARpro Software: The Polariemtric SAR Data Processing and Educational Toolbox Index,2009,0,1800,298,16,47,90,130,125,139,172,197,195,207
a2fd9b9b59646626b5104f781b16ce239c20f03b,Preface. Summary. Nomenclature. 1. Introduction. 2. Radar system theory and interferometric processing. 3. Functional model for radar interferometry. 4. Stochastic model for radar interferometry. 5. Data analysis and interpretation for deformation monitoring. 6. Atmospheric monitoring. 7. Conclusions and recommendations. A. Comparison neutral delay GPS and InSAR. B. Structure function and power spectrum. Bibliography. About the Author. Index.,2001,0,1970,298,4,15,37,37,49,49,71,61,94,118
23eb33af4f0495edff01402ec8eb019e80717897,Foreword. Introduction. Signal Processing Fundamentals. Pulse Compression. Synthetic Aperture Concepts. SAR Signal Properties. The Range Doppler Algorithm. The Chirp Scaling Algorithm. The Omega-K Algorithm. The SPECAN Algorithm. Processing ScanSAR Data. Doppler Parameter Estimation. Comparison of Algorithms. References.,2005,0,1674,246,6,10,16,41,43,79,117,132,127,145
98ec941f07556008c3c3226fd755d7c42ea21b3e,"This detailed guide clearly and concisely presents radar digital signal processing for both practicing engineers and engineering students. This revised edition of Fundamentals of Radar Signal Processing provides in-depth coverage of radar digital signal processing (DSP) fundamentals and applications. It has been updated to include coverage of measurement accuracy and target tracking. Additionally, to make it more useful as a teaching tool, it now includes end-of-chapter problems and a solutions manual. New to this Edition: New chapter on Measurement Accuracy and Target Tracking Two new appendices--Important Digital Signal Processing Facts; Important Probability Density Function and Their Relationships Addition of 20 to 30 problems to ends of chapters Solutions manual",2005,0,1534,178,2,16,20,31,49,85,73,84,114,125
8308e7b39d1f556e4041b4630a41aa8435fe1a49,"MIMO (multiple-input multiple-output) radar refers to an architecture that employs multiple, spatially distributed transmitters and receivers. While, in a general sense, MIMO radar can be viewed as a type of multistatic radar, the separate nomenclature suggests unique features that set MIMO radar apart from the multistatic radar literature and that have a close relation to MIMO communications. This article reviews some recent work on MIMO radar with widely separated antennas. Widely separated transmit/receive antennas capture the spatial diversity of the target's radar cross section (RCS). Unique features of MIMO radar are explained and illustrated by examples. It is shown that with noncoherent processing, a target's RCS spatial variations can be exploited to obtain a diversity gain for target detection and for estimation of various parameters, such as angle of arrival and Doppler. For target location, it is shown that coherent processing can provide a resolution far exceeding that supported by the radar's waveform.",2008,44,1641,72,20,71,104,118,127,118,146,146,155,155
26f825b4ae30b08241df7031a900892761c0f9c0,"We have provided a review of some recent results on the emerging technology of MIMO radar with colocated antennas. We have shown that the waveform diversity offered by such a MIMO radar system enables significant superiority over its phased-array counterpart, including much improved parameter identifiability, direct applicability of adaptive techniques for parameter estimation, as well as superior flexibility of transmit beampattern designs. We hope that this overview of our recent results on the MIMO radar, along with the related results obtained by our colleagues, will stimulate the interest deserved by this topic in both academia and government agencies as well as industry.",2007,32,1722,39,1,27,56,98,103,112,104,145,161,163
aafb36d70d896fad4e68ffceafb5ad53197f22c3,"For 11 days in February 2000, the Shuttle Radar Topography Mission (SRTM) successfully recorded by interferometric synthetic aperture radar (InSAR) data of the entire land mass of the earth between 60°N and 57°S. The data acquired in C- and X-bands are processed into the first global digital elevation models (DEMs) at 1 arc sec resolution, by NASA-JPL and German aerospace center (DLR), respectively. From the perspective of the SRTM-X system, we give in this paper an overview of the mission and the DEM production, as well as an evaluation of the DEM product quality. Special emphasis is on challenges and peculiarities of the processing that arose from the unique design of the SRTM system, which has been the first single-pass interferometer in space.",2003,31,1542,118,6,29,50,58,86,78,107,90,86,91
b064bb54e7d367513067982b7d97cf0697418ec0,"Elevation data is vital to successful mission planning, operations and readiness. Traditional methods for producing elevation data are very expensive and time consuming; major cloud belts would never be completed with existing methods. The Shuttle Radar Topography Mission (SRTM) was selected in 1995 as the best means of supplying nearly global, accurate elevation data. The SRTM is an interferometric SAR system that flew during 11-22 February 2000 aboard NASA's Space Shuttle Endeavour and collected highly specialized data that will allow the generation of Digital Terrain Elevation Data Level 2(DTED® 2). The result of the SRTM will increase the United States Government's coverage of vital and detailed DTED® 2from less than 5% to 80% of the Earth's landmass. This paper describes the shuttle mission and its deliverables.",2001,97,1496,152,3,1,5,4,7,5,9,27,41,64
201dea99707c04e1b659932bb2d46c3e37a6435e,"A stylized compressed sensing radar is proposed in which the time-frequency plane is discretized into an N times N grid. Assuming the number of targets K is small (i.e., K Lt N2), then we can transmit a sufficiently ldquoincoherentrdquo pulse and employ the techniques of compressed sensing to reconstruct the target scene. A theoretical upper bound on the sparsity K is presented. Numerical simulations verify that even better performance can be achieved in practice. This novel-compressed sensing approach offers great potential for better resolution over classical radar.",2008,52,985,28,9,31,43,85,105,120,102,105,94,83
ba841b3c6236793f084f3e056c858abbd05fe6a7,"It has recently been shown that multiple-input multiple-output (MIMO) antenna systems have the potential to improve dramatically the performance of communication systems over single antenna systems. Unlike beamforming, which presumes a high correlation between signals either transmitted or received by an array, the MIMO concept exploits the independence between signals at the array elements. In conventional radar, target scintillations are regarded as a nuisance parameter that degrades radar performance. The novelty of MIMO radar is that it takes the opposite view; namely, it capitalizes on target scintillations to improve the radar's performance. We introduce the MIMO concept for radar. The MIMO radar system under consideration consists of a transmit array with widely-spaced elements such that each views a different aspect of the target. The array at the receiver is a conventional array used for direction finding (DF). The system performance analysis is carried out in terms of the Cramer-Rao bound of the mean-square error in estimating the target direction. It is shown that MIMO radar leads to significant performance improvement in DF accuracy.",2004,20,1283,45,3,7,30,41,71,67,108,93,75,90
bb01353f818ca226b53433163893efc56c3df32d,"The proliferation of mobile computing devices and local-area wireless networks has fostered a growing interest in location-aware systems and services. In this paper we present RADAR, a radio-frequency (RF)-based system for locating and tracking users inside buildings. RADAR operates by recording and processing signal strength information at multiple base stations positioned to provide overlapping coverage in the area of interest. It combines empirical measurements with signal propagation modeling to determine user location and thereby enable location-aware services and applications. We present experimental results that demonstrate the ability of RADAR to estimate user location with a high degree of accuracy.",2000,36,8417,939,18,41,70,138,237,348,377,446,474,558
1e71e22a3012080f9d6d115080e3f4678e39f0b9,"[1] The Shuttle Radar Topography Mission produced the most complete, highest-resolution digital elevation model of the Earth. The project was a joint endeavor of NASA, the National Geospatial-Intelligence Agency, and the German and Italian Space Agencies and flew in February 2000. It used dual radar antennas to acquire interferometric radar data, processed to digital topographic data at 1 arc sec resolution. Details of the development, flight operations, data processing, and products are provided for users of this revolutionary data set.",2000,52,3523,186,2,5,1,2,1,6,13,14,54,95
a0abeeaef200e83a6d4538423c826a522f4e8b71,"Synthetic aperture radar interferometry is an imaging technique for measuring the topography of a surface, its changes over time, and other changes in the detailed characteristic of the surface. By exploiting the phase of the coherent radar signal, interferometry has transformed radar remote sensing from a largely interpretive science to a quantitative tool, with applications in cartography, geodesy, land cover characterization, and natural hazards. This paper reviews the techniques of interferometry, systems and limitations, and applications in a rapidly growing area of science and engineering.",2000,216,2887,220,23,38,65,78,79,93,114,122,104,141
ce9c55ed58d056b9c0723d048ecd8564fb0c4a16,Overview of Polarimetric Radar Imaging Brief History of Polarimetric Radar Imaging SAR Image Formation: Summary Airborne and Space-Borne PolSAR Systems Description of the Remaining Chapters Electromagnetic Vector Wave and Polarization Descriptors Monochromatic Electromagnetic Plane Wave Polarization Ellipse Jones Vector Stokes Vector Wave Covariance Matrix Electromagnetic Vector Scattering Operators Polarimetric Back Scattering Sinclair S Matrix Scattering Target Vectors k and Omega Polarimetric Coherency T and Covariance C Matrices Polarimetric Mueller M and Kennaugh K Matrices Change of Polarimetric Basis Target Polarimetric Characterization PolSAR Speckle Statistics Fundamental Property of Speckle in SAR Images Speckle Statistics for Multilook-Processed SAR Images Texture Model and K Distribution Effect of Speckle Spatial Correlation Polarimetric and Interferometric SAR Speckle Statistics Phase Difference Distributions of Single-Look and Multilook PolSAR Data Multilook Product Distribution Joint Distribution of Multilook Si2 and Sj2 Multilook Intensity and Amplitude Ratio Distributions Verifications of Multilook PDFs K Distribution for Multilook Polarimetric Data Summary Appendices PolSAR Speckle Filtering Introduction to Speckle Filtering of SAR Imagery Filtering of Single Polarization SAR Data Review of Multipolarization Speckle Filtering Algorithms PolSAR Speckle Filtering Scattering Model-Based PolSAR Speckle Filter Introduction to the Polarimetric Target Decomposition Concept Introduction Dichotomy of the Kennaugh Matrix K Eigenvector-Based Decompositions Model-Based Decompositions Coherent Decompositions The H/A/a Polarimetric Decomposition Theorem Introduction Pure Target Case Probabilistic Model for Random Media Scattering Roll Invariance Property Polarimetric Scattering a Parameter Polarimetric Scattering Entropy (H) Polarimetric Scattering Anisotropy (A) Three-Dimensional H/A/a Classification Space New Eigenvalue-Based Parameters Speckle Filtering Effects on H/A/a PolSAR Terrain and Land-Use Classification Introduction Maximum Likelihood Classifier Based on Complex Gaussian Distribution Complex Wishart Classifier for Multilook PolSAR Data Characteristics of Wishart Distance Measure Supervised Classification Using Wishart Distance Measure Unsupervised Classification Based on Scattering Mechanisms and Wishart Classifier Scattering Model-Based Unsupervised Classification Quantitative Comparison of Classification Capability: Fully PolSAR versus Dual- and Single-Polarization SAR Pol-InSAR Forest Mapping and Classification Introduction Pol-InSAR Scattering Descriptors Forest Mapping and Forest Classification Appendix Selected PolSAR Applications Polarimetric Signature Analysis of Manmade Structures Polarization Orientation Angle Estimation and Applications Ocean Surface Remote Sensing with PolSAR Ionosphere Faraday Rotation Estimation PolSAR Interferometry for Forest Height Estimation Nonstationary Natural Media Analysis from PolSAR Data Using a Two-Dimensional Time-Frequency Approach Appendix A: Eigen Characteristics of Hermitian Matrix Appendix B: PolSARpro Software: The Polariemtric SAR Data Processing and Educational Toolbox Index,2009,0,1800,298,16,47,90,130,125,139,172,197,195,207
a2fd9b9b59646626b5104f781b16ce239c20f03b,Preface. Summary. Nomenclature. 1. Introduction. 2. Radar system theory and interferometric processing. 3. Functional model for radar interferometry. 4. Stochastic model for radar interferometry. 5. Data analysis and interpretation for deformation monitoring. 6. Atmospheric monitoring. 7. Conclusions and recommendations. A. Comparison neutral delay GPS and InSAR. B. Structure function and power spectrum. Bibliography. About the Author. Index.,2001,0,1970,298,4,15,37,37,49,49,71,61,94,118
23eb33af4f0495edff01402ec8eb019e80717897,Foreword. Introduction. Signal Processing Fundamentals. Pulse Compression. Synthetic Aperture Concepts. SAR Signal Properties. The Range Doppler Algorithm. The Chirp Scaling Algorithm. The Omega-K Algorithm. The SPECAN Algorithm. Processing ScanSAR Data. Doppler Parameter Estimation. Comparison of Algorithms. References.,2005,0,1674,246,6,10,16,41,43,79,117,132,127,145
98ec941f07556008c3c3226fd755d7c42ea21b3e,"This detailed guide clearly and concisely presents radar digital signal processing for both practicing engineers and engineering students. This revised edition of Fundamentals of Radar Signal Processing provides in-depth coverage of radar digital signal processing (DSP) fundamentals and applications. It has been updated to include coverage of measurement accuracy and target tracking. Additionally, to make it more useful as a teaching tool, it now includes end-of-chapter problems and a solutions manual. New to this Edition: New chapter on Measurement Accuracy and Target Tracking Two new appendices--Important Digital Signal Processing Facts; Important Probability Density Function and Their Relationships Addition of 20 to 30 problems to ends of chapters Solutions manual",2005,0,1534,178,2,16,20,31,49,85,73,84,114,125
8308e7b39d1f556e4041b4630a41aa8435fe1a49,"MIMO (multiple-input multiple-output) radar refers to an architecture that employs multiple, spatially distributed transmitters and receivers. While, in a general sense, MIMO radar can be viewed as a type of multistatic radar, the separate nomenclature suggests unique features that set MIMO radar apart from the multistatic radar literature and that have a close relation to MIMO communications. This article reviews some recent work on MIMO radar with widely separated antennas. Widely separated transmit/receive antennas capture the spatial diversity of the target's radar cross section (RCS). Unique features of MIMO radar are explained and illustrated by examples. It is shown that with noncoherent processing, a target's RCS spatial variations can be exploited to obtain a diversity gain for target detection and for estimation of various parameters, such as angle of arrival and Doppler. For target location, it is shown that coherent processing can provide a resolution far exceeding that supported by the radar's waveform.",2008,44,1641,72,20,71,104,118,127,118,146,146,155,155
26f825b4ae30b08241df7031a900892761c0f9c0,"We have provided a review of some recent results on the emerging technology of MIMO radar with colocated antennas. We have shown that the waveform diversity offered by such a MIMO radar system enables significant superiority over its phased-array counterpart, including much improved parameter identifiability, direct applicability of adaptive techniques for parameter estimation, as well as superior flexibility of transmit beampattern designs. We hope that this overview of our recent results on the MIMO radar, along with the related results obtained by our colleagues, will stimulate the interest deserved by this topic in both academia and government agencies as well as industry.",2007,32,1722,39,1,27,56,98,103,112,104,145,161,163
aafb36d70d896fad4e68ffceafb5ad53197f22c3,"For 11 days in February 2000, the Shuttle Radar Topography Mission (SRTM) successfully recorded by interferometric synthetic aperture radar (InSAR) data of the entire land mass of the earth between 60°N and 57°S. The data acquired in C- and X-bands are processed into the first global digital elevation models (DEMs) at 1 arc sec resolution, by NASA-JPL and German aerospace center (DLR), respectively. From the perspective of the SRTM-X system, we give in this paper an overview of the mission and the DEM production, as well as an evaluation of the DEM product quality. Special emphasis is on challenges and peculiarities of the processing that arose from the unique design of the SRTM system, which has been the first single-pass interferometer in space.",2003,31,1542,118,6,29,50,58,86,78,107,90,86,91
b064bb54e7d367513067982b7d97cf0697418ec0,"Elevation data is vital to successful mission planning, operations and readiness. Traditional methods for producing elevation data are very expensive and time consuming; major cloud belts would never be completed with existing methods. The Shuttle Radar Topography Mission (SRTM) was selected in 1995 as the best means of supplying nearly global, accurate elevation data. The SRTM is an interferometric SAR system that flew during 11-22 February 2000 aboard NASA's Space Shuttle Endeavour and collected highly specialized data that will allow the generation of Digital Terrain Elevation Data Level 2(DTED® 2). The result of the SRTM will increase the United States Government's coverage of vital and detailed DTED® 2from less than 5% to 80% of the Earth's landmass. This paper describes the shuttle mission and its deliverables.",2001,97,1496,152,3,1,5,4,7,5,9,27,41,64
201dea99707c04e1b659932bb2d46c3e37a6435e,"A stylized compressed sensing radar is proposed in which the time-frequency plane is discretized into an N times N grid. Assuming the number of targets K is small (i.e., K Lt N2), then we can transmit a sufficiently ldquoincoherentrdquo pulse and employ the techniques of compressed sensing to reconstruct the target scene. A theoretical upper bound on the sparsity K is presented. Numerical simulations verify that even better performance can be achieved in practice. This novel-compressed sensing approach offers great potential for better resolution over classical radar.",2008,52,985,28,9,31,43,85,105,120,102,105,94,83
ba841b3c6236793f084f3e056c858abbd05fe6a7,"It has recently been shown that multiple-input multiple-output (MIMO) antenna systems have the potential to improve dramatically the performance of communication systems over single antenna systems. Unlike beamforming, which presumes a high correlation between signals either transmitted or received by an array, the MIMO concept exploits the independence between signals at the array elements. In conventional radar, target scintillations are regarded as a nuisance parameter that degrades radar performance. The novelty of MIMO radar is that it takes the opposite view; namely, it capitalizes on target scintillations to improve the radar's performance. We introduce the MIMO concept for radar. The MIMO radar system under consideration consists of a transmit array with widely-spaced elements such that each views a different aspect of the target. The array at the receiver is a conventional array used for direction finding (DF). The system performance analysis is carried out in terms of the Cramer-Rao bound of the mean-square error in estimating the target direction. It is shown that MIMO radar leads to significant performance improvement in DF accuracy.",2004,20,1283,45,3,7,30,41,71,67,108,93,75,90
bb01353f818ca226b53433163893efc56c3df32d,"The proliferation of mobile computing devices and local-area wireless networks has fostered a growing interest in location-aware systems and services. In this paper we present RADAR, a radio-frequency (RF)-based system for locating and tracking users inside buildings. RADAR operates by recording and processing signal strength information at multiple base stations positioned to provide overlapping coverage in the area of interest. It combines empirical measurements with signal propagation modeling to determine user location and thereby enable location-aware services and applications. We present experimental results that demonstrate the ability of RADAR to estimate user location with a high degree of accuracy.",2000,36,8417,939,18,41,70,138,237,348,377,446,474,558
1e71e22a3012080f9d6d115080e3f4678e39f0b9,"[1] The Shuttle Radar Topography Mission produced the most complete, highest-resolution digital elevation model of the Earth. The project was a joint endeavor of NASA, the National Geospatial-Intelligence Agency, and the German and Italian Space Agencies and flew in February 2000. It used dual radar antennas to acquire interferometric radar data, processed to digital topographic data at 1 arc sec resolution. Details of the development, flight operations, data processing, and products are provided for users of this revolutionary data set.",2000,52,3523,186,2,5,1,2,1,6,13,14,54,95
a0abeeaef200e83a6d4538423c826a522f4e8b71,"Synthetic aperture radar interferometry is an imaging technique for measuring the topography of a surface, its changes over time, and other changes in the detailed characteristic of the surface. By exploiting the phase of the coherent radar signal, interferometry has transformed radar remote sensing from a largely interpretive science to a quantitative tool, with applications in cartography, geodesy, land cover characterization, and natural hazards. This paper reviews the techniques of interferometry, systems and limitations, and applications in a rapidly growing area of science and engineering.",2000,216,2887,220,23,38,65,78,79,93,114,122,104,141
ce9c55ed58d056b9c0723d048ecd8564fb0c4a16,Overview of Polarimetric Radar Imaging Brief History of Polarimetric Radar Imaging SAR Image Formation: Summary Airborne and Space-Borne PolSAR Systems Description of the Remaining Chapters Electromagnetic Vector Wave and Polarization Descriptors Monochromatic Electromagnetic Plane Wave Polarization Ellipse Jones Vector Stokes Vector Wave Covariance Matrix Electromagnetic Vector Scattering Operators Polarimetric Back Scattering Sinclair S Matrix Scattering Target Vectors k and Omega Polarimetric Coherency T and Covariance C Matrices Polarimetric Mueller M and Kennaugh K Matrices Change of Polarimetric Basis Target Polarimetric Characterization PolSAR Speckle Statistics Fundamental Property of Speckle in SAR Images Speckle Statistics for Multilook-Processed SAR Images Texture Model and K Distribution Effect of Speckle Spatial Correlation Polarimetric and Interferometric SAR Speckle Statistics Phase Difference Distributions of Single-Look and Multilook PolSAR Data Multilook Product Distribution Joint Distribution of Multilook Si2 and Sj2 Multilook Intensity and Amplitude Ratio Distributions Verifications of Multilook PDFs K Distribution for Multilook Polarimetric Data Summary Appendices PolSAR Speckle Filtering Introduction to Speckle Filtering of SAR Imagery Filtering of Single Polarization SAR Data Review of Multipolarization Speckle Filtering Algorithms PolSAR Speckle Filtering Scattering Model-Based PolSAR Speckle Filter Introduction to the Polarimetric Target Decomposition Concept Introduction Dichotomy of the Kennaugh Matrix K Eigenvector-Based Decompositions Model-Based Decompositions Coherent Decompositions The H/A/a Polarimetric Decomposition Theorem Introduction Pure Target Case Probabilistic Model for Random Media Scattering Roll Invariance Property Polarimetric Scattering a Parameter Polarimetric Scattering Entropy (H) Polarimetric Scattering Anisotropy (A) Three-Dimensional H/A/a Classification Space New Eigenvalue-Based Parameters Speckle Filtering Effects on H/A/a PolSAR Terrain and Land-Use Classification Introduction Maximum Likelihood Classifier Based on Complex Gaussian Distribution Complex Wishart Classifier for Multilook PolSAR Data Characteristics of Wishart Distance Measure Supervised Classification Using Wishart Distance Measure Unsupervised Classification Based on Scattering Mechanisms and Wishart Classifier Scattering Model-Based Unsupervised Classification Quantitative Comparison of Classification Capability: Fully PolSAR versus Dual- and Single-Polarization SAR Pol-InSAR Forest Mapping and Classification Introduction Pol-InSAR Scattering Descriptors Forest Mapping and Forest Classification Appendix Selected PolSAR Applications Polarimetric Signature Analysis of Manmade Structures Polarization Orientation Angle Estimation and Applications Ocean Surface Remote Sensing with PolSAR Ionosphere Faraday Rotation Estimation PolSAR Interferometry for Forest Height Estimation Nonstationary Natural Media Analysis from PolSAR Data Using a Two-Dimensional Time-Frequency Approach Appendix A: Eigen Characteristics of Hermitian Matrix Appendix B: PolSARpro Software: The Polariemtric SAR Data Processing and Educational Toolbox Index,2009,0,1800,298,16,47,90,130,125,139,172,197,195,207
a2fd9b9b59646626b5104f781b16ce239c20f03b,Preface. Summary. Nomenclature. 1. Introduction. 2. Radar system theory and interferometric processing. 3. Functional model for radar interferometry. 4. Stochastic model for radar interferometry. 5. Data analysis and interpretation for deformation monitoring. 6. Atmospheric monitoring. 7. Conclusions and recommendations. A. Comparison neutral delay GPS and InSAR. B. Structure function and power spectrum. Bibliography. About the Author. Index.,2001,0,1970,298,4,15,37,37,49,49,71,61,94,118
23eb33af4f0495edff01402ec8eb019e80717897,Foreword. Introduction. Signal Processing Fundamentals. Pulse Compression. Synthetic Aperture Concepts. SAR Signal Properties. The Range Doppler Algorithm. The Chirp Scaling Algorithm. The Omega-K Algorithm. The SPECAN Algorithm. Processing ScanSAR Data. Doppler Parameter Estimation. Comparison of Algorithms. References.,2005,0,1674,246,6,10,16,41,43,79,117,132,127,145
98ec941f07556008c3c3226fd755d7c42ea21b3e,"This detailed guide clearly and concisely presents radar digital signal processing for both practicing engineers and engineering students. This revised edition of Fundamentals of Radar Signal Processing provides in-depth coverage of radar digital signal processing (DSP) fundamentals and applications. It has been updated to include coverage of measurement accuracy and target tracking. Additionally, to make it more useful as a teaching tool, it now includes end-of-chapter problems and a solutions manual. New to this Edition: New chapter on Measurement Accuracy and Target Tracking Two new appendices--Important Digital Signal Processing Facts; Important Probability Density Function and Their Relationships Addition of 20 to 30 problems to ends of chapters Solutions manual",2005,0,1534,178,2,16,20,31,49,85,73,84,114,125
8308e7b39d1f556e4041b4630a41aa8435fe1a49,"MIMO (multiple-input multiple-output) radar refers to an architecture that employs multiple, spatially distributed transmitters and receivers. While, in a general sense, MIMO radar can be viewed as a type of multistatic radar, the separate nomenclature suggests unique features that set MIMO radar apart from the multistatic radar literature and that have a close relation to MIMO communications. This article reviews some recent work on MIMO radar with widely separated antennas. Widely separated transmit/receive antennas capture the spatial diversity of the target's radar cross section (RCS). Unique features of MIMO radar are explained and illustrated by examples. It is shown that with noncoherent processing, a target's RCS spatial variations can be exploited to obtain a diversity gain for target detection and for estimation of various parameters, such as angle of arrival and Doppler. For target location, it is shown that coherent processing can provide a resolution far exceeding that supported by the radar's waveform.",2008,44,1641,72,20,71,104,118,127,118,146,146,155,155
26f825b4ae30b08241df7031a900892761c0f9c0,"We have provided a review of some recent results on the emerging technology of MIMO radar with colocated antennas. We have shown that the waveform diversity offered by such a MIMO radar system enables significant superiority over its phased-array counterpart, including much improved parameter identifiability, direct applicability of adaptive techniques for parameter estimation, as well as superior flexibility of transmit beampattern designs. We hope that this overview of our recent results on the MIMO radar, along with the related results obtained by our colleagues, will stimulate the interest deserved by this topic in both academia and government agencies as well as industry.",2007,32,1722,39,1,27,56,98,103,112,104,145,161,163
aafb36d70d896fad4e68ffceafb5ad53197f22c3,"For 11 days in February 2000, the Shuttle Radar Topography Mission (SRTM) successfully recorded by interferometric synthetic aperture radar (InSAR) data of the entire land mass of the earth between 60°N and 57°S. The data acquired in C- and X-bands are processed into the first global digital elevation models (DEMs) at 1 arc sec resolution, by NASA-JPL and German aerospace center (DLR), respectively. From the perspective of the SRTM-X system, we give in this paper an overview of the mission and the DEM production, as well as an evaluation of the DEM product quality. Special emphasis is on challenges and peculiarities of the processing that arose from the unique design of the SRTM system, which has been the first single-pass interferometer in space.",2003,31,1542,118,6,29,50,58,86,78,107,90,86,91
b064bb54e7d367513067982b7d97cf0697418ec0,"Elevation data is vital to successful mission planning, operations and readiness. Traditional methods for producing elevation data are very expensive and time consuming; major cloud belts would never be completed with existing methods. The Shuttle Radar Topography Mission (SRTM) was selected in 1995 as the best means of supplying nearly global, accurate elevation data. The SRTM is an interferometric SAR system that flew during 11-22 February 2000 aboard NASA's Space Shuttle Endeavour and collected highly specialized data that will allow the generation of Digital Terrain Elevation Data Level 2(DTED® 2). The result of the SRTM will increase the United States Government's coverage of vital and detailed DTED® 2from less than 5% to 80% of the Earth's landmass. This paper describes the shuttle mission and its deliverables.",2001,97,1496,152,3,1,5,4,7,5,9,27,41,64
201dea99707c04e1b659932bb2d46c3e37a6435e,"A stylized compressed sensing radar is proposed in which the time-frequency plane is discretized into an N times N grid. Assuming the number of targets K is small (i.e., K Lt N2), then we can transmit a sufficiently ldquoincoherentrdquo pulse and employ the techniques of compressed sensing to reconstruct the target scene. A theoretical upper bound on the sparsity K is presented. Numerical simulations verify that even better performance can be achieved in practice. This novel-compressed sensing approach offers great potential for better resolution over classical radar.",2008,52,985,28,9,31,43,85,105,120,102,105,94,83
ba841b3c6236793f084f3e056c858abbd05fe6a7,"It has recently been shown that multiple-input multiple-output (MIMO) antenna systems have the potential to improve dramatically the performance of communication systems over single antenna systems. Unlike beamforming, which presumes a high correlation between signals either transmitted or received by an array, the MIMO concept exploits the independence between signals at the array elements. In conventional radar, target scintillations are regarded as a nuisance parameter that degrades radar performance. The novelty of MIMO radar is that it takes the opposite view; namely, it capitalizes on target scintillations to improve the radar's performance. We introduce the MIMO concept for radar. The MIMO radar system under consideration consists of a transmit array with widely-spaced elements such that each views a different aspect of the target. The array at the receiver is a conventional array used for direction finding (DF). The system performance analysis is carried out in terms of the Cramer-Rao bound of the mean-square error in estimating the target direction. It is shown that MIMO radar leads to significant performance improvement in DF accuracy.",2004,20,1283,45,3,7,30,41,71,67,108,93,75,90
bb01353f818ca226b53433163893efc56c3df32d,"The proliferation of mobile computing devices and local-area wireless networks has fostered a growing interest in location-aware systems and services. In this paper we present RADAR, a radio-frequency (RF)-based system for locating and tracking users inside buildings. RADAR operates by recording and processing signal strength information at multiple base stations positioned to provide overlapping coverage in the area of interest. It combines empirical measurements with signal propagation modeling to determine user location and thereby enable location-aware services and applications. We present experimental results that demonstrate the ability of RADAR to estimate user location with a high degree of accuracy.",2000,36,8417,939,18,41,70,138,237,348,377,446,474,558
1e71e22a3012080f9d6d115080e3f4678e39f0b9,"[1] The Shuttle Radar Topography Mission produced the most complete, highest-resolution digital elevation model of the Earth. The project was a joint endeavor of NASA, the National Geospatial-Intelligence Agency, and the German and Italian Space Agencies and flew in February 2000. It used dual radar antennas to acquire interferometric radar data, processed to digital topographic data at 1 arc sec resolution. Details of the development, flight operations, data processing, and products are provided for users of this revolutionary data set.",2000,52,3523,186,2,5,1,2,1,6,13,14,54,95
a0abeeaef200e83a6d4538423c826a522f4e8b71,"Synthetic aperture radar interferometry is an imaging technique for measuring the topography of a surface, its changes over time, and other changes in the detailed characteristic of the surface. By exploiting the phase of the coherent radar signal, interferometry has transformed radar remote sensing from a largely interpretive science to a quantitative tool, with applications in cartography, geodesy, land cover characterization, and natural hazards. This paper reviews the techniques of interferometry, systems and limitations, and applications in a rapidly growing area of science and engineering.",2000,216,2887,220,23,38,65,78,79,93,114,122,104,141
ce9c55ed58d056b9c0723d048ecd8564fb0c4a16,Overview of Polarimetric Radar Imaging Brief History of Polarimetric Radar Imaging SAR Image Formation: Summary Airborne and Space-Borne PolSAR Systems Description of the Remaining Chapters Electromagnetic Vector Wave and Polarization Descriptors Monochromatic Electromagnetic Plane Wave Polarization Ellipse Jones Vector Stokes Vector Wave Covariance Matrix Electromagnetic Vector Scattering Operators Polarimetric Back Scattering Sinclair S Matrix Scattering Target Vectors k and Omega Polarimetric Coherency T and Covariance C Matrices Polarimetric Mueller M and Kennaugh K Matrices Change of Polarimetric Basis Target Polarimetric Characterization PolSAR Speckle Statistics Fundamental Property of Speckle in SAR Images Speckle Statistics for Multilook-Processed SAR Images Texture Model and K Distribution Effect of Speckle Spatial Correlation Polarimetric and Interferometric SAR Speckle Statistics Phase Difference Distributions of Single-Look and Multilook PolSAR Data Multilook Product Distribution Joint Distribution of Multilook Si2 and Sj2 Multilook Intensity and Amplitude Ratio Distributions Verifications of Multilook PDFs K Distribution for Multilook Polarimetric Data Summary Appendices PolSAR Speckle Filtering Introduction to Speckle Filtering of SAR Imagery Filtering of Single Polarization SAR Data Review of Multipolarization Speckle Filtering Algorithms PolSAR Speckle Filtering Scattering Model-Based PolSAR Speckle Filter Introduction to the Polarimetric Target Decomposition Concept Introduction Dichotomy of the Kennaugh Matrix K Eigenvector-Based Decompositions Model-Based Decompositions Coherent Decompositions The H/A/a Polarimetric Decomposition Theorem Introduction Pure Target Case Probabilistic Model for Random Media Scattering Roll Invariance Property Polarimetric Scattering a Parameter Polarimetric Scattering Entropy (H) Polarimetric Scattering Anisotropy (A) Three-Dimensional H/A/a Classification Space New Eigenvalue-Based Parameters Speckle Filtering Effects on H/A/a PolSAR Terrain and Land-Use Classification Introduction Maximum Likelihood Classifier Based on Complex Gaussian Distribution Complex Wishart Classifier for Multilook PolSAR Data Characteristics of Wishart Distance Measure Supervised Classification Using Wishart Distance Measure Unsupervised Classification Based on Scattering Mechanisms and Wishart Classifier Scattering Model-Based Unsupervised Classification Quantitative Comparison of Classification Capability: Fully PolSAR versus Dual- and Single-Polarization SAR Pol-InSAR Forest Mapping and Classification Introduction Pol-InSAR Scattering Descriptors Forest Mapping and Forest Classification Appendix Selected PolSAR Applications Polarimetric Signature Analysis of Manmade Structures Polarization Orientation Angle Estimation and Applications Ocean Surface Remote Sensing with PolSAR Ionosphere Faraday Rotation Estimation PolSAR Interferometry for Forest Height Estimation Nonstationary Natural Media Analysis from PolSAR Data Using a Two-Dimensional Time-Frequency Approach Appendix A: Eigen Characteristics of Hermitian Matrix Appendix B: PolSARpro Software: The Polariemtric SAR Data Processing and Educational Toolbox Index,2009,0,1800,298,16,47,90,130,125,139,172,197,195,207
a2fd9b9b59646626b5104f781b16ce239c20f03b,Preface. Summary. Nomenclature. 1. Introduction. 2. Radar system theory and interferometric processing. 3. Functional model for radar interferometry. 4. Stochastic model for radar interferometry. 5. Data analysis and interpretation for deformation monitoring. 6. Atmospheric monitoring. 7. Conclusions and recommendations. A. Comparison neutral delay GPS and InSAR. B. Structure function and power spectrum. Bibliography. About the Author. Index.,2001,0,1970,298,4,15,37,37,49,49,71,61,94,118
23eb33af4f0495edff01402ec8eb019e80717897,Foreword. Introduction. Signal Processing Fundamentals. Pulse Compression. Synthetic Aperture Concepts. SAR Signal Properties. The Range Doppler Algorithm. The Chirp Scaling Algorithm. The Omega-K Algorithm. The SPECAN Algorithm. Processing ScanSAR Data. Doppler Parameter Estimation. Comparison of Algorithms. References.,2005,0,1674,246,6,10,16,41,43,79,117,132,127,145
98ec941f07556008c3c3226fd755d7c42ea21b3e,"This detailed guide clearly and concisely presents radar digital signal processing for both practicing engineers and engineering students. This revised edition of Fundamentals of Radar Signal Processing provides in-depth coverage of radar digital signal processing (DSP) fundamentals and applications. It has been updated to include coverage of measurement accuracy and target tracking. Additionally, to make it more useful as a teaching tool, it now includes end-of-chapter problems and a solutions manual. New to this Edition: New chapter on Measurement Accuracy and Target Tracking Two new appendices--Important Digital Signal Processing Facts; Important Probability Density Function and Their Relationships Addition of 20 to 30 problems to ends of chapters Solutions manual",2005,0,1534,178,2,16,20,31,49,85,73,84,114,125
8308e7b39d1f556e4041b4630a41aa8435fe1a49,"MIMO (multiple-input multiple-output) radar refers to an architecture that employs multiple, spatially distributed transmitters and receivers. While, in a general sense, MIMO radar can be viewed as a type of multistatic radar, the separate nomenclature suggests unique features that set MIMO radar apart from the multistatic radar literature and that have a close relation to MIMO communications. This article reviews some recent work on MIMO radar with widely separated antennas. Widely separated transmit/receive antennas capture the spatial diversity of the target's radar cross section (RCS). Unique features of MIMO radar are explained and illustrated by examples. It is shown that with noncoherent processing, a target's RCS spatial variations can be exploited to obtain a diversity gain for target detection and for estimation of various parameters, such as angle of arrival and Doppler. For target location, it is shown that coherent processing can provide a resolution far exceeding that supported by the radar's waveform.",2008,44,1641,72,20,71,104,118,127,118,146,146,155,155
26f825b4ae30b08241df7031a900892761c0f9c0,"We have provided a review of some recent results on the emerging technology of MIMO radar with colocated antennas. We have shown that the waveform diversity offered by such a MIMO radar system enables significant superiority over its phased-array counterpart, including much improved parameter identifiability, direct applicability of adaptive techniques for parameter estimation, as well as superior flexibility of transmit beampattern designs. We hope that this overview of our recent results on the MIMO radar, along with the related results obtained by our colleagues, will stimulate the interest deserved by this topic in both academia and government agencies as well as industry.",2007,32,1722,39,1,27,56,98,103,112,104,145,161,163
aafb36d70d896fad4e68ffceafb5ad53197f22c3,"For 11 days in February 2000, the Shuttle Radar Topography Mission (SRTM) successfully recorded by interferometric synthetic aperture radar (InSAR) data of the entire land mass of the earth between 60°N and 57°S. The data acquired in C- and X-bands are processed into the first global digital elevation models (DEMs) at 1 arc sec resolution, by NASA-JPL and German aerospace center (DLR), respectively. From the perspective of the SRTM-X system, we give in this paper an overview of the mission and the DEM production, as well as an evaluation of the DEM product quality. Special emphasis is on challenges and peculiarities of the processing that arose from the unique design of the SRTM system, which has been the first single-pass interferometer in space.",2003,31,1542,118,6,29,50,58,86,78,107,90,86,91
b064bb54e7d367513067982b7d97cf0697418ec0,"Elevation data is vital to successful mission planning, operations and readiness. Traditional methods for producing elevation data are very expensive and time consuming; major cloud belts would never be completed with existing methods. The Shuttle Radar Topography Mission (SRTM) was selected in 1995 as the best means of supplying nearly global, accurate elevation data. The SRTM is an interferometric SAR system that flew during 11-22 February 2000 aboard NASA's Space Shuttle Endeavour and collected highly specialized data that will allow the generation of Digital Terrain Elevation Data Level 2(DTED® 2). The result of the SRTM will increase the United States Government's coverage of vital and detailed DTED® 2from less than 5% to 80% of the Earth's landmass. This paper describes the shuttle mission and its deliverables.",2001,97,1496,152,3,1,5,4,7,5,9,27,41,64
201dea99707c04e1b659932bb2d46c3e37a6435e,"A stylized compressed sensing radar is proposed in which the time-frequency plane is discretized into an N times N grid. Assuming the number of targets K is small (i.e., K Lt N2), then we can transmit a sufficiently ldquoincoherentrdquo pulse and employ the techniques of compressed sensing to reconstruct the target scene. A theoretical upper bound on the sparsity K is presented. Numerical simulations verify that even better performance can be achieved in practice. This novel-compressed sensing approach offers great potential for better resolution over classical radar.",2008,52,985,28,9,31,43,85,105,120,102,105,94,83
ba841b3c6236793f084f3e056c858abbd05fe6a7,"It has recently been shown that multiple-input multiple-output (MIMO) antenna systems have the potential to improve dramatically the performance of communication systems over single antenna systems. Unlike beamforming, which presumes a high correlation between signals either transmitted or received by an array, the MIMO concept exploits the independence between signals at the array elements. In conventional radar, target scintillations are regarded as a nuisance parameter that degrades radar performance. The novelty of MIMO radar is that it takes the opposite view; namely, it capitalizes on target scintillations to improve the radar's performance. We introduce the MIMO concept for radar. The MIMO radar system under consideration consists of a transmit array with widely-spaced elements such that each views a different aspect of the target. The array at the receiver is a conventional array used for direction finding (DF). The system performance analysis is carried out in terms of the Cramer-Rao bound of the mean-square error in estimating the target direction. It is shown that MIMO radar leads to significant performance improvement in DF accuracy.",2004,20,1283,45,3,7,30,41,71,67,108,93,75,90
bb01353f818ca226b53433163893efc56c3df32d,"The proliferation of mobile computing devices and local-area wireless networks has fostered a growing interest in location-aware systems and services. In this paper we present RADAR, a radio-frequency (RF)-based system for locating and tracking users inside buildings. RADAR operates by recording and processing signal strength information at multiple base stations positioned to provide overlapping coverage in the area of interest. It combines empirical measurements with signal propagation modeling to determine user location and thereby enable location-aware services and applications. We present experimental results that demonstrate the ability of RADAR to estimate user location with a high degree of accuracy.",2000,36,8417,939,18,41,70,138,237,348,377,446,474,558
1e71e22a3012080f9d6d115080e3f4678e39f0b9,"[1] The Shuttle Radar Topography Mission produced the most complete, highest-resolution digital elevation model of the Earth. The project was a joint endeavor of NASA, the National Geospatial-Intelligence Agency, and the German and Italian Space Agencies and flew in February 2000. It used dual radar antennas to acquire interferometric radar data, processed to digital topographic data at 1 arc sec resolution. Details of the development, flight operations, data processing, and products are provided for users of this revolutionary data set.",2000,52,3523,186,2,5,1,2,1,6,13,14,54,95
a0abeeaef200e83a6d4538423c826a522f4e8b71,"Synthetic aperture radar interferometry is an imaging technique for measuring the topography of a surface, its changes over time, and other changes in the detailed characteristic of the surface. By exploiting the phase of the coherent radar signal, interferometry has transformed radar remote sensing from a largely interpretive science to a quantitative tool, with applications in cartography, geodesy, land cover characterization, and natural hazards. This paper reviews the techniques of interferometry, systems and limitations, and applications in a rapidly growing area of science and engineering.",2000,216,2887,220,23,38,65,78,79,93,114,122,104,141
ce9c55ed58d056b9c0723d048ecd8564fb0c4a16,Overview of Polarimetric Radar Imaging Brief History of Polarimetric Radar Imaging SAR Image Formation: Summary Airborne and Space-Borne PolSAR Systems Description of the Remaining Chapters Electromagnetic Vector Wave and Polarization Descriptors Monochromatic Electromagnetic Plane Wave Polarization Ellipse Jones Vector Stokes Vector Wave Covariance Matrix Electromagnetic Vector Scattering Operators Polarimetric Back Scattering Sinclair S Matrix Scattering Target Vectors k and Omega Polarimetric Coherency T and Covariance C Matrices Polarimetric Mueller M and Kennaugh K Matrices Change of Polarimetric Basis Target Polarimetric Characterization PolSAR Speckle Statistics Fundamental Property of Speckle in SAR Images Speckle Statistics for Multilook-Processed SAR Images Texture Model and K Distribution Effect of Speckle Spatial Correlation Polarimetric and Interferometric SAR Speckle Statistics Phase Difference Distributions of Single-Look and Multilook PolSAR Data Multilook Product Distribution Joint Distribution of Multilook Si2 and Sj2 Multilook Intensity and Amplitude Ratio Distributions Verifications of Multilook PDFs K Distribution for Multilook Polarimetric Data Summary Appendices PolSAR Speckle Filtering Introduction to Speckle Filtering of SAR Imagery Filtering of Single Polarization SAR Data Review of Multipolarization Speckle Filtering Algorithms PolSAR Speckle Filtering Scattering Model-Based PolSAR Speckle Filter Introduction to the Polarimetric Target Decomposition Concept Introduction Dichotomy of the Kennaugh Matrix K Eigenvector-Based Decompositions Model-Based Decompositions Coherent Decompositions The H/A/a Polarimetric Decomposition Theorem Introduction Pure Target Case Probabilistic Model for Random Media Scattering Roll Invariance Property Polarimetric Scattering a Parameter Polarimetric Scattering Entropy (H) Polarimetric Scattering Anisotropy (A) Three-Dimensional H/A/a Classification Space New Eigenvalue-Based Parameters Speckle Filtering Effects on H/A/a PolSAR Terrain and Land-Use Classification Introduction Maximum Likelihood Classifier Based on Complex Gaussian Distribution Complex Wishart Classifier for Multilook PolSAR Data Characteristics of Wishart Distance Measure Supervised Classification Using Wishart Distance Measure Unsupervised Classification Based on Scattering Mechanisms and Wishart Classifier Scattering Model-Based Unsupervised Classification Quantitative Comparison of Classification Capability: Fully PolSAR versus Dual- and Single-Polarization SAR Pol-InSAR Forest Mapping and Classification Introduction Pol-InSAR Scattering Descriptors Forest Mapping and Forest Classification Appendix Selected PolSAR Applications Polarimetric Signature Analysis of Manmade Structures Polarization Orientation Angle Estimation and Applications Ocean Surface Remote Sensing with PolSAR Ionosphere Faraday Rotation Estimation PolSAR Interferometry for Forest Height Estimation Nonstationary Natural Media Analysis from PolSAR Data Using a Two-Dimensional Time-Frequency Approach Appendix A: Eigen Characteristics of Hermitian Matrix Appendix B: PolSARpro Software: The Polariemtric SAR Data Processing and Educational Toolbox Index,2009,0,1800,298,16,47,90,130,125,139,172,197,195,207
a2fd9b9b59646626b5104f781b16ce239c20f03b,Preface. Summary. Nomenclature. 1. Introduction. 2. Radar system theory and interferometric processing. 3. Functional model for radar interferometry. 4. Stochastic model for radar interferometry. 5. Data analysis and interpretation for deformation monitoring. 6. Atmospheric monitoring. 7. Conclusions and recommendations. A. Comparison neutral delay GPS and InSAR. B. Structure function and power spectrum. Bibliography. About the Author. Index.,2001,0,1970,298,4,15,37,37,49,49,71,61,94,118
23eb33af4f0495edff01402ec8eb019e80717897,Foreword. Introduction. Signal Processing Fundamentals. Pulse Compression. Synthetic Aperture Concepts. SAR Signal Properties. The Range Doppler Algorithm. The Chirp Scaling Algorithm. The Omega-K Algorithm. The SPECAN Algorithm. Processing ScanSAR Data. Doppler Parameter Estimation. Comparison of Algorithms. References.,2005,0,1674,246,6,10,16,41,43,79,117,132,127,145
98ec941f07556008c3c3226fd755d7c42ea21b3e,"This detailed guide clearly and concisely presents radar digital signal processing for both practicing engineers and engineering students. This revised edition of Fundamentals of Radar Signal Processing provides in-depth coverage of radar digital signal processing (DSP) fundamentals and applications. It has been updated to include coverage of measurement accuracy and target tracking. Additionally, to make it more useful as a teaching tool, it now includes end-of-chapter problems and a solutions manual. New to this Edition: New chapter on Measurement Accuracy and Target Tracking Two new appendices--Important Digital Signal Processing Facts; Important Probability Density Function and Their Relationships Addition of 20 to 30 problems to ends of chapters Solutions manual",2005,0,1534,178,2,16,20,31,49,85,73,84,114,125
8308e7b39d1f556e4041b4630a41aa8435fe1a49,"MIMO (multiple-input multiple-output) radar refers to an architecture that employs multiple, spatially distributed transmitters and receivers. While, in a general sense, MIMO radar can be viewed as a type of multistatic radar, the separate nomenclature suggests unique features that set MIMO radar apart from the multistatic radar literature and that have a close relation to MIMO communications. This article reviews some recent work on MIMO radar with widely separated antennas. Widely separated transmit/receive antennas capture the spatial diversity of the target's radar cross section (RCS). Unique features of MIMO radar are explained and illustrated by examples. It is shown that with noncoherent processing, a target's RCS spatial variations can be exploited to obtain a diversity gain for target detection and for estimation of various parameters, such as angle of arrival and Doppler. For target location, it is shown that coherent processing can provide a resolution far exceeding that supported by the radar's waveform.",2008,44,1641,72,20,71,104,118,127,118,146,146,155,155
26f825b4ae30b08241df7031a900892761c0f9c0,"We have provided a review of some recent results on the emerging technology of MIMO radar with colocated antennas. We have shown that the waveform diversity offered by such a MIMO radar system enables significant superiority over its phased-array counterpart, including much improved parameter identifiability, direct applicability of adaptive techniques for parameter estimation, as well as superior flexibility of transmit beampattern designs. We hope that this overview of our recent results on the MIMO radar, along with the related results obtained by our colleagues, will stimulate the interest deserved by this topic in both academia and government agencies as well as industry.",2007,32,1722,39,1,27,56,98,103,112,104,145,161,163
aafb36d70d896fad4e68ffceafb5ad53197f22c3,"For 11 days in February 2000, the Shuttle Radar Topography Mission (SRTM) successfully recorded by interferometric synthetic aperture radar (InSAR) data of the entire land mass of the earth between 60°N and 57°S. The data acquired in C- and X-bands are processed into the first global digital elevation models (DEMs) at 1 arc sec resolution, by NASA-JPL and German aerospace center (DLR), respectively. From the perspective of the SRTM-X system, we give in this paper an overview of the mission and the DEM production, as well as an evaluation of the DEM product quality. Special emphasis is on challenges and peculiarities of the processing that arose from the unique design of the SRTM system, which has been the first single-pass interferometer in space.",2003,31,1542,118,6,29,50,58,86,78,107,90,86,91
b064bb54e7d367513067982b7d97cf0697418ec0,"Elevation data is vital to successful mission planning, operations and readiness. Traditional methods for producing elevation data are very expensive and time consuming; major cloud belts would never be completed with existing methods. The Shuttle Radar Topography Mission (SRTM) was selected in 1995 as the best means of supplying nearly global, accurate elevation data. The SRTM is an interferometric SAR system that flew during 11-22 February 2000 aboard NASA's Space Shuttle Endeavour and collected highly specialized data that will allow the generation of Digital Terrain Elevation Data Level 2(DTED® 2). The result of the SRTM will increase the United States Government's coverage of vital and detailed DTED® 2from less than 5% to 80% of the Earth's landmass. This paper describes the shuttle mission and its deliverables.",2001,97,1496,152,3,1,5,4,7,5,9,27,41,64
201dea99707c04e1b659932bb2d46c3e37a6435e,"A stylized compressed sensing radar is proposed in which the time-frequency plane is discretized into an N times N grid. Assuming the number of targets K is small (i.e., K Lt N2), then we can transmit a sufficiently ldquoincoherentrdquo pulse and employ the techniques of compressed sensing to reconstruct the target scene. A theoretical upper bound on the sparsity K is presented. Numerical simulations verify that even better performance can be achieved in practice. This novel-compressed sensing approach offers great potential for better resolution over classical radar.",2008,52,985,28,9,31,43,85,105,120,102,105,94,83
ba841b3c6236793f084f3e056c858abbd05fe6a7,"It has recently been shown that multiple-input multiple-output (MIMO) antenna systems have the potential to improve dramatically the performance of communication systems over single antenna systems. Unlike beamforming, which presumes a high correlation between signals either transmitted or received by an array, the MIMO concept exploits the independence between signals at the array elements. In conventional radar, target scintillations are regarded as a nuisance parameter that degrades radar performance. The novelty of MIMO radar is that it takes the opposite view; namely, it capitalizes on target scintillations to improve the radar's performance. We introduce the MIMO concept for radar. The MIMO radar system under consideration consists of a transmit array with widely-spaced elements such that each views a different aspect of the target. The array at the receiver is a conventional array used for direction finding (DF). The system performance analysis is carried out in terms of the Cramer-Rao bound of the mean-square error in estimating the target direction. It is shown that MIMO radar leads to significant performance improvement in DF accuracy.",2004,20,1283,45,3,7,30,41,71,67,108,93,75,90
bb01353f818ca226b53433163893efc56c3df32d,"The proliferation of mobile computing devices and local-area wireless networks has fostered a growing interest in location-aware systems and services. In this paper we present RADAR, a radio-frequency (RF)-based system for locating and tracking users inside buildings. RADAR operates by recording and processing signal strength information at multiple base stations positioned to provide overlapping coverage in the area of interest. It combines empirical measurements with signal propagation modeling to determine user location and thereby enable location-aware services and applications. We present experimental results that demonstrate the ability of RADAR to estimate user location with a high degree of accuracy.",2000,36,8417,939,18,41,70,138,237,348,377,446,474,558
1e71e22a3012080f9d6d115080e3f4678e39f0b9,"[1] The Shuttle Radar Topography Mission produced the most complete, highest-resolution digital elevation model of the Earth. The project was a joint endeavor of NASA, the National Geospatial-Intelligence Agency, and the German and Italian Space Agencies and flew in February 2000. It used dual radar antennas to acquire interferometric radar data, processed to digital topographic data at 1 arc sec resolution. Details of the development, flight operations, data processing, and products are provided for users of this revolutionary data set.",2000,52,3523,186,2,5,1,2,1,6,13,14,54,95
a0abeeaef200e83a6d4538423c826a522f4e8b71,"Synthetic aperture radar interferometry is an imaging technique for measuring the topography of a surface, its changes over time, and other changes in the detailed characteristic of the surface. By exploiting the phase of the coherent radar signal, interferometry has transformed radar remote sensing from a largely interpretive science to a quantitative tool, with applications in cartography, geodesy, land cover characterization, and natural hazards. This paper reviews the techniques of interferometry, systems and limitations, and applications in a rapidly growing area of science and engineering.",2000,216,2887,220,23,38,65,78,79,93,114,122,104,141
ce9c55ed58d056b9c0723d048ecd8564fb0c4a16,Overview of Polarimetric Radar Imaging Brief History of Polarimetric Radar Imaging SAR Image Formation: Summary Airborne and Space-Borne PolSAR Systems Description of the Remaining Chapters Electromagnetic Vector Wave and Polarization Descriptors Monochromatic Electromagnetic Plane Wave Polarization Ellipse Jones Vector Stokes Vector Wave Covariance Matrix Electromagnetic Vector Scattering Operators Polarimetric Back Scattering Sinclair S Matrix Scattering Target Vectors k and Omega Polarimetric Coherency T and Covariance C Matrices Polarimetric Mueller M and Kennaugh K Matrices Change of Polarimetric Basis Target Polarimetric Characterization PolSAR Speckle Statistics Fundamental Property of Speckle in SAR Images Speckle Statistics for Multilook-Processed SAR Images Texture Model and K Distribution Effect of Speckle Spatial Correlation Polarimetric and Interferometric SAR Speckle Statistics Phase Difference Distributions of Single-Look and Multilook PolSAR Data Multilook Product Distribution Joint Distribution of Multilook Si2 and Sj2 Multilook Intensity and Amplitude Ratio Distributions Verifications of Multilook PDFs K Distribution for Multilook Polarimetric Data Summary Appendices PolSAR Speckle Filtering Introduction to Speckle Filtering of SAR Imagery Filtering of Single Polarization SAR Data Review of Multipolarization Speckle Filtering Algorithms PolSAR Speckle Filtering Scattering Model-Based PolSAR Speckle Filter Introduction to the Polarimetric Target Decomposition Concept Introduction Dichotomy of the Kennaugh Matrix K Eigenvector-Based Decompositions Model-Based Decompositions Coherent Decompositions The H/A/a Polarimetric Decomposition Theorem Introduction Pure Target Case Probabilistic Model for Random Media Scattering Roll Invariance Property Polarimetric Scattering a Parameter Polarimetric Scattering Entropy (H) Polarimetric Scattering Anisotropy (A) Three-Dimensional H/A/a Classification Space New Eigenvalue-Based Parameters Speckle Filtering Effects on H/A/a PolSAR Terrain and Land-Use Classification Introduction Maximum Likelihood Classifier Based on Complex Gaussian Distribution Complex Wishart Classifier for Multilook PolSAR Data Characteristics of Wishart Distance Measure Supervised Classification Using Wishart Distance Measure Unsupervised Classification Based on Scattering Mechanisms and Wishart Classifier Scattering Model-Based Unsupervised Classification Quantitative Comparison of Classification Capability: Fully PolSAR versus Dual- and Single-Polarization SAR Pol-InSAR Forest Mapping and Classification Introduction Pol-InSAR Scattering Descriptors Forest Mapping and Forest Classification Appendix Selected PolSAR Applications Polarimetric Signature Analysis of Manmade Structures Polarization Orientation Angle Estimation and Applications Ocean Surface Remote Sensing with PolSAR Ionosphere Faraday Rotation Estimation PolSAR Interferometry for Forest Height Estimation Nonstationary Natural Media Analysis from PolSAR Data Using a Two-Dimensional Time-Frequency Approach Appendix A: Eigen Characteristics of Hermitian Matrix Appendix B: PolSARpro Software: The Polariemtric SAR Data Processing and Educational Toolbox Index,2009,0,1800,298,16,47,90,130,125,139,172,197,195,207
a2fd9b9b59646626b5104f781b16ce239c20f03b,Preface. Summary. Nomenclature. 1. Introduction. 2. Radar system theory and interferometric processing. 3. Functional model for radar interferometry. 4. Stochastic model for radar interferometry. 5. Data analysis and interpretation for deformation monitoring. 6. Atmospheric monitoring. 7. Conclusions and recommendations. A. Comparison neutral delay GPS and InSAR. B. Structure function and power spectrum. Bibliography. About the Author. Index.,2001,0,1970,298,4,15,37,37,49,49,71,61,94,118
23eb33af4f0495edff01402ec8eb019e80717897,Foreword. Introduction. Signal Processing Fundamentals. Pulse Compression. Synthetic Aperture Concepts. SAR Signal Properties. The Range Doppler Algorithm. The Chirp Scaling Algorithm. The Omega-K Algorithm. The SPECAN Algorithm. Processing ScanSAR Data. Doppler Parameter Estimation. Comparison of Algorithms. References.,2005,0,1674,246,6,10,16,41,43,79,117,132,127,145
98ec941f07556008c3c3226fd755d7c42ea21b3e,"This detailed guide clearly and concisely presents radar digital signal processing for both practicing engineers and engineering students. This revised edition of Fundamentals of Radar Signal Processing provides in-depth coverage of radar digital signal processing (DSP) fundamentals and applications. It has been updated to include coverage of measurement accuracy and target tracking. Additionally, to make it more useful as a teaching tool, it now includes end-of-chapter problems and a solutions manual. New to this Edition: New chapter on Measurement Accuracy and Target Tracking Two new appendices--Important Digital Signal Processing Facts; Important Probability Density Function and Their Relationships Addition of 20 to 30 problems to ends of chapters Solutions manual",2005,0,1534,178,2,16,20,31,49,85,73,84,114,125
8308e7b39d1f556e4041b4630a41aa8435fe1a49,"MIMO (multiple-input multiple-output) radar refers to an architecture that employs multiple, spatially distributed transmitters and receivers. While, in a general sense, MIMO radar can be viewed as a type of multistatic radar, the separate nomenclature suggests unique features that set MIMO radar apart from the multistatic radar literature and that have a close relation to MIMO communications. This article reviews some recent work on MIMO radar with widely separated antennas. Widely separated transmit/receive antennas capture the spatial diversity of the target's radar cross section (RCS). Unique features of MIMO radar are explained and illustrated by examples. It is shown that with noncoherent processing, a target's RCS spatial variations can be exploited to obtain a diversity gain for target detection and for estimation of various parameters, such as angle of arrival and Doppler. For target location, it is shown that coherent processing can provide a resolution far exceeding that supported by the radar's waveform.",2008,44,1641,72,20,71,104,118,127,118,146,146,155,155
26f825b4ae30b08241df7031a900892761c0f9c0,"We have provided a review of some recent results on the emerging technology of MIMO radar with colocated antennas. We have shown that the waveform diversity offered by such a MIMO radar system enables significant superiority over its phased-array counterpart, including much improved parameter identifiability, direct applicability of adaptive techniques for parameter estimation, as well as superior flexibility of transmit beampattern designs. We hope that this overview of our recent results on the MIMO radar, along with the related results obtained by our colleagues, will stimulate the interest deserved by this topic in both academia and government agencies as well as industry.",2007,32,1722,39,1,27,56,98,103,112,104,145,161,163
aafb36d70d896fad4e68ffceafb5ad53197f22c3,"For 11 days in February 2000, the Shuttle Radar Topography Mission (SRTM) successfully recorded by interferometric synthetic aperture radar (InSAR) data of the entire land mass of the earth between 60°N and 57°S. The data acquired in C- and X-bands are processed into the first global digital elevation models (DEMs) at 1 arc sec resolution, by NASA-JPL and German aerospace center (DLR), respectively. From the perspective of the SRTM-X system, we give in this paper an overview of the mission and the DEM production, as well as an evaluation of the DEM product quality. Special emphasis is on challenges and peculiarities of the processing that arose from the unique design of the SRTM system, which has been the first single-pass interferometer in space.",2003,31,1542,118,6,29,50,58,86,78,107,90,86,91
b064bb54e7d367513067982b7d97cf0697418ec0,"Elevation data is vital to successful mission planning, operations and readiness. Traditional methods for producing elevation data are very expensive and time consuming; major cloud belts would never be completed with existing methods. The Shuttle Radar Topography Mission (SRTM) was selected in 1995 as the best means of supplying nearly global, accurate elevation data. The SRTM is an interferometric SAR system that flew during 11-22 February 2000 aboard NASA's Space Shuttle Endeavour and collected highly specialized data that will allow the generation of Digital Terrain Elevation Data Level 2(DTED® 2). The result of the SRTM will increase the United States Government's coverage of vital and detailed DTED® 2from less than 5% to 80% of the Earth's landmass. This paper describes the shuttle mission and its deliverables.",2001,97,1496,152,3,1,5,4,7,5,9,27,41,64
201dea99707c04e1b659932bb2d46c3e37a6435e,"A stylized compressed sensing radar is proposed in which the time-frequency plane is discretized into an N times N grid. Assuming the number of targets K is small (i.e., K Lt N2), then we can transmit a sufficiently ldquoincoherentrdquo pulse and employ the techniques of compressed sensing to reconstruct the target scene. A theoretical upper bound on the sparsity K is presented. Numerical simulations verify that even better performance can be achieved in practice. This novel-compressed sensing approach offers great potential for better resolution over classical radar.",2008,52,985,28,9,31,43,85,105,120,102,105,94,83
ba841b3c6236793f084f3e056c858abbd05fe6a7,"It has recently been shown that multiple-input multiple-output (MIMO) antenna systems have the potential to improve dramatically the performance of communication systems over single antenna systems. Unlike beamforming, which presumes a high correlation between signals either transmitted or received by an array, the MIMO concept exploits the independence between signals at the array elements. In conventional radar, target scintillations are regarded as a nuisance parameter that degrades radar performance. The novelty of MIMO radar is that it takes the opposite view; namely, it capitalizes on target scintillations to improve the radar's performance. We introduce the MIMO concept for radar. The MIMO radar system under consideration consists of a transmit array with widely-spaced elements such that each views a different aspect of the target. The array at the receiver is a conventional array used for direction finding (DF). The system performance analysis is carried out in terms of the Cramer-Rao bound of the mean-square error in estimating the target direction. It is shown that MIMO radar leads to significant performance improvement in DF accuracy.",2004,20,1283,45,3,7,30,41,71,67,108,93,75,90
9b6fa3a9362cc3380185a7933d7982b874527230,"This paper reviews architectonic subdivisions and connections of the orbital and medial prefrontal cortex (OMPFC) in rats, monkeys and humans. Cortico-cortical connections provide the basis for recognition of 'medial' and 'orbital' networks within the OMPFC. These networks also have distinct connections with structures in other parts of the brain. The orbital network receives sensory inputs from several modalities, including olfaction, taste, visceral afferents, somatic sensation and vision, which appear to be especially related to food or eating. In contrast, the medial network provides the major cortical output to visceromotor structures in the hypothalamus and brainstem. The two networks have distinct connections with areas of the striatum and mediodorsal thalamus. In particular, projections to the nucleus accumbens and the adjacent ventromedial caudate and putamen arise predominantly from the medial network. Both networks also have extensive connections with limbic structures. Based on these and other observations, the OMPFC appears to function as a sensory-visceromotor link, especially for eating. This linkage appears to be critical for the guidance of reward-related behavior and for setting of mood. Imaging and histological observations on human brains indicate that clinical depressive disorders are associated with specific functional and cellular changes in the OMPFC, including activity and volume changes, and specific changes in the number of glial cells.",2000,133,2452,143,6,18,51,61,67,72,81,98,128,152
aaea825be9afc25ee2d6d7f279030d0711fa656f,"Entangled quantum states are not separable, regardless of the spatial separation of their components. This is a manifestation of an aspect of quantum mechanics known as quantum non-locality. An important consequence of this is that the measurement of the state of one particle in a two-particle entangled state defines the state of the second particle instantaneously, whereas neither particle possesses its own well-defined state before the measurement. Experimental realizations of entanglement have hitherto been restricted to two-state quantum systems, involving, for example, the two orthogonal polarization states of photons. Here we demonstrate entanglement involving the spatial modes of the electromagnetic field carrying orbital angular momentum. As these modes can be used to define an infinitely dimensional discrete Hilbert space, this approach provides a practical route to entanglement that involves many orthogonal quantum states, rather than just two Multi-dimensional entangled states could be of considerable importance in the field of quantum information, enabling, for example, more efficient use of communication channels in quantum cryptography.",2001,26,2257,31,4,13,24,54,49,52,55,60,75,64
a5c8d98d25da1770770d58ea53f51d614e44339f,"A high-resolution deuterium profile is now available along the entire European Project for Ice Coring in Antarctica Dome C ice core, extending this climate record back to marine isotope stage 20.2, ∼800,000 years ago. Experiments performed with an atmospheric general circulation model including water isotopes support its temperature interpretation. We assessed the general correspondence between Dansgaard-Oeschger events and their smoothed Antarctic counterparts for this Dome C record, which reveals the presence of such features with similar amplitudes during previous glacial periods. We suggest that the interplay between obliquity and precession accounts for the variable intensity of interglacial periods in ice core records.",2007,43,1774,71,21,45,75,120,120,121,134,140,134,127
6a145d8e7158476d0930c679a8777872928426af,"We demonstrate the transfer of information encoded as orbital angular momentum (OAM) states of a light beam. The transmitter and receiver units are based on spatial light modulators, which prepare or measure a laser beam in one of eight pure OAM states. We show that the information encoded in this way is resistant to eavesdropping in the sense that any attempt to sample the beam away from its axis will be subject to an angular restriction and a lateral offset, both of which result in inherent uncertainty in the measurement. This gives an experimental insight into the effects of aperturing and misalignment of the beam on the OAM measurement and demonstrates the uncertainty relationship for OAM.",2004,16,1792,14,2,12,22,26,30,38,46,71,93,120
c4950fc9bb26369182bcd30a863782cc873d71f1,"We demonstrate experimentally an optical process in which the spin angular momentum carried by a circularly polarized light beam is converted into orbital angular momentum, leading to the generation of helical modes with a wave-front helicity controlled by the input polarization. This phenomenon requires the interaction of light with matter that is both optically inhomogeneous and anisotropic. The underlying physics is also associated with the so-called Pancharatnam-Berry geometrical phases involved in any inhomogeneous transformation of the optical polarization.",2006,73,1319,18,1,10,14,21,26,36,47,57,92,110
74569b70f1d283bc43e07f3a078250677c89a5b6,"An electron in a solid, that is, bound to or nearly localized on the specific atomic site, has three attributes: charge, spin, and orbital. The orbital represents the shape of the electron cloud in solid. In transition-metal oxides with anisotropic-shaped d-orbital electrons, the Coulomb interaction between the electrons (strong electron correlation effect) is of importance for understanding their metal-insulator transitions and properties such as high-temperature superconductivity and colossal magnetoresistance. The orbital degree of freedom occasionally plays an important role in these phenomena, and its correlation and/or order-disorder transition causes a variety of phenomena through strong coupling with charge, spin, and lattice dynamics. An overview is given here on this ""orbital physics,"" which will be a key concept for the science and technology of correlated electrons.",2000,60,1553,7,6,26,54,65,61,82,70,66,69,53
c13e0d603a39430565ed7cb94ab5add3da5b280a,"This graduate-level text presents the first comprehensive overview of modern chemical valency and bonding theory, written by internationally recognized experts in the field. The authors build on the foundation of Lewisand Pauling-like localized structural and hybridization concepts to present a book that is directly based on current ab initio computational technology. The presentation is highly visual and intuitive throughout, being based on the recognizable and transferable graphical forms of natural bond orbitals (NBOs) and their spatial overlaps in the molecular environment. The book shows applications to a broad range of molecular and supramolecular species of organic, inorganic, and bioorganic interest. Hundreds of orbital illustrations help to convey the essence of modern NBO concepts in a facile manner for those with no extensive background in the mathematical machinery of the Schrödinger equation. This book will appeal to those studying chemical bonding in relation to chemistry, chemical engineering, biochemistry, and physics.",2005,1,1353,58,1,21,32,45,40,44,57,76,126,141
ddf1415e591f9637cc53dec22f6d4097ba05efc4,"We present a method to efficiently sort orbital angular momentum (OAM) states of light using two static optical elements. The optical elements perform a Cartesian to log-polar coordinate transformation, converting the helically phased light beam corresponding to OAM states into a beam with a transverse phase gradient. A subsequent lens then focuses each input OAM state to a different lateral position. We demonstrate the concept experimentally by using two spatial light modulators to create the desired optical elements, applying it to the separation of eleven OAM states.",2010,0,682,12,3,23,37,45,48,39,80,68,95,92
3d28ee266ac532ca0177a11b69f0bab556e8e4b8,"Recent discoveries concerning rotating (helical) phase fronts and orbital angular momentum (OAM) of laser beams are applied to radio frequencies and comprehensive simulations of a radio OAM system are performed. We find that with the use of vector field-sensing electric and magnetic triaxial antennas, it is possible to unambiguously estimate the OAM in radio beams by local measurements at a single point, assuming ideal (noiseless) conditions and that the beam axis is known. Furthermore, we show that conventional antenna pattern optimization methods can be applied to OAM-generating circular arrays to enhance their directivity.",2010,29,523,34,1,3,9,13,30,26,55,68,87,97
0dcaea1e332d723c98595308c3e6b79260794610,"For extrasolar planets discovered using the radial velocity method, the spectral characterization of the host star leads to a mass estimate of the star and subsequently of the orbiting planet. If the orbital velocity of the planet could be determined, the masses of both star and planet could be calculated using Newton’s law of gravity, just as in the case of stellar double-line eclipsing binaries. Here we report high-dispersion ground-based spectroscopy of a transit of the extrasolar planet HD 209458b. We see a significant wavelength shift in absorption lines from carbon monoxide in the planet’s atmosphere, which we conclude arises from a change in the radial component of the planet’s orbital velocity. The masses of the star and planet are 1.00 ± 0.22MSun and 0.64 ± 0.09MJup respectively. A blueshift of the carbon monoxide signal of approximately 2 km s−1 with respect to the systemic velocity of the host star suggests the presence of a strong wind flowing from the irradiated dayside to the non-irradiated nightside of the planet within the 0.01–0.1 mbar atmospheric pressure range probed by these observations. The strength of the carbon monoxide signal suggests a carbon monoxide mixing ratio of (1–3) × 10−3 in this planet’s upper atmosphere.",2010,26,443,41,10,28,23,33,39,32,37,45,46,50
02640f28ab5c2fe5a883c855fd0bc77505b48a00,"Planetary formation theories suggest that the giant planets formed on circular and coplanar orbits. The eccentricities of Jupiter, Saturn and Uranus, however, reach values of 6 per cent, 9 per cent and 8 per cent, respectively. In addition, the inclinations of the orbital planes of Saturn, Uranus and Neptune take maximum values of ∼2 degrees with respect to the mean orbital plane of Jupiter. Existing models for the excitation of the eccentricity of extrasolar giant planets have not been successfully applied to the Solar System. Here we show that a planetary system with initial quasi-circular, coplanar orbits would have evolved to the current orbital configuration, provided that Jupiter and Saturn crossed their 1:2 orbital resonance. We show that this resonance crossing could have occurred as the giant planets migrated owing to their interaction with a disk of planetesimals. Our model reproduces all the important characteristics of the giant planets' orbits, namely their final semimajor axes, eccentricities and mutual inclinations.",2005,59,1099,103,16,30,44,46,82,61,80,66,64,96
68d9db61afa6f2e179b162e8929946d938a5bc8a,"All forms of waves can contain phase singularities. In the case of optical waves, a light beam with a phase singularity carries orbital angular momentum, and such beams have found a range of applications in optical manipulation, quantum information and astronomy. Here we report the generation of an electron beam with a phase singularity propagating in free space, which we achieve by passing a plane electron wave through a spiral phase plate constructed naturally from a stack of graphite thin films. The interference pattern between the final beam and a plane electron wave in a transmission electron microscope shows the ‘Y’-like defect pattern characteristic of a beam carrying a phase singularity with a topological charge equal to one. This fundamentally new electron degree of freedom could find application in a number of research areas, as is the case for polarized electron beams.",2010,28,455,7,4,13,25,26,41,35,33,54,56,64
b57fe8cdc49f84ee230c4696aa81d8aa3e2a5ba5,"Entanglement in a Twist The strong correlations observed in quantum mechanically entangled particles, such as photons, offer potential for secure communication and quantum information processing. Leach et al. (p. 662) now show such strong quantum correlations between the complementary variables—angular position and orbital angular momentum—of two photons created during the parametric down-conversion process in a nonlinear crystal. This demonstration of entanglement in an angular basis establishes that angles are genuine quantum observables and can therefore be considered a resource for quantum information processing, capable of secure, high-dimension, key distribution. Strong quantum correlations are induced between the angular position and angular momentum of two photons. Entanglement of the properties of two separated particles constitutes a fundamental signature of quantum mechanics and is a key resource for quantum information science. We demonstrate strong Einstein, Podolsky, and Rosen correlations between the angular position and orbital angular momentum of two photons created by the nonlinear optical process of spontaneous parametric down-conversion. The discrete nature of orbital angular momentum and the continuous but periodic nature of angular position give rise to a special sort of entanglement between these two variables. The resulting correlations are found to be an order of magnitude stronger than those allowed by the uncertainty principle for independent (nonentangled) particles. Our results suggest that angular position and orbital angular momentum may find important applications in quantum information science.",2010,42,414,3,4,24,30,26,38,33,38,27,52,55
768980f65528c8bad41bc6cdf0d3b0eef8934d65,"The occupation of d orbitals controls the magnitude and anisotropy of the inter-atomic electron transfer in transition-metal oxides and hence exerts a key influence on their chemical bonding and physical properties. Atomic-scale modulations of the orbital occupation at surfaces and interfaces are believed to be responsible for massive variations of the magnetic and transport properties, but could not thus far be probed in a quantitative manner. Here we show that it is possible to derive quantitative, spatially resolved orbital polarization profiles from soft-X-ray reflectivity data, without resorting to model calculations. We demonstrate that the method is sensitive enough to resolve differences of ~3% in the occupation of Ni e(g) orbitals in adjacent atomic layers of a LaNiO(3)-LaAlO(3) superlattice, in good agreement with ab initio electronic-structure calculations. The possibility to quantitatively correlate theory and experiment on the atomic scale opens up many new perspectives for orbital physics in transition-metal oxides.",2010,41,152,5,0,5,10,9,17,15,18,15,17,15
d1620666ba23d4bce8c3035a87d06f5277819cc3,"Measurement of the quantum-mechanical phase in quantum matter provides the most direct manifestation of the underlying abstract physics. We used resonant x-ray scattering to probe the relative phases of constituent atomic orbitals in an electronic wave function, which uncovers the unconventional Mott insulating state induced by relativistic spin-orbit coupling in the layered 5d transition metal oxide Sr2IrO4. A selection rule based on intra-atomic interference effects establishes a complex spin-orbital state represented by an effective total angular momentum = 1/2 quantum number, the phase of which can lead to a quantum topological state of matter.",2009,11,642,18,5,10,20,32,47,45,56,54,56,94
411be93d0ae3ff9fbf174bd4de4f11e3203b8a77,"In iron pnictides, we find that the moderate electron-phonon interaction due to the Fe-ion oscillation can induce the critical d-orbital fluctuations, without being prohibited by the Coulomb interaction. These fluctuations give rise to the strong pairing interaction for the s-wave superconducting (SC) state without sign reversal (s(++)-wave state), which is consistent with experimentally observed robustness of superconductivity against impurities. When the magnetic fluctuations due to Coulomb interaction are also strong, the SC state shows a smooth crossover from the s-wave state with sign reversal (s(+/-)-wave state) to the s(++)-wave state as impurity concentration increases.",2009,0,377,6,2,9,32,46,40,46,38,41,34,36
cf335ec147d76c16e49263d17c388814290a35fc,"This review provides a perspective on the use of orbital-dependent functionals, which is currently considered one of the most promising avenues in modern density-functional theory. The focus here is on four major themes: the motivation for orbital-dependent functionals in terms of limitations of semilocal functionals; the optimized effective potential as a rigorous approach to incorporating orbital-dependent functionals within the Kohn-Sham framework; the rationale behind and advantages and limitations of four popular classes of orbital-dependent functionals; and the use of orbital-dependent functionals for predicting excited-state properties. For each of these issues, both formal and practical aspects are assessed.",2008,527,734,8,25,50,38,68,56,64,72,71,61,45
c9d24e78b2bdc2ddfe89144e020846610cdfcefd,"ABSTRACT. We analyze 8 years of precise radial velocity measurements from the Keck Planet Search, characterizing the detection threshold, selection effects, and completeness of the survey. We first carry out a systematic search for planets, by assessing the false-alarm probability associated with Keplerian orbit fits to the data. This allows us to understand the detection threshold for each star in terms of the number and time baseline of the observations, and the underlying “noise” from measurement errors, intrinsic stellar jitter, or additional low-mass planets. We show that all planets with orbital periods P   20 m s-1 K > 20 m s - 1 , and eccentricities e ≲ 0.6 e ≲ 0.6 have been announced, and we summarize the candidates at lower amplitudes and longer orbital periods. For the remaining stars, we calculate upper limits on the velocity amplitude of a companion. For orbital periods less than the duration of the observations, these are typically ...",2008,91,611,154,22,38,56,37,51,43,46,47,49,47
7a725f13577e44f5f39e262ceebc55d0316e6853,"For an isolated quantum particle, such as an electron, the orbital (L) and spin (S) magnetic moments can change provided that the total angular momentum of the particle is conserved. In condensed matter, an efficient transfer between L and S can occur owing to the spin–orbit interaction, which originates in the relativistic motion of electrons. Disentangling the absolute contributions of the orbital and spin angular momenta is challenging, however, as any transfer between the two occurs on femtosecond timescales. Here we investigate such phenomena by using ultrashort optical laser pulses to change the magnetization of a ferromagnetic film and then probe its dynamics with circularly polarized femtosecond X-ray pulses. Our measurements enable us to disentangle the spin and orbital components of the magnetic moment, revealing different dynamics for L and S. We highlight the important role played by the spin–orbit interaction in the ultrafast laser-induced demagnetization of ferromagnetic films, and show also that the magneto-crystalline anisotropy energy is an important quantity to consider in such processes. Our study provides insights into the dynamics in magnetic systems as well as perspectives for the ultrafast control of information in magnetic recording media.",2010,38,297,4,2,19,20,31,26,29,30,24,28,32
45524fd482e1e348a63c2d146a55a77d6ce36608,"The control of charge transport in an active electronic device depends intimately on the modulation of the internal charge density by an external node. For example, a field-effect transistor relies on the gated electrostatic modulation of the channel charge produced by changing the relative position of the conduction and valence bands with respect to the electrodes. In molecular-scale devices, a longstanding challenge has been to create a true three-terminal device that operates in this manner (that is, by modifying orbital energy). Here we report the observation of such a solid-state molecular device, in which transport current is directly modulated by an external gate voltage. Resonance-enhanced coupling to the nearest molecular orbital is revealed by electron tunnelling spectroscopy, demonstrating direct molecular orbital gating in an electronic device. Our findings demonstrate that true molecular transistors can be created, and so enhance the prospects for molecularly engineered electronic devices.",2009,35,585,8,3,29,65,55,56,74,63,51,45,49
0e15715debd0a700242264e06f84fd9e37ac86a3,"We show numerically that vector antenna arrays can generate radio beams that exhibit spin and orbital angular momentum characteristics similar to those of helical Laguerre-Gauss laser beams in paraxial optics. For low frequencies (< or = 1 GHz), digital techniques can be used to coherently measure the instantaneous, local field vectors and to manipulate them in software. This enables new types of experiments that go beyond what is possible in optics. It allows information-rich radio astronomy and paves the way for novel wireless communication concepts.",2007,59,698,31,2,6,9,7,12,17,17,45,44,78
af174b8b4484dd8657819d20baed7995de17bcdb,"We predict a new category of optical orbital angular momentum that is associated with the curl of polarization and a kind of vector field with radial-variant hybrid states of polarization that can carry such novel optical orbital angular momentum. We present a scheme for creating the desired vector fields. Optical trapping experiments validate that the vector fields, which have no additional phase vortex, exert torques to drive the orbital motion of the trapped isotropic microspheres.",2010,12,161,3,0,6,14,7,12,13,20,18,15,20
6e62526fba615f7e3d0f49711a41fd6047be4b5f,"The structure of the human orbital and medial prefrontal cortex (OMPFC) was investigated using five histological and immunohistochemical stains and was correlated with a previous analysis in macaque monkeys [Carmichael and Price ( 1994 ) J. Comp. Neurol. 346:366–402]. A cortical area was recognized if it was distinct with at least two stains and was found in similar locations in different brains. All of the areas recognized in the macaque OMPFC have counterparts in humans. Areas 11, 13, and 14 were subdivided into areas 11m, 11l, 13a, 13b, 13m, 13l, 14r, and 14c. Within area 10, the region corresponding to area 10m in monkeys was divided into 10m and 10r, and area 10o (orbital) was renamed area 10p (polar). Areas 47/12r, 47/12m, 47/12l, and 47/12s occupy the lateral orbital cortex, corresponding to monkey areas 12r, 12m, 12l, and 12o. The agranular insula (areas Iam, Iapm, Iai, and Ial) extends onto the caudal orbital surface and into the horizontal ramus of the lateral sulcus. The growth of the frontal pole in humans has pushed area 25 and area 32pl, which corresponds to the prelimbic area 32 in Brodmann's monkey brain map, caudal and ventral to the genu of the corpus callosum. Anterior cingulate areas 24a and 24b also extend ventral to the genu of the corpus callosum. Area 32ac, corresponding to the dorsal anterior cingulate area 32 in Brodmann's human brain map, is anterior and dorsal to the genu. The parallel organization of the OMPFC in monkeys and humans allows experimental data from monkeys to be applied to studies of the human cortex. J. Comp. Neurol. 460:425–449, 2003. © 2003 Wiley‐Liss, Inc.",2003,76,858,62,9,9,31,34,47,42,58,52,65,51
6479c0e44ab143679d2337e9b726d6196d8dfa0b,"Geochemical models for Mars predict carbonate formation during aqueous alteration. Carbonate-bearing rocks had not previously been detected on Mars' surface, but Mars Reconnaissance Orbiter mapping reveals a regional rock layer with near-infrared spectral characteristics that are consistent with the presence of magnesium carbonate in the Nili Fossae region. The carbonate is closely associated with both phyllosilicate-bearing and olivine-rich rock units and probably formed during the Noachian or early Hesperian era from the alteration of olivine by either hydrothermal fluids or near-surface water. The presence of carbonate as well as accompanying clays suggests that waters were neutral to alkaline at the time of its formation and that acidic weathering, proposed to be characteristic of Hesperian Mars, did not destroy these carbonates and thus did not dominate all aqueous environments.",2008,89,516,18,2,31,49,39,49,56,39,38,29,36
8b75af5b595e3402c77aa438f926ad3dba9fde17,"Orbital mechanics is a cornerstone subject for aerospace engineering students. Maintaining the focus of the first edition, the author provides the foundation needed to understand the subject and proceed to advanced topics. Starting with the solution of the two-body problem and formulas for the different kinds of orbits, the text moves on to Kepler's equations, orbits in three dimensions, orbital elements from observations, orbital maneuvers, orbital rendezvous and interplanetary missions. This is followed by an introduction to spacecraft dynamics and a final chapter on basic rocket dynamics. The author's teach-by-example approach emphasizes the analytical procedures and computer-implemented algorithms required by today's students. There are a large number of worked examples, illustrations, end of chapter exercises (with answers) as well as many MATLAB[registered] programs for use in homework and projects. The text can be used for one and two semester courses in space mechanics. Features: a new section on numerical integration methods applicable to space mechanics problems; a more centralized and improved discussion of coordinate systems and Euler angle sequences; an expanded development of relative motion in orbit; a new section on quaternions; new worked-out examples, illustrations and homework problems; new algorithms, MATLAB[registered] scripts and simulations; instructor's manual and lecture slides available online; and included online testing and assessment component helps students assess their knowledge of the topics.",2005,0,745,81,1,2,6,5,19,19,31,50,54,71
56677386dc3d3ecd1f51a292810a648bc68da1db,"The theoretical need to study the properties of the Fe-based high-Tc superconductors using reliable manybody techniques has highlighted the importance of determining what is the minimum number of orbital degrees of freedom that will capture the physics of these materials. While the shape of the Fermi surface FS obtained with the local-density approximation LDA can be reproduced by a two-orbital model, it has been argued that the bands that cross the chemical potential result from the strong hybridization of three of the Fe 3d orbitals. For this reason, a three orbital Hamiltonian for LaOFeAs obtained with the Slater-Koster formalism by considering the hybridization of the As p orbitals with the Fe dxz, dyz, and dxy orbitals is discussed here. This model reproduces qualitatively the FS shape and orbital composition obtained by LDA calculations for undoped LaOFeAs when four electrons per Fe are considered. Within a mean-field approximation, its magnetic and orbital properties in the undoped case are here described for intermediate values of J/U. Increasing the Coulomb repulsion U at zero temperature, four different regimes are obtained: 1 paramagnetic, 2 magnetic ,0 spin order, 3 the same ,0 spin order but now including orbital order, and finally 4 a magneticmore » and orbital ordered insulator. The spin-singlet pairing operators allowed by the lattice and orbital symmetries are also constructed. It is found that for pairs of electrons involving up to diagonal nearest-neighbors sites, the only fully gapped and purely intraband spin-singlet pairing operator is given by k= fkdk,, d k,, with fk=1 or cos kx cos ky which would arise only if the electrons in all different orbitals couple with equal strength to the source of pairing.« less",2009,2,123,4,1,5,8,12,17,12,17,11,9,10
9b6fa3a9362cc3380185a7933d7982b874527230,"This paper reviews architectonic subdivisions and connections of the orbital and medial prefrontal cortex (OMPFC) in rats, monkeys and humans. Cortico-cortical connections provide the basis for recognition of 'medial' and 'orbital' networks within the OMPFC. These networks also have distinct connections with structures in other parts of the brain. The orbital network receives sensory inputs from several modalities, including olfaction, taste, visceral afferents, somatic sensation and vision, which appear to be especially related to food or eating. In contrast, the medial network provides the major cortical output to visceromotor structures in the hypothalamus and brainstem. The two networks have distinct connections with areas of the striatum and mediodorsal thalamus. In particular, projections to the nucleus accumbens and the adjacent ventromedial caudate and putamen arise predominantly from the medial network. Both networks also have extensive connections with limbic structures. Based on these and other observations, the OMPFC appears to function as a sensory-visceromotor link, especially for eating. This linkage appears to be critical for the guidance of reward-related behavior and for setting of mood. Imaging and histological observations on human brains indicate that clinical depressive disorders are associated with specific functional and cellular changes in the OMPFC, including activity and volume changes, and specific changes in the number of glial cells.",2000,133,2452,143,6,18,51,61,67,72,81,98,128,152
aaea825be9afc25ee2d6d7f279030d0711fa656f,"Entangled quantum states are not separable, regardless of the spatial separation of their components. This is a manifestation of an aspect of quantum mechanics known as quantum non-locality. An important consequence of this is that the measurement of the state of one particle in a two-particle entangled state defines the state of the second particle instantaneously, whereas neither particle possesses its own well-defined state before the measurement. Experimental realizations of entanglement have hitherto been restricted to two-state quantum systems, involving, for example, the two orthogonal polarization states of photons. Here we demonstrate entanglement involving the spatial modes of the electromagnetic field carrying orbital angular momentum. As these modes can be used to define an infinitely dimensional discrete Hilbert space, this approach provides a practical route to entanglement that involves many orthogonal quantum states, rather than just two Multi-dimensional entangled states could be of considerable importance in the field of quantum information, enabling, for example, more efficient use of communication channels in quantum cryptography.",2001,26,2257,31,4,13,24,54,49,52,55,60,75,64
a5c8d98d25da1770770d58ea53f51d614e44339f,"A high-resolution deuterium profile is now available along the entire European Project for Ice Coring in Antarctica Dome C ice core, extending this climate record back to marine isotope stage 20.2, ∼800,000 years ago. Experiments performed with an atmospheric general circulation model including water isotopes support its temperature interpretation. We assessed the general correspondence between Dansgaard-Oeschger events and their smoothed Antarctic counterparts for this Dome C record, which reveals the presence of such features with similar amplitudes during previous glacial periods. We suggest that the interplay between obliquity and precession accounts for the variable intensity of interglacial periods in ice core records.",2007,43,1774,71,21,45,75,120,120,121,134,140,134,127
6a145d8e7158476d0930c679a8777872928426af,"We demonstrate the transfer of information encoded as orbital angular momentum (OAM) states of a light beam. The transmitter and receiver units are based on spatial light modulators, which prepare or measure a laser beam in one of eight pure OAM states. We show that the information encoded in this way is resistant to eavesdropping in the sense that any attempt to sample the beam away from its axis will be subject to an angular restriction and a lateral offset, both of which result in inherent uncertainty in the measurement. This gives an experimental insight into the effects of aperturing and misalignment of the beam on the OAM measurement and demonstrates the uncertainty relationship for OAM.",2004,16,1792,14,2,12,22,26,30,38,46,71,93,120
c4950fc9bb26369182bcd30a863782cc873d71f1,"We demonstrate experimentally an optical process in which the spin angular momentum carried by a circularly polarized light beam is converted into orbital angular momentum, leading to the generation of helical modes with a wave-front helicity controlled by the input polarization. This phenomenon requires the interaction of light with matter that is both optically inhomogeneous and anisotropic. The underlying physics is also associated with the so-called Pancharatnam-Berry geometrical phases involved in any inhomogeneous transformation of the optical polarization.",2006,73,1319,18,1,10,14,21,26,36,47,57,92,110
74569b70f1d283bc43e07f3a078250677c89a5b6,"An electron in a solid, that is, bound to or nearly localized on the specific atomic site, has three attributes: charge, spin, and orbital. The orbital represents the shape of the electron cloud in solid. In transition-metal oxides with anisotropic-shaped d-orbital electrons, the Coulomb interaction between the electrons (strong electron correlation effect) is of importance for understanding their metal-insulator transitions and properties such as high-temperature superconductivity and colossal magnetoresistance. The orbital degree of freedom occasionally plays an important role in these phenomena, and its correlation and/or order-disorder transition causes a variety of phenomena through strong coupling with charge, spin, and lattice dynamics. An overview is given here on this ""orbital physics,"" which will be a key concept for the science and technology of correlated electrons.",2000,60,1553,7,6,26,54,65,61,82,70,66,69,53
c13e0d603a39430565ed7cb94ab5add3da5b280a,"This graduate-level text presents the first comprehensive overview of modern chemical valency and bonding theory, written by internationally recognized experts in the field. The authors build on the foundation of Lewisand Pauling-like localized structural and hybridization concepts to present a book that is directly based on current ab initio computational technology. The presentation is highly visual and intuitive throughout, being based on the recognizable and transferable graphical forms of natural bond orbitals (NBOs) and their spatial overlaps in the molecular environment. The book shows applications to a broad range of molecular and supramolecular species of organic, inorganic, and bioorganic interest. Hundreds of orbital illustrations help to convey the essence of modern NBO concepts in a facile manner for those with no extensive background in the mathematical machinery of the Schrödinger equation. This book will appeal to those studying chemical bonding in relation to chemistry, chemical engineering, biochemistry, and physics.",2005,1,1353,58,1,21,32,45,40,44,57,76,126,141
ddf1415e591f9637cc53dec22f6d4097ba05efc4,"We present a method to efficiently sort orbital angular momentum (OAM) states of light using two static optical elements. The optical elements perform a Cartesian to log-polar coordinate transformation, converting the helically phased light beam corresponding to OAM states into a beam with a transverse phase gradient. A subsequent lens then focuses each input OAM state to a different lateral position. We demonstrate the concept experimentally by using two spatial light modulators to create the desired optical elements, applying it to the separation of eleven OAM states.",2010,0,682,12,3,23,37,45,48,39,80,68,95,92
3d28ee266ac532ca0177a11b69f0bab556e8e4b8,"Recent discoveries concerning rotating (helical) phase fronts and orbital angular momentum (OAM) of laser beams are applied to radio frequencies and comprehensive simulations of a radio OAM system are performed. We find that with the use of vector field-sensing electric and magnetic triaxial antennas, it is possible to unambiguously estimate the OAM in radio beams by local measurements at a single point, assuming ideal (noiseless) conditions and that the beam axis is known. Furthermore, we show that conventional antenna pattern optimization methods can be applied to OAM-generating circular arrays to enhance their directivity.",2010,29,523,34,1,3,9,13,30,26,55,68,87,97
0dcaea1e332d723c98595308c3e6b79260794610,"For extrasolar planets discovered using the radial velocity method, the spectral characterization of the host star leads to a mass estimate of the star and subsequently of the orbiting planet. If the orbital velocity of the planet could be determined, the masses of both star and planet could be calculated using Newton’s law of gravity, just as in the case of stellar double-line eclipsing binaries. Here we report high-dispersion ground-based spectroscopy of a transit of the extrasolar planet HD 209458b. We see a significant wavelength shift in absorption lines from carbon monoxide in the planet’s atmosphere, which we conclude arises from a change in the radial component of the planet’s orbital velocity. The masses of the star and planet are 1.00 ± 0.22MSun and 0.64 ± 0.09MJup respectively. A blueshift of the carbon monoxide signal of approximately 2 km s−1 with respect to the systemic velocity of the host star suggests the presence of a strong wind flowing from the irradiated dayside to the non-irradiated nightside of the planet within the 0.01–0.1 mbar atmospheric pressure range probed by these observations. The strength of the carbon monoxide signal suggests a carbon monoxide mixing ratio of (1–3) × 10−3 in this planet’s upper atmosphere.",2010,26,443,41,10,28,23,33,39,32,37,45,46,50
02640f28ab5c2fe5a883c855fd0bc77505b48a00,"Planetary formation theories suggest that the giant planets formed on circular and coplanar orbits. The eccentricities of Jupiter, Saturn and Uranus, however, reach values of 6 per cent, 9 per cent and 8 per cent, respectively. In addition, the inclinations of the orbital planes of Saturn, Uranus and Neptune take maximum values of ∼2 degrees with respect to the mean orbital plane of Jupiter. Existing models for the excitation of the eccentricity of extrasolar giant planets have not been successfully applied to the Solar System. Here we show that a planetary system with initial quasi-circular, coplanar orbits would have evolved to the current orbital configuration, provided that Jupiter and Saturn crossed their 1:2 orbital resonance. We show that this resonance crossing could have occurred as the giant planets migrated owing to their interaction with a disk of planetesimals. Our model reproduces all the important characteristics of the giant planets' orbits, namely their final semimajor axes, eccentricities and mutual inclinations.",2005,59,1099,103,16,30,44,46,82,61,80,66,64,96
68d9db61afa6f2e179b162e8929946d938a5bc8a,"All forms of waves can contain phase singularities. In the case of optical waves, a light beam with a phase singularity carries orbital angular momentum, and such beams have found a range of applications in optical manipulation, quantum information and astronomy. Here we report the generation of an electron beam with a phase singularity propagating in free space, which we achieve by passing a plane electron wave through a spiral phase plate constructed naturally from a stack of graphite thin films. The interference pattern between the final beam and a plane electron wave in a transmission electron microscope shows the ‘Y’-like defect pattern characteristic of a beam carrying a phase singularity with a topological charge equal to one. This fundamentally new electron degree of freedom could find application in a number of research areas, as is the case for polarized electron beams.",2010,28,455,7,4,13,25,26,41,35,33,54,56,64
b57fe8cdc49f84ee230c4696aa81d8aa3e2a5ba5,"Entanglement in a Twist The strong correlations observed in quantum mechanically entangled particles, such as photons, offer potential for secure communication and quantum information processing. Leach et al. (p. 662) now show such strong quantum correlations between the complementary variables—angular position and orbital angular momentum—of two photons created during the parametric down-conversion process in a nonlinear crystal. This demonstration of entanglement in an angular basis establishes that angles are genuine quantum observables and can therefore be considered a resource for quantum information processing, capable of secure, high-dimension, key distribution. Strong quantum correlations are induced between the angular position and angular momentum of two photons. Entanglement of the properties of two separated particles constitutes a fundamental signature of quantum mechanics and is a key resource for quantum information science. We demonstrate strong Einstein, Podolsky, and Rosen correlations between the angular position and orbital angular momentum of two photons created by the nonlinear optical process of spontaneous parametric down-conversion. The discrete nature of orbital angular momentum and the continuous but periodic nature of angular position give rise to a special sort of entanglement between these two variables. The resulting correlations are found to be an order of magnitude stronger than those allowed by the uncertainty principle for independent (nonentangled) particles. Our results suggest that angular position and orbital angular momentum may find important applications in quantum information science.",2010,42,414,3,4,24,30,26,38,33,38,27,52,55
768980f65528c8bad41bc6cdf0d3b0eef8934d65,"The occupation of d orbitals controls the magnitude and anisotropy of the inter-atomic electron transfer in transition-metal oxides and hence exerts a key influence on their chemical bonding and physical properties. Atomic-scale modulations of the orbital occupation at surfaces and interfaces are believed to be responsible for massive variations of the magnetic and transport properties, but could not thus far be probed in a quantitative manner. Here we show that it is possible to derive quantitative, spatially resolved orbital polarization profiles from soft-X-ray reflectivity data, without resorting to model calculations. We demonstrate that the method is sensitive enough to resolve differences of ~3% in the occupation of Ni e(g) orbitals in adjacent atomic layers of a LaNiO(3)-LaAlO(3) superlattice, in good agreement with ab initio electronic-structure calculations. The possibility to quantitatively correlate theory and experiment on the atomic scale opens up many new perspectives for orbital physics in transition-metal oxides.",2010,41,152,5,0,5,10,9,17,15,18,15,17,15
d1620666ba23d4bce8c3035a87d06f5277819cc3,"Measurement of the quantum-mechanical phase in quantum matter provides the most direct manifestation of the underlying abstract physics. We used resonant x-ray scattering to probe the relative phases of constituent atomic orbitals in an electronic wave function, which uncovers the unconventional Mott insulating state induced by relativistic spin-orbit coupling in the layered 5d transition metal oxide Sr2IrO4. A selection rule based on intra-atomic interference effects establishes a complex spin-orbital state represented by an effective total angular momentum = 1/2 quantum number, the phase of which can lead to a quantum topological state of matter.",2009,11,642,18,5,10,20,32,47,45,56,54,56,94
411be93d0ae3ff9fbf174bd4de4f11e3203b8a77,"In iron pnictides, we find that the moderate electron-phonon interaction due to the Fe-ion oscillation can induce the critical d-orbital fluctuations, without being prohibited by the Coulomb interaction. These fluctuations give rise to the strong pairing interaction for the s-wave superconducting (SC) state without sign reversal (s(++)-wave state), which is consistent with experimentally observed robustness of superconductivity against impurities. When the magnetic fluctuations due to Coulomb interaction are also strong, the SC state shows a smooth crossover from the s-wave state with sign reversal (s(+/-)-wave state) to the s(++)-wave state as impurity concentration increases.",2009,0,377,6,2,9,32,46,40,46,38,41,34,36
cf335ec147d76c16e49263d17c388814290a35fc,"This review provides a perspective on the use of orbital-dependent functionals, which is currently considered one of the most promising avenues in modern density-functional theory. The focus here is on four major themes: the motivation for orbital-dependent functionals in terms of limitations of semilocal functionals; the optimized effective potential as a rigorous approach to incorporating orbital-dependent functionals within the Kohn-Sham framework; the rationale behind and advantages and limitations of four popular classes of orbital-dependent functionals; and the use of orbital-dependent functionals for predicting excited-state properties. For each of these issues, both formal and practical aspects are assessed.",2008,527,734,8,25,50,38,68,56,64,72,71,61,45
c9d24e78b2bdc2ddfe89144e020846610cdfcefd,"ABSTRACT. We analyze 8 years of precise radial velocity measurements from the Keck Planet Search, characterizing the detection threshold, selection effects, and completeness of the survey. We first carry out a systematic search for planets, by assessing the false-alarm probability associated with Keplerian orbit fits to the data. This allows us to understand the detection threshold for each star in terms of the number and time baseline of the observations, and the underlying “noise” from measurement errors, intrinsic stellar jitter, or additional low-mass planets. We show that all planets with orbital periods P   20 m s-1 K > 20 m s - 1 , and eccentricities e ≲ 0.6 e ≲ 0.6 have been announced, and we summarize the candidates at lower amplitudes and longer orbital periods. For the remaining stars, we calculate upper limits on the velocity amplitude of a companion. For orbital periods less than the duration of the observations, these are typically ...",2008,91,611,154,22,38,56,37,51,43,46,47,49,47
7a725f13577e44f5f39e262ceebc55d0316e6853,"For an isolated quantum particle, such as an electron, the orbital (L) and spin (S) magnetic moments can change provided that the total angular momentum of the particle is conserved. In condensed matter, an efficient transfer between L and S can occur owing to the spin–orbit interaction, which originates in the relativistic motion of electrons. Disentangling the absolute contributions of the orbital and spin angular momenta is challenging, however, as any transfer between the two occurs on femtosecond timescales. Here we investigate such phenomena by using ultrashort optical laser pulses to change the magnetization of a ferromagnetic film and then probe its dynamics with circularly polarized femtosecond X-ray pulses. Our measurements enable us to disentangle the spin and orbital components of the magnetic moment, revealing different dynamics for L and S. We highlight the important role played by the spin–orbit interaction in the ultrafast laser-induced demagnetization of ferromagnetic films, and show also that the magneto-crystalline anisotropy energy is an important quantity to consider in such processes. Our study provides insights into the dynamics in magnetic systems as well as perspectives for the ultrafast control of information in magnetic recording media.",2010,38,297,4,2,19,20,31,26,29,30,24,28,32
45524fd482e1e348a63c2d146a55a77d6ce36608,"The control of charge transport in an active electronic device depends intimately on the modulation of the internal charge density by an external node. For example, a field-effect transistor relies on the gated electrostatic modulation of the channel charge produced by changing the relative position of the conduction and valence bands with respect to the electrodes. In molecular-scale devices, a longstanding challenge has been to create a true three-terminal device that operates in this manner (that is, by modifying orbital energy). Here we report the observation of such a solid-state molecular device, in which transport current is directly modulated by an external gate voltage. Resonance-enhanced coupling to the nearest molecular orbital is revealed by electron tunnelling spectroscopy, demonstrating direct molecular orbital gating in an electronic device. Our findings demonstrate that true molecular transistors can be created, and so enhance the prospects for molecularly engineered electronic devices.",2009,35,585,8,3,29,65,55,56,74,63,51,45,49
0e15715debd0a700242264e06f84fd9e37ac86a3,"We show numerically that vector antenna arrays can generate radio beams that exhibit spin and orbital angular momentum characteristics similar to those of helical Laguerre-Gauss laser beams in paraxial optics. For low frequencies (< or = 1 GHz), digital techniques can be used to coherently measure the instantaneous, local field vectors and to manipulate them in software. This enables new types of experiments that go beyond what is possible in optics. It allows information-rich radio astronomy and paves the way for novel wireless communication concepts.",2007,59,698,31,2,6,9,7,12,17,17,45,44,78
af174b8b4484dd8657819d20baed7995de17bcdb,"We predict a new category of optical orbital angular momentum that is associated with the curl of polarization and a kind of vector field with radial-variant hybrid states of polarization that can carry such novel optical orbital angular momentum. We present a scheme for creating the desired vector fields. Optical trapping experiments validate that the vector fields, which have no additional phase vortex, exert torques to drive the orbital motion of the trapped isotropic microspheres.",2010,12,161,3,0,6,14,7,12,13,20,18,15,20
6e62526fba615f7e3d0f49711a41fd6047be4b5f,"The structure of the human orbital and medial prefrontal cortex (OMPFC) was investigated using five histological and immunohistochemical stains and was correlated with a previous analysis in macaque monkeys [Carmichael and Price ( 1994 ) J. Comp. Neurol. 346:366–402]. A cortical area was recognized if it was distinct with at least two stains and was found in similar locations in different brains. All of the areas recognized in the macaque OMPFC have counterparts in humans. Areas 11, 13, and 14 were subdivided into areas 11m, 11l, 13a, 13b, 13m, 13l, 14r, and 14c. Within area 10, the region corresponding to area 10m in monkeys was divided into 10m and 10r, and area 10o (orbital) was renamed area 10p (polar). Areas 47/12r, 47/12m, 47/12l, and 47/12s occupy the lateral orbital cortex, corresponding to monkey areas 12r, 12m, 12l, and 12o. The agranular insula (areas Iam, Iapm, Iai, and Ial) extends onto the caudal orbital surface and into the horizontal ramus of the lateral sulcus. The growth of the frontal pole in humans has pushed area 25 and area 32pl, which corresponds to the prelimbic area 32 in Brodmann's monkey brain map, caudal and ventral to the genu of the corpus callosum. Anterior cingulate areas 24a and 24b also extend ventral to the genu of the corpus callosum. Area 32ac, corresponding to the dorsal anterior cingulate area 32 in Brodmann's human brain map, is anterior and dorsal to the genu. The parallel organization of the OMPFC in monkeys and humans allows experimental data from monkeys to be applied to studies of the human cortex. J. Comp. Neurol. 460:425–449, 2003. © 2003 Wiley‐Liss, Inc.",2003,76,858,62,9,9,31,34,47,42,58,52,65,51
6479c0e44ab143679d2337e9b726d6196d8dfa0b,"Geochemical models for Mars predict carbonate formation during aqueous alteration. Carbonate-bearing rocks had not previously been detected on Mars' surface, but Mars Reconnaissance Orbiter mapping reveals a regional rock layer with near-infrared spectral characteristics that are consistent with the presence of magnesium carbonate in the Nili Fossae region. The carbonate is closely associated with both phyllosilicate-bearing and olivine-rich rock units and probably formed during the Noachian or early Hesperian era from the alteration of olivine by either hydrothermal fluids or near-surface water. The presence of carbonate as well as accompanying clays suggests that waters were neutral to alkaline at the time of its formation and that acidic weathering, proposed to be characteristic of Hesperian Mars, did not destroy these carbonates and thus did not dominate all aqueous environments.",2008,89,516,18,2,31,49,39,49,56,39,38,29,36
8b75af5b595e3402c77aa438f926ad3dba9fde17,"Orbital mechanics is a cornerstone subject for aerospace engineering students. Maintaining the focus of the first edition, the author provides the foundation needed to understand the subject and proceed to advanced topics. Starting with the solution of the two-body problem and formulas for the different kinds of orbits, the text moves on to Kepler's equations, orbits in three dimensions, orbital elements from observations, orbital maneuvers, orbital rendezvous and interplanetary missions. This is followed by an introduction to spacecraft dynamics and a final chapter on basic rocket dynamics. The author's teach-by-example approach emphasizes the analytical procedures and computer-implemented algorithms required by today's students. There are a large number of worked examples, illustrations, end of chapter exercises (with answers) as well as many MATLAB[registered] programs for use in homework and projects. The text can be used for one and two semester courses in space mechanics. Features: a new section on numerical integration methods applicable to space mechanics problems; a more centralized and improved discussion of coordinate systems and Euler angle sequences; an expanded development of relative motion in orbit; a new section on quaternions; new worked-out examples, illustrations and homework problems; new algorithms, MATLAB[registered] scripts and simulations; instructor's manual and lecture slides available online; and included online testing and assessment component helps students assess their knowledge of the topics.",2005,0,745,81,1,2,6,5,19,19,31,50,54,71
56677386dc3d3ecd1f51a292810a648bc68da1db,"The theoretical need to study the properties of the Fe-based high-Tc superconductors using reliable manybody techniques has highlighted the importance of determining what is the minimum number of orbital degrees of freedom that will capture the physics of these materials. While the shape of the Fermi surface FS obtained with the local-density approximation LDA can be reproduced by a two-orbital model, it has been argued that the bands that cross the chemical potential result from the strong hybridization of three of the Fe 3d orbitals. For this reason, a three orbital Hamiltonian for LaOFeAs obtained with the Slater-Koster formalism by considering the hybridization of the As p orbitals with the Fe dxz, dyz, and dxy orbitals is discussed here. This model reproduces qualitatively the FS shape and orbital composition obtained by LDA calculations for undoped LaOFeAs when four electrons per Fe are considered. Within a mean-field approximation, its magnetic and orbital properties in the undoped case are here described for intermediate values of J/U. Increasing the Coulomb repulsion U at zero temperature, four different regimes are obtained: 1 paramagnetic, 2 magnetic ,0 spin order, 3 the same ,0 spin order but now including orbital order, and finally 4 a magneticmore » and orbital ordered insulator. The spin-singlet pairing operators allowed by the lattice and orbital symmetries are also constructed. It is found that for pairs of electrons involving up to diagonal nearest-neighbors sites, the only fully gapped and purely intraband spin-singlet pairing operator is given by k= fkdk,, d k,, with fk=1 or cos kx cos ky which would arise only if the electrons in all different orbitals couple with equal strength to the source of pairing.« less",2009,2,123,4,1,5,8,12,17,12,17,11,9,10
9b6fa3a9362cc3380185a7933d7982b874527230,"This paper reviews architectonic subdivisions and connections of the orbital and medial prefrontal cortex (OMPFC) in rats, monkeys and humans. Cortico-cortical connections provide the basis for recognition of 'medial' and 'orbital' networks within the OMPFC. These networks also have distinct connections with structures in other parts of the brain. The orbital network receives sensory inputs from several modalities, including olfaction, taste, visceral afferents, somatic sensation and vision, which appear to be especially related to food or eating. In contrast, the medial network provides the major cortical output to visceromotor structures in the hypothalamus and brainstem. The two networks have distinct connections with areas of the striatum and mediodorsal thalamus. In particular, projections to the nucleus accumbens and the adjacent ventromedial caudate and putamen arise predominantly from the medial network. Both networks also have extensive connections with limbic structures. Based on these and other observations, the OMPFC appears to function as a sensory-visceromotor link, especially for eating. This linkage appears to be critical for the guidance of reward-related behavior and for setting of mood. Imaging and histological observations on human brains indicate that clinical depressive disorders are associated with specific functional and cellular changes in the OMPFC, including activity and volume changes, and specific changes in the number of glial cells.",2000,133,2452,143,6,18,51,61,67,72,81,98,128,152
aaea825be9afc25ee2d6d7f279030d0711fa656f,"Entangled quantum states are not separable, regardless of the spatial separation of their components. This is a manifestation of an aspect of quantum mechanics known as quantum non-locality. An important consequence of this is that the measurement of the state of one particle in a two-particle entangled state defines the state of the second particle instantaneously, whereas neither particle possesses its own well-defined state before the measurement. Experimental realizations of entanglement have hitherto been restricted to two-state quantum systems, involving, for example, the two orthogonal polarization states of photons. Here we demonstrate entanglement involving the spatial modes of the electromagnetic field carrying orbital angular momentum. As these modes can be used to define an infinitely dimensional discrete Hilbert space, this approach provides a practical route to entanglement that involves many orthogonal quantum states, rather than just two Multi-dimensional entangled states could be of considerable importance in the field of quantum information, enabling, for example, more efficient use of communication channels in quantum cryptography.",2001,26,2257,31,4,13,24,54,49,52,55,60,75,64
a5c8d98d25da1770770d58ea53f51d614e44339f,"A high-resolution deuterium profile is now available along the entire European Project for Ice Coring in Antarctica Dome C ice core, extending this climate record back to marine isotope stage 20.2, ∼800,000 years ago. Experiments performed with an atmospheric general circulation model including water isotopes support its temperature interpretation. We assessed the general correspondence between Dansgaard-Oeschger events and their smoothed Antarctic counterparts for this Dome C record, which reveals the presence of such features with similar amplitudes during previous glacial periods. We suggest that the interplay between obliquity and precession accounts for the variable intensity of interglacial periods in ice core records.",2007,43,1774,71,21,45,75,120,120,121,134,140,134,127
6a145d8e7158476d0930c679a8777872928426af,"We demonstrate the transfer of information encoded as orbital angular momentum (OAM) states of a light beam. The transmitter and receiver units are based on spatial light modulators, which prepare or measure a laser beam in one of eight pure OAM states. We show that the information encoded in this way is resistant to eavesdropping in the sense that any attempt to sample the beam away from its axis will be subject to an angular restriction and a lateral offset, both of which result in inherent uncertainty in the measurement. This gives an experimental insight into the effects of aperturing and misalignment of the beam on the OAM measurement and demonstrates the uncertainty relationship for OAM.",2004,16,1792,14,2,12,22,26,30,38,46,71,93,120
c4950fc9bb26369182bcd30a863782cc873d71f1,"We demonstrate experimentally an optical process in which the spin angular momentum carried by a circularly polarized light beam is converted into orbital angular momentum, leading to the generation of helical modes with a wave-front helicity controlled by the input polarization. This phenomenon requires the interaction of light with matter that is both optically inhomogeneous and anisotropic. The underlying physics is also associated with the so-called Pancharatnam-Berry geometrical phases involved in any inhomogeneous transformation of the optical polarization.",2006,73,1319,18,1,10,14,21,26,36,47,57,92,110
74569b70f1d283bc43e07f3a078250677c89a5b6,"An electron in a solid, that is, bound to or nearly localized on the specific atomic site, has three attributes: charge, spin, and orbital. The orbital represents the shape of the electron cloud in solid. In transition-metal oxides with anisotropic-shaped d-orbital electrons, the Coulomb interaction between the electrons (strong electron correlation effect) is of importance for understanding their metal-insulator transitions and properties such as high-temperature superconductivity and colossal magnetoresistance. The orbital degree of freedom occasionally plays an important role in these phenomena, and its correlation and/or order-disorder transition causes a variety of phenomena through strong coupling with charge, spin, and lattice dynamics. An overview is given here on this ""orbital physics,"" which will be a key concept for the science and technology of correlated electrons.",2000,60,1553,7,6,26,54,65,61,82,70,66,69,53
c13e0d603a39430565ed7cb94ab5add3da5b280a,"This graduate-level text presents the first comprehensive overview of modern chemical valency and bonding theory, written by internationally recognized experts in the field. The authors build on the foundation of Lewisand Pauling-like localized structural and hybridization concepts to present a book that is directly based on current ab initio computational technology. The presentation is highly visual and intuitive throughout, being based on the recognizable and transferable graphical forms of natural bond orbitals (NBOs) and their spatial overlaps in the molecular environment. The book shows applications to a broad range of molecular and supramolecular species of organic, inorganic, and bioorganic interest. Hundreds of orbital illustrations help to convey the essence of modern NBO concepts in a facile manner for those with no extensive background in the mathematical machinery of the Schrödinger equation. This book will appeal to those studying chemical bonding in relation to chemistry, chemical engineering, biochemistry, and physics.",2005,1,1353,58,1,21,32,45,40,44,57,76,126,141
ddf1415e591f9637cc53dec22f6d4097ba05efc4,"We present a method to efficiently sort orbital angular momentum (OAM) states of light using two static optical elements. The optical elements perform a Cartesian to log-polar coordinate transformation, converting the helically phased light beam corresponding to OAM states into a beam with a transverse phase gradient. A subsequent lens then focuses each input OAM state to a different lateral position. We demonstrate the concept experimentally by using two spatial light modulators to create the desired optical elements, applying it to the separation of eleven OAM states.",2010,0,682,12,3,23,37,45,48,39,80,68,95,92
3d28ee266ac532ca0177a11b69f0bab556e8e4b8,"Recent discoveries concerning rotating (helical) phase fronts and orbital angular momentum (OAM) of laser beams are applied to radio frequencies and comprehensive simulations of a radio OAM system are performed. We find that with the use of vector field-sensing electric and magnetic triaxial antennas, it is possible to unambiguously estimate the OAM in radio beams by local measurements at a single point, assuming ideal (noiseless) conditions and that the beam axis is known. Furthermore, we show that conventional antenna pattern optimization methods can be applied to OAM-generating circular arrays to enhance their directivity.",2010,29,523,34,1,3,9,13,30,26,55,68,87,97
0dcaea1e332d723c98595308c3e6b79260794610,"For extrasolar planets discovered using the radial velocity method, the spectral characterization of the host star leads to a mass estimate of the star and subsequently of the orbiting planet. If the orbital velocity of the planet could be determined, the masses of both star and planet could be calculated using Newton’s law of gravity, just as in the case of stellar double-line eclipsing binaries. Here we report high-dispersion ground-based spectroscopy of a transit of the extrasolar planet HD 209458b. We see a significant wavelength shift in absorption lines from carbon monoxide in the planet’s atmosphere, which we conclude arises from a change in the radial component of the planet’s orbital velocity. The masses of the star and planet are 1.00 ± 0.22MSun and 0.64 ± 0.09MJup respectively. A blueshift of the carbon monoxide signal of approximately 2 km s−1 with respect to the systemic velocity of the host star suggests the presence of a strong wind flowing from the irradiated dayside to the non-irradiated nightside of the planet within the 0.01–0.1 mbar atmospheric pressure range probed by these observations. The strength of the carbon monoxide signal suggests a carbon monoxide mixing ratio of (1–3) × 10−3 in this planet’s upper atmosphere.",2010,26,443,41,10,28,23,33,39,32,37,45,46,50
02640f28ab5c2fe5a883c855fd0bc77505b48a00,"Planetary formation theories suggest that the giant planets formed on circular and coplanar orbits. The eccentricities of Jupiter, Saturn and Uranus, however, reach values of 6 per cent, 9 per cent and 8 per cent, respectively. In addition, the inclinations of the orbital planes of Saturn, Uranus and Neptune take maximum values of ∼2 degrees with respect to the mean orbital plane of Jupiter. Existing models for the excitation of the eccentricity of extrasolar giant planets have not been successfully applied to the Solar System. Here we show that a planetary system with initial quasi-circular, coplanar orbits would have evolved to the current orbital configuration, provided that Jupiter and Saturn crossed their 1:2 orbital resonance. We show that this resonance crossing could have occurred as the giant planets migrated owing to their interaction with a disk of planetesimals. Our model reproduces all the important characteristics of the giant planets' orbits, namely their final semimajor axes, eccentricities and mutual inclinations.",2005,59,1099,103,16,30,44,46,82,61,80,66,64,96
68d9db61afa6f2e179b162e8929946d938a5bc8a,"All forms of waves can contain phase singularities. In the case of optical waves, a light beam with a phase singularity carries orbital angular momentum, and such beams have found a range of applications in optical manipulation, quantum information and astronomy. Here we report the generation of an electron beam with a phase singularity propagating in free space, which we achieve by passing a plane electron wave through a spiral phase plate constructed naturally from a stack of graphite thin films. The interference pattern between the final beam and a plane electron wave in a transmission electron microscope shows the ‘Y’-like defect pattern characteristic of a beam carrying a phase singularity with a topological charge equal to one. This fundamentally new electron degree of freedom could find application in a number of research areas, as is the case for polarized electron beams.",2010,28,455,7,4,13,25,26,41,35,33,54,56,64
b57fe8cdc49f84ee230c4696aa81d8aa3e2a5ba5,"Entanglement in a Twist The strong correlations observed in quantum mechanically entangled particles, such as photons, offer potential for secure communication and quantum information processing. Leach et al. (p. 662) now show such strong quantum correlations between the complementary variables—angular position and orbital angular momentum—of two photons created during the parametric down-conversion process in a nonlinear crystal. This demonstration of entanglement in an angular basis establishes that angles are genuine quantum observables and can therefore be considered a resource for quantum information processing, capable of secure, high-dimension, key distribution. Strong quantum correlations are induced between the angular position and angular momentum of two photons. Entanglement of the properties of two separated particles constitutes a fundamental signature of quantum mechanics and is a key resource for quantum information science. We demonstrate strong Einstein, Podolsky, and Rosen correlations between the angular position and orbital angular momentum of two photons created by the nonlinear optical process of spontaneous parametric down-conversion. The discrete nature of orbital angular momentum and the continuous but periodic nature of angular position give rise to a special sort of entanglement between these two variables. The resulting correlations are found to be an order of magnitude stronger than those allowed by the uncertainty principle for independent (nonentangled) particles. Our results suggest that angular position and orbital angular momentum may find important applications in quantum information science.",2010,42,414,3,4,24,30,26,38,33,38,27,52,55
768980f65528c8bad41bc6cdf0d3b0eef8934d65,"The occupation of d orbitals controls the magnitude and anisotropy of the inter-atomic electron transfer in transition-metal oxides and hence exerts a key influence on their chemical bonding and physical properties. Atomic-scale modulations of the orbital occupation at surfaces and interfaces are believed to be responsible for massive variations of the magnetic and transport properties, but could not thus far be probed in a quantitative manner. Here we show that it is possible to derive quantitative, spatially resolved orbital polarization profiles from soft-X-ray reflectivity data, without resorting to model calculations. We demonstrate that the method is sensitive enough to resolve differences of ~3% in the occupation of Ni e(g) orbitals in adjacent atomic layers of a LaNiO(3)-LaAlO(3) superlattice, in good agreement with ab initio electronic-structure calculations. The possibility to quantitatively correlate theory and experiment on the atomic scale opens up many new perspectives for orbital physics in transition-metal oxides.",2010,41,152,5,0,5,10,9,17,15,18,15,17,15
d1620666ba23d4bce8c3035a87d06f5277819cc3,"Measurement of the quantum-mechanical phase in quantum matter provides the most direct manifestation of the underlying abstract physics. We used resonant x-ray scattering to probe the relative phases of constituent atomic orbitals in an electronic wave function, which uncovers the unconventional Mott insulating state induced by relativistic spin-orbit coupling in the layered 5d transition metal oxide Sr2IrO4. A selection rule based on intra-atomic interference effects establishes a complex spin-orbital state represented by an effective total angular momentum = 1/2 quantum number, the phase of which can lead to a quantum topological state of matter.",2009,11,642,18,5,10,20,32,47,45,56,54,56,94
411be93d0ae3ff9fbf174bd4de4f11e3203b8a77,"In iron pnictides, we find that the moderate electron-phonon interaction due to the Fe-ion oscillation can induce the critical d-orbital fluctuations, without being prohibited by the Coulomb interaction. These fluctuations give rise to the strong pairing interaction for the s-wave superconducting (SC) state without sign reversal (s(++)-wave state), which is consistent with experimentally observed robustness of superconductivity against impurities. When the magnetic fluctuations due to Coulomb interaction are also strong, the SC state shows a smooth crossover from the s-wave state with sign reversal (s(+/-)-wave state) to the s(++)-wave state as impurity concentration increases.",2009,0,377,6,2,9,32,46,40,46,38,41,34,36
cf335ec147d76c16e49263d17c388814290a35fc,"This review provides a perspective on the use of orbital-dependent functionals, which is currently considered one of the most promising avenues in modern density-functional theory. The focus here is on four major themes: the motivation for orbital-dependent functionals in terms of limitations of semilocal functionals; the optimized effective potential as a rigorous approach to incorporating orbital-dependent functionals within the Kohn-Sham framework; the rationale behind and advantages and limitations of four popular classes of orbital-dependent functionals; and the use of orbital-dependent functionals for predicting excited-state properties. For each of these issues, both formal and practical aspects are assessed.",2008,527,734,8,25,50,38,68,56,64,72,71,61,45
c9d24e78b2bdc2ddfe89144e020846610cdfcefd,"ABSTRACT. We analyze 8 years of precise radial velocity measurements from the Keck Planet Search, characterizing the detection threshold, selection effects, and completeness of the survey. We first carry out a systematic search for planets, by assessing the false-alarm probability associated with Keplerian orbit fits to the data. This allows us to understand the detection threshold for each star in terms of the number and time baseline of the observations, and the underlying “noise” from measurement errors, intrinsic stellar jitter, or additional low-mass planets. We show that all planets with orbital periods P   20 m s-1 K > 20 m s - 1 , and eccentricities e ≲ 0.6 e ≲ 0.6 have been announced, and we summarize the candidates at lower amplitudes and longer orbital periods. For the remaining stars, we calculate upper limits on the velocity amplitude of a companion. For orbital periods less than the duration of the observations, these are typically ...",2008,91,611,154,22,38,56,37,51,43,46,47,49,47
7a725f13577e44f5f39e262ceebc55d0316e6853,"For an isolated quantum particle, such as an electron, the orbital (L) and spin (S) magnetic moments can change provided that the total angular momentum of the particle is conserved. In condensed matter, an efficient transfer between L and S can occur owing to the spin–orbit interaction, which originates in the relativistic motion of electrons. Disentangling the absolute contributions of the orbital and spin angular momenta is challenging, however, as any transfer between the two occurs on femtosecond timescales. Here we investigate such phenomena by using ultrashort optical laser pulses to change the magnetization of a ferromagnetic film and then probe its dynamics with circularly polarized femtosecond X-ray pulses. Our measurements enable us to disentangle the spin and orbital components of the magnetic moment, revealing different dynamics for L and S. We highlight the important role played by the spin–orbit interaction in the ultrafast laser-induced demagnetization of ferromagnetic films, and show also that the magneto-crystalline anisotropy energy is an important quantity to consider in such processes. Our study provides insights into the dynamics in magnetic systems as well as perspectives for the ultrafast control of information in magnetic recording media.",2010,38,297,4,2,19,20,31,26,29,30,24,28,32
45524fd482e1e348a63c2d146a55a77d6ce36608,"The control of charge transport in an active electronic device depends intimately on the modulation of the internal charge density by an external node. For example, a field-effect transistor relies on the gated electrostatic modulation of the channel charge produced by changing the relative position of the conduction and valence bands with respect to the electrodes. In molecular-scale devices, a longstanding challenge has been to create a true three-terminal device that operates in this manner (that is, by modifying orbital energy). Here we report the observation of such a solid-state molecular device, in which transport current is directly modulated by an external gate voltage. Resonance-enhanced coupling to the nearest molecular orbital is revealed by electron tunnelling spectroscopy, demonstrating direct molecular orbital gating in an electronic device. Our findings demonstrate that true molecular transistors can be created, and so enhance the prospects for molecularly engineered electronic devices.",2009,35,585,8,3,29,65,55,56,74,63,51,45,49
0e15715debd0a700242264e06f84fd9e37ac86a3,"We show numerically that vector antenna arrays can generate radio beams that exhibit spin and orbital angular momentum characteristics similar to those of helical Laguerre-Gauss laser beams in paraxial optics. For low frequencies (< or = 1 GHz), digital techniques can be used to coherently measure the instantaneous, local field vectors and to manipulate them in software. This enables new types of experiments that go beyond what is possible in optics. It allows information-rich radio astronomy and paves the way for novel wireless communication concepts.",2007,59,698,31,2,6,9,7,12,17,17,45,44,78
af174b8b4484dd8657819d20baed7995de17bcdb,"We predict a new category of optical orbital angular momentum that is associated with the curl of polarization and a kind of vector field with radial-variant hybrid states of polarization that can carry such novel optical orbital angular momentum. We present a scheme for creating the desired vector fields. Optical trapping experiments validate that the vector fields, which have no additional phase vortex, exert torques to drive the orbital motion of the trapped isotropic microspheres.",2010,12,161,3,0,6,14,7,12,13,20,18,15,20
6e62526fba615f7e3d0f49711a41fd6047be4b5f,"The structure of the human orbital and medial prefrontal cortex (OMPFC) was investigated using five histological and immunohistochemical stains and was correlated with a previous analysis in macaque monkeys [Carmichael and Price ( 1994 ) J. Comp. Neurol. 346:366–402]. A cortical area was recognized if it was distinct with at least two stains and was found in similar locations in different brains. All of the areas recognized in the macaque OMPFC have counterparts in humans. Areas 11, 13, and 14 were subdivided into areas 11m, 11l, 13a, 13b, 13m, 13l, 14r, and 14c. Within area 10, the region corresponding to area 10m in monkeys was divided into 10m and 10r, and area 10o (orbital) was renamed area 10p (polar). Areas 47/12r, 47/12m, 47/12l, and 47/12s occupy the lateral orbital cortex, corresponding to monkey areas 12r, 12m, 12l, and 12o. The agranular insula (areas Iam, Iapm, Iai, and Ial) extends onto the caudal orbital surface and into the horizontal ramus of the lateral sulcus. The growth of the frontal pole in humans has pushed area 25 and area 32pl, which corresponds to the prelimbic area 32 in Brodmann's monkey brain map, caudal and ventral to the genu of the corpus callosum. Anterior cingulate areas 24a and 24b also extend ventral to the genu of the corpus callosum. Area 32ac, corresponding to the dorsal anterior cingulate area 32 in Brodmann's human brain map, is anterior and dorsal to the genu. The parallel organization of the OMPFC in monkeys and humans allows experimental data from monkeys to be applied to studies of the human cortex. J. Comp. Neurol. 460:425–449, 2003. © 2003 Wiley‐Liss, Inc.",2003,76,858,62,9,9,31,34,47,42,58,52,65,51
6479c0e44ab143679d2337e9b726d6196d8dfa0b,"Geochemical models for Mars predict carbonate formation during aqueous alteration. Carbonate-bearing rocks had not previously been detected on Mars' surface, but Mars Reconnaissance Orbiter mapping reveals a regional rock layer with near-infrared spectral characteristics that are consistent with the presence of magnesium carbonate in the Nili Fossae region. The carbonate is closely associated with both phyllosilicate-bearing and olivine-rich rock units and probably formed during the Noachian or early Hesperian era from the alteration of olivine by either hydrothermal fluids or near-surface water. The presence of carbonate as well as accompanying clays suggests that waters were neutral to alkaline at the time of its formation and that acidic weathering, proposed to be characteristic of Hesperian Mars, did not destroy these carbonates and thus did not dominate all aqueous environments.",2008,89,516,18,2,31,49,39,49,56,39,38,29,36
8b75af5b595e3402c77aa438f926ad3dba9fde17,"Orbital mechanics is a cornerstone subject for aerospace engineering students. Maintaining the focus of the first edition, the author provides the foundation needed to understand the subject and proceed to advanced topics. Starting with the solution of the two-body problem and formulas for the different kinds of orbits, the text moves on to Kepler's equations, orbits in three dimensions, orbital elements from observations, orbital maneuvers, orbital rendezvous and interplanetary missions. This is followed by an introduction to spacecraft dynamics and a final chapter on basic rocket dynamics. The author's teach-by-example approach emphasizes the analytical procedures and computer-implemented algorithms required by today's students. There are a large number of worked examples, illustrations, end of chapter exercises (with answers) as well as many MATLAB[registered] programs for use in homework and projects. The text can be used for one and two semester courses in space mechanics. Features: a new section on numerical integration methods applicable to space mechanics problems; a more centralized and improved discussion of coordinate systems and Euler angle sequences; an expanded development of relative motion in orbit; a new section on quaternions; new worked-out examples, illustrations and homework problems; new algorithms, MATLAB[registered] scripts and simulations; instructor's manual and lecture slides available online; and included online testing and assessment component helps students assess their knowledge of the topics.",2005,0,745,81,1,2,6,5,19,19,31,50,54,71
56677386dc3d3ecd1f51a292810a648bc68da1db,"The theoretical need to study the properties of the Fe-based high-Tc superconductors using reliable manybody techniques has highlighted the importance of determining what is the minimum number of orbital degrees of freedom that will capture the physics of these materials. While the shape of the Fermi surface FS obtained with the local-density approximation LDA can be reproduced by a two-orbital model, it has been argued that the bands that cross the chemical potential result from the strong hybridization of three of the Fe 3d orbitals. For this reason, a three orbital Hamiltonian for LaOFeAs obtained with the Slater-Koster formalism by considering the hybridization of the As p orbitals with the Fe dxz, dyz, and dxy orbitals is discussed here. This model reproduces qualitatively the FS shape and orbital composition obtained by LDA calculations for undoped LaOFeAs when four electrons per Fe are considered. Within a mean-field approximation, its magnetic and orbital properties in the undoped case are here described for intermediate values of J/U. Increasing the Coulomb repulsion U at zero temperature, four different regimes are obtained: 1 paramagnetic, 2 magnetic ,0 spin order, 3 the same ,0 spin order but now including orbital order, and finally 4 a magneticmore » and orbital ordered insulator. The spin-singlet pairing operators allowed by the lattice and orbital symmetries are also constructed. It is found that for pairs of electrons involving up to diagonal nearest-neighbors sites, the only fully gapped and purely intraband spin-singlet pairing operator is given by k= fkdk,, d k,, with fk=1 or cos kx cos ky which would arise only if the electrons in all different orbitals couple with equal strength to the source of pairing.« less",2009,2,123,4,1,5,8,12,17,12,17,11,9,10
9b6fa3a9362cc3380185a7933d7982b874527230,"This paper reviews architectonic subdivisions and connections of the orbital and medial prefrontal cortex (OMPFC) in rats, monkeys and humans. Cortico-cortical connections provide the basis for recognition of 'medial' and 'orbital' networks within the OMPFC. These networks also have distinct connections with structures in other parts of the brain. The orbital network receives sensory inputs from several modalities, including olfaction, taste, visceral afferents, somatic sensation and vision, which appear to be especially related to food or eating. In contrast, the medial network provides the major cortical output to visceromotor structures in the hypothalamus and brainstem. The two networks have distinct connections with areas of the striatum and mediodorsal thalamus. In particular, projections to the nucleus accumbens and the adjacent ventromedial caudate and putamen arise predominantly from the medial network. Both networks also have extensive connections with limbic structures. Based on these and other observations, the OMPFC appears to function as a sensory-visceromotor link, especially for eating. This linkage appears to be critical for the guidance of reward-related behavior and for setting of mood. Imaging and histological observations on human brains indicate that clinical depressive disorders are associated with specific functional and cellular changes in the OMPFC, including activity and volume changes, and specific changes in the number of glial cells.",2000,133,2452,143,6,18,51,61,67,72,81,98,128,152
aaea825be9afc25ee2d6d7f279030d0711fa656f,"Entangled quantum states are not separable, regardless of the spatial separation of their components. This is a manifestation of an aspect of quantum mechanics known as quantum non-locality. An important consequence of this is that the measurement of the state of one particle in a two-particle entangled state defines the state of the second particle instantaneously, whereas neither particle possesses its own well-defined state before the measurement. Experimental realizations of entanglement have hitherto been restricted to two-state quantum systems, involving, for example, the two orthogonal polarization states of photons. Here we demonstrate entanglement involving the spatial modes of the electromagnetic field carrying orbital angular momentum. As these modes can be used to define an infinitely dimensional discrete Hilbert space, this approach provides a practical route to entanglement that involves many orthogonal quantum states, rather than just two Multi-dimensional entangled states could be of considerable importance in the field of quantum information, enabling, for example, more efficient use of communication channels in quantum cryptography.",2001,26,2257,31,4,13,24,54,49,52,55,60,75,64
a5c8d98d25da1770770d58ea53f51d614e44339f,"A high-resolution deuterium profile is now available along the entire European Project for Ice Coring in Antarctica Dome C ice core, extending this climate record back to marine isotope stage 20.2, ∼800,000 years ago. Experiments performed with an atmospheric general circulation model including water isotopes support its temperature interpretation. We assessed the general correspondence between Dansgaard-Oeschger events and their smoothed Antarctic counterparts for this Dome C record, which reveals the presence of such features with similar amplitudes during previous glacial periods. We suggest that the interplay between obliquity and precession accounts for the variable intensity of interglacial periods in ice core records.",2007,43,1774,71,21,45,75,120,120,121,134,140,134,127
6a145d8e7158476d0930c679a8777872928426af,"We demonstrate the transfer of information encoded as orbital angular momentum (OAM) states of a light beam. The transmitter and receiver units are based on spatial light modulators, which prepare or measure a laser beam in one of eight pure OAM states. We show that the information encoded in this way is resistant to eavesdropping in the sense that any attempt to sample the beam away from its axis will be subject to an angular restriction and a lateral offset, both of which result in inherent uncertainty in the measurement. This gives an experimental insight into the effects of aperturing and misalignment of the beam on the OAM measurement and demonstrates the uncertainty relationship for OAM.",2004,16,1792,14,2,12,22,26,30,38,46,71,93,120
c4950fc9bb26369182bcd30a863782cc873d71f1,"We demonstrate experimentally an optical process in which the spin angular momentum carried by a circularly polarized light beam is converted into orbital angular momentum, leading to the generation of helical modes with a wave-front helicity controlled by the input polarization. This phenomenon requires the interaction of light with matter that is both optically inhomogeneous and anisotropic. The underlying physics is also associated with the so-called Pancharatnam-Berry geometrical phases involved in any inhomogeneous transformation of the optical polarization.",2006,73,1319,18,1,10,14,21,26,36,47,57,92,110
74569b70f1d283bc43e07f3a078250677c89a5b6,"An electron in a solid, that is, bound to or nearly localized on the specific atomic site, has three attributes: charge, spin, and orbital. The orbital represents the shape of the electron cloud in solid. In transition-metal oxides with anisotropic-shaped d-orbital electrons, the Coulomb interaction between the electrons (strong electron correlation effect) is of importance for understanding their metal-insulator transitions and properties such as high-temperature superconductivity and colossal magnetoresistance. The orbital degree of freedom occasionally plays an important role in these phenomena, and its correlation and/or order-disorder transition causes a variety of phenomena through strong coupling with charge, spin, and lattice dynamics. An overview is given here on this ""orbital physics,"" which will be a key concept for the science and technology of correlated electrons.",2000,60,1553,7,6,26,54,65,61,82,70,66,69,53
c13e0d603a39430565ed7cb94ab5add3da5b280a,"This graduate-level text presents the first comprehensive overview of modern chemical valency and bonding theory, written by internationally recognized experts in the field. The authors build on the foundation of Lewisand Pauling-like localized structural and hybridization concepts to present a book that is directly based on current ab initio computational technology. The presentation is highly visual and intuitive throughout, being based on the recognizable and transferable graphical forms of natural bond orbitals (NBOs) and their spatial overlaps in the molecular environment. The book shows applications to a broad range of molecular and supramolecular species of organic, inorganic, and bioorganic interest. Hundreds of orbital illustrations help to convey the essence of modern NBO concepts in a facile manner for those with no extensive background in the mathematical machinery of the Schrödinger equation. This book will appeal to those studying chemical bonding in relation to chemistry, chemical engineering, biochemistry, and physics.",2005,1,1353,58,1,21,32,45,40,44,57,76,126,141
ddf1415e591f9637cc53dec22f6d4097ba05efc4,"We present a method to efficiently sort orbital angular momentum (OAM) states of light using two static optical elements. The optical elements perform a Cartesian to log-polar coordinate transformation, converting the helically phased light beam corresponding to OAM states into a beam with a transverse phase gradient. A subsequent lens then focuses each input OAM state to a different lateral position. We demonstrate the concept experimentally by using two spatial light modulators to create the desired optical elements, applying it to the separation of eleven OAM states.",2010,0,682,12,3,23,37,45,48,39,80,68,95,92
3d28ee266ac532ca0177a11b69f0bab556e8e4b8,"Recent discoveries concerning rotating (helical) phase fronts and orbital angular momentum (OAM) of laser beams are applied to radio frequencies and comprehensive simulations of a radio OAM system are performed. We find that with the use of vector field-sensing electric and magnetic triaxial antennas, it is possible to unambiguously estimate the OAM in radio beams by local measurements at a single point, assuming ideal (noiseless) conditions and that the beam axis is known. Furthermore, we show that conventional antenna pattern optimization methods can be applied to OAM-generating circular arrays to enhance their directivity.",2010,29,523,34,1,3,9,13,30,26,55,68,87,97
0dcaea1e332d723c98595308c3e6b79260794610,"For extrasolar planets discovered using the radial velocity method, the spectral characterization of the host star leads to a mass estimate of the star and subsequently of the orbiting planet. If the orbital velocity of the planet could be determined, the masses of both star and planet could be calculated using Newton’s law of gravity, just as in the case of stellar double-line eclipsing binaries. Here we report high-dispersion ground-based spectroscopy of a transit of the extrasolar planet HD 209458b. We see a significant wavelength shift in absorption lines from carbon monoxide in the planet’s atmosphere, which we conclude arises from a change in the radial component of the planet’s orbital velocity. The masses of the star and planet are 1.00 ± 0.22MSun and 0.64 ± 0.09MJup respectively. A blueshift of the carbon monoxide signal of approximately 2 km s−1 with respect to the systemic velocity of the host star suggests the presence of a strong wind flowing from the irradiated dayside to the non-irradiated nightside of the planet within the 0.01–0.1 mbar atmospheric pressure range probed by these observations. The strength of the carbon monoxide signal suggests a carbon monoxide mixing ratio of (1–3) × 10−3 in this planet’s upper atmosphere.",2010,26,443,41,10,28,23,33,39,32,37,45,46,50
02640f28ab5c2fe5a883c855fd0bc77505b48a00,"Planetary formation theories suggest that the giant planets formed on circular and coplanar orbits. The eccentricities of Jupiter, Saturn and Uranus, however, reach values of 6 per cent, 9 per cent and 8 per cent, respectively. In addition, the inclinations of the orbital planes of Saturn, Uranus and Neptune take maximum values of ∼2 degrees with respect to the mean orbital plane of Jupiter. Existing models for the excitation of the eccentricity of extrasolar giant planets have not been successfully applied to the Solar System. Here we show that a planetary system with initial quasi-circular, coplanar orbits would have evolved to the current orbital configuration, provided that Jupiter and Saturn crossed their 1:2 orbital resonance. We show that this resonance crossing could have occurred as the giant planets migrated owing to their interaction with a disk of planetesimals. Our model reproduces all the important characteristics of the giant planets' orbits, namely their final semimajor axes, eccentricities and mutual inclinations.",2005,59,1099,103,16,30,44,46,82,61,80,66,64,96
68d9db61afa6f2e179b162e8929946d938a5bc8a,"All forms of waves can contain phase singularities. In the case of optical waves, a light beam with a phase singularity carries orbital angular momentum, and such beams have found a range of applications in optical manipulation, quantum information and astronomy. Here we report the generation of an electron beam with a phase singularity propagating in free space, which we achieve by passing a plane electron wave through a spiral phase plate constructed naturally from a stack of graphite thin films. The interference pattern between the final beam and a plane electron wave in a transmission electron microscope shows the ‘Y’-like defect pattern characteristic of a beam carrying a phase singularity with a topological charge equal to one. This fundamentally new electron degree of freedom could find application in a number of research areas, as is the case for polarized electron beams.",2010,28,455,7,4,13,25,26,41,35,33,54,56,64
b57fe8cdc49f84ee230c4696aa81d8aa3e2a5ba5,"Entanglement in a Twist The strong correlations observed in quantum mechanically entangled particles, such as photons, offer potential for secure communication and quantum information processing. Leach et al. (p. 662) now show such strong quantum correlations between the complementary variables—angular position and orbital angular momentum—of two photons created during the parametric down-conversion process in a nonlinear crystal. This demonstration of entanglement in an angular basis establishes that angles are genuine quantum observables and can therefore be considered a resource for quantum information processing, capable of secure, high-dimension, key distribution. Strong quantum correlations are induced between the angular position and angular momentum of two photons. Entanglement of the properties of two separated particles constitutes a fundamental signature of quantum mechanics and is a key resource for quantum information science. We demonstrate strong Einstein, Podolsky, and Rosen correlations between the angular position and orbital angular momentum of two photons created by the nonlinear optical process of spontaneous parametric down-conversion. The discrete nature of orbital angular momentum and the continuous but periodic nature of angular position give rise to a special sort of entanglement between these two variables. The resulting correlations are found to be an order of magnitude stronger than those allowed by the uncertainty principle for independent (nonentangled) particles. Our results suggest that angular position and orbital angular momentum may find important applications in quantum information science.",2010,42,414,3,4,24,30,26,38,33,38,27,52,55
768980f65528c8bad41bc6cdf0d3b0eef8934d65,"The occupation of d orbitals controls the magnitude and anisotropy of the inter-atomic electron transfer in transition-metal oxides and hence exerts a key influence on their chemical bonding and physical properties. Atomic-scale modulations of the orbital occupation at surfaces and interfaces are believed to be responsible for massive variations of the magnetic and transport properties, but could not thus far be probed in a quantitative manner. Here we show that it is possible to derive quantitative, spatially resolved orbital polarization profiles from soft-X-ray reflectivity data, without resorting to model calculations. We demonstrate that the method is sensitive enough to resolve differences of ~3% in the occupation of Ni e(g) orbitals in adjacent atomic layers of a LaNiO(3)-LaAlO(3) superlattice, in good agreement with ab initio electronic-structure calculations. The possibility to quantitatively correlate theory and experiment on the atomic scale opens up many new perspectives for orbital physics in transition-metal oxides.",2010,41,152,5,0,5,10,9,17,15,18,15,17,15
d1620666ba23d4bce8c3035a87d06f5277819cc3,"Measurement of the quantum-mechanical phase in quantum matter provides the most direct manifestation of the underlying abstract physics. We used resonant x-ray scattering to probe the relative phases of constituent atomic orbitals in an electronic wave function, which uncovers the unconventional Mott insulating state induced by relativistic spin-orbit coupling in the layered 5d transition metal oxide Sr2IrO4. A selection rule based on intra-atomic interference effects establishes a complex spin-orbital state represented by an effective total angular momentum = 1/2 quantum number, the phase of which can lead to a quantum topological state of matter.",2009,11,642,18,5,10,20,32,47,45,56,54,56,94
411be93d0ae3ff9fbf174bd4de4f11e3203b8a77,"In iron pnictides, we find that the moderate electron-phonon interaction due to the Fe-ion oscillation can induce the critical d-orbital fluctuations, without being prohibited by the Coulomb interaction. These fluctuations give rise to the strong pairing interaction for the s-wave superconducting (SC) state without sign reversal (s(++)-wave state), which is consistent with experimentally observed robustness of superconductivity against impurities. When the magnetic fluctuations due to Coulomb interaction are also strong, the SC state shows a smooth crossover from the s-wave state with sign reversal (s(+/-)-wave state) to the s(++)-wave state as impurity concentration increases.",2009,0,377,6,2,9,32,46,40,46,38,41,34,36
cf335ec147d76c16e49263d17c388814290a35fc,"This review provides a perspective on the use of orbital-dependent functionals, which is currently considered one of the most promising avenues in modern density-functional theory. The focus here is on four major themes: the motivation for orbital-dependent functionals in terms of limitations of semilocal functionals; the optimized effective potential as a rigorous approach to incorporating orbital-dependent functionals within the Kohn-Sham framework; the rationale behind and advantages and limitations of four popular classes of orbital-dependent functionals; and the use of orbital-dependent functionals for predicting excited-state properties. For each of these issues, both formal and practical aspects are assessed.",2008,527,734,8,25,50,38,68,56,64,72,71,61,45
c9d24e78b2bdc2ddfe89144e020846610cdfcefd,"ABSTRACT. We analyze 8 years of precise radial velocity measurements from the Keck Planet Search, characterizing the detection threshold, selection effects, and completeness of the survey. We first carry out a systematic search for planets, by assessing the false-alarm probability associated with Keplerian orbit fits to the data. This allows us to understand the detection threshold for each star in terms of the number and time baseline of the observations, and the underlying “noise” from measurement errors, intrinsic stellar jitter, or additional low-mass planets. We show that all planets with orbital periods P   20 m s-1 K > 20 m s - 1 , and eccentricities e ≲ 0.6 e ≲ 0.6 have been announced, and we summarize the candidates at lower amplitudes and longer orbital periods. For the remaining stars, we calculate upper limits on the velocity amplitude of a companion. For orbital periods less than the duration of the observations, these are typically ...",2008,91,611,154,22,38,56,37,51,43,46,47,49,47
7a725f13577e44f5f39e262ceebc55d0316e6853,"For an isolated quantum particle, such as an electron, the orbital (L) and spin (S) magnetic moments can change provided that the total angular momentum of the particle is conserved. In condensed matter, an efficient transfer between L and S can occur owing to the spin–orbit interaction, which originates in the relativistic motion of electrons. Disentangling the absolute contributions of the orbital and spin angular momenta is challenging, however, as any transfer between the two occurs on femtosecond timescales. Here we investigate such phenomena by using ultrashort optical laser pulses to change the magnetization of a ferromagnetic film and then probe its dynamics with circularly polarized femtosecond X-ray pulses. Our measurements enable us to disentangle the spin and orbital components of the magnetic moment, revealing different dynamics for L and S. We highlight the important role played by the spin–orbit interaction in the ultrafast laser-induced demagnetization of ferromagnetic films, and show also that the magneto-crystalline anisotropy energy is an important quantity to consider in such processes. Our study provides insights into the dynamics in magnetic systems as well as perspectives for the ultrafast control of information in magnetic recording media.",2010,38,297,4,2,19,20,31,26,29,30,24,28,32
45524fd482e1e348a63c2d146a55a77d6ce36608,"The control of charge transport in an active electronic device depends intimately on the modulation of the internal charge density by an external node. For example, a field-effect transistor relies on the gated electrostatic modulation of the channel charge produced by changing the relative position of the conduction and valence bands with respect to the electrodes. In molecular-scale devices, a longstanding challenge has been to create a true three-terminal device that operates in this manner (that is, by modifying orbital energy). Here we report the observation of such a solid-state molecular device, in which transport current is directly modulated by an external gate voltage. Resonance-enhanced coupling to the nearest molecular orbital is revealed by electron tunnelling spectroscopy, demonstrating direct molecular orbital gating in an electronic device. Our findings demonstrate that true molecular transistors can be created, and so enhance the prospects for molecularly engineered electronic devices.",2009,35,585,8,3,29,65,55,56,74,63,51,45,49
0e15715debd0a700242264e06f84fd9e37ac86a3,"We show numerically that vector antenna arrays can generate radio beams that exhibit spin and orbital angular momentum characteristics similar to those of helical Laguerre-Gauss laser beams in paraxial optics. For low frequencies (< or = 1 GHz), digital techniques can be used to coherently measure the instantaneous, local field vectors and to manipulate them in software. This enables new types of experiments that go beyond what is possible in optics. It allows information-rich radio astronomy and paves the way for novel wireless communication concepts.",2007,59,698,31,2,6,9,7,12,17,17,45,44,78
af174b8b4484dd8657819d20baed7995de17bcdb,"We predict a new category of optical orbital angular momentum that is associated with the curl of polarization and a kind of vector field with radial-variant hybrid states of polarization that can carry such novel optical orbital angular momentum. We present a scheme for creating the desired vector fields. Optical trapping experiments validate that the vector fields, which have no additional phase vortex, exert torques to drive the orbital motion of the trapped isotropic microspheres.",2010,12,161,3,0,6,14,7,12,13,20,18,15,20
6e62526fba615f7e3d0f49711a41fd6047be4b5f,"The structure of the human orbital and medial prefrontal cortex (OMPFC) was investigated using five histological and immunohistochemical stains and was correlated with a previous analysis in macaque monkeys [Carmichael and Price ( 1994 ) J. Comp. Neurol. 346:366–402]. A cortical area was recognized if it was distinct with at least two stains and was found in similar locations in different brains. All of the areas recognized in the macaque OMPFC have counterparts in humans. Areas 11, 13, and 14 were subdivided into areas 11m, 11l, 13a, 13b, 13m, 13l, 14r, and 14c. Within area 10, the region corresponding to area 10m in monkeys was divided into 10m and 10r, and area 10o (orbital) was renamed area 10p (polar). Areas 47/12r, 47/12m, 47/12l, and 47/12s occupy the lateral orbital cortex, corresponding to monkey areas 12r, 12m, 12l, and 12o. The agranular insula (areas Iam, Iapm, Iai, and Ial) extends onto the caudal orbital surface and into the horizontal ramus of the lateral sulcus. The growth of the frontal pole in humans has pushed area 25 and area 32pl, which corresponds to the prelimbic area 32 in Brodmann's monkey brain map, caudal and ventral to the genu of the corpus callosum. Anterior cingulate areas 24a and 24b also extend ventral to the genu of the corpus callosum. Area 32ac, corresponding to the dorsal anterior cingulate area 32 in Brodmann's human brain map, is anterior and dorsal to the genu. The parallel organization of the OMPFC in monkeys and humans allows experimental data from monkeys to be applied to studies of the human cortex. J. Comp. Neurol. 460:425–449, 2003. © 2003 Wiley‐Liss, Inc.",2003,76,858,62,9,9,31,34,47,42,58,52,65,51
6479c0e44ab143679d2337e9b726d6196d8dfa0b,"Geochemical models for Mars predict carbonate formation during aqueous alteration. Carbonate-bearing rocks had not previously been detected on Mars' surface, but Mars Reconnaissance Orbiter mapping reveals a regional rock layer with near-infrared spectral characteristics that are consistent with the presence of magnesium carbonate in the Nili Fossae region. The carbonate is closely associated with both phyllosilicate-bearing and olivine-rich rock units and probably formed during the Noachian or early Hesperian era from the alteration of olivine by either hydrothermal fluids or near-surface water. The presence of carbonate as well as accompanying clays suggests that waters were neutral to alkaline at the time of its formation and that acidic weathering, proposed to be characteristic of Hesperian Mars, did not destroy these carbonates and thus did not dominate all aqueous environments.",2008,89,516,18,2,31,49,39,49,56,39,38,29,36
8b75af5b595e3402c77aa438f926ad3dba9fde17,"Orbital mechanics is a cornerstone subject for aerospace engineering students. Maintaining the focus of the first edition, the author provides the foundation needed to understand the subject and proceed to advanced topics. Starting with the solution of the two-body problem and formulas for the different kinds of orbits, the text moves on to Kepler's equations, orbits in three dimensions, orbital elements from observations, orbital maneuvers, orbital rendezvous and interplanetary missions. This is followed by an introduction to spacecraft dynamics and a final chapter on basic rocket dynamics. The author's teach-by-example approach emphasizes the analytical procedures and computer-implemented algorithms required by today's students. There are a large number of worked examples, illustrations, end of chapter exercises (with answers) as well as many MATLAB[registered] programs for use in homework and projects. The text can be used for one and two semester courses in space mechanics. Features: a new section on numerical integration methods applicable to space mechanics problems; a more centralized and improved discussion of coordinate systems and Euler angle sequences; an expanded development of relative motion in orbit; a new section on quaternions; new worked-out examples, illustrations and homework problems; new algorithms, MATLAB[registered] scripts and simulations; instructor's manual and lecture slides available online; and included online testing and assessment component helps students assess their knowledge of the topics.",2005,0,745,81,1,2,6,5,19,19,31,50,54,71
56677386dc3d3ecd1f51a292810a648bc68da1db,"The theoretical need to study the properties of the Fe-based high-Tc superconductors using reliable manybody techniques has highlighted the importance of determining what is the minimum number of orbital degrees of freedom that will capture the physics of these materials. While the shape of the Fermi surface FS obtained with the local-density approximation LDA can be reproduced by a two-orbital model, it has been argued that the bands that cross the chemical potential result from the strong hybridization of three of the Fe 3d orbitals. For this reason, a three orbital Hamiltonian for LaOFeAs obtained with the Slater-Koster formalism by considering the hybridization of the As p orbitals with the Fe dxz, dyz, and dxy orbitals is discussed here. This model reproduces qualitatively the FS shape and orbital composition obtained by LDA calculations for undoped LaOFeAs when four electrons per Fe are considered. Within a mean-field approximation, its magnetic and orbital properties in the undoped case are here described for intermediate values of J/U. Increasing the Coulomb repulsion U at zero temperature, four different regimes are obtained: 1 paramagnetic, 2 magnetic ,0 spin order, 3 the same ,0 spin order but now including orbital order, and finally 4 a magneticmore » and orbital ordered insulator. The spin-singlet pairing operators allowed by the lattice and orbital symmetries are also constructed. It is found that for pairs of electrons involving up to diagonal nearest-neighbors sites, the only fully gapped and purely intraband spin-singlet pairing operator is given by k= fkdk,, d k,, with fk=1 or cos kx cos ky which would arise only if the electrons in all different orbitals couple with equal strength to the source of pairing.« less",2009,2,123,4,1,5,8,12,17,12,17,11,9,10
0001655ad1dcf8afdea236c35558d5f638aee552,"A growing list of experiments show orthorhombic electronic anisotropy in the iron pnictides, in some cases at temperatures well above the spin-density-wave transition. These experiments include neutron scattering, resistivity and magnetoresistance measurements, and a variety of spectroscopies. We explore the idea that these anisotropies stem from a common underlying cause: orbital order manifest in an unequal occupation of ${d}_{xz}$ and ${d}_{yz}$ orbitals, arising from the coupled spin-orbital degrees of freedom. We emphasize the distinction between the total-orbital occupation (the integrated density of states), where the order parameter may be small and the orbital polarization near the Fermi level which can be more pronounced. We also discuss light-polarization studies of angle-resolved photoemission and demonstrate how x-ray absorption linear dichroism may be used as a method to detect an orbital-order parameter.",2010,60,124,0,4,13,12,15,12,16,14,8,7,9
9b6fa3a9362cc3380185a7933d7982b874527230,"This paper reviews architectonic subdivisions and connections of the orbital and medial prefrontal cortex (OMPFC) in rats, monkeys and humans. Cortico-cortical connections provide the basis for recognition of 'medial' and 'orbital' networks within the OMPFC. These networks also have distinct connections with structures in other parts of the brain. The orbital network receives sensory inputs from several modalities, including olfaction, taste, visceral afferents, somatic sensation and vision, which appear to be especially related to food or eating. In contrast, the medial network provides the major cortical output to visceromotor structures in the hypothalamus and brainstem. The two networks have distinct connections with areas of the striatum and mediodorsal thalamus. In particular, projections to the nucleus accumbens and the adjacent ventromedial caudate and putamen arise predominantly from the medial network. Both networks also have extensive connections with limbic structures. Based on these and other observations, the OMPFC appears to function as a sensory-visceromotor link, especially for eating. This linkage appears to be critical for the guidance of reward-related behavior and for setting of mood. Imaging and histological observations on human brains indicate that clinical depressive disorders are associated with specific functional and cellular changes in the OMPFC, including activity and volume changes, and specific changes in the number of glial cells.",2000,133,2452,143,6,18,51,61,67,72,81,98,128,152
aaea825be9afc25ee2d6d7f279030d0711fa656f,"Entangled quantum states are not separable, regardless of the spatial separation of their components. This is a manifestation of an aspect of quantum mechanics known as quantum non-locality. An important consequence of this is that the measurement of the state of one particle in a two-particle entangled state defines the state of the second particle instantaneously, whereas neither particle possesses its own well-defined state before the measurement. Experimental realizations of entanglement have hitherto been restricted to two-state quantum systems, involving, for example, the two orthogonal polarization states of photons. Here we demonstrate entanglement involving the spatial modes of the electromagnetic field carrying orbital angular momentum. As these modes can be used to define an infinitely dimensional discrete Hilbert space, this approach provides a practical route to entanglement that involves many orthogonal quantum states, rather than just two Multi-dimensional entangled states could be of considerable importance in the field of quantum information, enabling, for example, more efficient use of communication channels in quantum cryptography.",2001,26,2257,31,4,13,24,54,49,52,55,60,75,64
a5c8d98d25da1770770d58ea53f51d614e44339f,"A high-resolution deuterium profile is now available along the entire European Project for Ice Coring in Antarctica Dome C ice core, extending this climate record back to marine isotope stage 20.2, ∼800,000 years ago. Experiments performed with an atmospheric general circulation model including water isotopes support its temperature interpretation. We assessed the general correspondence between Dansgaard-Oeschger events and their smoothed Antarctic counterparts for this Dome C record, which reveals the presence of such features with similar amplitudes during previous glacial periods. We suggest that the interplay between obliquity and precession accounts for the variable intensity of interglacial periods in ice core records.",2007,43,1774,71,21,45,75,120,120,121,134,140,134,127
6a145d8e7158476d0930c679a8777872928426af,"We demonstrate the transfer of information encoded as orbital angular momentum (OAM) states of a light beam. The transmitter and receiver units are based on spatial light modulators, which prepare or measure a laser beam in one of eight pure OAM states. We show that the information encoded in this way is resistant to eavesdropping in the sense that any attempt to sample the beam away from its axis will be subject to an angular restriction and a lateral offset, both of which result in inherent uncertainty in the measurement. This gives an experimental insight into the effects of aperturing and misalignment of the beam on the OAM measurement and demonstrates the uncertainty relationship for OAM.",2004,16,1792,14,2,12,22,26,30,38,46,71,93,120
c4950fc9bb26369182bcd30a863782cc873d71f1,"We demonstrate experimentally an optical process in which the spin angular momentum carried by a circularly polarized light beam is converted into orbital angular momentum, leading to the generation of helical modes with a wave-front helicity controlled by the input polarization. This phenomenon requires the interaction of light with matter that is both optically inhomogeneous and anisotropic. The underlying physics is also associated with the so-called Pancharatnam-Berry geometrical phases involved in any inhomogeneous transformation of the optical polarization.",2006,73,1319,18,1,10,14,21,26,36,47,57,92,110
74569b70f1d283bc43e07f3a078250677c89a5b6,"An electron in a solid, that is, bound to or nearly localized on the specific atomic site, has three attributes: charge, spin, and orbital. The orbital represents the shape of the electron cloud in solid. In transition-metal oxides with anisotropic-shaped d-orbital electrons, the Coulomb interaction between the electrons (strong electron correlation effect) is of importance for understanding their metal-insulator transitions and properties such as high-temperature superconductivity and colossal magnetoresistance. The orbital degree of freedom occasionally plays an important role in these phenomena, and its correlation and/or order-disorder transition causes a variety of phenomena through strong coupling with charge, spin, and lattice dynamics. An overview is given here on this ""orbital physics,"" which will be a key concept for the science and technology of correlated electrons.",2000,60,1553,7,6,26,54,65,61,82,70,66,69,53
c13e0d603a39430565ed7cb94ab5add3da5b280a,"This graduate-level text presents the first comprehensive overview of modern chemical valency and bonding theory, written by internationally recognized experts in the field. The authors build on the foundation of Lewisand Pauling-like localized structural and hybridization concepts to present a book that is directly based on current ab initio computational technology. The presentation is highly visual and intuitive throughout, being based on the recognizable and transferable graphical forms of natural bond orbitals (NBOs) and their spatial overlaps in the molecular environment. The book shows applications to a broad range of molecular and supramolecular species of organic, inorganic, and bioorganic interest. Hundreds of orbital illustrations help to convey the essence of modern NBO concepts in a facile manner for those with no extensive background in the mathematical machinery of the Schrödinger equation. This book will appeal to those studying chemical bonding in relation to chemistry, chemical engineering, biochemistry, and physics.",2005,1,1353,58,1,21,32,45,40,44,57,76,126,141
ddf1415e591f9637cc53dec22f6d4097ba05efc4,"We present a method to efficiently sort orbital angular momentum (OAM) states of light using two static optical elements. The optical elements perform a Cartesian to log-polar coordinate transformation, converting the helically phased light beam corresponding to OAM states into a beam with a transverse phase gradient. A subsequent lens then focuses each input OAM state to a different lateral position. We demonstrate the concept experimentally by using two spatial light modulators to create the desired optical elements, applying it to the separation of eleven OAM states.",2010,0,682,12,3,23,37,45,48,39,80,68,95,92
3d28ee266ac532ca0177a11b69f0bab556e8e4b8,"Recent discoveries concerning rotating (helical) phase fronts and orbital angular momentum (OAM) of laser beams are applied to radio frequencies and comprehensive simulations of a radio OAM system are performed. We find that with the use of vector field-sensing electric and magnetic triaxial antennas, it is possible to unambiguously estimate the OAM in radio beams by local measurements at a single point, assuming ideal (noiseless) conditions and that the beam axis is known. Furthermore, we show that conventional antenna pattern optimization methods can be applied to OAM-generating circular arrays to enhance their directivity.",2010,29,523,34,1,3,9,13,30,26,55,68,87,97
0dcaea1e332d723c98595308c3e6b79260794610,"For extrasolar planets discovered using the radial velocity method, the spectral characterization of the host star leads to a mass estimate of the star and subsequently of the orbiting planet. If the orbital velocity of the planet could be determined, the masses of both star and planet could be calculated using Newton’s law of gravity, just as in the case of stellar double-line eclipsing binaries. Here we report high-dispersion ground-based spectroscopy of a transit of the extrasolar planet HD 209458b. We see a significant wavelength shift in absorption lines from carbon monoxide in the planet’s atmosphere, which we conclude arises from a change in the radial component of the planet’s orbital velocity. The masses of the star and planet are 1.00 ± 0.22MSun and 0.64 ± 0.09MJup respectively. A blueshift of the carbon monoxide signal of approximately 2 km s−1 with respect to the systemic velocity of the host star suggests the presence of a strong wind flowing from the irradiated dayside to the non-irradiated nightside of the planet within the 0.01–0.1 mbar atmospheric pressure range probed by these observations. The strength of the carbon monoxide signal suggests a carbon monoxide mixing ratio of (1–3) × 10−3 in this planet’s upper atmosphere.",2010,26,443,41,10,28,23,33,39,32,37,45,46,50
02640f28ab5c2fe5a883c855fd0bc77505b48a00,"Planetary formation theories suggest that the giant planets formed on circular and coplanar orbits. The eccentricities of Jupiter, Saturn and Uranus, however, reach values of 6 per cent, 9 per cent and 8 per cent, respectively. In addition, the inclinations of the orbital planes of Saturn, Uranus and Neptune take maximum values of ∼2 degrees with respect to the mean orbital plane of Jupiter. Existing models for the excitation of the eccentricity of extrasolar giant planets have not been successfully applied to the Solar System. Here we show that a planetary system with initial quasi-circular, coplanar orbits would have evolved to the current orbital configuration, provided that Jupiter and Saturn crossed their 1:2 orbital resonance. We show that this resonance crossing could have occurred as the giant planets migrated owing to their interaction with a disk of planetesimals. Our model reproduces all the important characteristics of the giant planets' orbits, namely their final semimajor axes, eccentricities and mutual inclinations.",2005,59,1099,103,16,30,44,46,82,61,80,66,64,96
68d9db61afa6f2e179b162e8929946d938a5bc8a,"All forms of waves can contain phase singularities. In the case of optical waves, a light beam with a phase singularity carries orbital angular momentum, and such beams have found a range of applications in optical manipulation, quantum information and astronomy. Here we report the generation of an electron beam with a phase singularity propagating in free space, which we achieve by passing a plane electron wave through a spiral phase plate constructed naturally from a stack of graphite thin films. The interference pattern between the final beam and a plane electron wave in a transmission electron microscope shows the ‘Y’-like defect pattern characteristic of a beam carrying a phase singularity with a topological charge equal to one. This fundamentally new electron degree of freedom could find application in a number of research areas, as is the case for polarized electron beams.",2010,28,455,7,4,13,25,26,41,35,33,54,56,64
b57fe8cdc49f84ee230c4696aa81d8aa3e2a5ba5,"Entanglement in a Twist The strong correlations observed in quantum mechanically entangled particles, such as photons, offer potential for secure communication and quantum information processing. Leach et al. (p. 662) now show such strong quantum correlations between the complementary variables—angular position and orbital angular momentum—of two photons created during the parametric down-conversion process in a nonlinear crystal. This demonstration of entanglement in an angular basis establishes that angles are genuine quantum observables and can therefore be considered a resource for quantum information processing, capable of secure, high-dimension, key distribution. Strong quantum correlations are induced between the angular position and angular momentum of two photons. Entanglement of the properties of two separated particles constitutes a fundamental signature of quantum mechanics and is a key resource for quantum information science. We demonstrate strong Einstein, Podolsky, and Rosen correlations between the angular position and orbital angular momentum of two photons created by the nonlinear optical process of spontaneous parametric down-conversion. The discrete nature of orbital angular momentum and the continuous but periodic nature of angular position give rise to a special sort of entanglement between these two variables. The resulting correlations are found to be an order of magnitude stronger than those allowed by the uncertainty principle for independent (nonentangled) particles. Our results suggest that angular position and orbital angular momentum may find important applications in quantum information science.",2010,42,414,3,4,24,30,26,38,33,38,27,52,55
768980f65528c8bad41bc6cdf0d3b0eef8934d65,"The occupation of d orbitals controls the magnitude and anisotropy of the inter-atomic electron transfer in transition-metal oxides and hence exerts a key influence on their chemical bonding and physical properties. Atomic-scale modulations of the orbital occupation at surfaces and interfaces are believed to be responsible for massive variations of the magnetic and transport properties, but could not thus far be probed in a quantitative manner. Here we show that it is possible to derive quantitative, spatially resolved orbital polarization profiles from soft-X-ray reflectivity data, without resorting to model calculations. We demonstrate that the method is sensitive enough to resolve differences of ~3% in the occupation of Ni e(g) orbitals in adjacent atomic layers of a LaNiO(3)-LaAlO(3) superlattice, in good agreement with ab initio electronic-structure calculations. The possibility to quantitatively correlate theory and experiment on the atomic scale opens up many new perspectives for orbital physics in transition-metal oxides.",2010,41,152,5,0,5,10,9,17,15,18,15,17,15
d1620666ba23d4bce8c3035a87d06f5277819cc3,"Measurement of the quantum-mechanical phase in quantum matter provides the most direct manifestation of the underlying abstract physics. We used resonant x-ray scattering to probe the relative phases of constituent atomic orbitals in an electronic wave function, which uncovers the unconventional Mott insulating state induced by relativistic spin-orbit coupling in the layered 5d transition metal oxide Sr2IrO4. A selection rule based on intra-atomic interference effects establishes a complex spin-orbital state represented by an effective total angular momentum = 1/2 quantum number, the phase of which can lead to a quantum topological state of matter.",2009,11,642,18,5,10,20,32,47,45,56,54,56,94
411be93d0ae3ff9fbf174bd4de4f11e3203b8a77,"In iron pnictides, we find that the moderate electron-phonon interaction due to the Fe-ion oscillation can induce the critical d-orbital fluctuations, without being prohibited by the Coulomb interaction. These fluctuations give rise to the strong pairing interaction for the s-wave superconducting (SC) state without sign reversal (s(++)-wave state), which is consistent with experimentally observed robustness of superconductivity against impurities. When the magnetic fluctuations due to Coulomb interaction are also strong, the SC state shows a smooth crossover from the s-wave state with sign reversal (s(+/-)-wave state) to the s(++)-wave state as impurity concentration increases.",2009,0,377,6,2,9,32,46,40,46,38,41,34,36
cf335ec147d76c16e49263d17c388814290a35fc,"This review provides a perspective on the use of orbital-dependent functionals, which is currently considered one of the most promising avenues in modern density-functional theory. The focus here is on four major themes: the motivation for orbital-dependent functionals in terms of limitations of semilocal functionals; the optimized effective potential as a rigorous approach to incorporating orbital-dependent functionals within the Kohn-Sham framework; the rationale behind and advantages and limitations of four popular classes of orbital-dependent functionals; and the use of orbital-dependent functionals for predicting excited-state properties. For each of these issues, both formal and practical aspects are assessed.",2008,527,734,8,25,50,38,68,56,64,72,71,61,45
c9d24e78b2bdc2ddfe89144e020846610cdfcefd,"ABSTRACT. We analyze 8 years of precise radial velocity measurements from the Keck Planet Search, characterizing the detection threshold, selection effects, and completeness of the survey. We first carry out a systematic search for planets, by assessing the false-alarm probability associated with Keplerian orbit fits to the data. This allows us to understand the detection threshold for each star in terms of the number and time baseline of the observations, and the underlying “noise” from measurement errors, intrinsic stellar jitter, or additional low-mass planets. We show that all planets with orbital periods P   20 m s-1 K > 20 m s - 1 , and eccentricities e ≲ 0.6 e ≲ 0.6 have been announced, and we summarize the candidates at lower amplitudes and longer orbital periods. For the remaining stars, we calculate upper limits on the velocity amplitude of a companion. For orbital periods less than the duration of the observations, these are typically ...",2008,91,611,154,22,38,56,37,51,43,46,47,49,47
7a725f13577e44f5f39e262ceebc55d0316e6853,"For an isolated quantum particle, such as an electron, the orbital (L) and spin (S) magnetic moments can change provided that the total angular momentum of the particle is conserved. In condensed matter, an efficient transfer between L and S can occur owing to the spin–orbit interaction, which originates in the relativistic motion of electrons. Disentangling the absolute contributions of the orbital and spin angular momenta is challenging, however, as any transfer between the two occurs on femtosecond timescales. Here we investigate such phenomena by using ultrashort optical laser pulses to change the magnetization of a ferromagnetic film and then probe its dynamics with circularly polarized femtosecond X-ray pulses. Our measurements enable us to disentangle the spin and orbital components of the magnetic moment, revealing different dynamics for L and S. We highlight the important role played by the spin–orbit interaction in the ultrafast laser-induced demagnetization of ferromagnetic films, and show also that the magneto-crystalline anisotropy energy is an important quantity to consider in such processes. Our study provides insights into the dynamics in magnetic systems as well as perspectives for the ultrafast control of information in magnetic recording media.",2010,38,297,4,2,19,20,31,26,29,30,24,28,32
45524fd482e1e348a63c2d146a55a77d6ce36608,"The control of charge transport in an active electronic device depends intimately on the modulation of the internal charge density by an external node. For example, a field-effect transistor relies on the gated electrostatic modulation of the channel charge produced by changing the relative position of the conduction and valence bands with respect to the electrodes. In molecular-scale devices, a longstanding challenge has been to create a true three-terminal device that operates in this manner (that is, by modifying orbital energy). Here we report the observation of such a solid-state molecular device, in which transport current is directly modulated by an external gate voltage. Resonance-enhanced coupling to the nearest molecular orbital is revealed by electron tunnelling spectroscopy, demonstrating direct molecular orbital gating in an electronic device. Our findings demonstrate that true molecular transistors can be created, and so enhance the prospects for molecularly engineered electronic devices.",2009,35,585,8,3,29,65,55,56,74,63,51,45,49
0e15715debd0a700242264e06f84fd9e37ac86a3,"We show numerically that vector antenna arrays can generate radio beams that exhibit spin and orbital angular momentum characteristics similar to those of helical Laguerre-Gauss laser beams in paraxial optics. For low frequencies (< or = 1 GHz), digital techniques can be used to coherently measure the instantaneous, local field vectors and to manipulate them in software. This enables new types of experiments that go beyond what is possible in optics. It allows information-rich radio astronomy and paves the way for novel wireless communication concepts.",2007,59,698,31,2,6,9,7,12,17,17,45,44,78
af174b8b4484dd8657819d20baed7995de17bcdb,"We predict a new category of optical orbital angular momentum that is associated with the curl of polarization and a kind of vector field with radial-variant hybrid states of polarization that can carry such novel optical orbital angular momentum. We present a scheme for creating the desired vector fields. Optical trapping experiments validate that the vector fields, which have no additional phase vortex, exert torques to drive the orbital motion of the trapped isotropic microspheres.",2010,12,161,3,0,6,14,7,12,13,20,18,15,20
6e62526fba615f7e3d0f49711a41fd6047be4b5f,"The structure of the human orbital and medial prefrontal cortex (OMPFC) was investigated using five histological and immunohistochemical stains and was correlated with a previous analysis in macaque monkeys [Carmichael and Price ( 1994 ) J. Comp. Neurol. 346:366–402]. A cortical area was recognized if it was distinct with at least two stains and was found in similar locations in different brains. All of the areas recognized in the macaque OMPFC have counterparts in humans. Areas 11, 13, and 14 were subdivided into areas 11m, 11l, 13a, 13b, 13m, 13l, 14r, and 14c. Within area 10, the region corresponding to area 10m in monkeys was divided into 10m and 10r, and area 10o (orbital) was renamed area 10p (polar). Areas 47/12r, 47/12m, 47/12l, and 47/12s occupy the lateral orbital cortex, corresponding to monkey areas 12r, 12m, 12l, and 12o. The agranular insula (areas Iam, Iapm, Iai, and Ial) extends onto the caudal orbital surface and into the horizontal ramus of the lateral sulcus. The growth of the frontal pole in humans has pushed area 25 and area 32pl, which corresponds to the prelimbic area 32 in Brodmann's monkey brain map, caudal and ventral to the genu of the corpus callosum. Anterior cingulate areas 24a and 24b also extend ventral to the genu of the corpus callosum. Area 32ac, corresponding to the dorsal anterior cingulate area 32 in Brodmann's human brain map, is anterior and dorsal to the genu. The parallel organization of the OMPFC in monkeys and humans allows experimental data from monkeys to be applied to studies of the human cortex. J. Comp. Neurol. 460:425–449, 2003. © 2003 Wiley‐Liss, Inc.",2003,76,858,62,9,9,31,34,47,42,58,52,65,51
6479c0e44ab143679d2337e9b726d6196d8dfa0b,"Geochemical models for Mars predict carbonate formation during aqueous alteration. Carbonate-bearing rocks had not previously been detected on Mars' surface, but Mars Reconnaissance Orbiter mapping reveals a regional rock layer with near-infrared spectral characteristics that are consistent with the presence of magnesium carbonate in the Nili Fossae region. The carbonate is closely associated with both phyllosilicate-bearing and olivine-rich rock units and probably formed during the Noachian or early Hesperian era from the alteration of olivine by either hydrothermal fluids or near-surface water. The presence of carbonate as well as accompanying clays suggests that waters were neutral to alkaline at the time of its formation and that acidic weathering, proposed to be characteristic of Hesperian Mars, did not destroy these carbonates and thus did not dominate all aqueous environments.",2008,89,516,18,2,31,49,39,49,56,39,38,29,36
8b75af5b595e3402c77aa438f926ad3dba9fde17,"Orbital mechanics is a cornerstone subject for aerospace engineering students. Maintaining the focus of the first edition, the author provides the foundation needed to understand the subject and proceed to advanced topics. Starting with the solution of the two-body problem and formulas for the different kinds of orbits, the text moves on to Kepler's equations, orbits in three dimensions, orbital elements from observations, orbital maneuvers, orbital rendezvous and interplanetary missions. This is followed by an introduction to spacecraft dynamics and a final chapter on basic rocket dynamics. The author's teach-by-example approach emphasizes the analytical procedures and computer-implemented algorithms required by today's students. There are a large number of worked examples, illustrations, end of chapter exercises (with answers) as well as many MATLAB[registered] programs for use in homework and projects. The text can be used for one and two semester courses in space mechanics. Features: a new section on numerical integration methods applicable to space mechanics problems; a more centralized and improved discussion of coordinate systems and Euler angle sequences; an expanded development of relative motion in orbit; a new section on quaternions; new worked-out examples, illustrations and homework problems; new algorithms, MATLAB[registered] scripts and simulations; instructor's manual and lecture slides available online; and included online testing and assessment component helps students assess their knowledge of the topics.",2005,0,745,81,1,2,6,5,19,19,31,50,54,71
56677386dc3d3ecd1f51a292810a648bc68da1db,"The theoretical need to study the properties of the Fe-based high-Tc superconductors using reliable manybody techniques has highlighted the importance of determining what is the minimum number of orbital degrees of freedom that will capture the physics of these materials. While the shape of the Fermi surface FS obtained with the local-density approximation LDA can be reproduced by a two-orbital model, it has been argued that the bands that cross the chemical potential result from the strong hybridization of three of the Fe 3d orbitals. For this reason, a three orbital Hamiltonian for LaOFeAs obtained with the Slater-Koster formalism by considering the hybridization of the As p orbitals with the Fe dxz, dyz, and dxy orbitals is discussed here. This model reproduces qualitatively the FS shape and orbital composition obtained by LDA calculations for undoped LaOFeAs when four electrons per Fe are considered. Within a mean-field approximation, its magnetic and orbital properties in the undoped case are here described for intermediate values of J/U. Increasing the Coulomb repulsion U at zero temperature, four different regimes are obtained: 1 paramagnetic, 2 magnetic ,0 spin order, 3 the same ,0 spin order but now including orbital order, and finally 4 a magneticmore » and orbital ordered insulator. The spin-singlet pairing operators allowed by the lattice and orbital symmetries are also constructed. It is found that for pairs of electrons involving up to diagonal nearest-neighbors sites, the only fully gapped and purely intraband spin-singlet pairing operator is given by k= fkdk,, d k,, with fk=1 or cos kx cos ky which would arise only if the electrons in all different orbitals couple with equal strength to the source of pairing.« less",2009,2,123,4,1,5,8,12,17,12,17,11,9,10
5c2fb477ca3d7c3deb916e2722e15aaa21c28cb0,"In systems with strong electron-lattice coupling, such as manganites, orbital degeneracy is lifted, causing a null expectation value of the orbital magnetic moment. Magnetic structure is thus determined by spin-spin superexchange. In titanates, however, with much smaller Jahn-Teller distortions, orbital degeneracy might allow non-zero values of the orbital magnetic moment, and novel forms of ferromagnetic superexchange interaction unique to t(2g) electron systems have been theoretically predicted, although their experimental observation has remained elusive. In this paper, we report a new kind of Ti(3+) ferromagnetism at LaMnO(3)/SrTiO(3) epitaxial interfaces. It results from charge transfer to the empty conduction band of the titanate and has spin and orbital contributions evidencing the role of orbital degeneracy. The possibility of tuning magnetic alignment (ferromagnetic or antiferromagnetic) of Ti and Mn moments by structural parameters is demonstrated. This result will provide important clues for understanding the effects of orbital degeneracy in superexchange coupling.",2010,44,121,0,0,5,5,14,11,15,11,14,9,15
9b6fa3a9362cc3380185a7933d7982b874527230,"This paper reviews architectonic subdivisions and connections of the orbital and medial prefrontal cortex (OMPFC) in rats, monkeys and humans. Cortico-cortical connections provide the basis for recognition of 'medial' and 'orbital' networks within the OMPFC. These networks also have distinct connections with structures in other parts of the brain. The orbital network receives sensory inputs from several modalities, including olfaction, taste, visceral afferents, somatic sensation and vision, which appear to be especially related to food or eating. In contrast, the medial network provides the major cortical output to visceromotor structures in the hypothalamus and brainstem. The two networks have distinct connections with areas of the striatum and mediodorsal thalamus. In particular, projections to the nucleus accumbens and the adjacent ventromedial caudate and putamen arise predominantly from the medial network. Both networks also have extensive connections with limbic structures. Based on these and other observations, the OMPFC appears to function as a sensory-visceromotor link, especially for eating. This linkage appears to be critical for the guidance of reward-related behavior and for setting of mood. Imaging and histological observations on human brains indicate that clinical depressive disorders are associated with specific functional and cellular changes in the OMPFC, including activity and volume changes, and specific changes in the number of glial cells.",2000,133,2452,143,6,18,51,61,67,72,81,98,128,152
aaea825be9afc25ee2d6d7f279030d0711fa656f,"Entangled quantum states are not separable, regardless of the spatial separation of their components. This is a manifestation of an aspect of quantum mechanics known as quantum non-locality. An important consequence of this is that the measurement of the state of one particle in a two-particle entangled state defines the state of the second particle instantaneously, whereas neither particle possesses its own well-defined state before the measurement. Experimental realizations of entanglement have hitherto been restricted to two-state quantum systems, involving, for example, the two orthogonal polarization states of photons. Here we demonstrate entanglement involving the spatial modes of the electromagnetic field carrying orbital angular momentum. As these modes can be used to define an infinitely dimensional discrete Hilbert space, this approach provides a practical route to entanglement that involves many orthogonal quantum states, rather than just two Multi-dimensional entangled states could be of considerable importance in the field of quantum information, enabling, for example, more efficient use of communication channels in quantum cryptography.",2001,26,2257,31,4,13,24,54,49,52,55,60,75,64
a5c8d98d25da1770770d58ea53f51d614e44339f,"A high-resolution deuterium profile is now available along the entire European Project for Ice Coring in Antarctica Dome C ice core, extending this climate record back to marine isotope stage 20.2, ∼800,000 years ago. Experiments performed with an atmospheric general circulation model including water isotopes support its temperature interpretation. We assessed the general correspondence between Dansgaard-Oeschger events and their smoothed Antarctic counterparts for this Dome C record, which reveals the presence of such features with similar amplitudes during previous glacial periods. We suggest that the interplay between obliquity and precession accounts for the variable intensity of interglacial periods in ice core records.",2007,43,1774,71,21,45,75,120,120,121,134,140,134,127
6a145d8e7158476d0930c679a8777872928426af,"We demonstrate the transfer of information encoded as orbital angular momentum (OAM) states of a light beam. The transmitter and receiver units are based on spatial light modulators, which prepare or measure a laser beam in one of eight pure OAM states. We show that the information encoded in this way is resistant to eavesdropping in the sense that any attempt to sample the beam away from its axis will be subject to an angular restriction and a lateral offset, both of which result in inherent uncertainty in the measurement. This gives an experimental insight into the effects of aperturing and misalignment of the beam on the OAM measurement and demonstrates the uncertainty relationship for OAM.",2004,16,1792,14,2,12,22,26,30,38,46,71,93,120
c4950fc9bb26369182bcd30a863782cc873d71f1,"We demonstrate experimentally an optical process in which the spin angular momentum carried by a circularly polarized light beam is converted into orbital angular momentum, leading to the generation of helical modes with a wave-front helicity controlled by the input polarization. This phenomenon requires the interaction of light with matter that is both optically inhomogeneous and anisotropic. The underlying physics is also associated with the so-called Pancharatnam-Berry geometrical phases involved in any inhomogeneous transformation of the optical polarization.",2006,73,1319,18,1,10,14,21,26,36,47,57,92,110
74569b70f1d283bc43e07f3a078250677c89a5b6,"An electron in a solid, that is, bound to or nearly localized on the specific atomic site, has three attributes: charge, spin, and orbital. The orbital represents the shape of the electron cloud in solid. In transition-metal oxides with anisotropic-shaped d-orbital electrons, the Coulomb interaction between the electrons (strong electron correlation effect) is of importance for understanding their metal-insulator transitions and properties such as high-temperature superconductivity and colossal magnetoresistance. The orbital degree of freedom occasionally plays an important role in these phenomena, and its correlation and/or order-disorder transition causes a variety of phenomena through strong coupling with charge, spin, and lattice dynamics. An overview is given here on this ""orbital physics,"" which will be a key concept for the science and technology of correlated electrons.",2000,60,1553,7,6,26,54,65,61,82,70,66,69,53
c13e0d603a39430565ed7cb94ab5add3da5b280a,"This graduate-level text presents the first comprehensive overview of modern chemical valency and bonding theory, written by internationally recognized experts in the field. The authors build on the foundation of Lewisand Pauling-like localized structural and hybridization concepts to present a book that is directly based on current ab initio computational technology. The presentation is highly visual and intuitive throughout, being based on the recognizable and transferable graphical forms of natural bond orbitals (NBOs) and their spatial overlaps in the molecular environment. The book shows applications to a broad range of molecular and supramolecular species of organic, inorganic, and bioorganic interest. Hundreds of orbital illustrations help to convey the essence of modern NBO concepts in a facile manner for those with no extensive background in the mathematical machinery of the Schrödinger equation. This book will appeal to those studying chemical bonding in relation to chemistry, chemical engineering, biochemistry, and physics.",2005,1,1353,58,1,21,32,45,40,44,57,76,126,141
ddf1415e591f9637cc53dec22f6d4097ba05efc4,"We present a method to efficiently sort orbital angular momentum (OAM) states of light using two static optical elements. The optical elements perform a Cartesian to log-polar coordinate transformation, converting the helically phased light beam corresponding to OAM states into a beam with a transverse phase gradient. A subsequent lens then focuses each input OAM state to a different lateral position. We demonstrate the concept experimentally by using two spatial light modulators to create the desired optical elements, applying it to the separation of eleven OAM states.",2010,0,682,12,3,23,37,45,48,39,80,68,95,92
3d28ee266ac532ca0177a11b69f0bab556e8e4b8,"Recent discoveries concerning rotating (helical) phase fronts and orbital angular momentum (OAM) of laser beams are applied to radio frequencies and comprehensive simulations of a radio OAM system are performed. We find that with the use of vector field-sensing electric and magnetic triaxial antennas, it is possible to unambiguously estimate the OAM in radio beams by local measurements at a single point, assuming ideal (noiseless) conditions and that the beam axis is known. Furthermore, we show that conventional antenna pattern optimization methods can be applied to OAM-generating circular arrays to enhance their directivity.",2010,29,523,34,1,3,9,13,30,26,55,68,87,97
0dcaea1e332d723c98595308c3e6b79260794610,"For extrasolar planets discovered using the radial velocity method, the spectral characterization of the host star leads to a mass estimate of the star and subsequently of the orbiting planet. If the orbital velocity of the planet could be determined, the masses of both star and planet could be calculated using Newton’s law of gravity, just as in the case of stellar double-line eclipsing binaries. Here we report high-dispersion ground-based spectroscopy of a transit of the extrasolar planet HD 209458b. We see a significant wavelength shift in absorption lines from carbon monoxide in the planet’s atmosphere, which we conclude arises from a change in the radial component of the planet’s orbital velocity. The masses of the star and planet are 1.00 ± 0.22MSun and 0.64 ± 0.09MJup respectively. A blueshift of the carbon monoxide signal of approximately 2 km s−1 with respect to the systemic velocity of the host star suggests the presence of a strong wind flowing from the irradiated dayside to the non-irradiated nightside of the planet within the 0.01–0.1 mbar atmospheric pressure range probed by these observations. The strength of the carbon monoxide signal suggests a carbon monoxide mixing ratio of (1–3) × 10−3 in this planet’s upper atmosphere.",2010,26,443,41,10,28,23,33,39,32,37,45,46,50
02640f28ab5c2fe5a883c855fd0bc77505b48a00,"Planetary formation theories suggest that the giant planets formed on circular and coplanar orbits. The eccentricities of Jupiter, Saturn and Uranus, however, reach values of 6 per cent, 9 per cent and 8 per cent, respectively. In addition, the inclinations of the orbital planes of Saturn, Uranus and Neptune take maximum values of ∼2 degrees with respect to the mean orbital plane of Jupiter. Existing models for the excitation of the eccentricity of extrasolar giant planets have not been successfully applied to the Solar System. Here we show that a planetary system with initial quasi-circular, coplanar orbits would have evolved to the current orbital configuration, provided that Jupiter and Saturn crossed their 1:2 orbital resonance. We show that this resonance crossing could have occurred as the giant planets migrated owing to their interaction with a disk of planetesimals. Our model reproduces all the important characteristics of the giant planets' orbits, namely their final semimajor axes, eccentricities and mutual inclinations.",2005,59,1099,103,16,30,44,46,82,61,80,66,64,96
68d9db61afa6f2e179b162e8929946d938a5bc8a,"All forms of waves can contain phase singularities. In the case of optical waves, a light beam with a phase singularity carries orbital angular momentum, and such beams have found a range of applications in optical manipulation, quantum information and astronomy. Here we report the generation of an electron beam with a phase singularity propagating in free space, which we achieve by passing a plane electron wave through a spiral phase plate constructed naturally from a stack of graphite thin films. The interference pattern between the final beam and a plane electron wave in a transmission electron microscope shows the ‘Y’-like defect pattern characteristic of a beam carrying a phase singularity with a topological charge equal to one. This fundamentally new electron degree of freedom could find application in a number of research areas, as is the case for polarized electron beams.",2010,28,455,7,4,13,25,26,41,35,33,54,56,64
b57fe8cdc49f84ee230c4696aa81d8aa3e2a5ba5,"Entanglement in a Twist The strong correlations observed in quantum mechanically entangled particles, such as photons, offer potential for secure communication and quantum information processing. Leach et al. (p. 662) now show such strong quantum correlations between the complementary variables—angular position and orbital angular momentum—of two photons created during the parametric down-conversion process in a nonlinear crystal. This demonstration of entanglement in an angular basis establishes that angles are genuine quantum observables and can therefore be considered a resource for quantum information processing, capable of secure, high-dimension, key distribution. Strong quantum correlations are induced between the angular position and angular momentum of two photons. Entanglement of the properties of two separated particles constitutes a fundamental signature of quantum mechanics and is a key resource for quantum information science. We demonstrate strong Einstein, Podolsky, and Rosen correlations between the angular position and orbital angular momentum of two photons created by the nonlinear optical process of spontaneous parametric down-conversion. The discrete nature of orbital angular momentum and the continuous but periodic nature of angular position give rise to a special sort of entanglement between these two variables. The resulting correlations are found to be an order of magnitude stronger than those allowed by the uncertainty principle for independent (nonentangled) particles. Our results suggest that angular position and orbital angular momentum may find important applications in quantum information science.",2010,42,414,3,4,24,30,26,38,33,38,27,52,55
768980f65528c8bad41bc6cdf0d3b0eef8934d65,"The occupation of d orbitals controls the magnitude and anisotropy of the inter-atomic electron transfer in transition-metal oxides and hence exerts a key influence on their chemical bonding and physical properties. Atomic-scale modulations of the orbital occupation at surfaces and interfaces are believed to be responsible for massive variations of the magnetic and transport properties, but could not thus far be probed in a quantitative manner. Here we show that it is possible to derive quantitative, spatially resolved orbital polarization profiles from soft-X-ray reflectivity data, without resorting to model calculations. We demonstrate that the method is sensitive enough to resolve differences of ~3% in the occupation of Ni e(g) orbitals in adjacent atomic layers of a LaNiO(3)-LaAlO(3) superlattice, in good agreement with ab initio electronic-structure calculations. The possibility to quantitatively correlate theory and experiment on the atomic scale opens up many new perspectives for orbital physics in transition-metal oxides.",2010,41,152,5,0,5,10,9,17,15,18,15,17,15
d1620666ba23d4bce8c3035a87d06f5277819cc3,"Measurement of the quantum-mechanical phase in quantum matter provides the most direct manifestation of the underlying abstract physics. We used resonant x-ray scattering to probe the relative phases of constituent atomic orbitals in an electronic wave function, which uncovers the unconventional Mott insulating state induced by relativistic spin-orbit coupling in the layered 5d transition metal oxide Sr2IrO4. A selection rule based on intra-atomic interference effects establishes a complex spin-orbital state represented by an effective total angular momentum = 1/2 quantum number, the phase of which can lead to a quantum topological state of matter.",2009,11,642,18,5,10,20,32,47,45,56,54,56,94
411be93d0ae3ff9fbf174bd4de4f11e3203b8a77,"In iron pnictides, we find that the moderate electron-phonon interaction due to the Fe-ion oscillation can induce the critical d-orbital fluctuations, without being prohibited by the Coulomb interaction. These fluctuations give rise to the strong pairing interaction for the s-wave superconducting (SC) state without sign reversal (s(++)-wave state), which is consistent with experimentally observed robustness of superconductivity against impurities. When the magnetic fluctuations due to Coulomb interaction are also strong, the SC state shows a smooth crossover from the s-wave state with sign reversal (s(+/-)-wave state) to the s(++)-wave state as impurity concentration increases.",2009,0,377,6,2,9,32,46,40,46,38,41,34,36
cf335ec147d76c16e49263d17c388814290a35fc,"This review provides a perspective on the use of orbital-dependent functionals, which is currently considered one of the most promising avenues in modern density-functional theory. The focus here is on four major themes: the motivation for orbital-dependent functionals in terms of limitations of semilocal functionals; the optimized effective potential as a rigorous approach to incorporating orbital-dependent functionals within the Kohn-Sham framework; the rationale behind and advantages and limitations of four popular classes of orbital-dependent functionals; and the use of orbital-dependent functionals for predicting excited-state properties. For each of these issues, both formal and practical aspects are assessed.",2008,527,734,8,25,50,38,68,56,64,72,71,61,45
c9d24e78b2bdc2ddfe89144e020846610cdfcefd,"ABSTRACT. We analyze 8 years of precise radial velocity measurements from the Keck Planet Search, characterizing the detection threshold, selection effects, and completeness of the survey. We first carry out a systematic search for planets, by assessing the false-alarm probability associated with Keplerian orbit fits to the data. This allows us to understand the detection threshold for each star in terms of the number and time baseline of the observations, and the underlying “noise” from measurement errors, intrinsic stellar jitter, or additional low-mass planets. We show that all planets with orbital periods P   20 m s-1 K > 20 m s - 1 , and eccentricities e ≲ 0.6 e ≲ 0.6 have been announced, and we summarize the candidates at lower amplitudes and longer orbital periods. For the remaining stars, we calculate upper limits on the velocity amplitude of a companion. For orbital periods less than the duration of the observations, these are typically ...",2008,91,611,154,22,38,56,37,51,43,46,47,49,47
7a725f13577e44f5f39e262ceebc55d0316e6853,"For an isolated quantum particle, such as an electron, the orbital (L) and spin (S) magnetic moments can change provided that the total angular momentum of the particle is conserved. In condensed matter, an efficient transfer between L and S can occur owing to the spin–orbit interaction, which originates in the relativistic motion of electrons. Disentangling the absolute contributions of the orbital and spin angular momenta is challenging, however, as any transfer between the two occurs on femtosecond timescales. Here we investigate such phenomena by using ultrashort optical laser pulses to change the magnetization of a ferromagnetic film and then probe its dynamics with circularly polarized femtosecond X-ray pulses. Our measurements enable us to disentangle the spin and orbital components of the magnetic moment, revealing different dynamics for L and S. We highlight the important role played by the spin–orbit interaction in the ultrafast laser-induced demagnetization of ferromagnetic films, and show also that the magneto-crystalline anisotropy energy is an important quantity to consider in such processes. Our study provides insights into the dynamics in magnetic systems as well as perspectives for the ultrafast control of information in magnetic recording media.",2010,38,297,4,2,19,20,31,26,29,30,24,28,32
45524fd482e1e348a63c2d146a55a77d6ce36608,"The control of charge transport in an active electronic device depends intimately on the modulation of the internal charge density by an external node. For example, a field-effect transistor relies on the gated electrostatic modulation of the channel charge produced by changing the relative position of the conduction and valence bands with respect to the electrodes. In molecular-scale devices, a longstanding challenge has been to create a true three-terminal device that operates in this manner (that is, by modifying orbital energy). Here we report the observation of such a solid-state molecular device, in which transport current is directly modulated by an external gate voltage. Resonance-enhanced coupling to the nearest molecular orbital is revealed by electron tunnelling spectroscopy, demonstrating direct molecular orbital gating in an electronic device. Our findings demonstrate that true molecular transistors can be created, and so enhance the prospects for molecularly engineered electronic devices.",2009,35,585,8,3,29,65,55,56,74,63,51,45,49
0e15715debd0a700242264e06f84fd9e37ac86a3,"We show numerically that vector antenna arrays can generate radio beams that exhibit spin and orbital angular momentum characteristics similar to those of helical Laguerre-Gauss laser beams in paraxial optics. For low frequencies (< or = 1 GHz), digital techniques can be used to coherently measure the instantaneous, local field vectors and to manipulate them in software. This enables new types of experiments that go beyond what is possible in optics. It allows information-rich radio astronomy and paves the way for novel wireless communication concepts.",2007,59,698,31,2,6,9,7,12,17,17,45,44,78
af174b8b4484dd8657819d20baed7995de17bcdb,"We predict a new category of optical orbital angular momentum that is associated with the curl of polarization and a kind of vector field with radial-variant hybrid states of polarization that can carry such novel optical orbital angular momentum. We present a scheme for creating the desired vector fields. Optical trapping experiments validate that the vector fields, which have no additional phase vortex, exert torques to drive the orbital motion of the trapped isotropic microspheres.",2010,12,161,3,0,6,14,7,12,13,20,18,15,20
6e62526fba615f7e3d0f49711a41fd6047be4b5f,"The structure of the human orbital and medial prefrontal cortex (OMPFC) was investigated using five histological and immunohistochemical stains and was correlated with a previous analysis in macaque monkeys [Carmichael and Price ( 1994 ) J. Comp. Neurol. 346:366–402]. A cortical area was recognized if it was distinct with at least two stains and was found in similar locations in different brains. All of the areas recognized in the macaque OMPFC have counterparts in humans. Areas 11, 13, and 14 were subdivided into areas 11m, 11l, 13a, 13b, 13m, 13l, 14r, and 14c. Within area 10, the region corresponding to area 10m in monkeys was divided into 10m and 10r, and area 10o (orbital) was renamed area 10p (polar). Areas 47/12r, 47/12m, 47/12l, and 47/12s occupy the lateral orbital cortex, corresponding to monkey areas 12r, 12m, 12l, and 12o. The agranular insula (areas Iam, Iapm, Iai, and Ial) extends onto the caudal orbital surface and into the horizontal ramus of the lateral sulcus. The growth of the frontal pole in humans has pushed area 25 and area 32pl, which corresponds to the prelimbic area 32 in Brodmann's monkey brain map, caudal and ventral to the genu of the corpus callosum. Anterior cingulate areas 24a and 24b also extend ventral to the genu of the corpus callosum. Area 32ac, corresponding to the dorsal anterior cingulate area 32 in Brodmann's human brain map, is anterior and dorsal to the genu. The parallel organization of the OMPFC in monkeys and humans allows experimental data from monkeys to be applied to studies of the human cortex. J. Comp. Neurol. 460:425–449, 2003. © 2003 Wiley‐Liss, Inc.",2003,76,858,62,9,9,31,34,47,42,58,52,65,51
6479c0e44ab143679d2337e9b726d6196d8dfa0b,"Geochemical models for Mars predict carbonate formation during aqueous alteration. Carbonate-bearing rocks had not previously been detected on Mars' surface, but Mars Reconnaissance Orbiter mapping reveals a regional rock layer with near-infrared spectral characteristics that are consistent with the presence of magnesium carbonate in the Nili Fossae region. The carbonate is closely associated with both phyllosilicate-bearing and olivine-rich rock units and probably formed during the Noachian or early Hesperian era from the alteration of olivine by either hydrothermal fluids or near-surface water. The presence of carbonate as well as accompanying clays suggests that waters were neutral to alkaline at the time of its formation and that acidic weathering, proposed to be characteristic of Hesperian Mars, did not destroy these carbonates and thus did not dominate all aqueous environments.",2008,89,516,18,2,31,49,39,49,56,39,38,29,36
8b75af5b595e3402c77aa438f926ad3dba9fde17,"Orbital mechanics is a cornerstone subject for aerospace engineering students. Maintaining the focus of the first edition, the author provides the foundation needed to understand the subject and proceed to advanced topics. Starting with the solution of the two-body problem and formulas for the different kinds of orbits, the text moves on to Kepler's equations, orbits in three dimensions, orbital elements from observations, orbital maneuvers, orbital rendezvous and interplanetary missions. This is followed by an introduction to spacecraft dynamics and a final chapter on basic rocket dynamics. The author's teach-by-example approach emphasizes the analytical procedures and computer-implemented algorithms required by today's students. There are a large number of worked examples, illustrations, end of chapter exercises (with answers) as well as many MATLAB[registered] programs for use in homework and projects. The text can be used for one and two semester courses in space mechanics. Features: a new section on numerical integration methods applicable to space mechanics problems; a more centralized and improved discussion of coordinate systems and Euler angle sequences; an expanded development of relative motion in orbit; a new section on quaternions; new worked-out examples, illustrations and homework problems; new algorithms, MATLAB[registered] scripts and simulations; instructor's manual and lecture slides available online; and included online testing and assessment component helps students assess their knowledge of the topics.",2005,0,745,81,1,2,6,5,19,19,31,50,54,71
56677386dc3d3ecd1f51a292810a648bc68da1db,"The theoretical need to study the properties of the Fe-based high-Tc superconductors using reliable manybody techniques has highlighted the importance of determining what is the minimum number of orbital degrees of freedom that will capture the physics of these materials. While the shape of the Fermi surface FS obtained with the local-density approximation LDA can be reproduced by a two-orbital model, it has been argued that the bands that cross the chemical potential result from the strong hybridization of three of the Fe 3d orbitals. For this reason, a three orbital Hamiltonian for LaOFeAs obtained with the Slater-Koster formalism by considering the hybridization of the As p orbitals with the Fe dxz, dyz, and dxy orbitals is discussed here. This model reproduces qualitatively the FS shape and orbital composition obtained by LDA calculations for undoped LaOFeAs when four electrons per Fe are considered. Within a mean-field approximation, its magnetic and orbital properties in the undoped case are here described for intermediate values of J/U. Increasing the Coulomb repulsion U at zero temperature, four different regimes are obtained: 1 paramagnetic, 2 magnetic ,0 spin order, 3 the same ,0 spin order but now including orbital order, and finally 4 a magneticmore » and orbital ordered insulator. The spin-singlet pairing operators allowed by the lattice and orbital symmetries are also constructed. It is found that for pairs of electrons involving up to diagonal nearest-neighbors sites, the only fully gapped and purely intraband spin-singlet pairing operator is given by k= fkdk,, d k,, with fk=1 or cos kx cos ky which would arise only if the electrons in all different orbitals couple with equal strength to the source of pairing.« less",2009,2,123,4,1,5,8,12,17,12,17,11,9,10
5c2fb477ca3d7c3deb916e2722e15aaa21c28cb0,"In systems with strong electron-lattice coupling, such as manganites, orbital degeneracy is lifted, causing a null expectation value of the orbital magnetic moment. Magnetic structure is thus determined by spin-spin superexchange. In titanates, however, with much smaller Jahn-Teller distortions, orbital degeneracy might allow non-zero values of the orbital magnetic moment, and novel forms of ferromagnetic superexchange interaction unique to t(2g) electron systems have been theoretically predicted, although their experimental observation has remained elusive. In this paper, we report a new kind of Ti(3+) ferromagnetism at LaMnO(3)/SrTiO(3) epitaxial interfaces. It results from charge transfer to the empty conduction band of the titanate and has spin and orbital contributions evidencing the role of orbital degeneracy. The possibility of tuning magnetic alignment (ferromagnetic or antiferromagnetic) of Ti and Mn moments by structural parameters is demonstrated. This result will provide important clues for understanding the effects of orbital degeneracy in superexchange coupling.",2010,44,121,0,0,5,5,14,11,15,11,14,9,15
9b6fa3a9362cc3380185a7933d7982b874527230,"This paper reviews architectonic subdivisions and connections of the orbital and medial prefrontal cortex (OMPFC) in rats, monkeys and humans. Cortico-cortical connections provide the basis for recognition of 'medial' and 'orbital' networks within the OMPFC. These networks also have distinct connections with structures in other parts of the brain. The orbital network receives sensory inputs from several modalities, including olfaction, taste, visceral afferents, somatic sensation and vision, which appear to be especially related to food or eating. In contrast, the medial network provides the major cortical output to visceromotor structures in the hypothalamus and brainstem. The two networks have distinct connections with areas of the striatum and mediodorsal thalamus. In particular, projections to the nucleus accumbens and the adjacent ventromedial caudate and putamen arise predominantly from the medial network. Both networks also have extensive connections with limbic structures. Based on these and other observations, the OMPFC appears to function as a sensory-visceromotor link, especially for eating. This linkage appears to be critical for the guidance of reward-related behavior and for setting of mood. Imaging and histological observations on human brains indicate that clinical depressive disorders are associated with specific functional and cellular changes in the OMPFC, including activity and volume changes, and specific changes in the number of glial cells.",2000,133,2452,143,6,18,51,61,67,72,81,98,128,152
aaea825be9afc25ee2d6d7f279030d0711fa656f,"Entangled quantum states are not separable, regardless of the spatial separation of their components. This is a manifestation of an aspect of quantum mechanics known as quantum non-locality. An important consequence of this is that the measurement of the state of one particle in a two-particle entangled state defines the state of the second particle instantaneously, whereas neither particle possesses its own well-defined state before the measurement. Experimental realizations of entanglement have hitherto been restricted to two-state quantum systems, involving, for example, the two orthogonal polarization states of photons. Here we demonstrate entanglement involving the spatial modes of the electromagnetic field carrying orbital angular momentum. As these modes can be used to define an infinitely dimensional discrete Hilbert space, this approach provides a practical route to entanglement that involves many orthogonal quantum states, rather than just two Multi-dimensional entangled states could be of considerable importance in the field of quantum information, enabling, for example, more efficient use of communication channels in quantum cryptography.",2001,26,2257,31,4,13,24,54,49,52,55,60,75,64
a5c8d98d25da1770770d58ea53f51d614e44339f,"A high-resolution deuterium profile is now available along the entire European Project for Ice Coring in Antarctica Dome C ice core, extending this climate record back to marine isotope stage 20.2, ∼800,000 years ago. Experiments performed with an atmospheric general circulation model including water isotopes support its temperature interpretation. We assessed the general correspondence between Dansgaard-Oeschger events and their smoothed Antarctic counterparts for this Dome C record, which reveals the presence of such features with similar amplitudes during previous glacial periods. We suggest that the interplay between obliquity and precession accounts for the variable intensity of interglacial periods in ice core records.",2007,43,1774,71,21,45,75,120,120,121,134,140,134,127
6a145d8e7158476d0930c679a8777872928426af,"We demonstrate the transfer of information encoded as orbital angular momentum (OAM) states of a light beam. The transmitter and receiver units are based on spatial light modulators, which prepare or measure a laser beam in one of eight pure OAM states. We show that the information encoded in this way is resistant to eavesdropping in the sense that any attempt to sample the beam away from its axis will be subject to an angular restriction and a lateral offset, both of which result in inherent uncertainty in the measurement. This gives an experimental insight into the effects of aperturing and misalignment of the beam on the OAM measurement and demonstrates the uncertainty relationship for OAM.",2004,16,1792,14,2,12,22,26,30,38,46,71,93,120
c4950fc9bb26369182bcd30a863782cc873d71f1,"We demonstrate experimentally an optical process in which the spin angular momentum carried by a circularly polarized light beam is converted into orbital angular momentum, leading to the generation of helical modes with a wave-front helicity controlled by the input polarization. This phenomenon requires the interaction of light with matter that is both optically inhomogeneous and anisotropic. The underlying physics is also associated with the so-called Pancharatnam-Berry geometrical phases involved in any inhomogeneous transformation of the optical polarization.",2006,73,1319,18,1,10,14,21,26,36,47,57,92,110
74569b70f1d283bc43e07f3a078250677c89a5b6,"An electron in a solid, that is, bound to or nearly localized on the specific atomic site, has three attributes: charge, spin, and orbital. The orbital represents the shape of the electron cloud in solid. In transition-metal oxides with anisotropic-shaped d-orbital electrons, the Coulomb interaction between the electrons (strong electron correlation effect) is of importance for understanding their metal-insulator transitions and properties such as high-temperature superconductivity and colossal magnetoresistance. The orbital degree of freedom occasionally plays an important role in these phenomena, and its correlation and/or order-disorder transition causes a variety of phenomena through strong coupling with charge, spin, and lattice dynamics. An overview is given here on this ""orbital physics,"" which will be a key concept for the science and technology of correlated electrons.",2000,60,1553,7,6,26,54,65,61,82,70,66,69,53
c13e0d603a39430565ed7cb94ab5add3da5b280a,"This graduate-level text presents the first comprehensive overview of modern chemical valency and bonding theory, written by internationally recognized experts in the field. The authors build on the foundation of Lewisand Pauling-like localized structural and hybridization concepts to present a book that is directly based on current ab initio computational technology. The presentation is highly visual and intuitive throughout, being based on the recognizable and transferable graphical forms of natural bond orbitals (NBOs) and their spatial overlaps in the molecular environment. The book shows applications to a broad range of molecular and supramolecular species of organic, inorganic, and bioorganic interest. Hundreds of orbital illustrations help to convey the essence of modern NBO concepts in a facile manner for those with no extensive background in the mathematical machinery of the Schrödinger equation. This book will appeal to those studying chemical bonding in relation to chemistry, chemical engineering, biochemistry, and physics.",2005,1,1353,58,1,21,32,45,40,44,57,76,126,141
ddf1415e591f9637cc53dec22f6d4097ba05efc4,"We present a method to efficiently sort orbital angular momentum (OAM) states of light using two static optical elements. The optical elements perform a Cartesian to log-polar coordinate transformation, converting the helically phased light beam corresponding to OAM states into a beam with a transverse phase gradient. A subsequent lens then focuses each input OAM state to a different lateral position. We demonstrate the concept experimentally by using two spatial light modulators to create the desired optical elements, applying it to the separation of eleven OAM states.",2010,0,682,12,3,23,37,45,48,39,80,68,95,92
3d28ee266ac532ca0177a11b69f0bab556e8e4b8,"Recent discoveries concerning rotating (helical) phase fronts and orbital angular momentum (OAM) of laser beams are applied to radio frequencies and comprehensive simulations of a radio OAM system are performed. We find that with the use of vector field-sensing electric and magnetic triaxial antennas, it is possible to unambiguously estimate the OAM in radio beams by local measurements at a single point, assuming ideal (noiseless) conditions and that the beam axis is known. Furthermore, we show that conventional antenna pattern optimization methods can be applied to OAM-generating circular arrays to enhance their directivity.",2010,29,523,34,1,3,9,13,30,26,55,68,87,97
0dcaea1e332d723c98595308c3e6b79260794610,"For extrasolar planets discovered using the radial velocity method, the spectral characterization of the host star leads to a mass estimate of the star and subsequently of the orbiting planet. If the orbital velocity of the planet could be determined, the masses of both star and planet could be calculated using Newton’s law of gravity, just as in the case of stellar double-line eclipsing binaries. Here we report high-dispersion ground-based spectroscopy of a transit of the extrasolar planet HD 209458b. We see a significant wavelength shift in absorption lines from carbon monoxide in the planet’s atmosphere, which we conclude arises from a change in the radial component of the planet’s orbital velocity. The masses of the star and planet are 1.00 ± 0.22MSun and 0.64 ± 0.09MJup respectively. A blueshift of the carbon monoxide signal of approximately 2 km s−1 with respect to the systemic velocity of the host star suggests the presence of a strong wind flowing from the irradiated dayside to the non-irradiated nightside of the planet within the 0.01–0.1 mbar atmospheric pressure range probed by these observations. The strength of the carbon monoxide signal suggests a carbon monoxide mixing ratio of (1–3) × 10−3 in this planet’s upper atmosphere.",2010,26,443,41,10,28,23,33,39,32,37,45,46,50
02640f28ab5c2fe5a883c855fd0bc77505b48a00,"Planetary formation theories suggest that the giant planets formed on circular and coplanar orbits. The eccentricities of Jupiter, Saturn and Uranus, however, reach values of 6 per cent, 9 per cent and 8 per cent, respectively. In addition, the inclinations of the orbital planes of Saturn, Uranus and Neptune take maximum values of ∼2 degrees with respect to the mean orbital plane of Jupiter. Existing models for the excitation of the eccentricity of extrasolar giant planets have not been successfully applied to the Solar System. Here we show that a planetary system with initial quasi-circular, coplanar orbits would have evolved to the current orbital configuration, provided that Jupiter and Saturn crossed their 1:2 orbital resonance. We show that this resonance crossing could have occurred as the giant planets migrated owing to their interaction with a disk of planetesimals. Our model reproduces all the important characteristics of the giant planets' orbits, namely their final semimajor axes, eccentricities and mutual inclinations.",2005,59,1099,103,16,30,44,46,82,61,80,66,64,96
68d9db61afa6f2e179b162e8929946d938a5bc8a,"All forms of waves can contain phase singularities. In the case of optical waves, a light beam with a phase singularity carries orbital angular momentum, and such beams have found a range of applications in optical manipulation, quantum information and astronomy. Here we report the generation of an electron beam with a phase singularity propagating in free space, which we achieve by passing a plane electron wave through a spiral phase plate constructed naturally from a stack of graphite thin films. The interference pattern between the final beam and a plane electron wave in a transmission electron microscope shows the ‘Y’-like defect pattern characteristic of a beam carrying a phase singularity with a topological charge equal to one. This fundamentally new electron degree of freedom could find application in a number of research areas, as is the case for polarized electron beams.",2010,28,455,7,4,13,25,26,41,35,33,54,56,64
b57fe8cdc49f84ee230c4696aa81d8aa3e2a5ba5,"Entanglement in a Twist The strong correlations observed in quantum mechanically entangled particles, such as photons, offer potential for secure communication and quantum information processing. Leach et al. (p. 662) now show such strong quantum correlations between the complementary variables—angular position and orbital angular momentum—of two photons created during the parametric down-conversion process in a nonlinear crystal. This demonstration of entanglement in an angular basis establishes that angles are genuine quantum observables and can therefore be considered a resource for quantum information processing, capable of secure, high-dimension, key distribution. Strong quantum correlations are induced between the angular position and angular momentum of two photons. Entanglement of the properties of two separated particles constitutes a fundamental signature of quantum mechanics and is a key resource for quantum information science. We demonstrate strong Einstein, Podolsky, and Rosen correlations between the angular position and orbital angular momentum of two photons created by the nonlinear optical process of spontaneous parametric down-conversion. The discrete nature of orbital angular momentum and the continuous but periodic nature of angular position give rise to a special sort of entanglement between these two variables. The resulting correlations are found to be an order of magnitude stronger than those allowed by the uncertainty principle for independent (nonentangled) particles. Our results suggest that angular position and orbital angular momentum may find important applications in quantum information science.",2010,42,414,3,4,24,30,26,38,33,38,27,52,55
768980f65528c8bad41bc6cdf0d3b0eef8934d65,"The occupation of d orbitals controls the magnitude and anisotropy of the inter-atomic electron transfer in transition-metal oxides and hence exerts a key influence on their chemical bonding and physical properties. Atomic-scale modulations of the orbital occupation at surfaces and interfaces are believed to be responsible for massive variations of the magnetic and transport properties, but could not thus far be probed in a quantitative manner. Here we show that it is possible to derive quantitative, spatially resolved orbital polarization profiles from soft-X-ray reflectivity data, without resorting to model calculations. We demonstrate that the method is sensitive enough to resolve differences of ~3% in the occupation of Ni e(g) orbitals in adjacent atomic layers of a LaNiO(3)-LaAlO(3) superlattice, in good agreement with ab initio electronic-structure calculations. The possibility to quantitatively correlate theory and experiment on the atomic scale opens up many new perspectives for orbital physics in transition-metal oxides.",2010,41,152,5,0,5,10,9,17,15,18,15,17,15
d1620666ba23d4bce8c3035a87d06f5277819cc3,"Measurement of the quantum-mechanical phase in quantum matter provides the most direct manifestation of the underlying abstract physics. We used resonant x-ray scattering to probe the relative phases of constituent atomic orbitals in an electronic wave function, which uncovers the unconventional Mott insulating state induced by relativistic spin-orbit coupling in the layered 5d transition metal oxide Sr2IrO4. A selection rule based on intra-atomic interference effects establishes a complex spin-orbital state represented by an effective total angular momentum = 1/2 quantum number, the phase of which can lead to a quantum topological state of matter.",2009,11,642,18,5,10,20,32,47,45,56,54,56,94
411be93d0ae3ff9fbf174bd4de4f11e3203b8a77,"In iron pnictides, we find that the moderate electron-phonon interaction due to the Fe-ion oscillation can induce the critical d-orbital fluctuations, without being prohibited by the Coulomb interaction. These fluctuations give rise to the strong pairing interaction for the s-wave superconducting (SC) state without sign reversal (s(++)-wave state), which is consistent with experimentally observed robustness of superconductivity against impurities. When the magnetic fluctuations due to Coulomb interaction are also strong, the SC state shows a smooth crossover from the s-wave state with sign reversal (s(+/-)-wave state) to the s(++)-wave state as impurity concentration increases.",2009,0,377,6,2,9,32,46,40,46,38,41,34,36
cf335ec147d76c16e49263d17c388814290a35fc,"This review provides a perspective on the use of orbital-dependent functionals, which is currently considered one of the most promising avenues in modern density-functional theory. The focus here is on four major themes: the motivation for orbital-dependent functionals in terms of limitations of semilocal functionals; the optimized effective potential as a rigorous approach to incorporating orbital-dependent functionals within the Kohn-Sham framework; the rationale behind and advantages and limitations of four popular classes of orbital-dependent functionals; and the use of orbital-dependent functionals for predicting excited-state properties. For each of these issues, both formal and practical aspects are assessed.",2008,527,734,8,25,50,38,68,56,64,72,71,61,45
c9d24e78b2bdc2ddfe89144e020846610cdfcefd,"ABSTRACT. We analyze 8 years of precise radial velocity measurements from the Keck Planet Search, characterizing the detection threshold, selection effects, and completeness of the survey. We first carry out a systematic search for planets, by assessing the false-alarm probability associated with Keplerian orbit fits to the data. This allows us to understand the detection threshold for each star in terms of the number and time baseline of the observations, and the underlying “noise” from measurement errors, intrinsic stellar jitter, or additional low-mass planets. We show that all planets with orbital periods P   20 m s-1 K > 20 m s - 1 , and eccentricities e ≲ 0.6 e ≲ 0.6 have been announced, and we summarize the candidates at lower amplitudes and longer orbital periods. For the remaining stars, we calculate upper limits on the velocity amplitude of a companion. For orbital periods less than the duration of the observations, these are typically ...",2008,91,611,154,22,38,56,37,51,43,46,47,49,47
7a725f13577e44f5f39e262ceebc55d0316e6853,"For an isolated quantum particle, such as an electron, the orbital (L) and spin (S) magnetic moments can change provided that the total angular momentum of the particle is conserved. In condensed matter, an efficient transfer between L and S can occur owing to the spin–orbit interaction, which originates in the relativistic motion of electrons. Disentangling the absolute contributions of the orbital and spin angular momenta is challenging, however, as any transfer between the two occurs on femtosecond timescales. Here we investigate such phenomena by using ultrashort optical laser pulses to change the magnetization of a ferromagnetic film and then probe its dynamics with circularly polarized femtosecond X-ray pulses. Our measurements enable us to disentangle the spin and orbital components of the magnetic moment, revealing different dynamics for L and S. We highlight the important role played by the spin–orbit interaction in the ultrafast laser-induced demagnetization of ferromagnetic films, and show also that the magneto-crystalline anisotropy energy is an important quantity to consider in such processes. Our study provides insights into the dynamics in magnetic systems as well as perspectives for the ultrafast control of information in magnetic recording media.",2010,38,297,4,2,19,20,31,26,29,30,24,28,32
45524fd482e1e348a63c2d146a55a77d6ce36608,"The control of charge transport in an active electronic device depends intimately on the modulation of the internal charge density by an external node. For example, a field-effect transistor relies on the gated electrostatic modulation of the channel charge produced by changing the relative position of the conduction and valence bands with respect to the electrodes. In molecular-scale devices, a longstanding challenge has been to create a true three-terminal device that operates in this manner (that is, by modifying orbital energy). Here we report the observation of such a solid-state molecular device, in which transport current is directly modulated by an external gate voltage. Resonance-enhanced coupling to the nearest molecular orbital is revealed by electron tunnelling spectroscopy, demonstrating direct molecular orbital gating in an electronic device. Our findings demonstrate that true molecular transistors can be created, and so enhance the prospects for molecularly engineered electronic devices.",2009,35,585,8,3,29,65,55,56,74,63,51,45,49
0e15715debd0a700242264e06f84fd9e37ac86a3,"We show numerically that vector antenna arrays can generate radio beams that exhibit spin and orbital angular momentum characteristics similar to those of helical Laguerre-Gauss laser beams in paraxial optics. For low frequencies (< or = 1 GHz), digital techniques can be used to coherently measure the instantaneous, local field vectors and to manipulate them in software. This enables new types of experiments that go beyond what is possible in optics. It allows information-rich radio astronomy and paves the way for novel wireless communication concepts.",2007,59,698,31,2,6,9,7,12,17,17,45,44,78
af174b8b4484dd8657819d20baed7995de17bcdb,"We predict a new category of optical orbital angular momentum that is associated with the curl of polarization and a kind of vector field with radial-variant hybrid states of polarization that can carry such novel optical orbital angular momentum. We present a scheme for creating the desired vector fields. Optical trapping experiments validate that the vector fields, which have no additional phase vortex, exert torques to drive the orbital motion of the trapped isotropic microspheres.",2010,12,161,3,0,6,14,7,12,13,20,18,15,20
6e62526fba615f7e3d0f49711a41fd6047be4b5f,"The structure of the human orbital and medial prefrontal cortex (OMPFC) was investigated using five histological and immunohistochemical stains and was correlated with a previous analysis in macaque monkeys [Carmichael and Price ( 1994 ) J. Comp. Neurol. 346:366–402]. A cortical area was recognized if it was distinct with at least two stains and was found in similar locations in different brains. All of the areas recognized in the macaque OMPFC have counterparts in humans. Areas 11, 13, and 14 were subdivided into areas 11m, 11l, 13a, 13b, 13m, 13l, 14r, and 14c. Within area 10, the region corresponding to area 10m in monkeys was divided into 10m and 10r, and area 10o (orbital) was renamed area 10p (polar). Areas 47/12r, 47/12m, 47/12l, and 47/12s occupy the lateral orbital cortex, corresponding to monkey areas 12r, 12m, 12l, and 12o. The agranular insula (areas Iam, Iapm, Iai, and Ial) extends onto the caudal orbital surface and into the horizontal ramus of the lateral sulcus. The growth of the frontal pole in humans has pushed area 25 and area 32pl, which corresponds to the prelimbic area 32 in Brodmann's monkey brain map, caudal and ventral to the genu of the corpus callosum. Anterior cingulate areas 24a and 24b also extend ventral to the genu of the corpus callosum. Area 32ac, corresponding to the dorsal anterior cingulate area 32 in Brodmann's human brain map, is anterior and dorsal to the genu. The parallel organization of the OMPFC in monkeys and humans allows experimental data from monkeys to be applied to studies of the human cortex. J. Comp. Neurol. 460:425–449, 2003. © 2003 Wiley‐Liss, Inc.",2003,76,858,62,9,9,31,34,47,42,58,52,65,51
6479c0e44ab143679d2337e9b726d6196d8dfa0b,"Geochemical models for Mars predict carbonate formation during aqueous alteration. Carbonate-bearing rocks had not previously been detected on Mars' surface, but Mars Reconnaissance Orbiter mapping reveals a regional rock layer with near-infrared spectral characteristics that are consistent with the presence of magnesium carbonate in the Nili Fossae region. The carbonate is closely associated with both phyllosilicate-bearing and olivine-rich rock units and probably formed during the Noachian or early Hesperian era from the alteration of olivine by either hydrothermal fluids or near-surface water. The presence of carbonate as well as accompanying clays suggests that waters were neutral to alkaline at the time of its formation and that acidic weathering, proposed to be characteristic of Hesperian Mars, did not destroy these carbonates and thus did not dominate all aqueous environments.",2008,89,516,18,2,31,49,39,49,56,39,38,29,36
8b75af5b595e3402c77aa438f926ad3dba9fde17,"Orbital mechanics is a cornerstone subject for aerospace engineering students. Maintaining the focus of the first edition, the author provides the foundation needed to understand the subject and proceed to advanced topics. Starting with the solution of the two-body problem and formulas for the different kinds of orbits, the text moves on to Kepler's equations, orbits in three dimensions, orbital elements from observations, orbital maneuvers, orbital rendezvous and interplanetary missions. This is followed by an introduction to spacecraft dynamics and a final chapter on basic rocket dynamics. The author's teach-by-example approach emphasizes the analytical procedures and computer-implemented algorithms required by today's students. There are a large number of worked examples, illustrations, end of chapter exercises (with answers) as well as many MATLAB[registered] programs for use in homework and projects. The text can be used for one and two semester courses in space mechanics. Features: a new section on numerical integration methods applicable to space mechanics problems; a more centralized and improved discussion of coordinate systems and Euler angle sequences; an expanded development of relative motion in orbit; a new section on quaternions; new worked-out examples, illustrations and homework problems; new algorithms, MATLAB[registered] scripts and simulations; instructor's manual and lecture slides available online; and included online testing and assessment component helps students assess their knowledge of the topics.",2005,0,745,81,1,2,6,5,19,19,31,50,54,71
56677386dc3d3ecd1f51a292810a648bc68da1db,"The theoretical need to study the properties of the Fe-based high-Tc superconductors using reliable manybody techniques has highlighted the importance of determining what is the minimum number of orbital degrees of freedom that will capture the physics of these materials. While the shape of the Fermi surface FS obtained with the local-density approximation LDA can be reproduced by a two-orbital model, it has been argued that the bands that cross the chemical potential result from the strong hybridization of three of the Fe 3d orbitals. For this reason, a three orbital Hamiltonian for LaOFeAs obtained with the Slater-Koster formalism by considering the hybridization of the As p orbitals with the Fe dxz, dyz, and dxy orbitals is discussed here. This model reproduces qualitatively the FS shape and orbital composition obtained by LDA calculations for undoped LaOFeAs when four electrons per Fe are considered. Within a mean-field approximation, its magnetic and orbital properties in the undoped case are here described for intermediate values of J/U. Increasing the Coulomb repulsion U at zero temperature, four different regimes are obtained: 1 paramagnetic, 2 magnetic ,0 spin order, 3 the same ,0 spin order but now including orbital order, and finally 4 a magneticmore » and orbital ordered insulator. The spin-singlet pairing operators allowed by the lattice and orbital symmetries are also constructed. It is found that for pairs of electrons involving up to diagonal nearest-neighbors sites, the only fully gapped and purely intraband spin-singlet pairing operator is given by k= fkdk,, d k,, with fk=1 or cos kx cos ky which would arise only if the electrons in all different orbitals couple with equal strength to the source of pairing.« less",2009,2,123,4,1,5,8,12,17,12,17,11,9,10
9b6fa3a9362cc3380185a7933d7982b874527230,"This paper reviews architectonic subdivisions and connections of the orbital and medial prefrontal cortex (OMPFC) in rats, monkeys and humans. Cortico-cortical connections provide the basis for recognition of 'medial' and 'orbital' networks within the OMPFC. These networks also have distinct connections with structures in other parts of the brain. The orbital network receives sensory inputs from several modalities, including olfaction, taste, visceral afferents, somatic sensation and vision, which appear to be especially related to food or eating. In contrast, the medial network provides the major cortical output to visceromotor structures in the hypothalamus and brainstem. The two networks have distinct connections with areas of the striatum and mediodorsal thalamus. In particular, projections to the nucleus accumbens and the adjacent ventromedial caudate and putamen arise predominantly from the medial network. Both networks also have extensive connections with limbic structures. Based on these and other observations, the OMPFC appears to function as a sensory-visceromotor link, especially for eating. This linkage appears to be critical for the guidance of reward-related behavior and for setting of mood. Imaging and histological observations on human brains indicate that clinical depressive disorders are associated with specific functional and cellular changes in the OMPFC, including activity and volume changes, and specific changes in the number of glial cells.",2000,133,2452,143,6,18,51,61,67,72,81,98,128,152
aaea825be9afc25ee2d6d7f279030d0711fa656f,"Entangled quantum states are not separable, regardless of the spatial separation of their components. This is a manifestation of an aspect of quantum mechanics known as quantum non-locality. An important consequence of this is that the measurement of the state of one particle in a two-particle entangled state defines the state of the second particle instantaneously, whereas neither particle possesses its own well-defined state before the measurement. Experimental realizations of entanglement have hitherto been restricted to two-state quantum systems, involving, for example, the two orthogonal polarization states of photons. Here we demonstrate entanglement involving the spatial modes of the electromagnetic field carrying orbital angular momentum. As these modes can be used to define an infinitely dimensional discrete Hilbert space, this approach provides a practical route to entanglement that involves many orthogonal quantum states, rather than just two Multi-dimensional entangled states could be of considerable importance in the field of quantum information, enabling, for example, more efficient use of communication channels in quantum cryptography.",2001,26,2257,31,4,13,24,54,49,52,55,60,75,64
a5c8d98d25da1770770d58ea53f51d614e44339f,"A high-resolution deuterium profile is now available along the entire European Project for Ice Coring in Antarctica Dome C ice core, extending this climate record back to marine isotope stage 20.2, ∼800,000 years ago. Experiments performed with an atmospheric general circulation model including water isotopes support its temperature interpretation. We assessed the general correspondence between Dansgaard-Oeschger events and their smoothed Antarctic counterparts for this Dome C record, which reveals the presence of such features with similar amplitudes during previous glacial periods. We suggest that the interplay between obliquity and precession accounts for the variable intensity of interglacial periods in ice core records.",2007,43,1774,71,21,45,75,120,120,121,134,140,134,127
6a145d8e7158476d0930c679a8777872928426af,"We demonstrate the transfer of information encoded as orbital angular momentum (OAM) states of a light beam. The transmitter and receiver units are based on spatial light modulators, which prepare or measure a laser beam in one of eight pure OAM states. We show that the information encoded in this way is resistant to eavesdropping in the sense that any attempt to sample the beam away from its axis will be subject to an angular restriction and a lateral offset, both of which result in inherent uncertainty in the measurement. This gives an experimental insight into the effects of aperturing and misalignment of the beam on the OAM measurement and demonstrates the uncertainty relationship for OAM.",2004,16,1792,14,2,12,22,26,30,38,46,71,93,120
c4950fc9bb26369182bcd30a863782cc873d71f1,"We demonstrate experimentally an optical process in which the spin angular momentum carried by a circularly polarized light beam is converted into orbital angular momentum, leading to the generation of helical modes with a wave-front helicity controlled by the input polarization. This phenomenon requires the interaction of light with matter that is both optically inhomogeneous and anisotropic. The underlying physics is also associated with the so-called Pancharatnam-Berry geometrical phases involved in any inhomogeneous transformation of the optical polarization.",2006,73,1319,18,1,10,14,21,26,36,47,57,92,110
74569b70f1d283bc43e07f3a078250677c89a5b6,"An electron in a solid, that is, bound to or nearly localized on the specific atomic site, has three attributes: charge, spin, and orbital. The orbital represents the shape of the electron cloud in solid. In transition-metal oxides with anisotropic-shaped d-orbital electrons, the Coulomb interaction between the electrons (strong electron correlation effect) is of importance for understanding their metal-insulator transitions and properties such as high-temperature superconductivity and colossal magnetoresistance. The orbital degree of freedom occasionally plays an important role in these phenomena, and its correlation and/or order-disorder transition causes a variety of phenomena through strong coupling with charge, spin, and lattice dynamics. An overview is given here on this ""orbital physics,"" which will be a key concept for the science and technology of correlated electrons.",2000,60,1553,7,6,26,54,65,61,82,70,66,69,53
c13e0d603a39430565ed7cb94ab5add3da5b280a,"This graduate-level text presents the first comprehensive overview of modern chemical valency and bonding theory, written by internationally recognized experts in the field. The authors build on the foundation of Lewisand Pauling-like localized structural and hybridization concepts to present a book that is directly based on current ab initio computational technology. The presentation is highly visual and intuitive throughout, being based on the recognizable and transferable graphical forms of natural bond orbitals (NBOs) and their spatial overlaps in the molecular environment. The book shows applications to a broad range of molecular and supramolecular species of organic, inorganic, and bioorganic interest. Hundreds of orbital illustrations help to convey the essence of modern NBO concepts in a facile manner for those with no extensive background in the mathematical machinery of the Schrödinger equation. This book will appeal to those studying chemical bonding in relation to chemistry, chemical engineering, biochemistry, and physics.",2005,1,1353,58,1,21,32,45,40,44,57,76,126,141
ddf1415e591f9637cc53dec22f6d4097ba05efc4,"We present a method to efficiently sort orbital angular momentum (OAM) states of light using two static optical elements. The optical elements perform a Cartesian to log-polar coordinate transformation, converting the helically phased light beam corresponding to OAM states into a beam with a transverse phase gradient. A subsequent lens then focuses each input OAM state to a different lateral position. We demonstrate the concept experimentally by using two spatial light modulators to create the desired optical elements, applying it to the separation of eleven OAM states.",2010,0,682,12,3,23,37,45,48,39,80,68,95,92
3d28ee266ac532ca0177a11b69f0bab556e8e4b8,"Recent discoveries concerning rotating (helical) phase fronts and orbital angular momentum (OAM) of laser beams are applied to radio frequencies and comprehensive simulations of a radio OAM system are performed. We find that with the use of vector field-sensing electric and magnetic triaxial antennas, it is possible to unambiguously estimate the OAM in radio beams by local measurements at a single point, assuming ideal (noiseless) conditions and that the beam axis is known. Furthermore, we show that conventional antenna pattern optimization methods can be applied to OAM-generating circular arrays to enhance their directivity.",2010,29,523,34,1,3,9,13,30,26,55,68,87,97
0dcaea1e332d723c98595308c3e6b79260794610,"For extrasolar planets discovered using the radial velocity method, the spectral characterization of the host star leads to a mass estimate of the star and subsequently of the orbiting planet. If the orbital velocity of the planet could be determined, the masses of both star and planet could be calculated using Newton’s law of gravity, just as in the case of stellar double-line eclipsing binaries. Here we report high-dispersion ground-based spectroscopy of a transit of the extrasolar planet HD 209458b. We see a significant wavelength shift in absorption lines from carbon monoxide in the planet’s atmosphere, which we conclude arises from a change in the radial component of the planet’s orbital velocity. The masses of the star and planet are 1.00 ± 0.22MSun and 0.64 ± 0.09MJup respectively. A blueshift of the carbon monoxide signal of approximately 2 km s−1 with respect to the systemic velocity of the host star suggests the presence of a strong wind flowing from the irradiated dayside to the non-irradiated nightside of the planet within the 0.01–0.1 mbar atmospheric pressure range probed by these observations. The strength of the carbon monoxide signal suggests a carbon monoxide mixing ratio of (1–3) × 10−3 in this planet’s upper atmosphere.",2010,26,443,41,10,28,23,33,39,32,37,45,46,50
02640f28ab5c2fe5a883c855fd0bc77505b48a00,"Planetary formation theories suggest that the giant planets formed on circular and coplanar orbits. The eccentricities of Jupiter, Saturn and Uranus, however, reach values of 6 per cent, 9 per cent and 8 per cent, respectively. In addition, the inclinations of the orbital planes of Saturn, Uranus and Neptune take maximum values of ∼2 degrees with respect to the mean orbital plane of Jupiter. Existing models for the excitation of the eccentricity of extrasolar giant planets have not been successfully applied to the Solar System. Here we show that a planetary system with initial quasi-circular, coplanar orbits would have evolved to the current orbital configuration, provided that Jupiter and Saturn crossed their 1:2 orbital resonance. We show that this resonance crossing could have occurred as the giant planets migrated owing to their interaction with a disk of planetesimals. Our model reproduces all the important characteristics of the giant planets' orbits, namely their final semimajor axes, eccentricities and mutual inclinations.",2005,59,1099,103,16,30,44,46,82,61,80,66,64,96
68d9db61afa6f2e179b162e8929946d938a5bc8a,"All forms of waves can contain phase singularities. In the case of optical waves, a light beam with a phase singularity carries orbital angular momentum, and such beams have found a range of applications in optical manipulation, quantum information and astronomy. Here we report the generation of an electron beam with a phase singularity propagating in free space, which we achieve by passing a plane electron wave through a spiral phase plate constructed naturally from a stack of graphite thin films. The interference pattern between the final beam and a plane electron wave in a transmission electron microscope shows the ‘Y’-like defect pattern characteristic of a beam carrying a phase singularity with a topological charge equal to one. This fundamentally new electron degree of freedom could find application in a number of research areas, as is the case for polarized electron beams.",2010,28,455,7,4,13,25,26,41,35,33,54,56,64
b57fe8cdc49f84ee230c4696aa81d8aa3e2a5ba5,"Entanglement in a Twist The strong correlations observed in quantum mechanically entangled particles, such as photons, offer potential for secure communication and quantum information processing. Leach et al. (p. 662) now show such strong quantum correlations between the complementary variables—angular position and orbital angular momentum—of two photons created during the parametric down-conversion process in a nonlinear crystal. This demonstration of entanglement in an angular basis establishes that angles are genuine quantum observables and can therefore be considered a resource for quantum information processing, capable of secure, high-dimension, key distribution. Strong quantum correlations are induced between the angular position and angular momentum of two photons. Entanglement of the properties of two separated particles constitutes a fundamental signature of quantum mechanics and is a key resource for quantum information science. We demonstrate strong Einstein, Podolsky, and Rosen correlations between the angular position and orbital angular momentum of two photons created by the nonlinear optical process of spontaneous parametric down-conversion. The discrete nature of orbital angular momentum and the continuous but periodic nature of angular position give rise to a special sort of entanglement between these two variables. The resulting correlations are found to be an order of magnitude stronger than those allowed by the uncertainty principle for independent (nonentangled) particles. Our results suggest that angular position and orbital angular momentum may find important applications in quantum information science.",2010,42,414,3,4,24,30,26,38,33,38,27,52,55
768980f65528c8bad41bc6cdf0d3b0eef8934d65,"The occupation of d orbitals controls the magnitude and anisotropy of the inter-atomic electron transfer in transition-metal oxides and hence exerts a key influence on their chemical bonding and physical properties. Atomic-scale modulations of the orbital occupation at surfaces and interfaces are believed to be responsible for massive variations of the magnetic and transport properties, but could not thus far be probed in a quantitative manner. Here we show that it is possible to derive quantitative, spatially resolved orbital polarization profiles from soft-X-ray reflectivity data, without resorting to model calculations. We demonstrate that the method is sensitive enough to resolve differences of ~3% in the occupation of Ni e(g) orbitals in adjacent atomic layers of a LaNiO(3)-LaAlO(3) superlattice, in good agreement with ab initio electronic-structure calculations. The possibility to quantitatively correlate theory and experiment on the atomic scale opens up many new perspectives for orbital physics in transition-metal oxides.",2010,41,152,5,0,5,10,9,17,15,18,15,17,15
d1620666ba23d4bce8c3035a87d06f5277819cc3,"Measurement of the quantum-mechanical phase in quantum matter provides the most direct manifestation of the underlying abstract physics. We used resonant x-ray scattering to probe the relative phases of constituent atomic orbitals in an electronic wave function, which uncovers the unconventional Mott insulating state induced by relativistic spin-orbit coupling in the layered 5d transition metal oxide Sr2IrO4. A selection rule based on intra-atomic interference effects establishes a complex spin-orbital state represented by an effective total angular momentum = 1/2 quantum number, the phase of which can lead to a quantum topological state of matter.",2009,11,642,18,5,10,20,32,47,45,56,54,56,94
411be93d0ae3ff9fbf174bd4de4f11e3203b8a77,"In iron pnictides, we find that the moderate electron-phonon interaction due to the Fe-ion oscillation can induce the critical d-orbital fluctuations, without being prohibited by the Coulomb interaction. These fluctuations give rise to the strong pairing interaction for the s-wave superconducting (SC) state without sign reversal (s(++)-wave state), which is consistent with experimentally observed robustness of superconductivity against impurities. When the magnetic fluctuations due to Coulomb interaction are also strong, the SC state shows a smooth crossover from the s-wave state with sign reversal (s(+/-)-wave state) to the s(++)-wave state as impurity concentration increases.",2009,0,377,6,2,9,32,46,40,46,38,41,34,36
cf335ec147d76c16e49263d17c388814290a35fc,"This review provides a perspective on the use of orbital-dependent functionals, which is currently considered one of the most promising avenues in modern density-functional theory. The focus here is on four major themes: the motivation for orbital-dependent functionals in terms of limitations of semilocal functionals; the optimized effective potential as a rigorous approach to incorporating orbital-dependent functionals within the Kohn-Sham framework; the rationale behind and advantages and limitations of four popular classes of orbital-dependent functionals; and the use of orbital-dependent functionals for predicting excited-state properties. For each of these issues, both formal and practical aspects are assessed.",2008,527,734,8,25,50,38,68,56,64,72,71,61,45
c9d24e78b2bdc2ddfe89144e020846610cdfcefd,"ABSTRACT. We analyze 8 years of precise radial velocity measurements from the Keck Planet Search, characterizing the detection threshold, selection effects, and completeness of the survey. We first carry out a systematic search for planets, by assessing the false-alarm probability associated with Keplerian orbit fits to the data. This allows us to understand the detection threshold for each star in terms of the number and time baseline of the observations, and the underlying “noise” from measurement errors, intrinsic stellar jitter, or additional low-mass planets. We show that all planets with orbital periods P   20 m s-1 K > 20 m s - 1 , and eccentricities e ≲ 0.6 e ≲ 0.6 have been announced, and we summarize the candidates at lower amplitudes and longer orbital periods. For the remaining stars, we calculate upper limits on the velocity amplitude of a companion. For orbital periods less than the duration of the observations, these are typically ...",2008,91,611,154,22,38,56,37,51,43,46,47,49,47
7a725f13577e44f5f39e262ceebc55d0316e6853,"For an isolated quantum particle, such as an electron, the orbital (L) and spin (S) magnetic moments can change provided that the total angular momentum of the particle is conserved. In condensed matter, an efficient transfer between L and S can occur owing to the spin–orbit interaction, which originates in the relativistic motion of electrons. Disentangling the absolute contributions of the orbital and spin angular momenta is challenging, however, as any transfer between the two occurs on femtosecond timescales. Here we investigate such phenomena by using ultrashort optical laser pulses to change the magnetization of a ferromagnetic film and then probe its dynamics with circularly polarized femtosecond X-ray pulses. Our measurements enable us to disentangle the spin and orbital components of the magnetic moment, revealing different dynamics for L and S. We highlight the important role played by the spin–orbit interaction in the ultrafast laser-induced demagnetization of ferromagnetic films, and show also that the magneto-crystalline anisotropy energy is an important quantity to consider in such processes. Our study provides insights into the dynamics in magnetic systems as well as perspectives for the ultrafast control of information in magnetic recording media.",2010,38,297,4,2,19,20,31,26,29,30,24,28,32
45524fd482e1e348a63c2d146a55a77d6ce36608,"The control of charge transport in an active electronic device depends intimately on the modulation of the internal charge density by an external node. For example, a field-effect transistor relies on the gated electrostatic modulation of the channel charge produced by changing the relative position of the conduction and valence bands with respect to the electrodes. In molecular-scale devices, a longstanding challenge has been to create a true three-terminal device that operates in this manner (that is, by modifying orbital energy). Here we report the observation of such a solid-state molecular device, in which transport current is directly modulated by an external gate voltage. Resonance-enhanced coupling to the nearest molecular orbital is revealed by electron tunnelling spectroscopy, demonstrating direct molecular orbital gating in an electronic device. Our findings demonstrate that true molecular transistors can be created, and so enhance the prospects for molecularly engineered electronic devices.",2009,35,585,8,3,29,65,55,56,74,63,51,45,49
0e15715debd0a700242264e06f84fd9e37ac86a3,"We show numerically that vector antenna arrays can generate radio beams that exhibit spin and orbital angular momentum characteristics similar to those of helical Laguerre-Gauss laser beams in paraxial optics. For low frequencies (< or = 1 GHz), digital techniques can be used to coherently measure the instantaneous, local field vectors and to manipulate them in software. This enables new types of experiments that go beyond what is possible in optics. It allows information-rich radio astronomy and paves the way for novel wireless communication concepts.",2007,59,698,31,2,6,9,7,12,17,17,45,44,78
af174b8b4484dd8657819d20baed7995de17bcdb,"We predict a new category of optical orbital angular momentum that is associated with the curl of polarization and a kind of vector field with radial-variant hybrid states of polarization that can carry such novel optical orbital angular momentum. We present a scheme for creating the desired vector fields. Optical trapping experiments validate that the vector fields, which have no additional phase vortex, exert torques to drive the orbital motion of the trapped isotropic microspheres.",2010,12,161,3,0,6,14,7,12,13,20,18,15,20
6e62526fba615f7e3d0f49711a41fd6047be4b5f,"The structure of the human orbital and medial prefrontal cortex (OMPFC) was investigated using five histological and immunohistochemical stains and was correlated with a previous analysis in macaque monkeys [Carmichael and Price ( 1994 ) J. Comp. Neurol. 346:366–402]. A cortical area was recognized if it was distinct with at least two stains and was found in similar locations in different brains. All of the areas recognized in the macaque OMPFC have counterparts in humans. Areas 11, 13, and 14 were subdivided into areas 11m, 11l, 13a, 13b, 13m, 13l, 14r, and 14c. Within area 10, the region corresponding to area 10m in monkeys was divided into 10m and 10r, and area 10o (orbital) was renamed area 10p (polar). Areas 47/12r, 47/12m, 47/12l, and 47/12s occupy the lateral orbital cortex, corresponding to monkey areas 12r, 12m, 12l, and 12o. The agranular insula (areas Iam, Iapm, Iai, and Ial) extends onto the caudal orbital surface and into the horizontal ramus of the lateral sulcus. The growth of the frontal pole in humans has pushed area 25 and area 32pl, which corresponds to the prelimbic area 32 in Brodmann's monkey brain map, caudal and ventral to the genu of the corpus callosum. Anterior cingulate areas 24a and 24b also extend ventral to the genu of the corpus callosum. Area 32ac, corresponding to the dorsal anterior cingulate area 32 in Brodmann's human brain map, is anterior and dorsal to the genu. The parallel organization of the OMPFC in monkeys and humans allows experimental data from monkeys to be applied to studies of the human cortex. J. Comp. Neurol. 460:425–449, 2003. © 2003 Wiley‐Liss, Inc.",2003,76,858,62,9,9,31,34,47,42,58,52,65,51
6479c0e44ab143679d2337e9b726d6196d8dfa0b,"Geochemical models for Mars predict carbonate formation during aqueous alteration. Carbonate-bearing rocks had not previously been detected on Mars' surface, but Mars Reconnaissance Orbiter mapping reveals a regional rock layer with near-infrared spectral characteristics that are consistent with the presence of magnesium carbonate in the Nili Fossae region. The carbonate is closely associated with both phyllosilicate-bearing and olivine-rich rock units and probably formed during the Noachian or early Hesperian era from the alteration of olivine by either hydrothermal fluids or near-surface water. The presence of carbonate as well as accompanying clays suggests that waters were neutral to alkaline at the time of its formation and that acidic weathering, proposed to be characteristic of Hesperian Mars, did not destroy these carbonates and thus did not dominate all aqueous environments.",2008,89,516,18,2,31,49,39,49,56,39,38,29,36
8b75af5b595e3402c77aa438f926ad3dba9fde17,"Orbital mechanics is a cornerstone subject for aerospace engineering students. Maintaining the focus of the first edition, the author provides the foundation needed to understand the subject and proceed to advanced topics. Starting with the solution of the two-body problem and formulas for the different kinds of orbits, the text moves on to Kepler's equations, orbits in three dimensions, orbital elements from observations, orbital maneuvers, orbital rendezvous and interplanetary missions. This is followed by an introduction to spacecraft dynamics and a final chapter on basic rocket dynamics. The author's teach-by-example approach emphasizes the analytical procedures and computer-implemented algorithms required by today's students. There are a large number of worked examples, illustrations, end of chapter exercises (with answers) as well as many MATLAB[registered] programs for use in homework and projects. The text can be used for one and two semester courses in space mechanics. Features: a new section on numerical integration methods applicable to space mechanics problems; a more centralized and improved discussion of coordinate systems and Euler angle sequences; an expanded development of relative motion in orbit; a new section on quaternions; new worked-out examples, illustrations and homework problems; new algorithms, MATLAB[registered] scripts and simulations; instructor's manual and lecture slides available online; and included online testing and assessment component helps students assess their knowledge of the topics.",2005,0,745,81,1,2,6,5,19,19,31,50,54,71
56677386dc3d3ecd1f51a292810a648bc68da1db,"The theoretical need to study the properties of the Fe-based high-Tc superconductors using reliable manybody techniques has highlighted the importance of determining what is the minimum number of orbital degrees of freedom that will capture the physics of these materials. While the shape of the Fermi surface FS obtained with the local-density approximation LDA can be reproduced by a two-orbital model, it has been argued that the bands that cross the chemical potential result from the strong hybridization of three of the Fe 3d orbitals. For this reason, a three orbital Hamiltonian for LaOFeAs obtained with the Slater-Koster formalism by considering the hybridization of the As p orbitals with the Fe dxz, dyz, and dxy orbitals is discussed here. This model reproduces qualitatively the FS shape and orbital composition obtained by LDA calculations for undoped LaOFeAs when four electrons per Fe are considered. Within a mean-field approximation, its magnetic and orbital properties in the undoped case are here described for intermediate values of J/U. Increasing the Coulomb repulsion U at zero temperature, four different regimes are obtained: 1 paramagnetic, 2 magnetic ,0 spin order, 3 the same ,0 spin order but now including orbital order, and finally 4 a magneticmore » and orbital ordered insulator. The spin-singlet pairing operators allowed by the lattice and orbital symmetries are also constructed. It is found that for pairs of electrons involving up to diagonal nearest-neighbors sites, the only fully gapped and purely intraband spin-singlet pairing operator is given by k= fkdk,, d k,, with fk=1 or cos kx cos ky which would arise only if the electrons in all different orbitals couple with equal strength to the source of pairing.« less",2009,2,123,4,1,5,8,12,17,12,17,11,9,10
9b6fa3a9362cc3380185a7933d7982b874527230,"This paper reviews architectonic subdivisions and connections of the orbital and medial prefrontal cortex (OMPFC) in rats, monkeys and humans. Cortico-cortical connections provide the basis for recognition of 'medial' and 'orbital' networks within the OMPFC. These networks also have distinct connections with structures in other parts of the brain. The orbital network receives sensory inputs from several modalities, including olfaction, taste, visceral afferents, somatic sensation and vision, which appear to be especially related to food or eating. In contrast, the medial network provides the major cortical output to visceromotor structures in the hypothalamus and brainstem. The two networks have distinct connections with areas of the striatum and mediodorsal thalamus. In particular, projections to the nucleus accumbens and the adjacent ventromedial caudate and putamen arise predominantly from the medial network. Both networks also have extensive connections with limbic structures. Based on these and other observations, the OMPFC appears to function as a sensory-visceromotor link, especially for eating. This linkage appears to be critical for the guidance of reward-related behavior and for setting of mood. Imaging and histological observations on human brains indicate that clinical depressive disorders are associated with specific functional and cellular changes in the OMPFC, including activity and volume changes, and specific changes in the number of glial cells.",2000,133,2452,143,6,18,51,61,67,72,81,98,128,152
aaea825be9afc25ee2d6d7f279030d0711fa656f,"Entangled quantum states are not separable, regardless of the spatial separation of their components. This is a manifestation of an aspect of quantum mechanics known as quantum non-locality. An important consequence of this is that the measurement of the state of one particle in a two-particle entangled state defines the state of the second particle instantaneously, whereas neither particle possesses its own well-defined state before the measurement. Experimental realizations of entanglement have hitherto been restricted to two-state quantum systems, involving, for example, the two orthogonal polarization states of photons. Here we demonstrate entanglement involving the spatial modes of the electromagnetic field carrying orbital angular momentum. As these modes can be used to define an infinitely dimensional discrete Hilbert space, this approach provides a practical route to entanglement that involves many orthogonal quantum states, rather than just two Multi-dimensional entangled states could be of considerable importance in the field of quantum information, enabling, for example, more efficient use of communication channels in quantum cryptography.",2001,26,2257,31,4,13,24,54,49,52,55,60,75,64
a5c8d98d25da1770770d58ea53f51d614e44339f,"A high-resolution deuterium profile is now available along the entire European Project for Ice Coring in Antarctica Dome C ice core, extending this climate record back to marine isotope stage 20.2, ∼800,000 years ago. Experiments performed with an atmospheric general circulation model including water isotopes support its temperature interpretation. We assessed the general correspondence between Dansgaard-Oeschger events and their smoothed Antarctic counterparts for this Dome C record, which reveals the presence of such features with similar amplitudes during previous glacial periods. We suggest that the interplay between obliquity and precession accounts for the variable intensity of interglacial periods in ice core records.",2007,43,1774,71,21,45,75,120,120,121,134,140,134,127
6a145d8e7158476d0930c679a8777872928426af,"We demonstrate the transfer of information encoded as orbital angular momentum (OAM) states of a light beam. The transmitter and receiver units are based on spatial light modulators, which prepare or measure a laser beam in one of eight pure OAM states. We show that the information encoded in this way is resistant to eavesdropping in the sense that any attempt to sample the beam away from its axis will be subject to an angular restriction and a lateral offset, both of which result in inherent uncertainty in the measurement. This gives an experimental insight into the effects of aperturing and misalignment of the beam on the OAM measurement and demonstrates the uncertainty relationship for OAM.",2004,16,1792,14,2,12,22,26,30,38,46,71,93,120
c4950fc9bb26369182bcd30a863782cc873d71f1,"We demonstrate experimentally an optical process in which the spin angular momentum carried by a circularly polarized light beam is converted into orbital angular momentum, leading to the generation of helical modes with a wave-front helicity controlled by the input polarization. This phenomenon requires the interaction of light with matter that is both optically inhomogeneous and anisotropic. The underlying physics is also associated with the so-called Pancharatnam-Berry geometrical phases involved in any inhomogeneous transformation of the optical polarization.",2006,73,1319,18,1,10,14,21,26,36,47,57,92,110
74569b70f1d283bc43e07f3a078250677c89a5b6,"An electron in a solid, that is, bound to or nearly localized on the specific atomic site, has three attributes: charge, spin, and orbital. The orbital represents the shape of the electron cloud in solid. In transition-metal oxides with anisotropic-shaped d-orbital electrons, the Coulomb interaction between the electrons (strong electron correlation effect) is of importance for understanding their metal-insulator transitions and properties such as high-temperature superconductivity and colossal magnetoresistance. The orbital degree of freedom occasionally plays an important role in these phenomena, and its correlation and/or order-disorder transition causes a variety of phenomena through strong coupling with charge, spin, and lattice dynamics. An overview is given here on this ""orbital physics,"" which will be a key concept for the science and technology of correlated electrons.",2000,60,1553,7,6,26,54,65,61,82,70,66,69,53
c13e0d603a39430565ed7cb94ab5add3da5b280a,"This graduate-level text presents the first comprehensive overview of modern chemical valency and bonding theory, written by internationally recognized experts in the field. The authors build on the foundation of Lewisand Pauling-like localized structural and hybridization concepts to present a book that is directly based on current ab initio computational technology. The presentation is highly visual and intuitive throughout, being based on the recognizable and transferable graphical forms of natural bond orbitals (NBOs) and their spatial overlaps in the molecular environment. The book shows applications to a broad range of molecular and supramolecular species of organic, inorganic, and bioorganic interest. Hundreds of orbital illustrations help to convey the essence of modern NBO concepts in a facile manner for those with no extensive background in the mathematical machinery of the Schrödinger equation. This book will appeal to those studying chemical bonding in relation to chemistry, chemical engineering, biochemistry, and physics.",2005,1,1353,58,1,21,32,45,40,44,57,76,126,141
ddf1415e591f9637cc53dec22f6d4097ba05efc4,"We present a method to efficiently sort orbital angular momentum (OAM) states of light using two static optical elements. The optical elements perform a Cartesian to log-polar coordinate transformation, converting the helically phased light beam corresponding to OAM states into a beam with a transverse phase gradient. A subsequent lens then focuses each input OAM state to a different lateral position. We demonstrate the concept experimentally by using two spatial light modulators to create the desired optical elements, applying it to the separation of eleven OAM states.",2010,0,682,12,3,23,37,45,48,39,80,68,95,92
3d28ee266ac532ca0177a11b69f0bab556e8e4b8,"Recent discoveries concerning rotating (helical) phase fronts and orbital angular momentum (OAM) of laser beams are applied to radio frequencies and comprehensive simulations of a radio OAM system are performed. We find that with the use of vector field-sensing electric and magnetic triaxial antennas, it is possible to unambiguously estimate the OAM in radio beams by local measurements at a single point, assuming ideal (noiseless) conditions and that the beam axis is known. Furthermore, we show that conventional antenna pattern optimization methods can be applied to OAM-generating circular arrays to enhance their directivity.",2010,29,523,34,1,3,9,13,30,26,55,68,87,97
0dcaea1e332d723c98595308c3e6b79260794610,"For extrasolar planets discovered using the radial velocity method, the spectral characterization of the host star leads to a mass estimate of the star and subsequently of the orbiting planet. If the orbital velocity of the planet could be determined, the masses of both star and planet could be calculated using Newton’s law of gravity, just as in the case of stellar double-line eclipsing binaries. Here we report high-dispersion ground-based spectroscopy of a transit of the extrasolar planet HD 209458b. We see a significant wavelength shift in absorption lines from carbon monoxide in the planet’s atmosphere, which we conclude arises from a change in the radial component of the planet’s orbital velocity. The masses of the star and planet are 1.00 ± 0.22MSun and 0.64 ± 0.09MJup respectively. A blueshift of the carbon monoxide signal of approximately 2 km s−1 with respect to the systemic velocity of the host star suggests the presence of a strong wind flowing from the irradiated dayside to the non-irradiated nightside of the planet within the 0.01–0.1 mbar atmospheric pressure range probed by these observations. The strength of the carbon monoxide signal suggests a carbon monoxide mixing ratio of (1–3) × 10−3 in this planet’s upper atmosphere.",2010,26,443,41,10,28,23,33,39,32,37,45,46,50
02640f28ab5c2fe5a883c855fd0bc77505b48a00,"Planetary formation theories suggest that the giant planets formed on circular and coplanar orbits. The eccentricities of Jupiter, Saturn and Uranus, however, reach values of 6 per cent, 9 per cent and 8 per cent, respectively. In addition, the inclinations of the orbital planes of Saturn, Uranus and Neptune take maximum values of ∼2 degrees with respect to the mean orbital plane of Jupiter. Existing models for the excitation of the eccentricity of extrasolar giant planets have not been successfully applied to the Solar System. Here we show that a planetary system with initial quasi-circular, coplanar orbits would have evolved to the current orbital configuration, provided that Jupiter and Saturn crossed their 1:2 orbital resonance. We show that this resonance crossing could have occurred as the giant planets migrated owing to their interaction with a disk of planetesimals. Our model reproduces all the important characteristics of the giant planets' orbits, namely their final semimajor axes, eccentricities and mutual inclinations.",2005,59,1099,103,16,30,44,46,82,61,80,66,64,96
68d9db61afa6f2e179b162e8929946d938a5bc8a,"All forms of waves can contain phase singularities. In the case of optical waves, a light beam with a phase singularity carries orbital angular momentum, and such beams have found a range of applications in optical manipulation, quantum information and astronomy. Here we report the generation of an electron beam with a phase singularity propagating in free space, which we achieve by passing a plane electron wave through a spiral phase plate constructed naturally from a stack of graphite thin films. The interference pattern between the final beam and a plane electron wave in a transmission electron microscope shows the ‘Y’-like defect pattern characteristic of a beam carrying a phase singularity with a topological charge equal to one. This fundamentally new electron degree of freedom could find application in a number of research areas, as is the case for polarized electron beams.",2010,28,455,7,4,13,25,26,41,35,33,54,56,64
b57fe8cdc49f84ee230c4696aa81d8aa3e2a5ba5,"Entanglement in a Twist The strong correlations observed in quantum mechanically entangled particles, such as photons, offer potential for secure communication and quantum information processing. Leach et al. (p. 662) now show such strong quantum correlations between the complementary variables—angular position and orbital angular momentum—of two photons created during the parametric down-conversion process in a nonlinear crystal. This demonstration of entanglement in an angular basis establishes that angles are genuine quantum observables and can therefore be considered a resource for quantum information processing, capable of secure, high-dimension, key distribution. Strong quantum correlations are induced between the angular position and angular momentum of two photons. Entanglement of the properties of two separated particles constitutes a fundamental signature of quantum mechanics and is a key resource for quantum information science. We demonstrate strong Einstein, Podolsky, and Rosen correlations between the angular position and orbital angular momentum of two photons created by the nonlinear optical process of spontaneous parametric down-conversion. The discrete nature of orbital angular momentum and the continuous but periodic nature of angular position give rise to a special sort of entanglement between these two variables. The resulting correlations are found to be an order of magnitude stronger than those allowed by the uncertainty principle for independent (nonentangled) particles. Our results suggest that angular position and orbital angular momentum may find important applications in quantum information science.",2010,42,414,3,4,24,30,26,38,33,38,27,52,55
768980f65528c8bad41bc6cdf0d3b0eef8934d65,"The occupation of d orbitals controls the magnitude and anisotropy of the inter-atomic electron transfer in transition-metal oxides and hence exerts a key influence on their chemical bonding and physical properties. Atomic-scale modulations of the orbital occupation at surfaces and interfaces are believed to be responsible for massive variations of the magnetic and transport properties, but could not thus far be probed in a quantitative manner. Here we show that it is possible to derive quantitative, spatially resolved orbital polarization profiles from soft-X-ray reflectivity data, without resorting to model calculations. We demonstrate that the method is sensitive enough to resolve differences of ~3% in the occupation of Ni e(g) orbitals in adjacent atomic layers of a LaNiO(3)-LaAlO(3) superlattice, in good agreement with ab initio electronic-structure calculations. The possibility to quantitatively correlate theory and experiment on the atomic scale opens up many new perspectives for orbital physics in transition-metal oxides.",2010,41,152,5,0,5,10,9,17,15,18,15,17,15
d1620666ba23d4bce8c3035a87d06f5277819cc3,"Measurement of the quantum-mechanical phase in quantum matter provides the most direct manifestation of the underlying abstract physics. We used resonant x-ray scattering to probe the relative phases of constituent atomic orbitals in an electronic wave function, which uncovers the unconventional Mott insulating state induced by relativistic spin-orbit coupling in the layered 5d transition metal oxide Sr2IrO4. A selection rule based on intra-atomic interference effects establishes a complex spin-orbital state represented by an effective total angular momentum = 1/2 quantum number, the phase of which can lead to a quantum topological state of matter.",2009,11,642,18,5,10,20,32,47,45,56,54,56,94
411be93d0ae3ff9fbf174bd4de4f11e3203b8a77,"In iron pnictides, we find that the moderate electron-phonon interaction due to the Fe-ion oscillation can induce the critical d-orbital fluctuations, without being prohibited by the Coulomb interaction. These fluctuations give rise to the strong pairing interaction for the s-wave superconducting (SC) state without sign reversal (s(++)-wave state), which is consistent with experimentally observed robustness of superconductivity against impurities. When the magnetic fluctuations due to Coulomb interaction are also strong, the SC state shows a smooth crossover from the s-wave state with sign reversal (s(+/-)-wave state) to the s(++)-wave state as impurity concentration increases.",2009,0,377,6,2,9,32,46,40,46,38,41,34,36
cf335ec147d76c16e49263d17c388814290a35fc,"This review provides a perspective on the use of orbital-dependent functionals, which is currently considered one of the most promising avenues in modern density-functional theory. The focus here is on four major themes: the motivation for orbital-dependent functionals in terms of limitations of semilocal functionals; the optimized effective potential as a rigorous approach to incorporating orbital-dependent functionals within the Kohn-Sham framework; the rationale behind and advantages and limitations of four popular classes of orbital-dependent functionals; and the use of orbital-dependent functionals for predicting excited-state properties. For each of these issues, both formal and practical aspects are assessed.",2008,527,734,8,25,50,38,68,56,64,72,71,61,45
c9d24e78b2bdc2ddfe89144e020846610cdfcefd,"ABSTRACT. We analyze 8 years of precise radial velocity measurements from the Keck Planet Search, characterizing the detection threshold, selection effects, and completeness of the survey. We first carry out a systematic search for planets, by assessing the false-alarm probability associated with Keplerian orbit fits to the data. This allows us to understand the detection threshold for each star in terms of the number and time baseline of the observations, and the underlying “noise” from measurement errors, intrinsic stellar jitter, or additional low-mass planets. We show that all planets with orbital periods P   20 m s-1 K > 20 m s - 1 , and eccentricities e ≲ 0.6 e ≲ 0.6 have been announced, and we summarize the candidates at lower amplitudes and longer orbital periods. For the remaining stars, we calculate upper limits on the velocity amplitude of a companion. For orbital periods less than the duration of the observations, these are typically ...",2008,91,611,154,22,38,56,37,51,43,46,47,49,47
7a725f13577e44f5f39e262ceebc55d0316e6853,"For an isolated quantum particle, such as an electron, the orbital (L) and spin (S) magnetic moments can change provided that the total angular momentum of the particle is conserved. In condensed matter, an efficient transfer between L and S can occur owing to the spin–orbit interaction, which originates in the relativistic motion of electrons. Disentangling the absolute contributions of the orbital and spin angular momenta is challenging, however, as any transfer between the two occurs on femtosecond timescales. Here we investigate such phenomena by using ultrashort optical laser pulses to change the magnetization of a ferromagnetic film and then probe its dynamics with circularly polarized femtosecond X-ray pulses. Our measurements enable us to disentangle the spin and orbital components of the magnetic moment, revealing different dynamics for L and S. We highlight the important role played by the spin–orbit interaction in the ultrafast laser-induced demagnetization of ferromagnetic films, and show also that the magneto-crystalline anisotropy energy is an important quantity to consider in such processes. Our study provides insights into the dynamics in magnetic systems as well as perspectives for the ultrafast control of information in magnetic recording media.",2010,38,297,4,2,19,20,31,26,29,30,24,28,32
45524fd482e1e348a63c2d146a55a77d6ce36608,"The control of charge transport in an active electronic device depends intimately on the modulation of the internal charge density by an external node. For example, a field-effect transistor relies on the gated electrostatic modulation of the channel charge produced by changing the relative position of the conduction and valence bands with respect to the electrodes. In molecular-scale devices, a longstanding challenge has been to create a true three-terminal device that operates in this manner (that is, by modifying orbital energy). Here we report the observation of such a solid-state molecular device, in which transport current is directly modulated by an external gate voltage. Resonance-enhanced coupling to the nearest molecular orbital is revealed by electron tunnelling spectroscopy, demonstrating direct molecular orbital gating in an electronic device. Our findings demonstrate that true molecular transistors can be created, and so enhance the prospects for molecularly engineered electronic devices.",2009,35,585,8,3,29,65,55,56,74,63,51,45,49
0e15715debd0a700242264e06f84fd9e37ac86a3,"We show numerically that vector antenna arrays can generate radio beams that exhibit spin and orbital angular momentum characteristics similar to those of helical Laguerre-Gauss laser beams in paraxial optics. For low frequencies (< or = 1 GHz), digital techniques can be used to coherently measure the instantaneous, local field vectors and to manipulate them in software. This enables new types of experiments that go beyond what is possible in optics. It allows information-rich radio astronomy and paves the way for novel wireless communication concepts.",2007,59,698,31,2,6,9,7,12,17,17,45,44,78
af174b8b4484dd8657819d20baed7995de17bcdb,"We predict a new category of optical orbital angular momentum that is associated with the curl of polarization and a kind of vector field with radial-variant hybrid states of polarization that can carry such novel optical orbital angular momentum. We present a scheme for creating the desired vector fields. Optical trapping experiments validate that the vector fields, which have no additional phase vortex, exert torques to drive the orbital motion of the trapped isotropic microspheres.",2010,12,161,3,0,6,14,7,12,13,20,18,15,20
6e62526fba615f7e3d0f49711a41fd6047be4b5f,"The structure of the human orbital and medial prefrontal cortex (OMPFC) was investigated using five histological and immunohistochemical stains and was correlated with a previous analysis in macaque monkeys [Carmichael and Price ( 1994 ) J. Comp. Neurol. 346:366–402]. A cortical area was recognized if it was distinct with at least two stains and was found in similar locations in different brains. All of the areas recognized in the macaque OMPFC have counterparts in humans. Areas 11, 13, and 14 were subdivided into areas 11m, 11l, 13a, 13b, 13m, 13l, 14r, and 14c. Within area 10, the region corresponding to area 10m in monkeys was divided into 10m and 10r, and area 10o (orbital) was renamed area 10p (polar). Areas 47/12r, 47/12m, 47/12l, and 47/12s occupy the lateral orbital cortex, corresponding to monkey areas 12r, 12m, 12l, and 12o. The agranular insula (areas Iam, Iapm, Iai, and Ial) extends onto the caudal orbital surface and into the horizontal ramus of the lateral sulcus. The growth of the frontal pole in humans has pushed area 25 and area 32pl, which corresponds to the prelimbic area 32 in Brodmann's monkey brain map, caudal and ventral to the genu of the corpus callosum. Anterior cingulate areas 24a and 24b also extend ventral to the genu of the corpus callosum. Area 32ac, corresponding to the dorsal anterior cingulate area 32 in Brodmann's human brain map, is anterior and dorsal to the genu. The parallel organization of the OMPFC in monkeys and humans allows experimental data from monkeys to be applied to studies of the human cortex. J. Comp. Neurol. 460:425–449, 2003. © 2003 Wiley‐Liss, Inc.",2003,76,858,62,9,9,31,34,47,42,58,52,65,51
6479c0e44ab143679d2337e9b726d6196d8dfa0b,"Geochemical models for Mars predict carbonate formation during aqueous alteration. Carbonate-bearing rocks had not previously been detected on Mars' surface, but Mars Reconnaissance Orbiter mapping reveals a regional rock layer with near-infrared spectral characteristics that are consistent with the presence of magnesium carbonate in the Nili Fossae region. The carbonate is closely associated with both phyllosilicate-bearing and olivine-rich rock units and probably formed during the Noachian or early Hesperian era from the alteration of olivine by either hydrothermal fluids or near-surface water. The presence of carbonate as well as accompanying clays suggests that waters were neutral to alkaline at the time of its formation and that acidic weathering, proposed to be characteristic of Hesperian Mars, did not destroy these carbonates and thus did not dominate all aqueous environments.",2008,89,516,18,2,31,49,39,49,56,39,38,29,36
8b75af5b595e3402c77aa438f926ad3dba9fde17,"Orbital mechanics is a cornerstone subject for aerospace engineering students. Maintaining the focus of the first edition, the author provides the foundation needed to understand the subject and proceed to advanced topics. Starting with the solution of the two-body problem and formulas for the different kinds of orbits, the text moves on to Kepler's equations, orbits in three dimensions, orbital elements from observations, orbital maneuvers, orbital rendezvous and interplanetary missions. This is followed by an introduction to spacecraft dynamics and a final chapter on basic rocket dynamics. The author's teach-by-example approach emphasizes the analytical procedures and computer-implemented algorithms required by today's students. There are a large number of worked examples, illustrations, end of chapter exercises (with answers) as well as many MATLAB[registered] programs for use in homework and projects. The text can be used for one and two semester courses in space mechanics. Features: a new section on numerical integration methods applicable to space mechanics problems; a more centralized and improved discussion of coordinate systems and Euler angle sequences; an expanded development of relative motion in orbit; a new section on quaternions; new worked-out examples, illustrations and homework problems; new algorithms, MATLAB[registered] scripts and simulations; instructor's manual and lecture slides available online; and included online testing and assessment component helps students assess their knowledge of the topics.",2005,0,745,81,1,2,6,5,19,19,31,50,54,71
56677386dc3d3ecd1f51a292810a648bc68da1db,"The theoretical need to study the properties of the Fe-based high-Tc superconductors using reliable manybody techniques has highlighted the importance of determining what is the minimum number of orbital degrees of freedom that will capture the physics of these materials. While the shape of the Fermi surface FS obtained with the local-density approximation LDA can be reproduced by a two-orbital model, it has been argued that the bands that cross the chemical potential result from the strong hybridization of three of the Fe 3d orbitals. For this reason, a three orbital Hamiltonian for LaOFeAs obtained with the Slater-Koster formalism by considering the hybridization of the As p orbitals with the Fe dxz, dyz, and dxy orbitals is discussed here. This model reproduces qualitatively the FS shape and orbital composition obtained by LDA calculations for undoped LaOFeAs when four electrons per Fe are considered. Within a mean-field approximation, its magnetic and orbital properties in the undoped case are here described for intermediate values of J/U. Increasing the Coulomb repulsion U at zero temperature, four different regimes are obtained: 1 paramagnetic, 2 magnetic ,0 spin order, 3 the same ,0 spin order but now including orbital order, and finally 4 a magneticmore » and orbital ordered insulator. The spin-singlet pairing operators allowed by the lattice and orbital symmetries are also constructed. It is found that for pairs of electrons involving up to diagonal nearest-neighbors sites, the only fully gapped and purely intraband spin-singlet pairing operator is given by k= fkdk,, d k,, with fk=1 or cos kx cos ky which would arise only if the electrons in all different orbitals couple with equal strength to the source of pairing.« less",2009,2,123,4,1,5,8,12,17,12,17,11,9,10
9b6fa3a9362cc3380185a7933d7982b874527230,"This paper reviews architectonic subdivisions and connections of the orbital and medial prefrontal cortex (OMPFC) in rats, monkeys and humans. Cortico-cortical connections provide the basis for recognition of 'medial' and 'orbital' networks within the OMPFC. These networks also have distinct connections with structures in other parts of the brain. The orbital network receives sensory inputs from several modalities, including olfaction, taste, visceral afferents, somatic sensation and vision, which appear to be especially related to food or eating. In contrast, the medial network provides the major cortical output to visceromotor structures in the hypothalamus and brainstem. The two networks have distinct connections with areas of the striatum and mediodorsal thalamus. In particular, projections to the nucleus accumbens and the adjacent ventromedial caudate and putamen arise predominantly from the medial network. Both networks also have extensive connections with limbic structures. Based on these and other observations, the OMPFC appears to function as a sensory-visceromotor link, especially for eating. This linkage appears to be critical for the guidance of reward-related behavior and for setting of mood. Imaging and histological observations on human brains indicate that clinical depressive disorders are associated with specific functional and cellular changes in the OMPFC, including activity and volume changes, and specific changes in the number of glial cells.",2000,133,2452,143,6,18,51,61,67,72,81,98,128,152
aaea825be9afc25ee2d6d7f279030d0711fa656f,"Entangled quantum states are not separable, regardless of the spatial separation of their components. This is a manifestation of an aspect of quantum mechanics known as quantum non-locality. An important consequence of this is that the measurement of the state of one particle in a two-particle entangled state defines the state of the second particle instantaneously, whereas neither particle possesses its own well-defined state before the measurement. Experimental realizations of entanglement have hitherto been restricted to two-state quantum systems, involving, for example, the two orthogonal polarization states of photons. Here we demonstrate entanglement involving the spatial modes of the electromagnetic field carrying orbital angular momentum. As these modes can be used to define an infinitely dimensional discrete Hilbert space, this approach provides a practical route to entanglement that involves many orthogonal quantum states, rather than just two Multi-dimensional entangled states could be of considerable importance in the field of quantum information, enabling, for example, more efficient use of communication channels in quantum cryptography.",2001,26,2257,31,4,13,24,54,49,52,55,60,75,64
a5c8d98d25da1770770d58ea53f51d614e44339f,"A high-resolution deuterium profile is now available along the entire European Project for Ice Coring in Antarctica Dome C ice core, extending this climate record back to marine isotope stage 20.2, ∼800,000 years ago. Experiments performed with an atmospheric general circulation model including water isotopes support its temperature interpretation. We assessed the general correspondence between Dansgaard-Oeschger events and their smoothed Antarctic counterparts for this Dome C record, which reveals the presence of such features with similar amplitudes during previous glacial periods. We suggest that the interplay between obliquity and precession accounts for the variable intensity of interglacial periods in ice core records.",2007,43,1774,71,21,45,75,120,120,121,134,140,134,127
6a145d8e7158476d0930c679a8777872928426af,"We demonstrate the transfer of information encoded as orbital angular momentum (OAM) states of a light beam. The transmitter and receiver units are based on spatial light modulators, which prepare or measure a laser beam in one of eight pure OAM states. We show that the information encoded in this way is resistant to eavesdropping in the sense that any attempt to sample the beam away from its axis will be subject to an angular restriction and a lateral offset, both of which result in inherent uncertainty in the measurement. This gives an experimental insight into the effects of aperturing and misalignment of the beam on the OAM measurement and demonstrates the uncertainty relationship for OAM.",2004,16,1792,14,2,12,22,26,30,38,46,71,93,120
c4950fc9bb26369182bcd30a863782cc873d71f1,"We demonstrate experimentally an optical process in which the spin angular momentum carried by a circularly polarized light beam is converted into orbital angular momentum, leading to the generation of helical modes with a wave-front helicity controlled by the input polarization. This phenomenon requires the interaction of light with matter that is both optically inhomogeneous and anisotropic. The underlying physics is also associated with the so-called Pancharatnam-Berry geometrical phases involved in any inhomogeneous transformation of the optical polarization.",2006,73,1319,18,1,10,14,21,26,36,47,57,92,110
74569b70f1d283bc43e07f3a078250677c89a5b6,"An electron in a solid, that is, bound to or nearly localized on the specific atomic site, has three attributes: charge, spin, and orbital. The orbital represents the shape of the electron cloud in solid. In transition-metal oxides with anisotropic-shaped d-orbital electrons, the Coulomb interaction between the electrons (strong electron correlation effect) is of importance for understanding their metal-insulator transitions and properties such as high-temperature superconductivity and colossal magnetoresistance. The orbital degree of freedom occasionally plays an important role in these phenomena, and its correlation and/or order-disorder transition causes a variety of phenomena through strong coupling with charge, spin, and lattice dynamics. An overview is given here on this ""orbital physics,"" which will be a key concept for the science and technology of correlated electrons.",2000,60,1553,7,6,26,54,65,61,82,70,66,69,53
c13e0d603a39430565ed7cb94ab5add3da5b280a,"This graduate-level text presents the first comprehensive overview of modern chemical valency and bonding theory, written by internationally recognized experts in the field. The authors build on the foundation of Lewisand Pauling-like localized structural and hybridization concepts to present a book that is directly based on current ab initio computational technology. The presentation is highly visual and intuitive throughout, being based on the recognizable and transferable graphical forms of natural bond orbitals (NBOs) and their spatial overlaps in the molecular environment. The book shows applications to a broad range of molecular and supramolecular species of organic, inorganic, and bioorganic interest. Hundreds of orbital illustrations help to convey the essence of modern NBO concepts in a facile manner for those with no extensive background in the mathematical machinery of the Schrödinger equation. This book will appeal to those studying chemical bonding in relation to chemistry, chemical engineering, biochemistry, and physics.",2005,1,1353,58,1,21,32,45,40,44,57,76,126,141
ddf1415e591f9637cc53dec22f6d4097ba05efc4,"We present a method to efficiently sort orbital angular momentum (OAM) states of light using two static optical elements. The optical elements perform a Cartesian to log-polar coordinate transformation, converting the helically phased light beam corresponding to OAM states into a beam with a transverse phase gradient. A subsequent lens then focuses each input OAM state to a different lateral position. We demonstrate the concept experimentally by using two spatial light modulators to create the desired optical elements, applying it to the separation of eleven OAM states.",2010,0,682,12,3,23,37,45,48,39,80,68,95,92
3d28ee266ac532ca0177a11b69f0bab556e8e4b8,"Recent discoveries concerning rotating (helical) phase fronts and orbital angular momentum (OAM) of laser beams are applied to radio frequencies and comprehensive simulations of a radio OAM system are performed. We find that with the use of vector field-sensing electric and magnetic triaxial antennas, it is possible to unambiguously estimate the OAM in radio beams by local measurements at a single point, assuming ideal (noiseless) conditions and that the beam axis is known. Furthermore, we show that conventional antenna pattern optimization methods can be applied to OAM-generating circular arrays to enhance their directivity.",2010,29,523,34,1,3,9,13,30,26,55,68,87,97
0dcaea1e332d723c98595308c3e6b79260794610,"For extrasolar planets discovered using the radial velocity method, the spectral characterization of the host star leads to a mass estimate of the star and subsequently of the orbiting planet. If the orbital velocity of the planet could be determined, the masses of both star and planet could be calculated using Newton’s law of gravity, just as in the case of stellar double-line eclipsing binaries. Here we report high-dispersion ground-based spectroscopy of a transit of the extrasolar planet HD 209458b. We see a significant wavelength shift in absorption lines from carbon monoxide in the planet’s atmosphere, which we conclude arises from a change in the radial component of the planet’s orbital velocity. The masses of the star and planet are 1.00 ± 0.22MSun and 0.64 ± 0.09MJup respectively. A blueshift of the carbon monoxide signal of approximately 2 km s−1 with respect to the systemic velocity of the host star suggests the presence of a strong wind flowing from the irradiated dayside to the non-irradiated nightside of the planet within the 0.01–0.1 mbar atmospheric pressure range probed by these observations. The strength of the carbon monoxide signal suggests a carbon monoxide mixing ratio of (1–3) × 10−3 in this planet’s upper atmosphere.",2010,26,443,41,10,28,23,33,39,32,37,45,46,50
02640f28ab5c2fe5a883c855fd0bc77505b48a00,"Planetary formation theories suggest that the giant planets formed on circular and coplanar orbits. The eccentricities of Jupiter, Saturn and Uranus, however, reach values of 6 per cent, 9 per cent and 8 per cent, respectively. In addition, the inclinations of the orbital planes of Saturn, Uranus and Neptune take maximum values of ∼2 degrees with respect to the mean orbital plane of Jupiter. Existing models for the excitation of the eccentricity of extrasolar giant planets have not been successfully applied to the Solar System. Here we show that a planetary system with initial quasi-circular, coplanar orbits would have evolved to the current orbital configuration, provided that Jupiter and Saturn crossed their 1:2 orbital resonance. We show that this resonance crossing could have occurred as the giant planets migrated owing to their interaction with a disk of planetesimals. Our model reproduces all the important characteristics of the giant planets' orbits, namely their final semimajor axes, eccentricities and mutual inclinations.",2005,59,1099,103,16,30,44,46,82,61,80,66,64,96
68d9db61afa6f2e179b162e8929946d938a5bc8a,"All forms of waves can contain phase singularities. In the case of optical waves, a light beam with a phase singularity carries orbital angular momentum, and such beams have found a range of applications in optical manipulation, quantum information and astronomy. Here we report the generation of an electron beam with a phase singularity propagating in free space, which we achieve by passing a plane electron wave through a spiral phase plate constructed naturally from a stack of graphite thin films. The interference pattern between the final beam and a plane electron wave in a transmission electron microscope shows the ‘Y’-like defect pattern characteristic of a beam carrying a phase singularity with a topological charge equal to one. This fundamentally new electron degree of freedom could find application in a number of research areas, as is the case for polarized electron beams.",2010,28,455,7,4,13,25,26,41,35,33,54,56,64
b57fe8cdc49f84ee230c4696aa81d8aa3e2a5ba5,"Entanglement in a Twist The strong correlations observed in quantum mechanically entangled particles, such as photons, offer potential for secure communication and quantum information processing. Leach et al. (p. 662) now show such strong quantum correlations between the complementary variables—angular position and orbital angular momentum—of two photons created during the parametric down-conversion process in a nonlinear crystal. This demonstration of entanglement in an angular basis establishes that angles are genuine quantum observables and can therefore be considered a resource for quantum information processing, capable of secure, high-dimension, key distribution. Strong quantum correlations are induced between the angular position and angular momentum of two photons. Entanglement of the properties of two separated particles constitutes a fundamental signature of quantum mechanics and is a key resource for quantum information science. We demonstrate strong Einstein, Podolsky, and Rosen correlations between the angular position and orbital angular momentum of two photons created by the nonlinear optical process of spontaneous parametric down-conversion. The discrete nature of orbital angular momentum and the continuous but periodic nature of angular position give rise to a special sort of entanglement between these two variables. The resulting correlations are found to be an order of magnitude stronger than those allowed by the uncertainty principle for independent (nonentangled) particles. Our results suggest that angular position and orbital angular momentum may find important applications in quantum information science.",2010,42,414,3,4,24,30,26,38,33,38,27,52,55
768980f65528c8bad41bc6cdf0d3b0eef8934d65,"The occupation of d orbitals controls the magnitude and anisotropy of the inter-atomic electron transfer in transition-metal oxides and hence exerts a key influence on their chemical bonding and physical properties. Atomic-scale modulations of the orbital occupation at surfaces and interfaces are believed to be responsible for massive variations of the magnetic and transport properties, but could not thus far be probed in a quantitative manner. Here we show that it is possible to derive quantitative, spatially resolved orbital polarization profiles from soft-X-ray reflectivity data, without resorting to model calculations. We demonstrate that the method is sensitive enough to resolve differences of ~3% in the occupation of Ni e(g) orbitals in adjacent atomic layers of a LaNiO(3)-LaAlO(3) superlattice, in good agreement with ab initio electronic-structure calculations. The possibility to quantitatively correlate theory and experiment on the atomic scale opens up many new perspectives for orbital physics in transition-metal oxides.",2010,41,152,5,0,5,10,9,17,15,18,15,17,15
d1620666ba23d4bce8c3035a87d06f5277819cc3,"Measurement of the quantum-mechanical phase in quantum matter provides the most direct manifestation of the underlying abstract physics. We used resonant x-ray scattering to probe the relative phases of constituent atomic orbitals in an electronic wave function, which uncovers the unconventional Mott insulating state induced by relativistic spin-orbit coupling in the layered 5d transition metal oxide Sr2IrO4. A selection rule based on intra-atomic interference effects establishes a complex spin-orbital state represented by an effective total angular momentum = 1/2 quantum number, the phase of which can lead to a quantum topological state of matter.",2009,11,642,18,5,10,20,32,47,45,56,54,56,94
411be93d0ae3ff9fbf174bd4de4f11e3203b8a77,"In iron pnictides, we find that the moderate electron-phonon interaction due to the Fe-ion oscillation can induce the critical d-orbital fluctuations, without being prohibited by the Coulomb interaction. These fluctuations give rise to the strong pairing interaction for the s-wave superconducting (SC) state without sign reversal (s(++)-wave state), which is consistent with experimentally observed robustness of superconductivity against impurities. When the magnetic fluctuations due to Coulomb interaction are also strong, the SC state shows a smooth crossover from the s-wave state with sign reversal (s(+/-)-wave state) to the s(++)-wave state as impurity concentration increases.",2009,0,377,6,2,9,32,46,40,46,38,41,34,36
cf335ec147d76c16e49263d17c388814290a35fc,"This review provides a perspective on the use of orbital-dependent functionals, which is currently considered one of the most promising avenues in modern density-functional theory. The focus here is on four major themes: the motivation for orbital-dependent functionals in terms of limitations of semilocal functionals; the optimized effective potential as a rigorous approach to incorporating orbital-dependent functionals within the Kohn-Sham framework; the rationale behind and advantages and limitations of four popular classes of orbital-dependent functionals; and the use of orbital-dependent functionals for predicting excited-state properties. For each of these issues, both formal and practical aspects are assessed.",2008,527,734,8,25,50,38,68,56,64,72,71,61,45
c9d24e78b2bdc2ddfe89144e020846610cdfcefd,"ABSTRACT. We analyze 8 years of precise radial velocity measurements from the Keck Planet Search, characterizing the detection threshold, selection effects, and completeness of the survey. We first carry out a systematic search for planets, by assessing the false-alarm probability associated with Keplerian orbit fits to the data. This allows us to understand the detection threshold for each star in terms of the number and time baseline of the observations, and the underlying “noise” from measurement errors, intrinsic stellar jitter, or additional low-mass planets. We show that all planets with orbital periods P   20 m s-1 K > 20 m s - 1 , and eccentricities e ≲ 0.6 e ≲ 0.6 have been announced, and we summarize the candidates at lower amplitudes and longer orbital periods. For the remaining stars, we calculate upper limits on the velocity amplitude of a companion. For orbital periods less than the duration of the observations, these are typically ...",2008,91,611,154,22,38,56,37,51,43,46,47,49,47
7a725f13577e44f5f39e262ceebc55d0316e6853,"For an isolated quantum particle, such as an electron, the orbital (L) and spin (S) magnetic moments can change provided that the total angular momentum of the particle is conserved. In condensed matter, an efficient transfer between L and S can occur owing to the spin–orbit interaction, which originates in the relativistic motion of electrons. Disentangling the absolute contributions of the orbital and spin angular momenta is challenging, however, as any transfer between the two occurs on femtosecond timescales. Here we investigate such phenomena by using ultrashort optical laser pulses to change the magnetization of a ferromagnetic film and then probe its dynamics with circularly polarized femtosecond X-ray pulses. Our measurements enable us to disentangle the spin and orbital components of the magnetic moment, revealing different dynamics for L and S. We highlight the important role played by the spin–orbit interaction in the ultrafast laser-induced demagnetization of ferromagnetic films, and show also that the magneto-crystalline anisotropy energy is an important quantity to consider in such processes. Our study provides insights into the dynamics in magnetic systems as well as perspectives for the ultrafast control of information in magnetic recording media.",2010,38,297,4,2,19,20,31,26,29,30,24,28,32
45524fd482e1e348a63c2d146a55a77d6ce36608,"The control of charge transport in an active electronic device depends intimately on the modulation of the internal charge density by an external node. For example, a field-effect transistor relies on the gated electrostatic modulation of the channel charge produced by changing the relative position of the conduction and valence bands with respect to the electrodes. In molecular-scale devices, a longstanding challenge has been to create a true three-terminal device that operates in this manner (that is, by modifying orbital energy). Here we report the observation of such a solid-state molecular device, in which transport current is directly modulated by an external gate voltage. Resonance-enhanced coupling to the nearest molecular orbital is revealed by electron tunnelling spectroscopy, demonstrating direct molecular orbital gating in an electronic device. Our findings demonstrate that true molecular transistors can be created, and so enhance the prospects for molecularly engineered electronic devices.",2009,35,585,8,3,29,65,55,56,74,63,51,45,49
0e15715debd0a700242264e06f84fd9e37ac86a3,"We show numerically that vector antenna arrays can generate radio beams that exhibit spin and orbital angular momentum characteristics similar to those of helical Laguerre-Gauss laser beams in paraxial optics. For low frequencies (< or = 1 GHz), digital techniques can be used to coherently measure the instantaneous, local field vectors and to manipulate them in software. This enables new types of experiments that go beyond what is possible in optics. It allows information-rich radio astronomy and paves the way for novel wireless communication concepts.",2007,59,698,31,2,6,9,7,12,17,17,45,44,78
af174b8b4484dd8657819d20baed7995de17bcdb,"We predict a new category of optical orbital angular momentum that is associated with the curl of polarization and a kind of vector field with radial-variant hybrid states of polarization that can carry such novel optical orbital angular momentum. We present a scheme for creating the desired vector fields. Optical trapping experiments validate that the vector fields, which have no additional phase vortex, exert torques to drive the orbital motion of the trapped isotropic microspheres.",2010,12,161,3,0,6,14,7,12,13,20,18,15,20
6e62526fba615f7e3d0f49711a41fd6047be4b5f,"The structure of the human orbital and medial prefrontal cortex (OMPFC) was investigated using five histological and immunohistochemical stains and was correlated with a previous analysis in macaque monkeys [Carmichael and Price ( 1994 ) J. Comp. Neurol. 346:366–402]. A cortical area was recognized if it was distinct with at least two stains and was found in similar locations in different brains. All of the areas recognized in the macaque OMPFC have counterparts in humans. Areas 11, 13, and 14 were subdivided into areas 11m, 11l, 13a, 13b, 13m, 13l, 14r, and 14c. Within area 10, the region corresponding to area 10m in monkeys was divided into 10m and 10r, and area 10o (orbital) was renamed area 10p (polar). Areas 47/12r, 47/12m, 47/12l, and 47/12s occupy the lateral orbital cortex, corresponding to monkey areas 12r, 12m, 12l, and 12o. The agranular insula (areas Iam, Iapm, Iai, and Ial) extends onto the caudal orbital surface and into the horizontal ramus of the lateral sulcus. The growth of the frontal pole in humans has pushed area 25 and area 32pl, which corresponds to the prelimbic area 32 in Brodmann's monkey brain map, caudal and ventral to the genu of the corpus callosum. Anterior cingulate areas 24a and 24b also extend ventral to the genu of the corpus callosum. Area 32ac, corresponding to the dorsal anterior cingulate area 32 in Brodmann's human brain map, is anterior and dorsal to the genu. The parallel organization of the OMPFC in monkeys and humans allows experimental data from monkeys to be applied to studies of the human cortex. J. Comp. Neurol. 460:425–449, 2003. © 2003 Wiley‐Liss, Inc.",2003,76,858,62,9,9,31,34,47,42,58,52,65,51
6479c0e44ab143679d2337e9b726d6196d8dfa0b,"Geochemical models for Mars predict carbonate formation during aqueous alteration. Carbonate-bearing rocks had not previously been detected on Mars' surface, but Mars Reconnaissance Orbiter mapping reveals a regional rock layer with near-infrared spectral characteristics that are consistent with the presence of magnesium carbonate in the Nili Fossae region. The carbonate is closely associated with both phyllosilicate-bearing and olivine-rich rock units and probably formed during the Noachian or early Hesperian era from the alteration of olivine by either hydrothermal fluids or near-surface water. The presence of carbonate as well as accompanying clays suggests that waters were neutral to alkaline at the time of its formation and that acidic weathering, proposed to be characteristic of Hesperian Mars, did not destroy these carbonates and thus did not dominate all aqueous environments.",2008,89,516,18,2,31,49,39,49,56,39,38,29,36
8b75af5b595e3402c77aa438f926ad3dba9fde17,"Orbital mechanics is a cornerstone subject for aerospace engineering students. Maintaining the focus of the first edition, the author provides the foundation needed to understand the subject and proceed to advanced topics. Starting with the solution of the two-body problem and formulas for the different kinds of orbits, the text moves on to Kepler's equations, orbits in three dimensions, orbital elements from observations, orbital maneuvers, orbital rendezvous and interplanetary missions. This is followed by an introduction to spacecraft dynamics and a final chapter on basic rocket dynamics. The author's teach-by-example approach emphasizes the analytical procedures and computer-implemented algorithms required by today's students. There are a large number of worked examples, illustrations, end of chapter exercises (with answers) as well as many MATLAB[registered] programs for use in homework and projects. The text can be used for one and two semester courses in space mechanics. Features: a new section on numerical integration methods applicable to space mechanics problems; a more centralized and improved discussion of coordinate systems and Euler angle sequences; an expanded development of relative motion in orbit; a new section on quaternions; new worked-out examples, illustrations and homework problems; new algorithms, MATLAB[registered] scripts and simulations; instructor's manual and lecture slides available online; and included online testing and assessment component helps students assess their knowledge of the topics.",2005,0,745,81,1,2,6,5,19,19,31,50,54,71
f7216b952af5bb89b11039ea5a5ebc0edf2f45ca,,2001,0,2803,305,1,21,27,42,65,79,119,111,133,153
c54d65d53d7ada275d34e1a7c53643ff0c82eb93,"Abstract The increasing industrialization and motorization of the world has led to a steep rise for the demand of petroleum-based fuels. Petroleum-based fuels are obtained from limited reserves. These finite reserves are highly concentrated in certain regions of the world. Therefore, those countries not having these resources are facing energy/foreign exchange crisis, mainly due to the import of crude petroleum. Hence, it is necessary to look for alternative fuels which can be produced from resources available locally within the country such as alcohol, biodiesel, vegetable oils etc. This paper reviews the production, characterization and current statuses of vegetable oil and biodiesel as well as the experimental research work carried out in various countries. This paper touches upon well-to-wheel greenhouse gas emissions, well-to-wheel efficiencies, fuel versatility, infrastructure, availability, economics, engine performance and emissions, effect on wear, lubricating oil etc. Ethanol is also an attractive alternative fuel because it is a renewable bio-based resource and it is oxygenated, thereby providing the potential to reduce particulate emissions in compression-ignition engines. In this review, the properties and specifications of ethanol blended with diesel and gasoline fuel are also discussed. Special emphasis is placed on the factors critical to the potential commercial use of these blends. The effect of the fuel on engine performance and emissions (SI as well as compression ignition (CI) engines), and material compatibility is also considered. Biodiesel is methyl or ethyl ester of fatty acid made from virgin or used vegetable oils (both edible and non-edible) and animal fat. The main resources for biodiesel production can be non-edible oils obtained from plant species such as Jatropha curcas (Ratanjyot), Pongamia pinnata (Karanj), Calophyllum inophyllum (Nagchampa), Hevca brasiliensis (Rubber) etc. Biodiesel can be blended in any proportion with mineral diesel to create a biodiesel blend or can be used in its pure form. Just like petroleum diesel, biodiesel operates in compression ignition (diesel) engine, and essentially require very little or no engine modifications because biodiesel has properties similar to mineral diesel. It can be stored just like mineral diesel and hence does not require separate infrastructure. The use of biodiesel in conventional diesel engines result in substantial reduction in emission of unburned hydrocarbons, carbon monoxide and particulate. This review focuses on performance and emission of biodiesel in CI engines, combustion analysis, wear performance on long-term engine usage, and economic feasibility.",2007,97,2767,89,5,44,115,145,190,170,250,224,240,240
da65f4970806ab2724947247e8aa498203443f13,"Preface Preface to the Second Edition Preface to the First Edition 1: Introduction 2: Combustion and Thermochemistry 3: Introduction to Mass Transfer 4: Chemical Kinetics 5: Some Important Chemical Mechanisms 6: Coupling Chemical and Thermal Analyses of Reacting Systems 7: Simplifed Conversation Equations for Reacting Flows 8: Laminar Premixed Flames 9: Laminar Diffusion Flames 10: Droplet Evaporation and Burning 11: Introduction to Turbulent Flows 12: Turbulent Premixed Flames 13: Turbulent Nonpremixed Flames 14: Burning of Solids 15: Pollutant Emissions 16: Detonations Appendix A: Selected Thermodynamic Propertiesof Gases Comprising C-H-O-N System Appendix B: Fuel Properties Appendix C: Selected Properties of Air, Nitrogen, and Oxygen Appendix D: Diffusion Coefficients and Methodology for their Estimation Appendix E: Generalized Newton's Method for the Solution of Nonlinear Equations Appendix F: Computer Codes for Equilibrium Products of Hydrocarbon-Air Combustion",2000,0,2106,187,12,30,26,33,55,62,63,74,68,96
3e0725a32c83ee06419edafccacd6f3768ab5da7,"[1] We present a global tabulation of black carbon (BC) and primary organic carbon (OC) particles emitted from combustion. We include emissions from fossil fuels, biofuels, open biomass burning, and burning of urban waste. Previous ‘‘bottom-up’’ inventories of black and organic carbon have assigned emission factors on the basis of fuel type and economic sector alone. Because emission rates are highly dependent on combustion practice, we consider combinations of fuel, combustion type, and emission controls and their prevalence on a regional basis. Central estimates of global annual emissions are 8.0 Tg for black carbon and 33.9 Tg for organic carbon. These estimates are lower than previously published estimates by 25–35%. The present inventory is based on 1996 fuel-use data, updating previous estimates that have relied on consumption data from 1984. An offset between decreased emission factors and increased energy use since the base year of the previous inventory prevents the difference between this work and previous inventories from being greater. The contributions of fossil fuel, biofuel, and open burning are estimated as 38%, 20%, and 42%, respectively, for BC, and 7%, 19%, and 74%, respectively, for OC. We present a bottom-up estimate of uncertainties in source strength by combining uncertainties in particulate matter emission factors, emission characterization, and fuel use. The total uncertainties are about a factor of 2, with uncertainty ranges of 4.3–22 Tg/yr for BC and 17–77 Tg/yr for OC. Low-technology combustion contributes greatly to both the emissions and the uncertainties. Advances in emission characterization for small residential, industrial, and mobile sources and topdown analysis combining field measurements and transport modeling with iterative inventory development will be required to reduce the uncertainties further. INDEX TERMS: 0305 Atmospheric Composition and Structure: Aerosols and particles (0345, 4801); 0322 Atmospheric Composition and Structure: Constituent sources and sinks; 0345 Atmospheric Composition and Structure: Pollution—urban and regional (0305); 0360 Atmospheric Composition and Structure: Transmission and scattering of radiation; 0365 Atmospheric Composition and Structure: Troposphere—composition and chemistry; KEYWORDS: emission, black carbon, organic carbon, fossil fuel, biofuel, biomass burning",2004,394,2043,178,16,63,49,72,80,122,98,160,145,154
7be9620770607f4f08ec341438bdc52cff53f79b,,2009,0,1388,55,3,15,65,95,114,148,207,185,173,136
49a0fa5c59dc62b44684777c54b2bd0c2294821b,"Abstract Carbon dioxide capture from power plant flue gas and subsequent sequestration is expected to play a key role in mitigating global climate change. Conventional amine technologies being considered for separating CO 2 from flue gas are costly, energy intensive, and if implemented, would result in large increases in the cost of producing electricity. Membranes offer potential as an energy-efficient, low-cost CO 2 capture option. Recently, working with the U.S. Department of Energy (DOE), we have developed membranes with CO 2 permeances of greater than 1000 gpu and a CO 2 /N 2 selectivity of 50 at 30 °C. This permeance is ten times higher than commercial CO 2 membranes and the selectivity is among the highest reported for non-facilitated transport materials. These membranes, in combination with a novel process design that uses incoming combustion air as a sweep gas to generate driving force, could meet DOE CO 2 capture cost targets. Under these conditions, improving membrane permeance is more important than increasing selectivity to further reduce the cost of CO 2 capture from flue gas. Membrane cost and reliability issues will be key to the eventual competitiveness of this technology for flue gas treatment.",2010,27,1107,39,12,37,55,98,97,97,95,150,119,106
bcab7fbc5c745a55d39d5811c96d553865599caf,"Abstract Oxy-fuel combustion is suggested as one of the possible, promising technologies for capturing CO 2 from power plants. The concept of oxy-fuel combustion is removal of nitrogen from the oxidizer to carry out the combustion process in oxygen and, in most concepts, recycled flue gas to lower the flame temperature. The flue gas produced thus consists primarily of carbon dioxide and water. Much research on the different aspects of an oxy-fuel power plant has been performed during the last decade. Focus has mainly been on retrofits of existing pulverized-coal-fired power plant units. Green-field plants which provide additional options for improvement of process economics are however likewise investigated. Of particular interest is the change of the combustion process induced by the exchange of carbon dioxide and water vapor for nitrogen as diluent. This paper reviews the published knowledge on the oxy-fuel process and focuses particularly on the combustion fundamentals, i.e. flame temperatures and heat transfer, ignition and burnout, emissions, and fly ash characteristics. Knowledge is currently available regarding both an entire oxy-fuel power plant and the combustion fundamentals. However, several questions remain unanswered and more research and pilot plant testing of heat transfer profiles, emission levels, the optimum oxygen excess and inlet oxygen concentration levels, high and low-temperature fire-side corrosion, ash quality, plant operability, and models to predict NO x and SO 3 formation is required.",2010,209,959,28,9,65,82,100,101,106,92,90,86,79
07acf3c7e635c7970894192da585672e2bb51c42,"The awareness of the increase in greenhouse gas emissions has resulted in the development of new technologies with lower emissions and technologies that can accommodate capture and sequestration of carbon dioxide. For existing coal-fired combustion plants there are two main options for CO2 capture: removal of nitrogen from flue gases or removal of nitrogen from air before combustion to obtain a gas stream ready for geo-sequestration. In oxy-fuel combustion, fuel is combusted in pure oxygen rather than air. This technology recycles flue gas back into the furnace to control temperature and makeup the volume of the missing N2 to ensure there is sufficient gas to maintain the temperature and heat flux profiles in the boiler. A further advantage of the technology revealed in pilot-scale tests is substantially reduced NOx emissions. For coal-fired combustion, the technology was suggested in the eighties, however, recent developments have led to a renewed interest in the technology. This paper provides a comprehensive review of research that has been undertaken, gives the status of the technology development and assessments providing comparisons with other power generation options, and suggests research needs.",2005,42,1375,41,1,4,9,23,41,84,138,121,146,116
f7216b952af5bb89b11039ea5a5ebc0edf2f45ca,,2001,0,2803,305,1,21,27,42,65,79,119,111,133,153
c54d65d53d7ada275d34e1a7c53643ff0c82eb93,"Abstract The increasing industrialization and motorization of the world has led to a steep rise for the demand of petroleum-based fuels. Petroleum-based fuels are obtained from limited reserves. These finite reserves are highly concentrated in certain regions of the world. Therefore, those countries not having these resources are facing energy/foreign exchange crisis, mainly due to the import of crude petroleum. Hence, it is necessary to look for alternative fuels which can be produced from resources available locally within the country such as alcohol, biodiesel, vegetable oils etc. This paper reviews the production, characterization and current statuses of vegetable oil and biodiesel as well as the experimental research work carried out in various countries. This paper touches upon well-to-wheel greenhouse gas emissions, well-to-wheel efficiencies, fuel versatility, infrastructure, availability, economics, engine performance and emissions, effect on wear, lubricating oil etc. Ethanol is also an attractive alternative fuel because it is a renewable bio-based resource and it is oxygenated, thereby providing the potential to reduce particulate emissions in compression-ignition engines. In this review, the properties and specifications of ethanol blended with diesel and gasoline fuel are also discussed. Special emphasis is placed on the factors critical to the potential commercial use of these blends. The effect of the fuel on engine performance and emissions (SI as well as compression ignition (CI) engines), and material compatibility is also considered. Biodiesel is methyl or ethyl ester of fatty acid made from virgin or used vegetable oils (both edible and non-edible) and animal fat. The main resources for biodiesel production can be non-edible oils obtained from plant species such as Jatropha curcas (Ratanjyot), Pongamia pinnata (Karanj), Calophyllum inophyllum (Nagchampa), Hevca brasiliensis (Rubber) etc. Biodiesel can be blended in any proportion with mineral diesel to create a biodiesel blend or can be used in its pure form. Just like petroleum diesel, biodiesel operates in compression ignition (diesel) engine, and essentially require very little or no engine modifications because biodiesel has properties similar to mineral diesel. It can be stored just like mineral diesel and hence does not require separate infrastructure. The use of biodiesel in conventional diesel engines result in substantial reduction in emission of unburned hydrocarbons, carbon monoxide and particulate. This review focuses on performance and emission of biodiesel in CI engines, combustion analysis, wear performance on long-term engine usage, and economic feasibility.",2007,97,2767,89,5,44,115,145,190,170,250,224,240,240
da65f4970806ab2724947247e8aa498203443f13,"Preface Preface to the Second Edition Preface to the First Edition 1: Introduction 2: Combustion and Thermochemistry 3: Introduction to Mass Transfer 4: Chemical Kinetics 5: Some Important Chemical Mechanisms 6: Coupling Chemical and Thermal Analyses of Reacting Systems 7: Simplifed Conversation Equations for Reacting Flows 8: Laminar Premixed Flames 9: Laminar Diffusion Flames 10: Droplet Evaporation and Burning 11: Introduction to Turbulent Flows 12: Turbulent Premixed Flames 13: Turbulent Nonpremixed Flames 14: Burning of Solids 15: Pollutant Emissions 16: Detonations Appendix A: Selected Thermodynamic Propertiesof Gases Comprising C-H-O-N System Appendix B: Fuel Properties Appendix C: Selected Properties of Air, Nitrogen, and Oxygen Appendix D: Diffusion Coefficients and Methodology for their Estimation Appendix E: Generalized Newton's Method for the Solution of Nonlinear Equations Appendix F: Computer Codes for Equilibrium Products of Hydrocarbon-Air Combustion",2000,0,2106,187,12,30,26,33,55,62,63,74,68,96
3e0725a32c83ee06419edafccacd6f3768ab5da7,"[1] We present a global tabulation of black carbon (BC) and primary organic carbon (OC) particles emitted from combustion. We include emissions from fossil fuels, biofuels, open biomass burning, and burning of urban waste. Previous ‘‘bottom-up’’ inventories of black and organic carbon have assigned emission factors on the basis of fuel type and economic sector alone. Because emission rates are highly dependent on combustion practice, we consider combinations of fuel, combustion type, and emission controls and their prevalence on a regional basis. Central estimates of global annual emissions are 8.0 Tg for black carbon and 33.9 Tg for organic carbon. These estimates are lower than previously published estimates by 25–35%. The present inventory is based on 1996 fuel-use data, updating previous estimates that have relied on consumption data from 1984. An offset between decreased emission factors and increased energy use since the base year of the previous inventory prevents the difference between this work and previous inventories from being greater. The contributions of fossil fuel, biofuel, and open burning are estimated as 38%, 20%, and 42%, respectively, for BC, and 7%, 19%, and 74%, respectively, for OC. We present a bottom-up estimate of uncertainties in source strength by combining uncertainties in particulate matter emission factors, emission characterization, and fuel use. The total uncertainties are about a factor of 2, with uncertainty ranges of 4.3–22 Tg/yr for BC and 17–77 Tg/yr for OC. Low-technology combustion contributes greatly to both the emissions and the uncertainties. Advances in emission characterization for small residential, industrial, and mobile sources and topdown analysis combining field measurements and transport modeling with iterative inventory development will be required to reduce the uncertainties further. INDEX TERMS: 0305 Atmospheric Composition and Structure: Aerosols and particles (0345, 4801); 0322 Atmospheric Composition and Structure: Constituent sources and sinks; 0345 Atmospheric Composition and Structure: Pollution—urban and regional (0305); 0360 Atmospheric Composition and Structure: Transmission and scattering of radiation; 0365 Atmospheric Composition and Structure: Troposphere—composition and chemistry; KEYWORDS: emission, black carbon, organic carbon, fossil fuel, biofuel, biomass burning",2004,394,2043,178,16,63,49,72,80,122,98,160,145,154
7be9620770607f4f08ec341438bdc52cff53f79b,,2009,0,1388,55,3,15,65,95,114,148,207,185,173,136
49a0fa5c59dc62b44684777c54b2bd0c2294821b,"Abstract Carbon dioxide capture from power plant flue gas and subsequent sequestration is expected to play a key role in mitigating global climate change. Conventional amine technologies being considered for separating CO 2 from flue gas are costly, energy intensive, and if implemented, would result in large increases in the cost of producing electricity. Membranes offer potential as an energy-efficient, low-cost CO 2 capture option. Recently, working with the U.S. Department of Energy (DOE), we have developed membranes with CO 2 permeances of greater than 1000 gpu and a CO 2 /N 2 selectivity of 50 at 30 °C. This permeance is ten times higher than commercial CO 2 membranes and the selectivity is among the highest reported for non-facilitated transport materials. These membranes, in combination with a novel process design that uses incoming combustion air as a sweep gas to generate driving force, could meet DOE CO 2 capture cost targets. Under these conditions, improving membrane permeance is more important than increasing selectivity to further reduce the cost of CO 2 capture from flue gas. Membrane cost and reliability issues will be key to the eventual competitiveness of this technology for flue gas treatment.",2010,27,1107,39,12,37,55,98,97,97,95,150,119,106
bcab7fbc5c745a55d39d5811c96d553865599caf,"Abstract Oxy-fuel combustion is suggested as one of the possible, promising technologies for capturing CO 2 from power plants. The concept of oxy-fuel combustion is removal of nitrogen from the oxidizer to carry out the combustion process in oxygen and, in most concepts, recycled flue gas to lower the flame temperature. The flue gas produced thus consists primarily of carbon dioxide and water. Much research on the different aspects of an oxy-fuel power plant has been performed during the last decade. Focus has mainly been on retrofits of existing pulverized-coal-fired power plant units. Green-field plants which provide additional options for improvement of process economics are however likewise investigated. Of particular interest is the change of the combustion process induced by the exchange of carbon dioxide and water vapor for nitrogen as diluent. This paper reviews the published knowledge on the oxy-fuel process and focuses particularly on the combustion fundamentals, i.e. flame temperatures and heat transfer, ignition and burnout, emissions, and fly ash characteristics. Knowledge is currently available regarding both an entire oxy-fuel power plant and the combustion fundamentals. However, several questions remain unanswered and more research and pilot plant testing of heat transfer profiles, emission levels, the optimum oxygen excess and inlet oxygen concentration levels, high and low-temperature fire-side corrosion, ash quality, plant operability, and models to predict NO x and SO 3 formation is required.",2010,209,959,28,9,65,82,100,101,106,92,90,86,79
07acf3c7e635c7970894192da585672e2bb51c42,"The awareness of the increase in greenhouse gas emissions has resulted in the development of new technologies with lower emissions and technologies that can accommodate capture and sequestration of carbon dioxide. For existing coal-fired combustion plants there are two main options for CO2 capture: removal of nitrogen from flue gases or removal of nitrogen from air before combustion to obtain a gas stream ready for geo-sequestration. In oxy-fuel combustion, fuel is combusted in pure oxygen rather than air. This technology recycles flue gas back into the furnace to control temperature and makeup the volume of the missing N2 to ensure there is sufficient gas to maintain the temperature and heat flux profiles in the boiler. A further advantage of the technology revealed in pilot-scale tests is substantially reduced NOx emissions. For coal-fired combustion, the technology was suggested in the eighties, however, recent developments have led to a renewed interest in the technology. This paper provides a comprehensive review of research that has been undertaken, gives the status of the technology development and assessments providing comparisons with other power generation options, and suggests research needs.",2005,42,1375,41,1,4,9,23,41,84,138,121,146,116
f7216b952af5bb89b11039ea5a5ebc0edf2f45ca,,2001,0,2803,305,1,21,27,42,65,79,119,111,133,153
c54d65d53d7ada275d34e1a7c53643ff0c82eb93,"Abstract The increasing industrialization and motorization of the world has led to a steep rise for the demand of petroleum-based fuels. Petroleum-based fuels are obtained from limited reserves. These finite reserves are highly concentrated in certain regions of the world. Therefore, those countries not having these resources are facing energy/foreign exchange crisis, mainly due to the import of crude petroleum. Hence, it is necessary to look for alternative fuels which can be produced from resources available locally within the country such as alcohol, biodiesel, vegetable oils etc. This paper reviews the production, characterization and current statuses of vegetable oil and biodiesel as well as the experimental research work carried out in various countries. This paper touches upon well-to-wheel greenhouse gas emissions, well-to-wheel efficiencies, fuel versatility, infrastructure, availability, economics, engine performance and emissions, effect on wear, lubricating oil etc. Ethanol is also an attractive alternative fuel because it is a renewable bio-based resource and it is oxygenated, thereby providing the potential to reduce particulate emissions in compression-ignition engines. In this review, the properties and specifications of ethanol blended with diesel and gasoline fuel are also discussed. Special emphasis is placed on the factors critical to the potential commercial use of these blends. The effect of the fuel on engine performance and emissions (SI as well as compression ignition (CI) engines), and material compatibility is also considered. Biodiesel is methyl or ethyl ester of fatty acid made from virgin or used vegetable oils (both edible and non-edible) and animal fat. The main resources for biodiesel production can be non-edible oils obtained from plant species such as Jatropha curcas (Ratanjyot), Pongamia pinnata (Karanj), Calophyllum inophyllum (Nagchampa), Hevca brasiliensis (Rubber) etc. Biodiesel can be blended in any proportion with mineral diesel to create a biodiesel blend or can be used in its pure form. Just like petroleum diesel, biodiesel operates in compression ignition (diesel) engine, and essentially require very little or no engine modifications because biodiesel has properties similar to mineral diesel. It can be stored just like mineral diesel and hence does not require separate infrastructure. The use of biodiesel in conventional diesel engines result in substantial reduction in emission of unburned hydrocarbons, carbon monoxide and particulate. This review focuses on performance and emission of biodiesel in CI engines, combustion analysis, wear performance on long-term engine usage, and economic feasibility.",2007,97,2767,89,5,44,115,145,190,170,250,224,240,240
da65f4970806ab2724947247e8aa498203443f13,"Preface Preface to the Second Edition Preface to the First Edition 1: Introduction 2: Combustion and Thermochemistry 3: Introduction to Mass Transfer 4: Chemical Kinetics 5: Some Important Chemical Mechanisms 6: Coupling Chemical and Thermal Analyses of Reacting Systems 7: Simplifed Conversation Equations for Reacting Flows 8: Laminar Premixed Flames 9: Laminar Diffusion Flames 10: Droplet Evaporation and Burning 11: Introduction to Turbulent Flows 12: Turbulent Premixed Flames 13: Turbulent Nonpremixed Flames 14: Burning of Solids 15: Pollutant Emissions 16: Detonations Appendix A: Selected Thermodynamic Propertiesof Gases Comprising C-H-O-N System Appendix B: Fuel Properties Appendix C: Selected Properties of Air, Nitrogen, and Oxygen Appendix D: Diffusion Coefficients and Methodology for their Estimation Appendix E: Generalized Newton's Method for the Solution of Nonlinear Equations Appendix F: Computer Codes for Equilibrium Products of Hydrocarbon-Air Combustion",2000,0,2106,187,12,30,26,33,55,62,63,74,68,96
3e0725a32c83ee06419edafccacd6f3768ab5da7,"[1] We present a global tabulation of black carbon (BC) and primary organic carbon (OC) particles emitted from combustion. We include emissions from fossil fuels, biofuels, open biomass burning, and burning of urban waste. Previous ‘‘bottom-up’’ inventories of black and organic carbon have assigned emission factors on the basis of fuel type and economic sector alone. Because emission rates are highly dependent on combustion practice, we consider combinations of fuel, combustion type, and emission controls and their prevalence on a regional basis. Central estimates of global annual emissions are 8.0 Tg for black carbon and 33.9 Tg for organic carbon. These estimates are lower than previously published estimates by 25–35%. The present inventory is based on 1996 fuel-use data, updating previous estimates that have relied on consumption data from 1984. An offset between decreased emission factors and increased energy use since the base year of the previous inventory prevents the difference between this work and previous inventories from being greater. The contributions of fossil fuel, biofuel, and open burning are estimated as 38%, 20%, and 42%, respectively, for BC, and 7%, 19%, and 74%, respectively, for OC. We present a bottom-up estimate of uncertainties in source strength by combining uncertainties in particulate matter emission factors, emission characterization, and fuel use. The total uncertainties are about a factor of 2, with uncertainty ranges of 4.3–22 Tg/yr for BC and 17–77 Tg/yr for OC. Low-technology combustion contributes greatly to both the emissions and the uncertainties. Advances in emission characterization for small residential, industrial, and mobile sources and topdown analysis combining field measurements and transport modeling with iterative inventory development will be required to reduce the uncertainties further. INDEX TERMS: 0305 Atmospheric Composition and Structure: Aerosols and particles (0345, 4801); 0322 Atmospheric Composition and Structure: Constituent sources and sinks; 0345 Atmospheric Composition and Structure: Pollution—urban and regional (0305); 0360 Atmospheric Composition and Structure: Transmission and scattering of radiation; 0365 Atmospheric Composition and Structure: Troposphere—composition and chemistry; KEYWORDS: emission, black carbon, organic carbon, fossil fuel, biofuel, biomass burning",2004,394,2043,178,16,63,49,72,80,122,98,160,145,154
7be9620770607f4f08ec341438bdc52cff53f79b,,2009,0,1388,55,3,15,65,95,114,148,207,185,173,136
49a0fa5c59dc62b44684777c54b2bd0c2294821b,"Abstract Carbon dioxide capture from power plant flue gas and subsequent sequestration is expected to play a key role in mitigating global climate change. Conventional amine technologies being considered for separating CO 2 from flue gas are costly, energy intensive, and if implemented, would result in large increases in the cost of producing electricity. Membranes offer potential as an energy-efficient, low-cost CO 2 capture option. Recently, working with the U.S. Department of Energy (DOE), we have developed membranes with CO 2 permeances of greater than 1000 gpu and a CO 2 /N 2 selectivity of 50 at 30 °C. This permeance is ten times higher than commercial CO 2 membranes and the selectivity is among the highest reported for non-facilitated transport materials. These membranes, in combination with a novel process design that uses incoming combustion air as a sweep gas to generate driving force, could meet DOE CO 2 capture cost targets. Under these conditions, improving membrane permeance is more important than increasing selectivity to further reduce the cost of CO 2 capture from flue gas. Membrane cost and reliability issues will be key to the eventual competitiveness of this technology for flue gas treatment.",2010,27,1107,39,12,37,55,98,97,97,95,150,119,106
bcab7fbc5c745a55d39d5811c96d553865599caf,"Abstract Oxy-fuel combustion is suggested as one of the possible, promising technologies for capturing CO 2 from power plants. The concept of oxy-fuel combustion is removal of nitrogen from the oxidizer to carry out the combustion process in oxygen and, in most concepts, recycled flue gas to lower the flame temperature. The flue gas produced thus consists primarily of carbon dioxide and water. Much research on the different aspects of an oxy-fuel power plant has been performed during the last decade. Focus has mainly been on retrofits of existing pulverized-coal-fired power plant units. Green-field plants which provide additional options for improvement of process economics are however likewise investigated. Of particular interest is the change of the combustion process induced by the exchange of carbon dioxide and water vapor for nitrogen as diluent. This paper reviews the published knowledge on the oxy-fuel process and focuses particularly on the combustion fundamentals, i.e. flame temperatures and heat transfer, ignition and burnout, emissions, and fly ash characteristics. Knowledge is currently available regarding both an entire oxy-fuel power plant and the combustion fundamentals. However, several questions remain unanswered and more research and pilot plant testing of heat transfer profiles, emission levels, the optimum oxygen excess and inlet oxygen concentration levels, high and low-temperature fire-side corrosion, ash quality, plant operability, and models to predict NO x and SO 3 formation is required.",2010,209,959,28,9,65,82,100,101,106,92,90,86,79
07acf3c7e635c7970894192da585672e2bb51c42,"The awareness of the increase in greenhouse gas emissions has resulted in the development of new technologies with lower emissions and technologies that can accommodate capture and sequestration of carbon dioxide. For existing coal-fired combustion plants there are two main options for CO2 capture: removal of nitrogen from flue gases or removal of nitrogen from air before combustion to obtain a gas stream ready for geo-sequestration. In oxy-fuel combustion, fuel is combusted in pure oxygen rather than air. This technology recycles flue gas back into the furnace to control temperature and makeup the volume of the missing N2 to ensure there is sufficient gas to maintain the temperature and heat flux profiles in the boiler. A further advantage of the technology revealed in pilot-scale tests is substantially reduced NOx emissions. For coal-fired combustion, the technology was suggested in the eighties, however, recent developments have led to a renewed interest in the technology. This paper provides a comprehensive review of research that has been undertaken, gives the status of the technology development and assessments providing comparisons with other power generation options, and suggests research needs.",2005,42,1375,41,1,4,9,23,41,84,138,121,146,116
f7216b952af5bb89b11039ea5a5ebc0edf2f45ca,,2001,0,2803,305,1,21,27,42,65,79,119,111,133,153
c54d65d53d7ada275d34e1a7c53643ff0c82eb93,"Abstract The increasing industrialization and motorization of the world has led to a steep rise for the demand of petroleum-based fuels. Petroleum-based fuels are obtained from limited reserves. These finite reserves are highly concentrated in certain regions of the world. Therefore, those countries not having these resources are facing energy/foreign exchange crisis, mainly due to the import of crude petroleum. Hence, it is necessary to look for alternative fuels which can be produced from resources available locally within the country such as alcohol, biodiesel, vegetable oils etc. This paper reviews the production, characterization and current statuses of vegetable oil and biodiesel as well as the experimental research work carried out in various countries. This paper touches upon well-to-wheel greenhouse gas emissions, well-to-wheel efficiencies, fuel versatility, infrastructure, availability, economics, engine performance and emissions, effect on wear, lubricating oil etc. Ethanol is also an attractive alternative fuel because it is a renewable bio-based resource and it is oxygenated, thereby providing the potential to reduce particulate emissions in compression-ignition engines. In this review, the properties and specifications of ethanol blended with diesel and gasoline fuel are also discussed. Special emphasis is placed on the factors critical to the potential commercial use of these blends. The effect of the fuel on engine performance and emissions (SI as well as compression ignition (CI) engines), and material compatibility is also considered. Biodiesel is methyl or ethyl ester of fatty acid made from virgin or used vegetable oils (both edible and non-edible) and animal fat. The main resources for biodiesel production can be non-edible oils obtained from plant species such as Jatropha curcas (Ratanjyot), Pongamia pinnata (Karanj), Calophyllum inophyllum (Nagchampa), Hevca brasiliensis (Rubber) etc. Biodiesel can be blended in any proportion with mineral diesel to create a biodiesel blend or can be used in its pure form. Just like petroleum diesel, biodiesel operates in compression ignition (diesel) engine, and essentially require very little or no engine modifications because biodiesel has properties similar to mineral diesel. It can be stored just like mineral diesel and hence does not require separate infrastructure. The use of biodiesel in conventional diesel engines result in substantial reduction in emission of unburned hydrocarbons, carbon monoxide and particulate. This review focuses on performance and emission of biodiesel in CI engines, combustion analysis, wear performance on long-term engine usage, and economic feasibility.",2007,97,2767,89,5,44,115,145,190,170,250,224,240,240
da65f4970806ab2724947247e8aa498203443f13,"Preface Preface to the Second Edition Preface to the First Edition 1: Introduction 2: Combustion and Thermochemistry 3: Introduction to Mass Transfer 4: Chemical Kinetics 5: Some Important Chemical Mechanisms 6: Coupling Chemical and Thermal Analyses of Reacting Systems 7: Simplifed Conversation Equations for Reacting Flows 8: Laminar Premixed Flames 9: Laminar Diffusion Flames 10: Droplet Evaporation and Burning 11: Introduction to Turbulent Flows 12: Turbulent Premixed Flames 13: Turbulent Nonpremixed Flames 14: Burning of Solids 15: Pollutant Emissions 16: Detonations Appendix A: Selected Thermodynamic Propertiesof Gases Comprising C-H-O-N System Appendix B: Fuel Properties Appendix C: Selected Properties of Air, Nitrogen, and Oxygen Appendix D: Diffusion Coefficients and Methodology for their Estimation Appendix E: Generalized Newton's Method for the Solution of Nonlinear Equations Appendix F: Computer Codes for Equilibrium Products of Hydrocarbon-Air Combustion",2000,0,2106,187,12,30,26,33,55,62,63,74,68,96
3e0725a32c83ee06419edafccacd6f3768ab5da7,"[1] We present a global tabulation of black carbon (BC) and primary organic carbon (OC) particles emitted from combustion. We include emissions from fossil fuels, biofuels, open biomass burning, and burning of urban waste. Previous ‘‘bottom-up’’ inventories of black and organic carbon have assigned emission factors on the basis of fuel type and economic sector alone. Because emission rates are highly dependent on combustion practice, we consider combinations of fuel, combustion type, and emission controls and their prevalence on a regional basis. Central estimates of global annual emissions are 8.0 Tg for black carbon and 33.9 Tg for organic carbon. These estimates are lower than previously published estimates by 25–35%. The present inventory is based on 1996 fuel-use data, updating previous estimates that have relied on consumption data from 1984. An offset between decreased emission factors and increased energy use since the base year of the previous inventory prevents the difference between this work and previous inventories from being greater. The contributions of fossil fuel, biofuel, and open burning are estimated as 38%, 20%, and 42%, respectively, for BC, and 7%, 19%, and 74%, respectively, for OC. We present a bottom-up estimate of uncertainties in source strength by combining uncertainties in particulate matter emission factors, emission characterization, and fuel use. The total uncertainties are about a factor of 2, with uncertainty ranges of 4.3–22 Tg/yr for BC and 17–77 Tg/yr for OC. Low-technology combustion contributes greatly to both the emissions and the uncertainties. Advances in emission characterization for small residential, industrial, and mobile sources and topdown analysis combining field measurements and transport modeling with iterative inventory development will be required to reduce the uncertainties further. INDEX TERMS: 0305 Atmospheric Composition and Structure: Aerosols and particles (0345, 4801); 0322 Atmospheric Composition and Structure: Constituent sources and sinks; 0345 Atmospheric Composition and Structure: Pollution—urban and regional (0305); 0360 Atmospheric Composition and Structure: Transmission and scattering of radiation; 0365 Atmospheric Composition and Structure: Troposphere—composition and chemistry; KEYWORDS: emission, black carbon, organic carbon, fossil fuel, biofuel, biomass burning",2004,394,2043,178,16,63,49,72,80,122,98,160,145,154
7be9620770607f4f08ec341438bdc52cff53f79b,,2009,0,1388,55,3,15,65,95,114,148,207,185,173,136
49a0fa5c59dc62b44684777c54b2bd0c2294821b,"Abstract Carbon dioxide capture from power plant flue gas and subsequent sequestration is expected to play a key role in mitigating global climate change. Conventional amine technologies being considered for separating CO 2 from flue gas are costly, energy intensive, and if implemented, would result in large increases in the cost of producing electricity. Membranes offer potential as an energy-efficient, low-cost CO 2 capture option. Recently, working with the U.S. Department of Energy (DOE), we have developed membranes with CO 2 permeances of greater than 1000 gpu and a CO 2 /N 2 selectivity of 50 at 30 °C. This permeance is ten times higher than commercial CO 2 membranes and the selectivity is among the highest reported for non-facilitated transport materials. These membranes, in combination with a novel process design that uses incoming combustion air as a sweep gas to generate driving force, could meet DOE CO 2 capture cost targets. Under these conditions, improving membrane permeance is more important than increasing selectivity to further reduce the cost of CO 2 capture from flue gas. Membrane cost and reliability issues will be key to the eventual competitiveness of this technology for flue gas treatment.",2010,27,1107,39,12,37,55,98,97,97,95,150,119,106
bcab7fbc5c745a55d39d5811c96d553865599caf,"Abstract Oxy-fuel combustion is suggested as one of the possible, promising technologies for capturing CO 2 from power plants. The concept of oxy-fuel combustion is removal of nitrogen from the oxidizer to carry out the combustion process in oxygen and, in most concepts, recycled flue gas to lower the flame temperature. The flue gas produced thus consists primarily of carbon dioxide and water. Much research on the different aspects of an oxy-fuel power plant has been performed during the last decade. Focus has mainly been on retrofits of existing pulverized-coal-fired power plant units. Green-field plants which provide additional options for improvement of process economics are however likewise investigated. Of particular interest is the change of the combustion process induced by the exchange of carbon dioxide and water vapor for nitrogen as diluent. This paper reviews the published knowledge on the oxy-fuel process and focuses particularly on the combustion fundamentals, i.e. flame temperatures and heat transfer, ignition and burnout, emissions, and fly ash characteristics. Knowledge is currently available regarding both an entire oxy-fuel power plant and the combustion fundamentals. However, several questions remain unanswered and more research and pilot plant testing of heat transfer profiles, emission levels, the optimum oxygen excess and inlet oxygen concentration levels, high and low-temperature fire-side corrosion, ash quality, plant operability, and models to predict NO x and SO 3 formation is required.",2010,209,959,28,9,65,82,100,101,106,92,90,86,79
07acf3c7e635c7970894192da585672e2bb51c42,"The awareness of the increase in greenhouse gas emissions has resulted in the development of new technologies with lower emissions and technologies that can accommodate capture and sequestration of carbon dioxide. For existing coal-fired combustion plants there are two main options for CO2 capture: removal of nitrogen from flue gases or removal of nitrogen from air before combustion to obtain a gas stream ready for geo-sequestration. In oxy-fuel combustion, fuel is combusted in pure oxygen rather than air. This technology recycles flue gas back into the furnace to control temperature and makeup the volume of the missing N2 to ensure there is sufficient gas to maintain the temperature and heat flux profiles in the boiler. A further advantage of the technology revealed in pilot-scale tests is substantially reduced NOx emissions. For coal-fired combustion, the technology was suggested in the eighties, however, recent developments have led to a renewed interest in the technology. This paper provides a comprehensive review of research that has been undertaken, gives the status of the technology development and assessments providing comparisons with other power generation options, and suggests research needs.",2005,42,1375,41,1,4,9,23,41,84,138,121,146,116
f7216b952af5bb89b11039ea5a5ebc0edf2f45ca,,2001,0,2803,305,1,21,27,42,65,79,119,111,133,153
c54d65d53d7ada275d34e1a7c53643ff0c82eb93,"Abstract The increasing industrialization and motorization of the world has led to a steep rise for the demand of petroleum-based fuels. Petroleum-based fuels are obtained from limited reserves. These finite reserves are highly concentrated in certain regions of the world. Therefore, those countries not having these resources are facing energy/foreign exchange crisis, mainly due to the import of crude petroleum. Hence, it is necessary to look for alternative fuels which can be produced from resources available locally within the country such as alcohol, biodiesel, vegetable oils etc. This paper reviews the production, characterization and current statuses of vegetable oil and biodiesel as well as the experimental research work carried out in various countries. This paper touches upon well-to-wheel greenhouse gas emissions, well-to-wheel efficiencies, fuel versatility, infrastructure, availability, economics, engine performance and emissions, effect on wear, lubricating oil etc. Ethanol is also an attractive alternative fuel because it is a renewable bio-based resource and it is oxygenated, thereby providing the potential to reduce particulate emissions in compression-ignition engines. In this review, the properties and specifications of ethanol blended with diesel and gasoline fuel are also discussed. Special emphasis is placed on the factors critical to the potential commercial use of these blends. The effect of the fuel on engine performance and emissions (SI as well as compression ignition (CI) engines), and material compatibility is also considered. Biodiesel is methyl or ethyl ester of fatty acid made from virgin or used vegetable oils (both edible and non-edible) and animal fat. The main resources for biodiesel production can be non-edible oils obtained from plant species such as Jatropha curcas (Ratanjyot), Pongamia pinnata (Karanj), Calophyllum inophyllum (Nagchampa), Hevca brasiliensis (Rubber) etc. Biodiesel can be blended in any proportion with mineral diesel to create a biodiesel blend or can be used in its pure form. Just like petroleum diesel, biodiesel operates in compression ignition (diesel) engine, and essentially require very little or no engine modifications because biodiesel has properties similar to mineral diesel. It can be stored just like mineral diesel and hence does not require separate infrastructure. The use of biodiesel in conventional diesel engines result in substantial reduction in emission of unburned hydrocarbons, carbon monoxide and particulate. This review focuses on performance and emission of biodiesel in CI engines, combustion analysis, wear performance on long-term engine usage, and economic feasibility.",2007,97,2767,89,5,44,115,145,190,170,250,224,240,240
da65f4970806ab2724947247e8aa498203443f13,"Preface Preface to the Second Edition Preface to the First Edition 1: Introduction 2: Combustion and Thermochemistry 3: Introduction to Mass Transfer 4: Chemical Kinetics 5: Some Important Chemical Mechanisms 6: Coupling Chemical and Thermal Analyses of Reacting Systems 7: Simplifed Conversation Equations for Reacting Flows 8: Laminar Premixed Flames 9: Laminar Diffusion Flames 10: Droplet Evaporation and Burning 11: Introduction to Turbulent Flows 12: Turbulent Premixed Flames 13: Turbulent Nonpremixed Flames 14: Burning of Solids 15: Pollutant Emissions 16: Detonations Appendix A: Selected Thermodynamic Propertiesof Gases Comprising C-H-O-N System Appendix B: Fuel Properties Appendix C: Selected Properties of Air, Nitrogen, and Oxygen Appendix D: Diffusion Coefficients and Methodology for their Estimation Appendix E: Generalized Newton's Method for the Solution of Nonlinear Equations Appendix F: Computer Codes for Equilibrium Products of Hydrocarbon-Air Combustion",2000,0,2106,187,12,30,26,33,55,62,63,74,68,96
3e0725a32c83ee06419edafccacd6f3768ab5da7,"[1] We present a global tabulation of black carbon (BC) and primary organic carbon (OC) particles emitted from combustion. We include emissions from fossil fuels, biofuels, open biomass burning, and burning of urban waste. Previous ‘‘bottom-up’’ inventories of black and organic carbon have assigned emission factors on the basis of fuel type and economic sector alone. Because emission rates are highly dependent on combustion practice, we consider combinations of fuel, combustion type, and emission controls and their prevalence on a regional basis. Central estimates of global annual emissions are 8.0 Tg for black carbon and 33.9 Tg for organic carbon. These estimates are lower than previously published estimates by 25–35%. The present inventory is based on 1996 fuel-use data, updating previous estimates that have relied on consumption data from 1984. An offset between decreased emission factors and increased energy use since the base year of the previous inventory prevents the difference between this work and previous inventories from being greater. The contributions of fossil fuel, biofuel, and open burning are estimated as 38%, 20%, and 42%, respectively, for BC, and 7%, 19%, and 74%, respectively, for OC. We present a bottom-up estimate of uncertainties in source strength by combining uncertainties in particulate matter emission factors, emission characterization, and fuel use. The total uncertainties are about a factor of 2, with uncertainty ranges of 4.3–22 Tg/yr for BC and 17–77 Tg/yr for OC. Low-technology combustion contributes greatly to both the emissions and the uncertainties. Advances in emission characterization for small residential, industrial, and mobile sources and topdown analysis combining field measurements and transport modeling with iterative inventory development will be required to reduce the uncertainties further. INDEX TERMS: 0305 Atmospheric Composition and Structure: Aerosols and particles (0345, 4801); 0322 Atmospheric Composition and Structure: Constituent sources and sinks; 0345 Atmospheric Composition and Structure: Pollution—urban and regional (0305); 0360 Atmospheric Composition and Structure: Transmission and scattering of radiation; 0365 Atmospheric Composition and Structure: Troposphere—composition and chemistry; KEYWORDS: emission, black carbon, organic carbon, fossil fuel, biofuel, biomass burning",2004,394,2043,178,16,63,49,72,80,122,98,160,145,154
7be9620770607f4f08ec341438bdc52cff53f79b,,2009,0,1388,55,3,15,65,95,114,148,207,185,173,136
49a0fa5c59dc62b44684777c54b2bd0c2294821b,"Abstract Carbon dioxide capture from power plant flue gas and subsequent sequestration is expected to play a key role in mitigating global climate change. Conventional amine technologies being considered for separating CO 2 from flue gas are costly, energy intensive, and if implemented, would result in large increases in the cost of producing electricity. Membranes offer potential as an energy-efficient, low-cost CO 2 capture option. Recently, working with the U.S. Department of Energy (DOE), we have developed membranes with CO 2 permeances of greater than 1000 gpu and a CO 2 /N 2 selectivity of 50 at 30 °C. This permeance is ten times higher than commercial CO 2 membranes and the selectivity is among the highest reported for non-facilitated transport materials. These membranes, in combination with a novel process design that uses incoming combustion air as a sweep gas to generate driving force, could meet DOE CO 2 capture cost targets. Under these conditions, improving membrane permeance is more important than increasing selectivity to further reduce the cost of CO 2 capture from flue gas. Membrane cost and reliability issues will be key to the eventual competitiveness of this technology for flue gas treatment.",2010,27,1107,39,12,37,55,98,97,97,95,150,119,106
bcab7fbc5c745a55d39d5811c96d553865599caf,"Abstract Oxy-fuel combustion is suggested as one of the possible, promising technologies for capturing CO 2 from power plants. The concept of oxy-fuel combustion is removal of nitrogen from the oxidizer to carry out the combustion process in oxygen and, in most concepts, recycled flue gas to lower the flame temperature. The flue gas produced thus consists primarily of carbon dioxide and water. Much research on the different aspects of an oxy-fuel power plant has been performed during the last decade. Focus has mainly been on retrofits of existing pulverized-coal-fired power plant units. Green-field plants which provide additional options for improvement of process economics are however likewise investigated. Of particular interest is the change of the combustion process induced by the exchange of carbon dioxide and water vapor for nitrogen as diluent. This paper reviews the published knowledge on the oxy-fuel process and focuses particularly on the combustion fundamentals, i.e. flame temperatures and heat transfer, ignition and burnout, emissions, and fly ash characteristics. Knowledge is currently available regarding both an entire oxy-fuel power plant and the combustion fundamentals. However, several questions remain unanswered and more research and pilot plant testing of heat transfer profiles, emission levels, the optimum oxygen excess and inlet oxygen concentration levels, high and low-temperature fire-side corrosion, ash quality, plant operability, and models to predict NO x and SO 3 formation is required.",2010,209,959,28,9,65,82,100,101,106,92,90,86,79
07acf3c7e635c7970894192da585672e2bb51c42,"The awareness of the increase in greenhouse gas emissions has resulted in the development of new technologies with lower emissions and technologies that can accommodate capture and sequestration of carbon dioxide. For existing coal-fired combustion plants there are two main options for CO2 capture: removal of nitrogen from flue gases or removal of nitrogen from air before combustion to obtain a gas stream ready for geo-sequestration. In oxy-fuel combustion, fuel is combusted in pure oxygen rather than air. This technology recycles flue gas back into the furnace to control temperature and makeup the volume of the missing N2 to ensure there is sufficient gas to maintain the temperature and heat flux profiles in the boiler. A further advantage of the technology revealed in pilot-scale tests is substantially reduced NOx emissions. For coal-fired combustion, the technology was suggested in the eighties, however, recent developments have led to a renewed interest in the technology. This paper provides a comprehensive review of research that has been undertaken, gives the status of the technology development and assessments providing comparisons with other power generation options, and suggests research needs.",2005,42,1375,41,1,4,9,23,41,84,138,121,146,116
f7216b952af5bb89b11039ea5a5ebc0edf2f45ca,,2001,0,2803,305,1,21,27,42,65,79,119,111,133,153
c54d65d53d7ada275d34e1a7c53643ff0c82eb93,"Abstract The increasing industrialization and motorization of the world has led to a steep rise for the demand of petroleum-based fuels. Petroleum-based fuels are obtained from limited reserves. These finite reserves are highly concentrated in certain regions of the world. Therefore, those countries not having these resources are facing energy/foreign exchange crisis, mainly due to the import of crude petroleum. Hence, it is necessary to look for alternative fuels which can be produced from resources available locally within the country such as alcohol, biodiesel, vegetable oils etc. This paper reviews the production, characterization and current statuses of vegetable oil and biodiesel as well as the experimental research work carried out in various countries. This paper touches upon well-to-wheel greenhouse gas emissions, well-to-wheel efficiencies, fuel versatility, infrastructure, availability, economics, engine performance and emissions, effect on wear, lubricating oil etc. Ethanol is also an attractive alternative fuel because it is a renewable bio-based resource and it is oxygenated, thereby providing the potential to reduce particulate emissions in compression-ignition engines. In this review, the properties and specifications of ethanol blended with diesel and gasoline fuel are also discussed. Special emphasis is placed on the factors critical to the potential commercial use of these blends. The effect of the fuel on engine performance and emissions (SI as well as compression ignition (CI) engines), and material compatibility is also considered. Biodiesel is methyl or ethyl ester of fatty acid made from virgin or used vegetable oils (both edible and non-edible) and animal fat. The main resources for biodiesel production can be non-edible oils obtained from plant species such as Jatropha curcas (Ratanjyot), Pongamia pinnata (Karanj), Calophyllum inophyllum (Nagchampa), Hevca brasiliensis (Rubber) etc. Biodiesel can be blended in any proportion with mineral diesel to create a biodiesel blend or can be used in its pure form. Just like petroleum diesel, biodiesel operates in compression ignition (diesel) engine, and essentially require very little or no engine modifications because biodiesel has properties similar to mineral diesel. It can be stored just like mineral diesel and hence does not require separate infrastructure. The use of biodiesel in conventional diesel engines result in substantial reduction in emission of unburned hydrocarbons, carbon monoxide and particulate. This review focuses on performance and emission of biodiesel in CI engines, combustion analysis, wear performance on long-term engine usage, and economic feasibility.",2007,97,2767,89,5,44,115,145,190,170,250,224,240,240
da65f4970806ab2724947247e8aa498203443f13,"Preface Preface to the Second Edition Preface to the First Edition 1: Introduction 2: Combustion and Thermochemistry 3: Introduction to Mass Transfer 4: Chemical Kinetics 5: Some Important Chemical Mechanisms 6: Coupling Chemical and Thermal Analyses of Reacting Systems 7: Simplifed Conversation Equations for Reacting Flows 8: Laminar Premixed Flames 9: Laminar Diffusion Flames 10: Droplet Evaporation and Burning 11: Introduction to Turbulent Flows 12: Turbulent Premixed Flames 13: Turbulent Nonpremixed Flames 14: Burning of Solids 15: Pollutant Emissions 16: Detonations Appendix A: Selected Thermodynamic Propertiesof Gases Comprising C-H-O-N System Appendix B: Fuel Properties Appendix C: Selected Properties of Air, Nitrogen, and Oxygen Appendix D: Diffusion Coefficients and Methodology for their Estimation Appendix E: Generalized Newton's Method for the Solution of Nonlinear Equations Appendix F: Computer Codes for Equilibrium Products of Hydrocarbon-Air Combustion",2000,0,2106,187,12,30,26,33,55,62,63,74,68,96
3e0725a32c83ee06419edafccacd6f3768ab5da7,"[1] We present a global tabulation of black carbon (BC) and primary organic carbon (OC) particles emitted from combustion. We include emissions from fossil fuels, biofuels, open biomass burning, and burning of urban waste. Previous ‘‘bottom-up’’ inventories of black and organic carbon have assigned emission factors on the basis of fuel type and economic sector alone. Because emission rates are highly dependent on combustion practice, we consider combinations of fuel, combustion type, and emission controls and their prevalence on a regional basis. Central estimates of global annual emissions are 8.0 Tg for black carbon and 33.9 Tg for organic carbon. These estimates are lower than previously published estimates by 25–35%. The present inventory is based on 1996 fuel-use data, updating previous estimates that have relied on consumption data from 1984. An offset between decreased emission factors and increased energy use since the base year of the previous inventory prevents the difference between this work and previous inventories from being greater. The contributions of fossil fuel, biofuel, and open burning are estimated as 38%, 20%, and 42%, respectively, for BC, and 7%, 19%, and 74%, respectively, for OC. We present a bottom-up estimate of uncertainties in source strength by combining uncertainties in particulate matter emission factors, emission characterization, and fuel use. The total uncertainties are about a factor of 2, with uncertainty ranges of 4.3–22 Tg/yr for BC and 17–77 Tg/yr for OC. Low-technology combustion contributes greatly to both the emissions and the uncertainties. Advances in emission characterization for small residential, industrial, and mobile sources and topdown analysis combining field measurements and transport modeling with iterative inventory development will be required to reduce the uncertainties further. INDEX TERMS: 0305 Atmospheric Composition and Structure: Aerosols and particles (0345, 4801); 0322 Atmospheric Composition and Structure: Constituent sources and sinks; 0345 Atmospheric Composition and Structure: Pollution—urban and regional (0305); 0360 Atmospheric Composition and Structure: Transmission and scattering of radiation; 0365 Atmospheric Composition and Structure: Troposphere—composition and chemistry; KEYWORDS: emission, black carbon, organic carbon, fossil fuel, biofuel, biomass burning",2004,394,2043,178,16,63,49,72,80,122,98,160,145,154
7be9620770607f4f08ec341438bdc52cff53f79b,,2009,0,1388,55,3,15,65,95,114,148,207,185,173,136
49a0fa5c59dc62b44684777c54b2bd0c2294821b,"Abstract Carbon dioxide capture from power plant flue gas and subsequent sequestration is expected to play a key role in mitigating global climate change. Conventional amine technologies being considered for separating CO 2 from flue gas are costly, energy intensive, and if implemented, would result in large increases in the cost of producing electricity. Membranes offer potential as an energy-efficient, low-cost CO 2 capture option. Recently, working with the U.S. Department of Energy (DOE), we have developed membranes with CO 2 permeances of greater than 1000 gpu and a CO 2 /N 2 selectivity of 50 at 30 °C. This permeance is ten times higher than commercial CO 2 membranes and the selectivity is among the highest reported for non-facilitated transport materials. These membranes, in combination with a novel process design that uses incoming combustion air as a sweep gas to generate driving force, could meet DOE CO 2 capture cost targets. Under these conditions, improving membrane permeance is more important than increasing selectivity to further reduce the cost of CO 2 capture from flue gas. Membrane cost and reliability issues will be key to the eventual competitiveness of this technology for flue gas treatment.",2010,27,1107,39,12,37,55,98,97,97,95,150,119,106
bcab7fbc5c745a55d39d5811c96d553865599caf,"Abstract Oxy-fuel combustion is suggested as one of the possible, promising technologies for capturing CO 2 from power plants. The concept of oxy-fuel combustion is removal of nitrogen from the oxidizer to carry out the combustion process in oxygen and, in most concepts, recycled flue gas to lower the flame temperature. The flue gas produced thus consists primarily of carbon dioxide and water. Much research on the different aspects of an oxy-fuel power plant has been performed during the last decade. Focus has mainly been on retrofits of existing pulverized-coal-fired power plant units. Green-field plants which provide additional options for improvement of process economics are however likewise investigated. Of particular interest is the change of the combustion process induced by the exchange of carbon dioxide and water vapor for nitrogen as diluent. This paper reviews the published knowledge on the oxy-fuel process and focuses particularly on the combustion fundamentals, i.e. flame temperatures and heat transfer, ignition and burnout, emissions, and fly ash characteristics. Knowledge is currently available regarding both an entire oxy-fuel power plant and the combustion fundamentals. However, several questions remain unanswered and more research and pilot plant testing of heat transfer profiles, emission levels, the optimum oxygen excess and inlet oxygen concentration levels, high and low-temperature fire-side corrosion, ash quality, plant operability, and models to predict NO x and SO 3 formation is required.",2010,209,959,28,9,65,82,100,101,106,92,90,86,79
07acf3c7e635c7970894192da585672e2bb51c42,"The awareness of the increase in greenhouse gas emissions has resulted in the development of new technologies with lower emissions and technologies that can accommodate capture and sequestration of carbon dioxide. For existing coal-fired combustion plants there are two main options for CO2 capture: removal of nitrogen from flue gases or removal of nitrogen from air before combustion to obtain a gas stream ready for geo-sequestration. In oxy-fuel combustion, fuel is combusted in pure oxygen rather than air. This technology recycles flue gas back into the furnace to control temperature and makeup the volume of the missing N2 to ensure there is sufficient gas to maintain the temperature and heat flux profiles in the boiler. A further advantage of the technology revealed in pilot-scale tests is substantially reduced NOx emissions. For coal-fired combustion, the technology was suggested in the eighties, however, recent developments have led to a renewed interest in the technology. This paper provides a comprehensive review of research that has been undertaken, gives the status of the technology development and assessments providing comparisons with other power generation options, and suggests research needs.",2005,42,1375,41,1,4,9,23,41,84,138,121,146,116
f7216b952af5bb89b11039ea5a5ebc0edf2f45ca,,2001,0,2803,305,1,21,27,42,65,79,119,111,133,153
c54d65d53d7ada275d34e1a7c53643ff0c82eb93,"Abstract The increasing industrialization and motorization of the world has led to a steep rise for the demand of petroleum-based fuels. Petroleum-based fuels are obtained from limited reserves. These finite reserves are highly concentrated in certain regions of the world. Therefore, those countries not having these resources are facing energy/foreign exchange crisis, mainly due to the import of crude petroleum. Hence, it is necessary to look for alternative fuels which can be produced from resources available locally within the country such as alcohol, biodiesel, vegetable oils etc. This paper reviews the production, characterization and current statuses of vegetable oil and biodiesel as well as the experimental research work carried out in various countries. This paper touches upon well-to-wheel greenhouse gas emissions, well-to-wheel efficiencies, fuel versatility, infrastructure, availability, economics, engine performance and emissions, effect on wear, lubricating oil etc. Ethanol is also an attractive alternative fuel because it is a renewable bio-based resource and it is oxygenated, thereby providing the potential to reduce particulate emissions in compression-ignition engines. In this review, the properties and specifications of ethanol blended with diesel and gasoline fuel are also discussed. Special emphasis is placed on the factors critical to the potential commercial use of these blends. The effect of the fuel on engine performance and emissions (SI as well as compression ignition (CI) engines), and material compatibility is also considered. Biodiesel is methyl or ethyl ester of fatty acid made from virgin or used vegetable oils (both edible and non-edible) and animal fat. The main resources for biodiesel production can be non-edible oils obtained from plant species such as Jatropha curcas (Ratanjyot), Pongamia pinnata (Karanj), Calophyllum inophyllum (Nagchampa), Hevca brasiliensis (Rubber) etc. Biodiesel can be blended in any proportion with mineral diesel to create a biodiesel blend or can be used in its pure form. Just like petroleum diesel, biodiesel operates in compression ignition (diesel) engine, and essentially require very little or no engine modifications because biodiesel has properties similar to mineral diesel. It can be stored just like mineral diesel and hence does not require separate infrastructure. The use of biodiesel in conventional diesel engines result in substantial reduction in emission of unburned hydrocarbons, carbon monoxide and particulate. This review focuses on performance and emission of biodiesel in CI engines, combustion analysis, wear performance on long-term engine usage, and economic feasibility.",2007,97,2767,89,5,44,115,145,190,170,250,224,240,240
da65f4970806ab2724947247e8aa498203443f13,"Preface Preface to the Second Edition Preface to the First Edition 1: Introduction 2: Combustion and Thermochemistry 3: Introduction to Mass Transfer 4: Chemical Kinetics 5: Some Important Chemical Mechanisms 6: Coupling Chemical and Thermal Analyses of Reacting Systems 7: Simplifed Conversation Equations for Reacting Flows 8: Laminar Premixed Flames 9: Laminar Diffusion Flames 10: Droplet Evaporation and Burning 11: Introduction to Turbulent Flows 12: Turbulent Premixed Flames 13: Turbulent Nonpremixed Flames 14: Burning of Solids 15: Pollutant Emissions 16: Detonations Appendix A: Selected Thermodynamic Propertiesof Gases Comprising C-H-O-N System Appendix B: Fuel Properties Appendix C: Selected Properties of Air, Nitrogen, and Oxygen Appendix D: Diffusion Coefficients and Methodology for their Estimation Appendix E: Generalized Newton's Method for the Solution of Nonlinear Equations Appendix F: Computer Codes for Equilibrium Products of Hydrocarbon-Air Combustion",2000,0,2106,187,12,30,26,33,55,62,63,74,68,96
3e0725a32c83ee06419edafccacd6f3768ab5da7,"[1] We present a global tabulation of black carbon (BC) and primary organic carbon (OC) particles emitted from combustion. We include emissions from fossil fuels, biofuels, open biomass burning, and burning of urban waste. Previous ‘‘bottom-up’’ inventories of black and organic carbon have assigned emission factors on the basis of fuel type and economic sector alone. Because emission rates are highly dependent on combustion practice, we consider combinations of fuel, combustion type, and emission controls and their prevalence on a regional basis. Central estimates of global annual emissions are 8.0 Tg for black carbon and 33.9 Tg for organic carbon. These estimates are lower than previously published estimates by 25–35%. The present inventory is based on 1996 fuel-use data, updating previous estimates that have relied on consumption data from 1984. An offset between decreased emission factors and increased energy use since the base year of the previous inventory prevents the difference between this work and previous inventories from being greater. The contributions of fossil fuel, biofuel, and open burning are estimated as 38%, 20%, and 42%, respectively, for BC, and 7%, 19%, and 74%, respectively, for OC. We present a bottom-up estimate of uncertainties in source strength by combining uncertainties in particulate matter emission factors, emission characterization, and fuel use. The total uncertainties are about a factor of 2, with uncertainty ranges of 4.3–22 Tg/yr for BC and 17–77 Tg/yr for OC. Low-technology combustion contributes greatly to both the emissions and the uncertainties. Advances in emission characterization for small residential, industrial, and mobile sources and topdown analysis combining field measurements and transport modeling with iterative inventory development will be required to reduce the uncertainties further. INDEX TERMS: 0305 Atmospheric Composition and Structure: Aerosols and particles (0345, 4801); 0322 Atmospheric Composition and Structure: Constituent sources and sinks; 0345 Atmospheric Composition and Structure: Pollution—urban and regional (0305); 0360 Atmospheric Composition and Structure: Transmission and scattering of radiation; 0365 Atmospheric Composition and Structure: Troposphere—composition and chemistry; KEYWORDS: emission, black carbon, organic carbon, fossil fuel, biofuel, biomass burning",2004,394,2043,178,16,63,49,72,80,122,98,160,145,154
7be9620770607f4f08ec341438bdc52cff53f79b,,2009,0,1388,55,3,15,65,95,114,148,207,185,173,136
49a0fa5c59dc62b44684777c54b2bd0c2294821b,"Abstract Carbon dioxide capture from power plant flue gas and subsequent sequestration is expected to play a key role in mitigating global climate change. Conventional amine technologies being considered for separating CO 2 from flue gas are costly, energy intensive, and if implemented, would result in large increases in the cost of producing electricity. Membranes offer potential as an energy-efficient, low-cost CO 2 capture option. Recently, working with the U.S. Department of Energy (DOE), we have developed membranes with CO 2 permeances of greater than 1000 gpu and a CO 2 /N 2 selectivity of 50 at 30 °C. This permeance is ten times higher than commercial CO 2 membranes and the selectivity is among the highest reported for non-facilitated transport materials. These membranes, in combination with a novel process design that uses incoming combustion air as a sweep gas to generate driving force, could meet DOE CO 2 capture cost targets. Under these conditions, improving membrane permeance is more important than increasing selectivity to further reduce the cost of CO 2 capture from flue gas. Membrane cost and reliability issues will be key to the eventual competitiveness of this technology for flue gas treatment.",2010,27,1107,39,12,37,55,98,97,97,95,150,119,106
bcab7fbc5c745a55d39d5811c96d553865599caf,"Abstract Oxy-fuel combustion is suggested as one of the possible, promising technologies for capturing CO 2 from power plants. The concept of oxy-fuel combustion is removal of nitrogen from the oxidizer to carry out the combustion process in oxygen and, in most concepts, recycled flue gas to lower the flame temperature. The flue gas produced thus consists primarily of carbon dioxide and water. Much research on the different aspects of an oxy-fuel power plant has been performed during the last decade. Focus has mainly been on retrofits of existing pulverized-coal-fired power plant units. Green-field plants which provide additional options for improvement of process economics are however likewise investigated. Of particular interest is the change of the combustion process induced by the exchange of carbon dioxide and water vapor for nitrogen as diluent. This paper reviews the published knowledge on the oxy-fuel process and focuses particularly on the combustion fundamentals, i.e. flame temperatures and heat transfer, ignition and burnout, emissions, and fly ash characteristics. Knowledge is currently available regarding both an entire oxy-fuel power plant and the combustion fundamentals. However, several questions remain unanswered and more research and pilot plant testing of heat transfer profiles, emission levels, the optimum oxygen excess and inlet oxygen concentration levels, high and low-temperature fire-side corrosion, ash quality, plant operability, and models to predict NO x and SO 3 formation is required.",2010,209,959,28,9,65,82,100,101,106,92,90,86,79
07acf3c7e635c7970894192da585672e2bb51c42,"The awareness of the increase in greenhouse gas emissions has resulted in the development of new technologies with lower emissions and technologies that can accommodate capture and sequestration of carbon dioxide. For existing coal-fired combustion plants there are two main options for CO2 capture: removal of nitrogen from flue gases or removal of nitrogen from air before combustion to obtain a gas stream ready for geo-sequestration. In oxy-fuel combustion, fuel is combusted in pure oxygen rather than air. This technology recycles flue gas back into the furnace to control temperature and makeup the volume of the missing N2 to ensure there is sufficient gas to maintain the temperature and heat flux profiles in the boiler. A further advantage of the technology revealed in pilot-scale tests is substantially reduced NOx emissions. For coal-fired combustion, the technology was suggested in the eighties, however, recent developments have led to a renewed interest in the technology. This paper provides a comprehensive review of research that has been undertaken, gives the status of the technology development and assessments providing comparisons with other power generation options, and suggests research needs.",2005,42,1375,41,1,4,9,23,41,84,138,121,146,116
f7216b952af5bb89b11039ea5a5ebc0edf2f45ca,,2001,0,2803,305,1,21,27,42,65,79,119,111,133,153
c54d65d53d7ada275d34e1a7c53643ff0c82eb93,"Abstract The increasing industrialization and motorization of the world has led to a steep rise for the demand of petroleum-based fuels. Petroleum-based fuels are obtained from limited reserves. These finite reserves are highly concentrated in certain regions of the world. Therefore, those countries not having these resources are facing energy/foreign exchange crisis, mainly due to the import of crude petroleum. Hence, it is necessary to look for alternative fuels which can be produced from resources available locally within the country such as alcohol, biodiesel, vegetable oils etc. This paper reviews the production, characterization and current statuses of vegetable oil and biodiesel as well as the experimental research work carried out in various countries. This paper touches upon well-to-wheel greenhouse gas emissions, well-to-wheel efficiencies, fuel versatility, infrastructure, availability, economics, engine performance and emissions, effect on wear, lubricating oil etc. Ethanol is also an attractive alternative fuel because it is a renewable bio-based resource and it is oxygenated, thereby providing the potential to reduce particulate emissions in compression-ignition engines. In this review, the properties and specifications of ethanol blended with diesel and gasoline fuel are also discussed. Special emphasis is placed on the factors critical to the potential commercial use of these blends. The effect of the fuel on engine performance and emissions (SI as well as compression ignition (CI) engines), and material compatibility is also considered. Biodiesel is methyl or ethyl ester of fatty acid made from virgin or used vegetable oils (both edible and non-edible) and animal fat. The main resources for biodiesel production can be non-edible oils obtained from plant species such as Jatropha curcas (Ratanjyot), Pongamia pinnata (Karanj), Calophyllum inophyllum (Nagchampa), Hevca brasiliensis (Rubber) etc. Biodiesel can be blended in any proportion with mineral diesel to create a biodiesel blend or can be used in its pure form. Just like petroleum diesel, biodiesel operates in compression ignition (diesel) engine, and essentially require very little or no engine modifications because biodiesel has properties similar to mineral diesel. It can be stored just like mineral diesel and hence does not require separate infrastructure. The use of biodiesel in conventional diesel engines result in substantial reduction in emission of unburned hydrocarbons, carbon monoxide and particulate. This review focuses on performance and emission of biodiesel in CI engines, combustion analysis, wear performance on long-term engine usage, and economic feasibility.",2007,97,2767,89,5,44,115,145,190,170,250,224,240,240
da65f4970806ab2724947247e8aa498203443f13,"Preface Preface to the Second Edition Preface to the First Edition 1: Introduction 2: Combustion and Thermochemistry 3: Introduction to Mass Transfer 4: Chemical Kinetics 5: Some Important Chemical Mechanisms 6: Coupling Chemical and Thermal Analyses of Reacting Systems 7: Simplifed Conversation Equations for Reacting Flows 8: Laminar Premixed Flames 9: Laminar Diffusion Flames 10: Droplet Evaporation and Burning 11: Introduction to Turbulent Flows 12: Turbulent Premixed Flames 13: Turbulent Nonpremixed Flames 14: Burning of Solids 15: Pollutant Emissions 16: Detonations Appendix A: Selected Thermodynamic Propertiesof Gases Comprising C-H-O-N System Appendix B: Fuel Properties Appendix C: Selected Properties of Air, Nitrogen, and Oxygen Appendix D: Diffusion Coefficients and Methodology for their Estimation Appendix E: Generalized Newton's Method for the Solution of Nonlinear Equations Appendix F: Computer Codes for Equilibrium Products of Hydrocarbon-Air Combustion",2000,0,2106,187,12,30,26,33,55,62,63,74,68,96
3e0725a32c83ee06419edafccacd6f3768ab5da7,"[1] We present a global tabulation of black carbon (BC) and primary organic carbon (OC) particles emitted from combustion. We include emissions from fossil fuels, biofuels, open biomass burning, and burning of urban waste. Previous ‘‘bottom-up’’ inventories of black and organic carbon have assigned emission factors on the basis of fuel type and economic sector alone. Because emission rates are highly dependent on combustion practice, we consider combinations of fuel, combustion type, and emission controls and their prevalence on a regional basis. Central estimates of global annual emissions are 8.0 Tg for black carbon and 33.9 Tg for organic carbon. These estimates are lower than previously published estimates by 25–35%. The present inventory is based on 1996 fuel-use data, updating previous estimates that have relied on consumption data from 1984. An offset between decreased emission factors and increased energy use since the base year of the previous inventory prevents the difference between this work and previous inventories from being greater. The contributions of fossil fuel, biofuel, and open burning are estimated as 38%, 20%, and 42%, respectively, for BC, and 7%, 19%, and 74%, respectively, for OC. We present a bottom-up estimate of uncertainties in source strength by combining uncertainties in particulate matter emission factors, emission characterization, and fuel use. The total uncertainties are about a factor of 2, with uncertainty ranges of 4.3–22 Tg/yr for BC and 17–77 Tg/yr for OC. Low-technology combustion contributes greatly to both the emissions and the uncertainties. Advances in emission characterization for small residential, industrial, and mobile sources and topdown analysis combining field measurements and transport modeling with iterative inventory development will be required to reduce the uncertainties further. INDEX TERMS: 0305 Atmospheric Composition and Structure: Aerosols and particles (0345, 4801); 0322 Atmospheric Composition and Structure: Constituent sources and sinks; 0345 Atmospheric Composition and Structure: Pollution—urban and regional (0305); 0360 Atmospheric Composition and Structure: Transmission and scattering of radiation; 0365 Atmospheric Composition and Structure: Troposphere—composition and chemistry; KEYWORDS: emission, black carbon, organic carbon, fossil fuel, biofuel, biomass burning",2004,394,2043,178,16,63,49,72,80,122,98,160,145,154
7be9620770607f4f08ec341438bdc52cff53f79b,,2009,0,1388,55,3,15,65,95,114,148,207,185,173,136
49a0fa5c59dc62b44684777c54b2bd0c2294821b,"Abstract Carbon dioxide capture from power plant flue gas and subsequent sequestration is expected to play a key role in mitigating global climate change. Conventional amine technologies being considered for separating CO 2 from flue gas are costly, energy intensive, and if implemented, would result in large increases in the cost of producing electricity. Membranes offer potential as an energy-efficient, low-cost CO 2 capture option. Recently, working with the U.S. Department of Energy (DOE), we have developed membranes with CO 2 permeances of greater than 1000 gpu and a CO 2 /N 2 selectivity of 50 at 30 °C. This permeance is ten times higher than commercial CO 2 membranes and the selectivity is among the highest reported for non-facilitated transport materials. These membranes, in combination with a novel process design that uses incoming combustion air as a sweep gas to generate driving force, could meet DOE CO 2 capture cost targets. Under these conditions, improving membrane permeance is more important than increasing selectivity to further reduce the cost of CO 2 capture from flue gas. Membrane cost and reliability issues will be key to the eventual competitiveness of this technology for flue gas treatment.",2010,27,1107,39,12,37,55,98,97,97,95,150,119,106
bcab7fbc5c745a55d39d5811c96d553865599caf,"Abstract Oxy-fuel combustion is suggested as one of the possible, promising technologies for capturing CO 2 from power plants. The concept of oxy-fuel combustion is removal of nitrogen from the oxidizer to carry out the combustion process in oxygen and, in most concepts, recycled flue gas to lower the flame temperature. The flue gas produced thus consists primarily of carbon dioxide and water. Much research on the different aspects of an oxy-fuel power plant has been performed during the last decade. Focus has mainly been on retrofits of existing pulverized-coal-fired power plant units. Green-field plants which provide additional options for improvement of process economics are however likewise investigated. Of particular interest is the change of the combustion process induced by the exchange of carbon dioxide and water vapor for nitrogen as diluent. This paper reviews the published knowledge on the oxy-fuel process and focuses particularly on the combustion fundamentals, i.e. flame temperatures and heat transfer, ignition and burnout, emissions, and fly ash characteristics. Knowledge is currently available regarding both an entire oxy-fuel power plant and the combustion fundamentals. However, several questions remain unanswered and more research and pilot plant testing of heat transfer profiles, emission levels, the optimum oxygen excess and inlet oxygen concentration levels, high and low-temperature fire-side corrosion, ash quality, plant operability, and models to predict NO x and SO 3 formation is required.",2010,209,959,28,9,65,82,100,101,106,92,90,86,79
07acf3c7e635c7970894192da585672e2bb51c42,"The awareness of the increase in greenhouse gas emissions has resulted in the development of new technologies with lower emissions and technologies that can accommodate capture and sequestration of carbon dioxide. For existing coal-fired combustion plants there are two main options for CO2 capture: removal of nitrogen from flue gases or removal of nitrogen from air before combustion to obtain a gas stream ready for geo-sequestration. In oxy-fuel combustion, fuel is combusted in pure oxygen rather than air. This technology recycles flue gas back into the furnace to control temperature and makeup the volume of the missing N2 to ensure there is sufficient gas to maintain the temperature and heat flux profiles in the boiler. A further advantage of the technology revealed in pilot-scale tests is substantially reduced NOx emissions. For coal-fired combustion, the technology was suggested in the eighties, however, recent developments have led to a renewed interest in the technology. This paper provides a comprehensive review of research that has been undertaken, gives the status of the technology development and assessments providing comparisons with other power generation options, and suggests research needs.",2005,42,1375,41,1,4,9,23,41,84,138,121,146,116
f7216b952af5bb89b11039ea5a5ebc0edf2f45ca,,2001,0,2803,305,1,21,27,42,65,79,119,111,133,153
c54d65d53d7ada275d34e1a7c53643ff0c82eb93,"Abstract The increasing industrialization and motorization of the world has led to a steep rise for the demand of petroleum-based fuels. Petroleum-based fuels are obtained from limited reserves. These finite reserves are highly concentrated in certain regions of the world. Therefore, those countries not having these resources are facing energy/foreign exchange crisis, mainly due to the import of crude petroleum. Hence, it is necessary to look for alternative fuels which can be produced from resources available locally within the country such as alcohol, biodiesel, vegetable oils etc. This paper reviews the production, characterization and current statuses of vegetable oil and biodiesel as well as the experimental research work carried out in various countries. This paper touches upon well-to-wheel greenhouse gas emissions, well-to-wheel efficiencies, fuel versatility, infrastructure, availability, economics, engine performance and emissions, effect on wear, lubricating oil etc. Ethanol is also an attractive alternative fuel because it is a renewable bio-based resource and it is oxygenated, thereby providing the potential to reduce particulate emissions in compression-ignition engines. In this review, the properties and specifications of ethanol blended with diesel and gasoline fuel are also discussed. Special emphasis is placed on the factors critical to the potential commercial use of these blends. The effect of the fuel on engine performance and emissions (SI as well as compression ignition (CI) engines), and material compatibility is also considered. Biodiesel is methyl or ethyl ester of fatty acid made from virgin or used vegetable oils (both edible and non-edible) and animal fat. The main resources for biodiesel production can be non-edible oils obtained from plant species such as Jatropha curcas (Ratanjyot), Pongamia pinnata (Karanj), Calophyllum inophyllum (Nagchampa), Hevca brasiliensis (Rubber) etc. Biodiesel can be blended in any proportion with mineral diesel to create a biodiesel blend or can be used in its pure form. Just like petroleum diesel, biodiesel operates in compression ignition (diesel) engine, and essentially require very little or no engine modifications because biodiesel has properties similar to mineral diesel. It can be stored just like mineral diesel and hence does not require separate infrastructure. The use of biodiesel in conventional diesel engines result in substantial reduction in emission of unburned hydrocarbons, carbon monoxide and particulate. This review focuses on performance and emission of biodiesel in CI engines, combustion analysis, wear performance on long-term engine usage, and economic feasibility.",2007,97,2767,89,5,44,115,145,190,170,250,224,240,240
da65f4970806ab2724947247e8aa498203443f13,"Preface Preface to the Second Edition Preface to the First Edition 1: Introduction 2: Combustion and Thermochemistry 3: Introduction to Mass Transfer 4: Chemical Kinetics 5: Some Important Chemical Mechanisms 6: Coupling Chemical and Thermal Analyses of Reacting Systems 7: Simplifed Conversation Equations for Reacting Flows 8: Laminar Premixed Flames 9: Laminar Diffusion Flames 10: Droplet Evaporation and Burning 11: Introduction to Turbulent Flows 12: Turbulent Premixed Flames 13: Turbulent Nonpremixed Flames 14: Burning of Solids 15: Pollutant Emissions 16: Detonations Appendix A: Selected Thermodynamic Propertiesof Gases Comprising C-H-O-N System Appendix B: Fuel Properties Appendix C: Selected Properties of Air, Nitrogen, and Oxygen Appendix D: Diffusion Coefficients and Methodology for their Estimation Appendix E: Generalized Newton's Method for the Solution of Nonlinear Equations Appendix F: Computer Codes for Equilibrium Products of Hydrocarbon-Air Combustion",2000,0,2106,187,12,30,26,33,55,62,63,74,68,96
3e0725a32c83ee06419edafccacd6f3768ab5da7,"[1] We present a global tabulation of black carbon (BC) and primary organic carbon (OC) particles emitted from combustion. We include emissions from fossil fuels, biofuels, open biomass burning, and burning of urban waste. Previous ‘‘bottom-up’’ inventories of black and organic carbon have assigned emission factors on the basis of fuel type and economic sector alone. Because emission rates are highly dependent on combustion practice, we consider combinations of fuel, combustion type, and emission controls and their prevalence on a regional basis. Central estimates of global annual emissions are 8.0 Tg for black carbon and 33.9 Tg for organic carbon. These estimates are lower than previously published estimates by 25–35%. The present inventory is based on 1996 fuel-use data, updating previous estimates that have relied on consumption data from 1984. An offset between decreased emission factors and increased energy use since the base year of the previous inventory prevents the difference between this work and previous inventories from being greater. The contributions of fossil fuel, biofuel, and open burning are estimated as 38%, 20%, and 42%, respectively, for BC, and 7%, 19%, and 74%, respectively, for OC. We present a bottom-up estimate of uncertainties in source strength by combining uncertainties in particulate matter emission factors, emission characterization, and fuel use. The total uncertainties are about a factor of 2, with uncertainty ranges of 4.3–22 Tg/yr for BC and 17–77 Tg/yr for OC. Low-technology combustion contributes greatly to both the emissions and the uncertainties. Advances in emission characterization for small residential, industrial, and mobile sources and topdown analysis combining field measurements and transport modeling with iterative inventory development will be required to reduce the uncertainties further. INDEX TERMS: 0305 Atmospheric Composition and Structure: Aerosols and particles (0345, 4801); 0322 Atmospheric Composition and Structure: Constituent sources and sinks; 0345 Atmospheric Composition and Structure: Pollution—urban and regional (0305); 0360 Atmospheric Composition and Structure: Transmission and scattering of radiation; 0365 Atmospheric Composition and Structure: Troposphere—composition and chemistry; KEYWORDS: emission, black carbon, organic carbon, fossil fuel, biofuel, biomass burning",2004,394,2043,178,16,63,49,72,80,122,98,160,145,154
7be9620770607f4f08ec341438bdc52cff53f79b,,2009,0,1388,55,3,15,65,95,114,148,207,185,173,136
49a0fa5c59dc62b44684777c54b2bd0c2294821b,"Abstract Carbon dioxide capture from power plant flue gas and subsequent sequestration is expected to play a key role in mitigating global climate change. Conventional amine technologies being considered for separating CO 2 from flue gas are costly, energy intensive, and if implemented, would result in large increases in the cost of producing electricity. Membranes offer potential as an energy-efficient, low-cost CO 2 capture option. Recently, working with the U.S. Department of Energy (DOE), we have developed membranes with CO 2 permeances of greater than 1000 gpu and a CO 2 /N 2 selectivity of 50 at 30 °C. This permeance is ten times higher than commercial CO 2 membranes and the selectivity is among the highest reported for non-facilitated transport materials. These membranes, in combination with a novel process design that uses incoming combustion air as a sweep gas to generate driving force, could meet DOE CO 2 capture cost targets. Under these conditions, improving membrane permeance is more important than increasing selectivity to further reduce the cost of CO 2 capture from flue gas. Membrane cost and reliability issues will be key to the eventual competitiveness of this technology for flue gas treatment.",2010,27,1107,39,12,37,55,98,97,97,95,150,119,106
bcab7fbc5c745a55d39d5811c96d553865599caf,"Abstract Oxy-fuel combustion is suggested as one of the possible, promising technologies for capturing CO 2 from power plants. The concept of oxy-fuel combustion is removal of nitrogen from the oxidizer to carry out the combustion process in oxygen and, in most concepts, recycled flue gas to lower the flame temperature. The flue gas produced thus consists primarily of carbon dioxide and water. Much research on the different aspects of an oxy-fuel power plant has been performed during the last decade. Focus has mainly been on retrofits of existing pulverized-coal-fired power plant units. Green-field plants which provide additional options for improvement of process economics are however likewise investigated. Of particular interest is the change of the combustion process induced by the exchange of carbon dioxide and water vapor for nitrogen as diluent. This paper reviews the published knowledge on the oxy-fuel process and focuses particularly on the combustion fundamentals, i.e. flame temperatures and heat transfer, ignition and burnout, emissions, and fly ash characteristics. Knowledge is currently available regarding both an entire oxy-fuel power plant and the combustion fundamentals. However, several questions remain unanswered and more research and pilot plant testing of heat transfer profiles, emission levels, the optimum oxygen excess and inlet oxygen concentration levels, high and low-temperature fire-side corrosion, ash quality, plant operability, and models to predict NO x and SO 3 formation is required.",2010,209,959,28,9,65,82,100,101,106,92,90,86,79
07acf3c7e635c7970894192da585672e2bb51c42,"The awareness of the increase in greenhouse gas emissions has resulted in the development of new technologies with lower emissions and technologies that can accommodate capture and sequestration of carbon dioxide. For existing coal-fired combustion plants there are two main options for CO2 capture: removal of nitrogen from flue gases or removal of nitrogen from air before combustion to obtain a gas stream ready for geo-sequestration. In oxy-fuel combustion, fuel is combusted in pure oxygen rather than air. This technology recycles flue gas back into the furnace to control temperature and makeup the volume of the missing N2 to ensure there is sufficient gas to maintain the temperature and heat flux profiles in the boiler. A further advantage of the technology revealed in pilot-scale tests is substantially reduced NOx emissions. For coal-fired combustion, the technology was suggested in the eighties, however, recent developments have led to a renewed interest in the technology. This paper provides a comprehensive review of research that has been undertaken, gives the status of the technology development and assessments providing comparisons with other power generation options, and suggests research needs.",2005,42,1375,41,1,4,9,23,41,84,138,121,146,116
f7216b952af5bb89b11039ea5a5ebc0edf2f45ca,,2001,0,2803,305,1,21,27,42,65,79,119,111,133,153
c54d65d53d7ada275d34e1a7c53643ff0c82eb93,"Abstract The increasing industrialization and motorization of the world has led to a steep rise for the demand of petroleum-based fuels. Petroleum-based fuels are obtained from limited reserves. These finite reserves are highly concentrated in certain regions of the world. Therefore, those countries not having these resources are facing energy/foreign exchange crisis, mainly due to the import of crude petroleum. Hence, it is necessary to look for alternative fuels which can be produced from resources available locally within the country such as alcohol, biodiesel, vegetable oils etc. This paper reviews the production, characterization and current statuses of vegetable oil and biodiesel as well as the experimental research work carried out in various countries. This paper touches upon well-to-wheel greenhouse gas emissions, well-to-wheel efficiencies, fuel versatility, infrastructure, availability, economics, engine performance and emissions, effect on wear, lubricating oil etc. Ethanol is also an attractive alternative fuel because it is a renewable bio-based resource and it is oxygenated, thereby providing the potential to reduce particulate emissions in compression-ignition engines. In this review, the properties and specifications of ethanol blended with diesel and gasoline fuel are also discussed. Special emphasis is placed on the factors critical to the potential commercial use of these blends. The effect of the fuel on engine performance and emissions (SI as well as compression ignition (CI) engines), and material compatibility is also considered. Biodiesel is methyl or ethyl ester of fatty acid made from virgin or used vegetable oils (both edible and non-edible) and animal fat. The main resources for biodiesel production can be non-edible oils obtained from plant species such as Jatropha curcas (Ratanjyot), Pongamia pinnata (Karanj), Calophyllum inophyllum (Nagchampa), Hevca brasiliensis (Rubber) etc. Biodiesel can be blended in any proportion with mineral diesel to create a biodiesel blend or can be used in its pure form. Just like petroleum diesel, biodiesel operates in compression ignition (diesel) engine, and essentially require very little or no engine modifications because biodiesel has properties similar to mineral diesel. It can be stored just like mineral diesel and hence does not require separate infrastructure. The use of biodiesel in conventional diesel engines result in substantial reduction in emission of unburned hydrocarbons, carbon monoxide and particulate. This review focuses on performance and emission of biodiesel in CI engines, combustion analysis, wear performance on long-term engine usage, and economic feasibility.",2007,97,2767,89,5,44,115,145,190,170,250,224,240,240
da65f4970806ab2724947247e8aa498203443f13,"Preface Preface to the Second Edition Preface to the First Edition 1: Introduction 2: Combustion and Thermochemistry 3: Introduction to Mass Transfer 4: Chemical Kinetics 5: Some Important Chemical Mechanisms 6: Coupling Chemical and Thermal Analyses of Reacting Systems 7: Simplifed Conversation Equations for Reacting Flows 8: Laminar Premixed Flames 9: Laminar Diffusion Flames 10: Droplet Evaporation and Burning 11: Introduction to Turbulent Flows 12: Turbulent Premixed Flames 13: Turbulent Nonpremixed Flames 14: Burning of Solids 15: Pollutant Emissions 16: Detonations Appendix A: Selected Thermodynamic Propertiesof Gases Comprising C-H-O-N System Appendix B: Fuel Properties Appendix C: Selected Properties of Air, Nitrogen, and Oxygen Appendix D: Diffusion Coefficients and Methodology for their Estimation Appendix E: Generalized Newton's Method for the Solution of Nonlinear Equations Appendix F: Computer Codes for Equilibrium Products of Hydrocarbon-Air Combustion",2000,0,2106,187,12,30,26,33,55,62,63,74,68,96
3e0725a32c83ee06419edafccacd6f3768ab5da7,"[1] We present a global tabulation of black carbon (BC) and primary organic carbon (OC) particles emitted from combustion. We include emissions from fossil fuels, biofuels, open biomass burning, and burning of urban waste. Previous ‘‘bottom-up’’ inventories of black and organic carbon have assigned emission factors on the basis of fuel type and economic sector alone. Because emission rates are highly dependent on combustion practice, we consider combinations of fuel, combustion type, and emission controls and their prevalence on a regional basis. Central estimates of global annual emissions are 8.0 Tg for black carbon and 33.9 Tg for organic carbon. These estimates are lower than previously published estimates by 25–35%. The present inventory is based on 1996 fuel-use data, updating previous estimates that have relied on consumption data from 1984. An offset between decreased emission factors and increased energy use since the base year of the previous inventory prevents the difference between this work and previous inventories from being greater. The contributions of fossil fuel, biofuel, and open burning are estimated as 38%, 20%, and 42%, respectively, for BC, and 7%, 19%, and 74%, respectively, for OC. We present a bottom-up estimate of uncertainties in source strength by combining uncertainties in particulate matter emission factors, emission characterization, and fuel use. The total uncertainties are about a factor of 2, with uncertainty ranges of 4.3–22 Tg/yr for BC and 17–77 Tg/yr for OC. Low-technology combustion contributes greatly to both the emissions and the uncertainties. Advances in emission characterization for small residential, industrial, and mobile sources and topdown analysis combining field measurements and transport modeling with iterative inventory development will be required to reduce the uncertainties further. INDEX TERMS: 0305 Atmospheric Composition and Structure: Aerosols and particles (0345, 4801); 0322 Atmospheric Composition and Structure: Constituent sources and sinks; 0345 Atmospheric Composition and Structure: Pollution—urban and regional (0305); 0360 Atmospheric Composition and Structure: Transmission and scattering of radiation; 0365 Atmospheric Composition and Structure: Troposphere—composition and chemistry; KEYWORDS: emission, black carbon, organic carbon, fossil fuel, biofuel, biomass burning",2004,394,2043,178,16,63,49,72,80,122,98,160,145,154
7be9620770607f4f08ec341438bdc52cff53f79b,,2009,0,1388,55,3,15,65,95,114,148,207,185,173,136
49a0fa5c59dc62b44684777c54b2bd0c2294821b,"Abstract Carbon dioxide capture from power plant flue gas and subsequent sequestration is expected to play a key role in mitigating global climate change. Conventional amine technologies being considered for separating CO 2 from flue gas are costly, energy intensive, and if implemented, would result in large increases in the cost of producing electricity. Membranes offer potential as an energy-efficient, low-cost CO 2 capture option. Recently, working with the U.S. Department of Energy (DOE), we have developed membranes with CO 2 permeances of greater than 1000 gpu and a CO 2 /N 2 selectivity of 50 at 30 °C. This permeance is ten times higher than commercial CO 2 membranes and the selectivity is among the highest reported for non-facilitated transport materials. These membranes, in combination with a novel process design that uses incoming combustion air as a sweep gas to generate driving force, could meet DOE CO 2 capture cost targets. Under these conditions, improving membrane permeance is more important than increasing selectivity to further reduce the cost of CO 2 capture from flue gas. Membrane cost and reliability issues will be key to the eventual competitiveness of this technology for flue gas treatment.",2010,27,1107,39,12,37,55,98,97,97,95,150,119,106
bcab7fbc5c745a55d39d5811c96d553865599caf,"Abstract Oxy-fuel combustion is suggested as one of the possible, promising technologies for capturing CO 2 from power plants. The concept of oxy-fuel combustion is removal of nitrogen from the oxidizer to carry out the combustion process in oxygen and, in most concepts, recycled flue gas to lower the flame temperature. The flue gas produced thus consists primarily of carbon dioxide and water. Much research on the different aspects of an oxy-fuel power plant has been performed during the last decade. Focus has mainly been on retrofits of existing pulverized-coal-fired power plant units. Green-field plants which provide additional options for improvement of process economics are however likewise investigated. Of particular interest is the change of the combustion process induced by the exchange of carbon dioxide and water vapor for nitrogen as diluent. This paper reviews the published knowledge on the oxy-fuel process and focuses particularly on the combustion fundamentals, i.e. flame temperatures and heat transfer, ignition and burnout, emissions, and fly ash characteristics. Knowledge is currently available regarding both an entire oxy-fuel power plant and the combustion fundamentals. However, several questions remain unanswered and more research and pilot plant testing of heat transfer profiles, emission levels, the optimum oxygen excess and inlet oxygen concentration levels, high and low-temperature fire-side corrosion, ash quality, plant operability, and models to predict NO x and SO 3 formation is required.",2010,209,959,28,9,65,82,100,101,106,92,90,86,79
07acf3c7e635c7970894192da585672e2bb51c42,"The awareness of the increase in greenhouse gas emissions has resulted in the development of new technologies with lower emissions and technologies that can accommodate capture and sequestration of carbon dioxide. For existing coal-fired combustion plants there are two main options for CO2 capture: removal of nitrogen from flue gases or removal of nitrogen from air before combustion to obtain a gas stream ready for geo-sequestration. In oxy-fuel combustion, fuel is combusted in pure oxygen rather than air. This technology recycles flue gas back into the furnace to control temperature and makeup the volume of the missing N2 to ensure there is sufficient gas to maintain the temperature and heat flux profiles in the boiler. A further advantage of the technology revealed in pilot-scale tests is substantially reduced NOx emissions. For coal-fired combustion, the technology was suggested in the eighties, however, recent developments have led to a renewed interest in the technology. This paper provides a comprehensive review of research that has been undertaken, gives the status of the technology development and assessments providing comparisons with other power generation options, and suggests research needs.",2005,42,1375,41,1,4,9,23,41,84,138,121,146,116
9d0c4389436d3ab8ed329dba8c58e8ac6737fd3b,"Many models for the spread of infectious diseases in populations have been analyzed mathematically and applied to specific diseases. Threshold theorems involving the basic reproduction number $R_{0}$, the contact number $\sigma$, and the replacement number $R$ are reviewed for the classic SIR epidemic and endemic models. Similar results with new expressions for $R_{0}$ are obtained for MSEIR and SEIR endemic models with either continuous age or age groups. Values of $R_{0}$ and $\sigma$ are estimated for various diseases including measles in Niger and pertussis in the United States. Previous models with age structure, heterogeneity, and spatial structure are surveyed.",2000,226,4881,259,0,10,20,43,55,80,121,124,129,154
d3d720baa7080594c2fad06bb2ac90cc46666735,"The goals of this chapter are (1) to outline and substantiate a broad conceptualization of what it means to think mathematically, (2) to summarize the literature relevant to understanding mathematical thinking and problem solving, and (3) to point to new directions in research, development, and assessment consonant with an emerging understanding of mathematical thinking and the goals for instruction outlined here. The use of the phrase “learning to think mathematically” in this chapter’s title is deliberately broad. Although the original charter for this chapter was to review the literature on problem solving and metacognition, the literature itself is somewhat ill defined and poorly grounded. As the literature summary will make clear, problem solving has been used with multiple meanings that range from “working rote exercises” to “doing mathematics as a professional”; metacognition has multiple and almost disjoint meanings (from knowledge about one’s thought processes to self-regulation during problem solving) that make it difficult to use as a concept. This chapter outlines the various meanings that have been ascribed to these terms and discusses their role in mathematical thinking. The discussion will not have the character of a classic literature review, which is typically encyclopedic in its references and telegraphic in its discussions of individual papers or results. It will, instead, be selective and illustrative, with main points illustrated by extended discussions of pertinent examples. Problem solving has, as predicted in the 1980 Yearbook of the National Council of Teachers of Mathematics (Krulik, 1980, p. xiv), been the theme of the 1980s. The decade began with NCTM’s widely heralded statement, in its Agenda for Action, that “problem solving must be the focus of school mathematics” (NCTM, 1980, p. 1). It concluded with the publication of Everybody Counts (National Research Council, 1989) and the Curriculum and Evaluation Standards for School Mathematics (NCTM, 1989), both of which emphasize problem solving. One might infer, then, that there is general acceptance of the idea that the primary goal of mathematics instruction should be to have students become competent problem solvers. Yet, given the multiple interpretations of the term, the goal is hardly clear. Equally unclear is the role that problem solving, once adequately characterized, should play in the larger context of school mathematics. What are the goals for mathematics instruction, and how does problem solving fit within those goals? Such questions are complex. Goals for mathematics instruction depend on one’s conceptualization of what mathematics is, and what it means to understand mathematics. Such conceptualizations vary widely. At one end of the spectrum, mathematical knowledge is seen as a body of facts and procedures dealing with quantities, magnitudes, and forms, and the relationships among them; knowing mathematics is seen as having mastered these facts and procedures. At the other end of the spectrum, mathematics is conceptualized as the “science of patterns,” an (almost) empirical discipline closely akin to the sciences in its emphasis on pattern-seeking on the basis of empirical evidence. The author’s view is that the former perspective trivializes mathematics; that a curriculum based on mastering a corpus of mathematical facts and procedures is severely impoverished—in much the same way that an English curriculum would be considered impoverished if it focused largely, if not exclusively, on issues of grammar. The author characterizes the mathematical enterprise as follows:",2009,239,2893,267,123,144,163,155,189,196,226,163,163,178
f2e713dd0a1ee11892a90e0fb448dd5981e63550,,2000,7,7984,20,159,178,250,232,270,267,306,357,411,430
d82b5eb828d803e2f3fe041db20af8536f0fe99e,Author's Preface to the Anniversary Edition Series Editor's Introduction to the Anniversary Edition A Note about the Anniversary Edition Foreword Acknowledgments Introduction 1. Subtraction With Regrouping: Approaches To Teaching A Topic 2. Multidigit Number Multiplication: Dealing With Students' Mistakes 3. Generating Representations: Division By Fractions 4. Exploring New Knowledge: The Relationship Between Perimeter And Area 5. Teachers' Subject Matter Knowledge: Profound Understanding Of Fundamental Mathematics 6. Profound Understanding Of Fundamental Mathematics: When And How Is It Attained 7. Conclusion Appendix References New to the Anniversary Edition: Journal Article #1 New to the Anniversary Edition: Journal Article #2 Author Index Subject Index,2010,0,1684,360,141,143,135,137,149,142,142,129,128,88
7f3b042c8337fe9195ed6ca0cb017b76bbf1ff7c,"868 NOTICES OF THE AMS VOLUME 47, NUMBER 8 In April 2000 the National Council of Teachers of Mathematics (NCTM) released Principles and Standards for School Mathematics—the culmination of a multifaceted, three-year effort to update NCTM’s earlier standards documents and to set forth goals and recommendations for mathematics education in the prekindergarten-through-grade-twelve years. As the chair of the Writing Group, I had the privilege to interact with all aspects of the development and review of this document and with the committed groups of people, including the members of the Writing Group, who contributed immeasurably to this process. This article provides some background about NCTM and the standards, the process of development, efforts to gather input and feedback, and ways in which feedback from the mathematics community influenced the document. The article concludes with a section that provides some suggestions for mathematicians who are interested in using Principles and Standards.",2000,17,2165,296,10,25,47,49,66,78,79,118,115,118
a9386eb6808b41238381c708f2642bcb7dc34b29,"This book is about mathematical ideas, about what mathematics means-and why. Abstract ideas, for the most part, arise via conceptual metaphor-metaphorical ideas projecting from the way we function in the everyday physical world. Where Mathematics Comes From argues that conceptual metaphor plays a central role in mathematical ideas within the cognitive unconscious-from arithmetic and algebra to sets and logic to infinity in all of its forms.",2002,40,1920,107,19,40,48,55,72,74,102,91,120,102
4526716b3789971eaaa81d507abb657a29009957,"A gender gap in mathematics achievement persists in some nations but not in others. In light of the underrepresentation of women in careers in science, technology, mathematics, and engineering, increasing research attention is being devoted to understanding gender differences in mathematics achievement, attitudes, and affect. The gender stratification hypothesis maintains that such gender differences are closely related to cultural variations in opportunity structures for girls and women. We meta-analyzed 2 major international data sets, the 2003 Trends in International Mathematics and Science Study and the Programme for International Student Assessment, representing 493,495 students 14-16 years of age, to estimate the magnitude of gender differences in mathematics achievement, attitudes, and affect across 69 nations throughout the world. Consistent with the gender similarities hypothesis, all of the mean effect sizes in mathematics achievement were very small (d < 0.15); however, national effect sizes showed considerable variability (ds = -0.42 to 0.40). Despite gender similarities in achievement, boys reported more positive math attitudes and affect (ds = 0.10 to 0.33); national effect sizes ranged from d = -0.61 to 0.89. In contrast to those of previous tests of the gender stratification hypothesis, our results point to specific domains of gender equity responsible for gender gaps in math. Gender equity in school enrollment, women's share of research jobs, and women's parliamentary representation were the most powerful predictors of cross-national variability in gender gaps in math. Results are situated within the context of existing research demonstrating apparently paradoxical effects of societal gender equity and highlight the significance of increasing girls' and women's agency cross-nationally.",2010,126,1105,71,16,49,80,93,98,97,99,98,126,108
2ed2cd231aad7ea8a2b69a60d6df7539d6ee107f,"Vol. 72: The Syntax and Semantics of lnfimtary Languages. Edited by J. Barwtse. IV, 268 pages. 1968. DM 18,I $ 5.00 Vol. 73: P. E. Conner, Lectures on the Action of a Finite Group. IV, 123 pages. 1968. DM 10,1 $ 2.80 Vol. 74:A Frohlich, Formal Groups. IV, 140pages. 1968. DM12, -I $3.30 Vol. 75: G. Lumer, Algebras de fonctions et espaces de Hardy. VI, 80 pages. 1968. DM 8,I $ 2. 20 Vol. 76: R. G. Swan, Algebraic K-Theory. IV, 262 pages. 1968. DM18,I$ 5.00",2001,497,1653,59,73,89,93,103,106,99,152,152,126,57
7385b1bcd94ed3904c0e1429e209c80249de0d2a,"In this article, we use meta-analysis to analyze gender differences in recent studies of mathematics performance. First, we meta-analyzed data from 242 studies published between 1990 and 2007, representing the testing of 1,286,350 people. Overall, d = 0.05, indicating no gender difference, and variance ratio = 1.08, indicating nearly equal male and female variances. Second, we analyzed data from large data sets based on probability sampling of U.S. adolescents over the past 20 years: the National Longitudinal Surveys of Youth, the National Education Longitudinal Study of 1988, the Longitudinal Study of American Youth, and the National Assessment of Educational Progress. Effect sizes for the gender difference ranged between -0.15 and +0.22. Variance ratios ranged from 0.88 to 1.34. Taken together, these findings support the view that males and females perform similarly in mathematics.",2010,211,625,39,0,7,22,37,57,67,61,64,74,93
f008393f240508c1686a468b2c67371a7cdcb354,,2009,0,948,91,8,35,43,56,81,101,105,96,74,112
861a8ccc4002510aa1c844ea6f2c41fba69623f4,"Abstract Working memory refers to a mental workspace, involved in controlling, regulating, and actively maintaining relevant information to accomplish complex cognitive tasks (e.g. mathematical processing). Despite the potential relevance of a relation between working memory and math for understanding developmental and individual differences in mathematical skills, the nature of this relationship is not well-understood. This paper reviews four approaches that address the relation of working memory and math: 1) dual task studies establishing the role of working memory during on-line math performance; 2) individual difference studies examining working memory in children with math difficulties; 3) studies of working memory as a predictor of mathematical outcomes; and 4) longitudinal studies of working memory and math. The goal of this review is to evaluate current information on the nature of the relationship between working memory and math provided by these four approaches, and to present some of the outstanding questions for future research.",2010,165,756,23,7,17,40,52,64,69,91,88,85,83
813c3c045849f82cac2db2f26cee0ca306349f28,"Children's mathematical skills were considered in relation to executive functions. Using multiple measures-including the Wisconsin Card Sorting Task (WCST), dual-task performance, Stroop task, and counting span-it was found that mathematical ability was significantly correlated with all measures of executive functioning, with the exception of dual-task performance. Furthermore, regression analyses revealed that each executive function measure predicted unique variance in mathematics ability. These results are discussed in terms of a central executive with diverse functions (Shallice & Burgess, 1996) and with recent evidence from Miyake, et al. (2000) showing the unity and diversity among executive functions. It is proposed that the particular difficulties for children of lower mathematical ability are lack of inhibition and poor working memory, which result in problems with switching and evaluation of new strategies for dealing with a particular task. The practical and theoretical implications of these results are discussed, along with suggestions for task changes and longitudinal studies that would clarify theoretical and developmental issues related to executive functioning.",2001,79,1320,73,0,2,5,18,38,25,30,34,54,60
deac6a43706ea11bdd9fb07a73b54a08f0c114fb,"Teachers and teacher educators interested in synthesizing their current practice with new mathematics standards will welcome this highly useful volume. Presented are cases of mathematics instruction drawn from research of nearly 500 classroom lessons. Readers will gain insight about how to foster a challenging, cognitively rich, and exciting classroom climate that propels students toward a richer understanding of mathematics.",2009,0,714,82,39,42,46,57,63,50,74,59,57,52
f65040c3aa910788931c27c73006c5f3bb1e7e85,,2008,10,1101,87,44,48,62,72,80,103,88,77,98,55
34fb621cf73b7bad25d77ff1229467a34f736474,"Children's number competencies over 6 time points, from the beginning of kindergarten to the middle of 1st grade, were examined in relation to their mathematics achievement over 5 later time points, from the end of 1st grade to the end of 3rd grade. The relation between early number competence and mathematics achievement was strong and significant throughout the study period. A sequential process growth curve model showed that kindergarten number competence predicted rate of growth in mathematics achievement between 1st and 3rd grades as well as achievement level through 3rd grade. Further, rate of growth in early number competence predicted mathematics performance level in 3rd grade. Although low-income children performed more poorly than their middle-income counterparts in mathematics achievement and progressed at a slower rate, their performance and growth were mediated through relatively weak kindergarten number competence. Similarly, the better performance and faster growth of children who entered kindergarten at an older age were explained by kindergarten number competence. The findings show the importance of early number competence for setting children's learning trajectories in elementary school mathematics.",2009,70,768,38,3,16,21,32,54,72,66,77,73,94
69727a18c999db42c1e0062dd75870b4751ecc90,,2002,0,1397,4,56,59,58,63,81,92,111,128,120,121
c46e0a3586addefd8ffa8aef34afb534b8c1501e,"A model of the relations among cognitive precursors, early numeracy skill, and mathematical outcomes was tested for 182 children from 4.5 to 7.5 years of age. The model integrates research from neuroimaging, clinical populations, and normal development in children and adults. It includes 3 precursor pathways: quantitative, linguistic, and spatial attention. These pathways (a) contributed independently to early numeracy skills during preschool and kindergarten and (b) related differentially to performance on a variety of mathematical outcomes 2 years later. The success of the model in accounting for performance highlights the need to understand the fundamental underlying skills that contribute to diverse forms of mathematical competence.",2010,67,510,47,1,10,10,37,46,49,59,71,66,62
c62e9c1114644b601296d860dd643ff86473071b,"Studies of teachers’ use of mathematics curriculum materials are particularly timely given the current availability of reform-inspired curriculum materials and the increasingly widespread practice of mandating the use of a single curriculum to regulate mathematics teaching. A review of the research on mathematics curriculum use over the last 25 years reveals significant variation in findings and in theoretical foundations. The aim of this review is to examine the ways that central constructs of this body of research—such as curriculum use, teaching, and curriculum materials—are conceptualized and to consider the impact of various conceptualizations on knowledge in the field. Drawing on the literature, the author offers a framework for characterizing and studying teachers’ interactions with curriculum materials.",2005,119,999,143,2,9,21,37,52,49,56,50,64,78
06bdbd4f011e9497fddfc47654116feab28b63bd,"Between 5% and 8% of school-age children have some form of memory or cognitive deficit that interferes with their ability to learn concepts or procedures in one or more mathematical domains. A review of the arithmetical competencies of these children is provided, along with discussion of underlying memory and cognitive deficits and potential neural correlates. The deficits are discussed in terms of three subtypes of mathematics learning disability and in terms of a more general framework for linking research in mathematical cognition to research in learning disabilities.",2004,97,1068,158,5,27,28,49,42,51,68,57,83,95
feeef8d91cec3a9ffe5cf135a36a7f8596426ae1,"Amid ongoing public speculation about the reasons for sex differences in careers in science and mathematics, we present a consensus statement that is based on the best available scientific evidence. Sex differences in science and math achievement and ability are smaller for the mid-range of the abilities distribution than they are for those with the highest levels of achievement and ability. Males are more variable on most measures of quantitative and visuospatial ability, which necessarily results in more males at both high- and low-ability extremes; the reasons why males are often more variable remain elusive. Successful careers in math and science require many types of cognitive abilities. Females tend to excel in verbal abilities, with large differences between females and males found when assessments include writing samples. High-level achievement in science and math requires the ability to communicate effectively and comprehend abstract ideas, so the female advantage in writing should be helpful in all academic domains. Males outperform females on most measures of visuospatial abilities, which have been implicated as contributing to sex differences on standardized exams in mathematics and science. An evolutionary account of sex differences in mathematics and science supports the conclusion that, although sex differences in math and science performance have not directly evolved, they could be indirectly related to differences in interests and specific brain and cognitive systems. We review the brain basis for sex differences in science and mathematics, describe consistent effects, and identify numerous possible correlates. Experience alters brain structures and functioning, so causal statements about brain differences and success in math and science are circular. A wide range of sociocultural forces contribute to sex differences in mathematics and science achievement and ability—including the effects of family, neighborhood, peer, and school influences; training and experience; and cultural practices. We conclude that early experience, biological factors, educational policy, and cultural context affect the number of women and men who pursue advanced study in science and math and that these effects add and interact in complex ways. There are no single or simple answers to the complex questions about sex differences in science and mathematics.",2007,486,906,89,4,19,34,48,46,75,75,61,68,69
62bcc660cbd54558d3fcd07bade3bb764a1a146c,"This study examined the effects of a computer game on students' mathematics achievement and motivation, and the role of prior mathematics knowledge, computer skill, and English language skill on their achievement and motivation as they played the game. A total of 193 students and 10 teachers participated in this study. The teachers were randomly assigned to experimental and control groups. A mixed method of quantitative and interviews were used with Multivariate Analysis of Co-Variance to analyze the data. The results indicated significant improvement of the achievement of the experimental versus control group. No significant improvement was found in the motivation of the groups. Students who played the games in their classrooms and school labs reported greater motivation compared to the ones who played the games only in the school labs. Prior knowledge, computer and English language skill did not play significant roles in achievement and motivation of the experimental group.",2010,65,509,22,4,18,29,45,44,57,67,52,69,57
8d07144332f130bcfc5a5d30716b84a7afecbf9f,"Impairments in executive function have been documented in school-age children with mathematical learning difficulties. However, the utility and specificity of preschool executive function abilities in predicting later mathematical achievement are poorly understood. This study examined linkages between children's developing executive function abilities at age 4 and children's subsequent achievement in mathematics at age 6, 1 year after school entry. The study sample consisted of a regionally representative cohort of 104 children followed prospectively from ages 2 to 6 years. At age 4, children completed a battery of executive function tasks that assessed planning, set shifting, and inhibitory control. Teachers completed the preschool version of the Behavior Rating Inventory of Executive Function. Clinical and classroom measures of children's mathematical achievement were collected at age 6. Results showed that children's performance on set shifting, inhibitory control, and general executive behavior measures during the preschool period accounted for substantial variability in children's early mathematical achievement at school. These associations persisted even after individual differences in general cognitive ability and reading achievement were taken into account. Findings suggest that early measures of executive function may be useful in identifying children who may experience difficulties learning mathematical skills and concepts. They also suggest that the scaffolding of these executive skills could potentially be a useful additional component in early mathematics education.",2010,83,506,20,1,9,33,35,40,46,52,58,55,92
d4d7370670ffa790900ff05f96c208c9eda7d58b,"Graph theory models the Internet mathematically, and a number of plausible mathematically intersecting network models for the Internet have been developed and studied. Simultaneously, Internet researchers have developed methodology to use real data to validate, or invalidate, proposed Internet models. The authors look at these parallel developments, particularly as they apply to scale-free network models of the preferential attachment type.",2009,73,228,11,8,19,28,28,24,18,26,16,16,9
af30825f0c8adf31cf82028c8b50889b716ac362,"The work is giving estimations of the discrepancy between solutions of the initial and the homogenized problems for a one{dimensional second order elliptic operators with random coeecients satisfying strong or uniform mixing conditions. We obtain several sharp estimates in terms of the corresponding mixing coeecient. Abstract. In the theory of homogenisation it is of particular interest to determine the classes of problems which are stable on taking the homogenisation limits. A notable situation where the limit enlarges the class of original problems is known as memory (nonlocal) eeects. A number of results in that direction has been obtained for linear problems. Tartar (1990) innitiated the study of the eeective equation corresponding to nonlinear equation: @ t u n + a n u 2 n = f: Signiicant progress has been hampered by the complexity of required computations needed in order to obtain the terms in power{series expansion. We propose a method which overcomes that diiculty by introducing graphs representing the domain of integration of the integrals in each term. The graphs are relatively simple, it is easy to calculate with them and they give us a clear image of the form of each term. The method allows us to discuss the form of the eeective equation and the convergence of power{series expansions. The feasibility of our method for other types of nonlinearities will be discussed as well.",2010,40,569,7,58,54,70,82,115,47,12,7,10,6
e38ac5b98197284537fca03d8592adaae48841d4,"To understand the difficulties that many students have with comprehension of mathematics, we must determine the cognitive functioning underlying the diversity of mathematical processes. What are the cognitive systems that are required to give access to mathematical objects? Are these systems common to all processes of knowledge or, on the contrary, some of them are specific to mathematical activity? Starting from the paramount importance of semiotic representation for any mathematical activity, we put forward a classification of the various registers of semiotic representations that are mobilized in mathematical processes. Thus, we can reveal two types of transformation of semiotic representations: treatment and conversion. These two types correspond to quite different cognitive processes. They are two separate sources of incomprehension in the learning of mathematics. If treatment is the more important from a mathematical point of view, conversion is basically the deciding factor for learning. Supporting empirical data, at any level of curriculum and for any area of mathematics, can be widely and methodologically gathered: some empirical evidence is presented in this paper.",2006,28,901,111,10,12,20,25,59,41,61,55,62,91
786364fdd5a792fec5c5aaf23b87acbc4b57818b,"Abstract This study examines changes in teachers’ thinking as they participated in a video club designed to help them learn to notice and interpret students’ mathematical thinking. First, we investigate changes in teachers’ talk about classroom video segments before and after participation in the video club. Second, we identify three paths along which teachers learned to notice students’ mathematical thinking in this context: Direct, Cyclical, and Incremental. Finally, we explore ways the video club context influenced teacher learning. Understanding different forms of teacher learning provides insight for research on teacher cognition and may inform the design of video-based professional development.",2008,96,735,68,7,12,19,36,34,38,64,82,69,79
fe88603a338c69f37931facd17f22d6c4b5d5fe1,"Return by mail or fax to: SIAM Connie Young, Conference Director 3600 Market Street – 6 Floor Philadelphia, PA 19104-2688 Fax: 215-386-7999 Personal Information Name: _______________________________________________________________ Affiliation: _______________________________________________________________ Conference Name: _______________________________________________________________ Conference Location: _______________________________________________________________",2010,0,457,15,29,46,51,47,51,34,34,25,16,21
e7a5ff509962afa8850e1e682ebc224018366054,"Although it is often assumed that abilities that reflect basic numerical understanding, such as numerical comparison, are related to children's mathematical abilities, this relationship has not been tested rigorously. In addition, the extent to which symbolic and nonsymbolic number processing play differential roles in this relationship is not yet understood. To address these questions, we collected mathematics achievement measures from 6- to 8-year-olds as well as reaction times from a numerical comparison task. Using the reaction times, we calculated the size of the numerical distance effect exhibited by each child. In a correlational analysis, we found that the individual differences in the distance effect were related to mathematics achievement but not to reading achievement. This relationship was found to be specific to symbolic numerical comparison. Implications for the role of basic numerical competency and the role of accessing numerical magnitude information from Arabic numerals for the development of mathematical skills and their impairment are discussed.",2009,42,588,57,20,21,40,52,53,63,70,75,63,43
cd3a45bdd2c0ebdcfe4f2353da16c8c11ae5cb7f,"Boston College is an equal opportunity, affi rmative action employer.",2004,0,1142,63,2,15,33,42,62,78,86,89,152,109
0cd7e5ea0d7d91be0c9ce76406a1b57f8b57a3f2,"Relational mathematics is to operations research and informatics what numerical mathematics is to engineering: it is intended to help modelling, reasoning, and computing. Its applications are therefore diverse, ranging from psychology, linguistics, decision aid, and ranking to machine learning and spatial reasoning. Although many developments have been made in recent years, they have rarely been shared amongst this broad community of researchers. This first comprehensive overview begins with an easy introduction to the topic, assuming a minimum of prerequisites; but it is nevertheless theoretically sound and up to date. It is suitable for applied scientists, explaining all the necessary mathematics from scratch using a multitude of visualised examples, via matrices and graphs. It ends with tangible results on the research level. The author illustrates the theory and demonstrates practical tasks in operations research, social sciences and the humanities.",2010,0,116,14,0,7,11,9,23,21,10,13,7,4
0a4cf8c0ecf60c39234d48d9d99e03c804e067db,"We're performing all possible to bring our users the most effective books like Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics Download PDF free of charge download. Both you are looking for the book in PDF or EPUB our reference brings Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematicsto you in every possible format. You can obtain the Kindle app and then from Amazon Kindle store you are able to acquire Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics. Ebook Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics and a great many other books can be plumped for divided in to the class develop our website has therefore many categories it has a primarily old collection if you are enthusiastic about the old collection then you can certainly definitely go for it. The very best internet site to obtain Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics and all types of ebooks. They have around 2.5 million books. The same PDF version of any record is available from your personal computer or cellular devices that have a web connection to get Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics Download PDF for free. All the data on this amazing site is published in excellent trust and for normal data function only. Therefore you can easily obtain Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics. There's also some books however beneath the copyright which are offered for free on our site by specific arrangement with the author, like Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics. From this website, you are able to download Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics for free and even contribute or correct. This website is one of many sites for getting free Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics Download PDF. If you're having problem downloading Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics guide or if the hyperlinks aren't functioning, please create to email. We will change it, or send it for your requirements by email. Our digital library preserves in substance nations, letting you get the most less latency age to obtain any of our books subsequent that one. Just said, the Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics Download PDF is generally compatible afterward any units to read. As acknowledged, adventure as without problem as knowledge very almost session, entertainment, as skillfully as a package could be gotten by just looking at a guide Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics Download PDF next it is maybe not directly done, you might consent a lot more very nearly that life, on the buy of the world.",2010,201,322,32,10,16,6,10,11,23,14,19,27,36
1f80d103e387aeaa3513078745c41027b0f0f2a2,"Reprinted with permission from the Fall 2005 issue of American Educator, the quarterly journal of the American Federation of Teachers, AFL-CIO.",2005,17,900,78,3,9,28,37,43,65,50,68,89,91
2c5895c47012b9c42fad64e103f0a80fdacfd635,"This study examines the magnitude, destinations, and determinants of mathematics and science teacher turnover. The data are from the nationally representative Schools and Staffing Survey and the Teacher Follow-Up Survey. Over the past two decades, rates of mathematics and science teacher turnover have increased but, contrary to conventional wisdom, have not been consistently different than those of other teachers. Also, contrary to conventional wisdom, mathematics and science teachers were also no more likely than other teachers to take noneducation jobs, such as in technological fields or to be working for private business or industry. The data also show there are large school-to-school differences in mathematics and science turnover; high-poverty, high-minority, and urban public schools have among the highest rates. In the case of cross-school migration, the data show there is an annual asymmetric reshuffling of a significant portion of the mathematics and science teaching force from poor to not-poor schools, from high-minority to low-minority schools, and from urban to suburban schools. A number of key organizational characteristics and conditions of schools accounted for these school differences. The strongest factor for mathematics teachers was the degree of individual classroom autonomy held by teachers. Net of other factors such as salaries, schools with less classroom autonomy lose math teachers at a far higher rate than other teachers. In contrast, for science teachers salary was the strongest factor, while classroom autonomy was not strongly related to their turnover.",2010,144,278,31,1,4,12,12,24,22,28,32,43,33
69e23a9a149d7550b1afc324f326b264992693ce,"This study investigated adolescents’ developmental trajectories of mathematics interest and explored related effects of gender, family, and school context.Latent growth curvemodelingwas usedtoanalyzelongitudinaldataofN 53,193students(51%female)fromgrades5to9fromall3 ability tracks of the German state school system. Annual assessments involved student questionnaires on interest in mathematics, perceptions of classroom characteristics (classroom values for mathematics, mathematics teacher enthusiasm), as well as parent questionnaires regarding family values for mathematics. Results indicated a downward trend of students’ mathematics interest that plateaued in later years, with high variability in mean levels, but little variability in the shape of the growth trajectories. Boys reported higher mathematics interest than girls, but similar downward growth trajectories. Students from the lowest ability track showed more favorable interest trajectories than students from the middle and highest tracks. Family values andclassroomcharacteristicswerepositivelyrelatedtowithin-personlevelsofinterestovertime and to average individual levels of interest, but not to growth parameters. Theoretical and practical implications are discussed.",2010,116,313,16,4,5,15,15,17,31,31,33,54,36
a16f7f1fe98951487b7b83097b47f43f9e83ac1c,"Early childhood mathematics is vitally important for young children's present and future educational success. Research demonstrates that virtually all young children have the capability to learn and become competent in mathematics. Furthermore, young children enjoy their early informal experiences with mathematics. Unfortunately, many children's potential in mathematics is not fully realized, especially those children who are economically disadvantaged. This is due, in part, to a lack of opportunities to learn mathematics in early childhood settings or through everyday experiences in the home and in their communities. Improvements in early childhood mathematics education can provide young children with the foundation for school success. Relying on a comprehensive review of the research, Mathematics Learning in Early Childhood lays out the critical areas that should be the focus of young children's early mathematics education, explores the extent to which they are currently being incorporated in early childhood settings, and identifies the changes needed to improve the quality of mathematics experiences for young children. This book serves as a call to action to improve the state of early childhood mathematics. It will be especially useful for policy makers and practitioners-those who work directly with children and their families in shaping the policies that affect the education of young children.",2009,0,439,33,4,10,17,26,46,38,56,52,34,53
e2ce8e9f362fb1caf22cf5b7ad038dc9753c1190,"In this article we discuss efforts to design and empirically test measures of teachers’ content knowledge for teaching elementary mathematics. We begin by reviewing the literature on teacher knowledge, noting how scholars have organized such knowledge. Next we describe survey items we wrote to represent knowledge for teaching mathematics and results from factor analysis and scaling work with these items. We found that teachers’ knowledge for teaching elementary mathematics was multidimensional and included knowledge of various mathematical topics (e.g., number and operations, algebra) and domains (e.g., knowledge of content, knowledge of students and content). The constructs indicated by factor analysis formed psychometrically acceptable scales.",2004,37,899,70,2,5,12,30,56,37,52,48,71,94
99eaa4a03d94547bfb294460ce78ff9c753e0c2b,"Using contemporary data from the U.S. and other nations, we address 3 questions: Do gender differences in mathematics performance exist in the general population? Do gender differences exist among the mathematically talented? Do females exist who possess profound mathematical talent? In regard to the first question, contemporary data indicate that girls in the U.S. have reached parity with boys in mathematics performance, a pattern that is found in some other nations as well. Focusing on the second question, studies find more males than females scoring above the 95th or 99th percentile, but this gender gap has significantly narrowed over time in the U.S. and is not found among some ethnic groups and in some nations. Furthermore, data from several studies indicate that greater male variability with respect to mathematics is not ubiquitous. Rather, its presence correlates with several measures of gender inequality. Thus, it is largely an artifact of changeable sociocultural factors, not immutable, innate biological differences between the sexes. Responding to the third question, we document the existence of females who possess profound mathematical talent. Finally, we review mounting evidence that both the magnitude of mean math gender differences and the frequency of identification of gifted and profoundly gifted females significantly correlate with sociocultural factors, including measures of gender equality across nations.",2009,56,435,21,8,16,22,30,40,36,43,24,52,60
9d0c4389436d3ab8ed329dba8c58e8ac6737fd3b,"Many models for the spread of infectious diseases in populations have been analyzed mathematically and applied to specific diseases. Threshold theorems involving the basic reproduction number $R_{0}$, the contact number $\sigma$, and the replacement number $R$ are reviewed for the classic SIR epidemic and endemic models. Similar results with new expressions for $R_{0}$ are obtained for MSEIR and SEIR endemic models with either continuous age or age groups. Values of $R_{0}$ and $\sigma$ are estimated for various diseases including measles in Niger and pertussis in the United States. Previous models with age structure, heterogeneity, and spatial structure are surveyed.",2000,226,4881,259,0,10,20,43,55,80,121,124,129,154
d3d720baa7080594c2fad06bb2ac90cc46666735,"The goals of this chapter are (1) to outline and substantiate a broad conceptualization of what it means to think mathematically, (2) to summarize the literature relevant to understanding mathematical thinking and problem solving, and (3) to point to new directions in research, development, and assessment consonant with an emerging understanding of mathematical thinking and the goals for instruction outlined here. The use of the phrase “learning to think mathematically” in this chapter’s title is deliberately broad. Although the original charter for this chapter was to review the literature on problem solving and metacognition, the literature itself is somewhat ill defined and poorly grounded. As the literature summary will make clear, problem solving has been used with multiple meanings that range from “working rote exercises” to “doing mathematics as a professional”; metacognition has multiple and almost disjoint meanings (from knowledge about one’s thought processes to self-regulation during problem solving) that make it difficult to use as a concept. This chapter outlines the various meanings that have been ascribed to these terms and discusses their role in mathematical thinking. The discussion will not have the character of a classic literature review, which is typically encyclopedic in its references and telegraphic in its discussions of individual papers or results. It will, instead, be selective and illustrative, with main points illustrated by extended discussions of pertinent examples. Problem solving has, as predicted in the 1980 Yearbook of the National Council of Teachers of Mathematics (Krulik, 1980, p. xiv), been the theme of the 1980s. The decade began with NCTM’s widely heralded statement, in its Agenda for Action, that “problem solving must be the focus of school mathematics” (NCTM, 1980, p. 1). It concluded with the publication of Everybody Counts (National Research Council, 1989) and the Curriculum and Evaluation Standards for School Mathematics (NCTM, 1989), both of which emphasize problem solving. One might infer, then, that there is general acceptance of the idea that the primary goal of mathematics instruction should be to have students become competent problem solvers. Yet, given the multiple interpretations of the term, the goal is hardly clear. Equally unclear is the role that problem solving, once adequately characterized, should play in the larger context of school mathematics. What are the goals for mathematics instruction, and how does problem solving fit within those goals? Such questions are complex. Goals for mathematics instruction depend on one’s conceptualization of what mathematics is, and what it means to understand mathematics. Such conceptualizations vary widely. At one end of the spectrum, mathematical knowledge is seen as a body of facts and procedures dealing with quantities, magnitudes, and forms, and the relationships among them; knowing mathematics is seen as having mastered these facts and procedures. At the other end of the spectrum, mathematics is conceptualized as the “science of patterns,” an (almost) empirical discipline closely akin to the sciences in its emphasis on pattern-seeking on the basis of empirical evidence. The author’s view is that the former perspective trivializes mathematics; that a curriculum based on mastering a corpus of mathematical facts and procedures is severely impoverished—in much the same way that an English curriculum would be considered impoverished if it focused largely, if not exclusively, on issues of grammar. The author characterizes the mathematical enterprise as follows:",2009,239,2893,267,123,144,163,155,189,196,226,163,163,178
f2e713dd0a1ee11892a90e0fb448dd5981e63550,,2000,7,7984,20,159,178,250,232,270,267,306,357,411,430
d82b5eb828d803e2f3fe041db20af8536f0fe99e,Author's Preface to the Anniversary Edition Series Editor's Introduction to the Anniversary Edition A Note about the Anniversary Edition Foreword Acknowledgments Introduction 1. Subtraction With Regrouping: Approaches To Teaching A Topic 2. Multidigit Number Multiplication: Dealing With Students' Mistakes 3. Generating Representations: Division By Fractions 4. Exploring New Knowledge: The Relationship Between Perimeter And Area 5. Teachers' Subject Matter Knowledge: Profound Understanding Of Fundamental Mathematics 6. Profound Understanding Of Fundamental Mathematics: When And How Is It Attained 7. Conclusion Appendix References New to the Anniversary Edition: Journal Article #1 New to the Anniversary Edition: Journal Article #2 Author Index Subject Index,2010,0,1684,360,141,143,135,137,149,142,142,129,128,88
7f3b042c8337fe9195ed6ca0cb017b76bbf1ff7c,"868 NOTICES OF THE AMS VOLUME 47, NUMBER 8 In April 2000 the National Council of Teachers of Mathematics (NCTM) released Principles and Standards for School Mathematics—the culmination of a multifaceted, three-year effort to update NCTM’s earlier standards documents and to set forth goals and recommendations for mathematics education in the prekindergarten-through-grade-twelve years. As the chair of the Writing Group, I had the privilege to interact with all aspects of the development and review of this document and with the committed groups of people, including the members of the Writing Group, who contributed immeasurably to this process. This article provides some background about NCTM and the standards, the process of development, efforts to gather input and feedback, and ways in which feedback from the mathematics community influenced the document. The article concludes with a section that provides some suggestions for mathematicians who are interested in using Principles and Standards.",2000,17,2165,296,10,25,47,49,66,78,79,118,115,118
a9386eb6808b41238381c708f2642bcb7dc34b29,"This book is about mathematical ideas, about what mathematics means-and why. Abstract ideas, for the most part, arise via conceptual metaphor-metaphorical ideas projecting from the way we function in the everyday physical world. Where Mathematics Comes From argues that conceptual metaphor plays a central role in mathematical ideas within the cognitive unconscious-from arithmetic and algebra to sets and logic to infinity in all of its forms.",2002,40,1920,107,19,40,48,55,72,74,102,91,120,102
4526716b3789971eaaa81d507abb657a29009957,"A gender gap in mathematics achievement persists in some nations but not in others. In light of the underrepresentation of women in careers in science, technology, mathematics, and engineering, increasing research attention is being devoted to understanding gender differences in mathematics achievement, attitudes, and affect. The gender stratification hypothesis maintains that such gender differences are closely related to cultural variations in opportunity structures for girls and women. We meta-analyzed 2 major international data sets, the 2003 Trends in International Mathematics and Science Study and the Programme for International Student Assessment, representing 493,495 students 14-16 years of age, to estimate the magnitude of gender differences in mathematics achievement, attitudes, and affect across 69 nations throughout the world. Consistent with the gender similarities hypothesis, all of the mean effect sizes in mathematics achievement were very small (d < 0.15); however, national effect sizes showed considerable variability (ds = -0.42 to 0.40). Despite gender similarities in achievement, boys reported more positive math attitudes and affect (ds = 0.10 to 0.33); national effect sizes ranged from d = -0.61 to 0.89. In contrast to those of previous tests of the gender stratification hypothesis, our results point to specific domains of gender equity responsible for gender gaps in math. Gender equity in school enrollment, women's share of research jobs, and women's parliamentary representation were the most powerful predictors of cross-national variability in gender gaps in math. Results are situated within the context of existing research demonstrating apparently paradoxical effects of societal gender equity and highlight the significance of increasing girls' and women's agency cross-nationally.",2010,126,1105,71,16,49,80,93,98,97,99,98,126,108
2ed2cd231aad7ea8a2b69a60d6df7539d6ee107f,"Vol. 72: The Syntax and Semantics of lnfimtary Languages. Edited by J. Barwtse. IV, 268 pages. 1968. DM 18,I $ 5.00 Vol. 73: P. E. Conner, Lectures on the Action of a Finite Group. IV, 123 pages. 1968. DM 10,1 $ 2.80 Vol. 74:A Frohlich, Formal Groups. IV, 140pages. 1968. DM12, -I $3.30 Vol. 75: G. Lumer, Algebras de fonctions et espaces de Hardy. VI, 80 pages. 1968. DM 8,I $ 2. 20 Vol. 76: R. G. Swan, Algebraic K-Theory. IV, 262 pages. 1968. DM18,I$ 5.00",2001,497,1653,59,73,89,93,103,106,99,152,152,126,57
7385b1bcd94ed3904c0e1429e209c80249de0d2a,"In this article, we use meta-analysis to analyze gender differences in recent studies of mathematics performance. First, we meta-analyzed data from 242 studies published between 1990 and 2007, representing the testing of 1,286,350 people. Overall, d = 0.05, indicating no gender difference, and variance ratio = 1.08, indicating nearly equal male and female variances. Second, we analyzed data from large data sets based on probability sampling of U.S. adolescents over the past 20 years: the National Longitudinal Surveys of Youth, the National Education Longitudinal Study of 1988, the Longitudinal Study of American Youth, and the National Assessment of Educational Progress. Effect sizes for the gender difference ranged between -0.15 and +0.22. Variance ratios ranged from 0.88 to 1.34. Taken together, these findings support the view that males and females perform similarly in mathematics.",2010,211,625,39,0,7,22,37,57,67,61,64,74,93
f008393f240508c1686a468b2c67371a7cdcb354,,2009,0,948,91,8,35,43,56,81,101,105,96,74,112
861a8ccc4002510aa1c844ea6f2c41fba69623f4,"Abstract Working memory refers to a mental workspace, involved in controlling, regulating, and actively maintaining relevant information to accomplish complex cognitive tasks (e.g. mathematical processing). Despite the potential relevance of a relation between working memory and math for understanding developmental and individual differences in mathematical skills, the nature of this relationship is not well-understood. This paper reviews four approaches that address the relation of working memory and math: 1) dual task studies establishing the role of working memory during on-line math performance; 2) individual difference studies examining working memory in children with math difficulties; 3) studies of working memory as a predictor of mathematical outcomes; and 4) longitudinal studies of working memory and math. The goal of this review is to evaluate current information on the nature of the relationship between working memory and math provided by these four approaches, and to present some of the outstanding questions for future research.",2010,165,756,23,7,17,40,52,64,69,91,88,85,83
813c3c045849f82cac2db2f26cee0ca306349f28,"Children's mathematical skills were considered in relation to executive functions. Using multiple measures-including the Wisconsin Card Sorting Task (WCST), dual-task performance, Stroop task, and counting span-it was found that mathematical ability was significantly correlated with all measures of executive functioning, with the exception of dual-task performance. Furthermore, regression analyses revealed that each executive function measure predicted unique variance in mathematics ability. These results are discussed in terms of a central executive with diverse functions (Shallice & Burgess, 1996) and with recent evidence from Miyake, et al. (2000) showing the unity and diversity among executive functions. It is proposed that the particular difficulties for children of lower mathematical ability are lack of inhibition and poor working memory, which result in problems with switching and evaluation of new strategies for dealing with a particular task. The practical and theoretical implications of these results are discussed, along with suggestions for task changes and longitudinal studies that would clarify theoretical and developmental issues related to executive functioning.",2001,79,1320,73,0,2,5,18,38,25,30,34,54,60
deac6a43706ea11bdd9fb07a73b54a08f0c114fb,"Teachers and teacher educators interested in synthesizing their current practice with new mathematics standards will welcome this highly useful volume. Presented are cases of mathematics instruction drawn from research of nearly 500 classroom lessons. Readers will gain insight about how to foster a challenging, cognitively rich, and exciting classroom climate that propels students toward a richer understanding of mathematics.",2009,0,714,82,39,42,46,57,63,50,74,59,57,52
f65040c3aa910788931c27c73006c5f3bb1e7e85,,2008,10,1101,87,44,48,62,72,80,103,88,77,98,55
34fb621cf73b7bad25d77ff1229467a34f736474,"Children's number competencies over 6 time points, from the beginning of kindergarten to the middle of 1st grade, were examined in relation to their mathematics achievement over 5 later time points, from the end of 1st grade to the end of 3rd grade. The relation between early number competence and mathematics achievement was strong and significant throughout the study period. A sequential process growth curve model showed that kindergarten number competence predicted rate of growth in mathematics achievement between 1st and 3rd grades as well as achievement level through 3rd grade. Further, rate of growth in early number competence predicted mathematics performance level in 3rd grade. Although low-income children performed more poorly than their middle-income counterparts in mathematics achievement and progressed at a slower rate, their performance and growth were mediated through relatively weak kindergarten number competence. Similarly, the better performance and faster growth of children who entered kindergarten at an older age were explained by kindergarten number competence. The findings show the importance of early number competence for setting children's learning trajectories in elementary school mathematics.",2009,70,768,38,3,16,21,32,54,72,66,77,73,94
69727a18c999db42c1e0062dd75870b4751ecc90,,2002,0,1397,4,56,59,58,63,81,92,111,128,120,121
c46e0a3586addefd8ffa8aef34afb534b8c1501e,"A model of the relations among cognitive precursors, early numeracy skill, and mathematical outcomes was tested for 182 children from 4.5 to 7.5 years of age. The model integrates research from neuroimaging, clinical populations, and normal development in children and adults. It includes 3 precursor pathways: quantitative, linguistic, and spatial attention. These pathways (a) contributed independently to early numeracy skills during preschool and kindergarten and (b) related differentially to performance on a variety of mathematical outcomes 2 years later. The success of the model in accounting for performance highlights the need to understand the fundamental underlying skills that contribute to diverse forms of mathematical competence.",2010,67,510,47,1,10,10,37,46,49,59,71,66,62
06bdbd4f011e9497fddfc47654116feab28b63bd,"Between 5% and 8% of school-age children have some form of memory or cognitive deficit that interferes with their ability to learn concepts or procedures in one or more mathematical domains. A review of the arithmetical competencies of these children is provided, along with discussion of underlying memory and cognitive deficits and potential neural correlates. The deficits are discussed in terms of three subtypes of mathematics learning disability and in terms of a more general framework for linking research in mathematical cognition to research in learning disabilities.",2004,97,1068,158,5,27,28,49,42,51,68,57,83,95
c62e9c1114644b601296d860dd643ff86473071b,"Studies of teachers’ use of mathematics curriculum materials are particularly timely given the current availability of reform-inspired curriculum materials and the increasingly widespread practice of mandating the use of a single curriculum to regulate mathematics teaching. A review of the research on mathematics curriculum use over the last 25 years reveals significant variation in findings and in theoretical foundations. The aim of this review is to examine the ways that central constructs of this body of research—such as curriculum use, teaching, and curriculum materials—are conceptualized and to consider the impact of various conceptualizations on knowledge in the field. Drawing on the literature, the author offers a framework for characterizing and studying teachers’ interactions with curriculum materials.",2005,119,999,143,2,9,21,37,52,49,56,50,64,78
feeef8d91cec3a9ffe5cf135a36a7f8596426ae1,"Amid ongoing public speculation about the reasons for sex differences in careers in science and mathematics, we present a consensus statement that is based on the best available scientific evidence. Sex differences in science and math achievement and ability are smaller for the mid-range of the abilities distribution than they are for those with the highest levels of achievement and ability. Males are more variable on most measures of quantitative and visuospatial ability, which necessarily results in more males at both high- and low-ability extremes; the reasons why males are often more variable remain elusive. Successful careers in math and science require many types of cognitive abilities. Females tend to excel in verbal abilities, with large differences between females and males found when assessments include writing samples. High-level achievement in science and math requires the ability to communicate effectively and comprehend abstract ideas, so the female advantage in writing should be helpful in all academic domains. Males outperform females on most measures of visuospatial abilities, which have been implicated as contributing to sex differences on standardized exams in mathematics and science. An evolutionary account of sex differences in mathematics and science supports the conclusion that, although sex differences in math and science performance have not directly evolved, they could be indirectly related to differences in interests and specific brain and cognitive systems. We review the brain basis for sex differences in science and mathematics, describe consistent effects, and identify numerous possible correlates. Experience alters brain structures and functioning, so causal statements about brain differences and success in math and science are circular. A wide range of sociocultural forces contribute to sex differences in mathematics and science achievement and ability—including the effects of family, neighborhood, peer, and school influences; training and experience; and cultural practices. We conclude that early experience, biological factors, educational policy, and cultural context affect the number of women and men who pursue advanced study in science and math and that these effects add and interact in complex ways. There are no single or simple answers to the complex questions about sex differences in science and mathematics.",2007,486,906,89,4,19,34,48,46,75,75,61,68,69
62bcc660cbd54558d3fcd07bade3bb764a1a146c,"This study examined the effects of a computer game on students' mathematics achievement and motivation, and the role of prior mathematics knowledge, computer skill, and English language skill on their achievement and motivation as they played the game. A total of 193 students and 10 teachers participated in this study. The teachers were randomly assigned to experimental and control groups. A mixed method of quantitative and interviews were used with Multivariate Analysis of Co-Variance to analyze the data. The results indicated significant improvement of the achievement of the experimental versus control group. No significant improvement was found in the motivation of the groups. Students who played the games in their classrooms and school labs reported greater motivation compared to the ones who played the games only in the school labs. Prior knowledge, computer and English language skill did not play significant roles in achievement and motivation of the experimental group.",2010,65,509,22,4,18,29,45,44,57,67,52,69,57
8d07144332f130bcfc5a5d30716b84a7afecbf9f,"Impairments in executive function have been documented in school-age children with mathematical learning difficulties. However, the utility and specificity of preschool executive function abilities in predicting later mathematical achievement are poorly understood. This study examined linkages between children's developing executive function abilities at age 4 and children's subsequent achievement in mathematics at age 6, 1 year after school entry. The study sample consisted of a regionally representative cohort of 104 children followed prospectively from ages 2 to 6 years. At age 4, children completed a battery of executive function tasks that assessed planning, set shifting, and inhibitory control. Teachers completed the preschool version of the Behavior Rating Inventory of Executive Function. Clinical and classroom measures of children's mathematical achievement were collected at age 6. Results showed that children's performance on set shifting, inhibitory control, and general executive behavior measures during the preschool period accounted for substantial variability in children's early mathematical achievement at school. These associations persisted even after individual differences in general cognitive ability and reading achievement were taken into account. Findings suggest that early measures of executive function may be useful in identifying children who may experience difficulties learning mathematical skills and concepts. They also suggest that the scaffolding of these executive skills could potentially be a useful additional component in early mathematics education.",2010,83,506,20,1,9,33,35,40,46,52,58,55,92
d4d7370670ffa790900ff05f96c208c9eda7d58b,"Graph theory models the Internet mathematically, and a number of plausible mathematically intersecting network models for the Internet have been developed and studied. Simultaneously, Internet researchers have developed methodology to use real data to validate, or invalidate, proposed Internet models. The authors look at these parallel developments, particularly as they apply to scale-free network models of the preferential attachment type.",2009,73,228,11,8,19,28,28,24,18,26,16,16,9
af30825f0c8adf31cf82028c8b50889b716ac362,"The work is giving estimations of the discrepancy between solutions of the initial and the homogenized problems for a one{dimensional second order elliptic operators with random coeecients satisfying strong or uniform mixing conditions. We obtain several sharp estimates in terms of the corresponding mixing coeecient. Abstract. In the theory of homogenisation it is of particular interest to determine the classes of problems which are stable on taking the homogenisation limits. A notable situation where the limit enlarges the class of original problems is known as memory (nonlocal) eeects. A number of results in that direction has been obtained for linear problems. Tartar (1990) innitiated the study of the eeective equation corresponding to nonlinear equation: @ t u n + a n u 2 n = f: Signiicant progress has been hampered by the complexity of required computations needed in order to obtain the terms in power{series expansion. We propose a method which overcomes that diiculty by introducing graphs representing the domain of integration of the integrals in each term. The graphs are relatively simple, it is easy to calculate with them and they give us a clear image of the form of each term. The method allows us to discuss the form of the eeective equation and the convergence of power{series expansions. The feasibility of our method for other types of nonlinearities will be discussed as well.",2010,40,569,7,58,54,70,82,115,47,12,7,10,6
e38ac5b98197284537fca03d8592adaae48841d4,"To understand the difficulties that many students have with comprehension of mathematics, we must determine the cognitive functioning underlying the diversity of mathematical processes. What are the cognitive systems that are required to give access to mathematical objects? Are these systems common to all processes of knowledge or, on the contrary, some of them are specific to mathematical activity? Starting from the paramount importance of semiotic representation for any mathematical activity, we put forward a classification of the various registers of semiotic representations that are mobilized in mathematical processes. Thus, we can reveal two types of transformation of semiotic representations: treatment and conversion. These two types correspond to quite different cognitive processes. They are two separate sources of incomprehension in the learning of mathematics. If treatment is the more important from a mathematical point of view, conversion is basically the deciding factor for learning. Supporting empirical data, at any level of curriculum and for any area of mathematics, can be widely and methodologically gathered: some empirical evidence is presented in this paper.",2006,28,901,111,10,12,20,25,59,41,61,55,62,91
786364fdd5a792fec5c5aaf23b87acbc4b57818b,"Abstract This study examines changes in teachers’ thinking as they participated in a video club designed to help them learn to notice and interpret students’ mathematical thinking. First, we investigate changes in teachers’ talk about classroom video segments before and after participation in the video club. Second, we identify three paths along which teachers learned to notice students’ mathematical thinking in this context: Direct, Cyclical, and Incremental. Finally, we explore ways the video club context influenced teacher learning. Understanding different forms of teacher learning provides insight for research on teacher cognition and may inform the design of video-based professional development.",2008,96,735,68,7,12,19,36,34,38,64,82,69,79
fe88603a338c69f37931facd17f22d6c4b5d5fe1,"Return by mail or fax to: SIAM Connie Young, Conference Director 3600 Market Street – 6 Floor Philadelphia, PA 19104-2688 Fax: 215-386-7999 Personal Information Name: _______________________________________________________________ Affiliation: _______________________________________________________________ Conference Name: _______________________________________________________________ Conference Location: _______________________________________________________________",2010,0,457,15,29,46,51,47,51,34,34,25,16,21
e7a5ff509962afa8850e1e682ebc224018366054,"Although it is often assumed that abilities that reflect basic numerical understanding, such as numerical comparison, are related to children's mathematical abilities, this relationship has not been tested rigorously. In addition, the extent to which symbolic and nonsymbolic number processing play differential roles in this relationship is not yet understood. To address these questions, we collected mathematics achievement measures from 6- to 8-year-olds as well as reaction times from a numerical comparison task. Using the reaction times, we calculated the size of the numerical distance effect exhibited by each child. In a correlational analysis, we found that the individual differences in the distance effect were related to mathematics achievement but not to reading achievement. This relationship was found to be specific to symbolic numerical comparison. Implications for the role of basic numerical competency and the role of accessing numerical magnitude information from Arabic numerals for the development of mathematical skills and their impairment are discussed.",2009,42,588,57,20,21,40,52,53,63,70,75,63,43
cd3a45bdd2c0ebdcfe4f2353da16c8c11ae5cb7f,"Boston College is an equal opportunity, affi rmative action employer.",2004,0,1142,63,2,15,33,42,62,78,86,89,152,109
0cd7e5ea0d7d91be0c9ce76406a1b57f8b57a3f2,"Relational mathematics is to operations research and informatics what numerical mathematics is to engineering: it is intended to help modelling, reasoning, and computing. Its applications are therefore diverse, ranging from psychology, linguistics, decision aid, and ranking to machine learning and spatial reasoning. Although many developments have been made in recent years, they have rarely been shared amongst this broad community of researchers. This first comprehensive overview begins with an easy introduction to the topic, assuming a minimum of prerequisites; but it is nevertheless theoretically sound and up to date. It is suitable for applied scientists, explaining all the necessary mathematics from scratch using a multitude of visualised examples, via matrices and graphs. It ends with tangible results on the research level. The author illustrates the theory and demonstrates practical tasks in operations research, social sciences and the humanities.",2010,0,116,14,0,7,11,9,23,21,10,13,7,4
0a4cf8c0ecf60c39234d48d9d99e03c804e067db,"We're performing all possible to bring our users the most effective books like Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics Download PDF free of charge download. Both you are looking for the book in PDF or EPUB our reference brings Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematicsto you in every possible format. You can obtain the Kindle app and then from Amazon Kindle store you are able to acquire Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics. Ebook Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics and a great many other books can be plumped for divided in to the class develop our website has therefore many categories it has a primarily old collection if you are enthusiastic about the old collection then you can certainly definitely go for it. The very best internet site to obtain Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics and all types of ebooks. They have around 2.5 million books. The same PDF version of any record is available from your personal computer or cellular devices that have a web connection to get Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics Download PDF for free. All the data on this amazing site is published in excellent trust and for normal data function only. Therefore you can easily obtain Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics. There's also some books however beneath the copyright which are offered for free on our site by specific arrangement with the author, like Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics. From this website, you are able to download Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics for free and even contribute or correct. This website is one of many sites for getting free Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics Download PDF. If you're having problem downloading Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics guide or if the hyperlinks aren't functioning, please create to email. We will change it, or send it for your requirements by email. Our digital library preserves in substance nations, letting you get the most less latency age to obtain any of our books subsequent that one. Just said, the Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics Download PDF is generally compatible afterward any units to read. As acknowledged, adventure as without problem as knowledge very almost session, entertainment, as skillfully as a package could be gotten by just looking at a guide Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics Download PDF next it is maybe not directly done, you might consent a lot more very nearly that life, on the buy of the world.",2010,201,322,32,10,16,6,10,11,23,14,19,27,36
1f80d103e387aeaa3513078745c41027b0f0f2a2,"Reprinted with permission from the Fall 2005 issue of American Educator, the quarterly journal of the American Federation of Teachers, AFL-CIO.",2005,17,900,78,3,9,28,37,43,65,50,68,89,91
2c5895c47012b9c42fad64e103f0a80fdacfd635,"This study examines the magnitude, destinations, and determinants of mathematics and science teacher turnover. The data are from the nationally representative Schools and Staffing Survey and the Teacher Follow-Up Survey. Over the past two decades, rates of mathematics and science teacher turnover have increased but, contrary to conventional wisdom, have not been consistently different than those of other teachers. Also, contrary to conventional wisdom, mathematics and science teachers were also no more likely than other teachers to take noneducation jobs, such as in technological fields or to be working for private business or industry. The data also show there are large school-to-school differences in mathematics and science turnover; high-poverty, high-minority, and urban public schools have among the highest rates. In the case of cross-school migration, the data show there is an annual asymmetric reshuffling of a significant portion of the mathematics and science teaching force from poor to not-poor schools, from high-minority to low-minority schools, and from urban to suburban schools. A number of key organizational characteristics and conditions of schools accounted for these school differences. The strongest factor for mathematics teachers was the degree of individual classroom autonomy held by teachers. Net of other factors such as salaries, schools with less classroom autonomy lose math teachers at a far higher rate than other teachers. In contrast, for science teachers salary was the strongest factor, while classroom autonomy was not strongly related to their turnover.",2010,144,278,31,1,4,12,12,24,22,28,32,43,33
69e23a9a149d7550b1afc324f326b264992693ce,"This study investigated adolescents’ developmental trajectories of mathematics interest and explored related effects of gender, family, and school context.Latent growth curvemodelingwas usedtoanalyzelongitudinaldataofN 53,193students(51%female)fromgrades5to9fromall3 ability tracks of the German state school system. Annual assessments involved student questionnaires on interest in mathematics, perceptions of classroom characteristics (classroom values for mathematics, mathematics teacher enthusiasm), as well as parent questionnaires regarding family values for mathematics. Results indicated a downward trend of students’ mathematics interest that plateaued in later years, with high variability in mean levels, but little variability in the shape of the growth trajectories. Boys reported higher mathematics interest than girls, but similar downward growth trajectories. Students from the lowest ability track showed more favorable interest trajectories than students from the middle and highest tracks. Family values andclassroomcharacteristicswerepositivelyrelatedtowithin-personlevelsofinterestovertime and to average individual levels of interest, but not to growth parameters. Theoretical and practical implications are discussed.",2010,116,313,16,4,5,15,15,17,31,31,33,54,36
a16f7f1fe98951487b7b83097b47f43f9e83ac1c,"Early childhood mathematics is vitally important for young children's present and future educational success. Research demonstrates that virtually all young children have the capability to learn and become competent in mathematics. Furthermore, young children enjoy their early informal experiences with mathematics. Unfortunately, many children's potential in mathematics is not fully realized, especially those children who are economically disadvantaged. This is due, in part, to a lack of opportunities to learn mathematics in early childhood settings or through everyday experiences in the home and in their communities. Improvements in early childhood mathematics education can provide young children with the foundation for school success. Relying on a comprehensive review of the research, Mathematics Learning in Early Childhood lays out the critical areas that should be the focus of young children's early mathematics education, explores the extent to which they are currently being incorporated in early childhood settings, and identifies the changes needed to improve the quality of mathematics experiences for young children. This book serves as a call to action to improve the state of early childhood mathematics. It will be especially useful for policy makers and practitioners-those who work directly with children and their families in shaping the policies that affect the education of young children.",2009,0,439,33,4,10,17,26,46,38,56,52,34,53
e2ce8e9f362fb1caf22cf5b7ad038dc9753c1190,"In this article we discuss efforts to design and empirically test measures of teachers’ content knowledge for teaching elementary mathematics. We begin by reviewing the literature on teacher knowledge, noting how scholars have organized such knowledge. Next we describe survey items we wrote to represent knowledge for teaching mathematics and results from factor analysis and scaling work with these items. We found that teachers’ knowledge for teaching elementary mathematics was multidimensional and included knowledge of various mathematical topics (e.g., number and operations, algebra) and domains (e.g., knowledge of content, knowledge of students and content). The constructs indicated by factor analysis formed psychometrically acceptable scales.",2004,37,899,70,2,5,12,30,56,37,52,48,71,94
99eaa4a03d94547bfb294460ce78ff9c753e0c2b,"Using contemporary data from the U.S. and other nations, we address 3 questions: Do gender differences in mathematics performance exist in the general population? Do gender differences exist among the mathematically talented? Do females exist who possess profound mathematical talent? In regard to the first question, contemporary data indicate that girls in the U.S. have reached parity with boys in mathematics performance, a pattern that is found in some other nations as well. Focusing on the second question, studies find more males than females scoring above the 95th or 99th percentile, but this gender gap has significantly narrowed over time in the U.S. and is not found among some ethnic groups and in some nations. Furthermore, data from several studies indicate that greater male variability with respect to mathematics is not ubiquitous. Rather, its presence correlates with several measures of gender inequality. Thus, it is largely an artifact of changeable sociocultural factors, not immutable, innate biological differences between the sexes. Responding to the third question, we document the existence of females who possess profound mathematical talent. Finally, we review mounting evidence that both the magnitude of mean math gender differences and the frequency of identification of gifted and profoundly gifted females significantly correlate with sociocultural factors, including measures of gender equality across nations.",2009,56,435,21,8,16,22,30,40,36,43,24,52,60
9d0c4389436d3ab8ed329dba8c58e8ac6737fd3b,"Many models for the spread of infectious diseases in populations have been analyzed mathematically and applied to specific diseases. Threshold theorems involving the basic reproduction number $R_{0}$, the contact number $\sigma$, and the replacement number $R$ are reviewed for the classic SIR epidemic and endemic models. Similar results with new expressions for $R_{0}$ are obtained for MSEIR and SEIR endemic models with either continuous age or age groups. Values of $R_{0}$ and $\sigma$ are estimated for various diseases including measles in Niger and pertussis in the United States. Previous models with age structure, heterogeneity, and spatial structure are surveyed.",2000,226,4881,259,0,10,20,43,55,80,121,124,129,154
d3d720baa7080594c2fad06bb2ac90cc46666735,"The goals of this chapter are (1) to outline and substantiate a broad conceptualization of what it means to think mathematically, (2) to summarize the literature relevant to understanding mathematical thinking and problem solving, and (3) to point to new directions in research, development, and assessment consonant with an emerging understanding of mathematical thinking and the goals for instruction outlined here. The use of the phrase “learning to think mathematically” in this chapter’s title is deliberately broad. Although the original charter for this chapter was to review the literature on problem solving and metacognition, the literature itself is somewhat ill defined and poorly grounded. As the literature summary will make clear, problem solving has been used with multiple meanings that range from “working rote exercises” to “doing mathematics as a professional”; metacognition has multiple and almost disjoint meanings (from knowledge about one’s thought processes to self-regulation during problem solving) that make it difficult to use as a concept. This chapter outlines the various meanings that have been ascribed to these terms and discusses their role in mathematical thinking. The discussion will not have the character of a classic literature review, which is typically encyclopedic in its references and telegraphic in its discussions of individual papers or results. It will, instead, be selective and illustrative, with main points illustrated by extended discussions of pertinent examples. Problem solving has, as predicted in the 1980 Yearbook of the National Council of Teachers of Mathematics (Krulik, 1980, p. xiv), been the theme of the 1980s. The decade began with NCTM’s widely heralded statement, in its Agenda for Action, that “problem solving must be the focus of school mathematics” (NCTM, 1980, p. 1). It concluded with the publication of Everybody Counts (National Research Council, 1989) and the Curriculum and Evaluation Standards for School Mathematics (NCTM, 1989), both of which emphasize problem solving. One might infer, then, that there is general acceptance of the idea that the primary goal of mathematics instruction should be to have students become competent problem solvers. Yet, given the multiple interpretations of the term, the goal is hardly clear. Equally unclear is the role that problem solving, once adequately characterized, should play in the larger context of school mathematics. What are the goals for mathematics instruction, and how does problem solving fit within those goals? Such questions are complex. Goals for mathematics instruction depend on one’s conceptualization of what mathematics is, and what it means to understand mathematics. Such conceptualizations vary widely. At one end of the spectrum, mathematical knowledge is seen as a body of facts and procedures dealing with quantities, magnitudes, and forms, and the relationships among them; knowing mathematics is seen as having mastered these facts and procedures. At the other end of the spectrum, mathematics is conceptualized as the “science of patterns,” an (almost) empirical discipline closely akin to the sciences in its emphasis on pattern-seeking on the basis of empirical evidence. The author’s view is that the former perspective trivializes mathematics; that a curriculum based on mastering a corpus of mathematical facts and procedures is severely impoverished—in much the same way that an English curriculum would be considered impoverished if it focused largely, if not exclusively, on issues of grammar. The author characterizes the mathematical enterprise as follows:",2009,239,2893,267,123,144,163,155,189,196,226,163,163,178
f2e713dd0a1ee11892a90e0fb448dd5981e63550,,2000,7,7984,20,159,178,250,232,270,267,306,357,411,430
d82b5eb828d803e2f3fe041db20af8536f0fe99e,Author's Preface to the Anniversary Edition Series Editor's Introduction to the Anniversary Edition A Note about the Anniversary Edition Foreword Acknowledgments Introduction 1. Subtraction With Regrouping: Approaches To Teaching A Topic 2. Multidigit Number Multiplication: Dealing With Students' Mistakes 3. Generating Representations: Division By Fractions 4. Exploring New Knowledge: The Relationship Between Perimeter And Area 5. Teachers' Subject Matter Knowledge: Profound Understanding Of Fundamental Mathematics 6. Profound Understanding Of Fundamental Mathematics: When And How Is It Attained 7. Conclusion Appendix References New to the Anniversary Edition: Journal Article #1 New to the Anniversary Edition: Journal Article #2 Author Index Subject Index,2010,0,1684,360,141,143,135,137,149,142,142,129,128,88
7f3b042c8337fe9195ed6ca0cb017b76bbf1ff7c,"868 NOTICES OF THE AMS VOLUME 47, NUMBER 8 In April 2000 the National Council of Teachers of Mathematics (NCTM) released Principles and Standards for School Mathematics—the culmination of a multifaceted, three-year effort to update NCTM’s earlier standards documents and to set forth goals and recommendations for mathematics education in the prekindergarten-through-grade-twelve years. As the chair of the Writing Group, I had the privilege to interact with all aspects of the development and review of this document and with the committed groups of people, including the members of the Writing Group, who contributed immeasurably to this process. This article provides some background about NCTM and the standards, the process of development, efforts to gather input and feedback, and ways in which feedback from the mathematics community influenced the document. The article concludes with a section that provides some suggestions for mathematicians who are interested in using Principles and Standards.",2000,17,2165,296,10,25,47,49,66,78,79,118,115,118
a9386eb6808b41238381c708f2642bcb7dc34b29,"This book is about mathematical ideas, about what mathematics means-and why. Abstract ideas, for the most part, arise via conceptual metaphor-metaphorical ideas projecting from the way we function in the everyday physical world. Where Mathematics Comes From argues that conceptual metaphor plays a central role in mathematical ideas within the cognitive unconscious-from arithmetic and algebra to sets and logic to infinity in all of its forms.",2002,40,1920,107,19,40,48,55,72,74,102,91,120,102
4526716b3789971eaaa81d507abb657a29009957,"A gender gap in mathematics achievement persists in some nations but not in others. In light of the underrepresentation of women in careers in science, technology, mathematics, and engineering, increasing research attention is being devoted to understanding gender differences in mathematics achievement, attitudes, and affect. The gender stratification hypothesis maintains that such gender differences are closely related to cultural variations in opportunity structures for girls and women. We meta-analyzed 2 major international data sets, the 2003 Trends in International Mathematics and Science Study and the Programme for International Student Assessment, representing 493,495 students 14-16 years of age, to estimate the magnitude of gender differences in mathematics achievement, attitudes, and affect across 69 nations throughout the world. Consistent with the gender similarities hypothesis, all of the mean effect sizes in mathematics achievement were very small (d < 0.15); however, national effect sizes showed considerable variability (ds = -0.42 to 0.40). Despite gender similarities in achievement, boys reported more positive math attitudes and affect (ds = 0.10 to 0.33); national effect sizes ranged from d = -0.61 to 0.89. In contrast to those of previous tests of the gender stratification hypothesis, our results point to specific domains of gender equity responsible for gender gaps in math. Gender equity in school enrollment, women's share of research jobs, and women's parliamentary representation were the most powerful predictors of cross-national variability in gender gaps in math. Results are situated within the context of existing research demonstrating apparently paradoxical effects of societal gender equity and highlight the significance of increasing girls' and women's agency cross-nationally.",2010,126,1105,71,16,49,80,93,98,97,99,98,126,108
2ed2cd231aad7ea8a2b69a60d6df7539d6ee107f,"Vol. 72: The Syntax and Semantics of lnfimtary Languages. Edited by J. Barwtse. IV, 268 pages. 1968. DM 18,I $ 5.00 Vol. 73: P. E. Conner, Lectures on the Action of a Finite Group. IV, 123 pages. 1968. DM 10,1 $ 2.80 Vol. 74:A Frohlich, Formal Groups. IV, 140pages. 1968. DM12, -I $3.30 Vol. 75: G. Lumer, Algebras de fonctions et espaces de Hardy. VI, 80 pages. 1968. DM 8,I $ 2. 20 Vol. 76: R. G. Swan, Algebraic K-Theory. IV, 262 pages. 1968. DM18,I$ 5.00",2001,497,1653,59,73,89,93,103,106,99,152,152,126,57
7385b1bcd94ed3904c0e1429e209c80249de0d2a,"In this article, we use meta-analysis to analyze gender differences in recent studies of mathematics performance. First, we meta-analyzed data from 242 studies published between 1990 and 2007, representing the testing of 1,286,350 people. Overall, d = 0.05, indicating no gender difference, and variance ratio = 1.08, indicating nearly equal male and female variances. Second, we analyzed data from large data sets based on probability sampling of U.S. adolescents over the past 20 years: the National Longitudinal Surveys of Youth, the National Education Longitudinal Study of 1988, the Longitudinal Study of American Youth, and the National Assessment of Educational Progress. Effect sizes for the gender difference ranged between -0.15 and +0.22. Variance ratios ranged from 0.88 to 1.34. Taken together, these findings support the view that males and females perform similarly in mathematics.",2010,211,625,39,0,7,22,37,57,67,61,64,74,93
f008393f240508c1686a468b2c67371a7cdcb354,,2009,0,948,91,8,35,43,56,81,101,105,96,74,112
861a8ccc4002510aa1c844ea6f2c41fba69623f4,"Abstract Working memory refers to a mental workspace, involved in controlling, regulating, and actively maintaining relevant information to accomplish complex cognitive tasks (e.g. mathematical processing). Despite the potential relevance of a relation between working memory and math for understanding developmental and individual differences in mathematical skills, the nature of this relationship is not well-understood. This paper reviews four approaches that address the relation of working memory and math: 1) dual task studies establishing the role of working memory during on-line math performance; 2) individual difference studies examining working memory in children with math difficulties; 3) studies of working memory as a predictor of mathematical outcomes; and 4) longitudinal studies of working memory and math. The goal of this review is to evaluate current information on the nature of the relationship between working memory and math provided by these four approaches, and to present some of the outstanding questions for future research.",2010,165,756,23,7,17,40,52,64,69,91,88,85,83
813c3c045849f82cac2db2f26cee0ca306349f28,"Children's mathematical skills were considered in relation to executive functions. Using multiple measures-including the Wisconsin Card Sorting Task (WCST), dual-task performance, Stroop task, and counting span-it was found that mathematical ability was significantly correlated with all measures of executive functioning, with the exception of dual-task performance. Furthermore, regression analyses revealed that each executive function measure predicted unique variance in mathematics ability. These results are discussed in terms of a central executive with diverse functions (Shallice & Burgess, 1996) and with recent evidence from Miyake, et al. (2000) showing the unity and diversity among executive functions. It is proposed that the particular difficulties for children of lower mathematical ability are lack of inhibition and poor working memory, which result in problems with switching and evaluation of new strategies for dealing with a particular task. The practical and theoretical implications of these results are discussed, along with suggestions for task changes and longitudinal studies that would clarify theoretical and developmental issues related to executive functioning.",2001,79,1320,73,0,2,5,18,38,25,30,34,54,60
deac6a43706ea11bdd9fb07a73b54a08f0c114fb,"Teachers and teacher educators interested in synthesizing their current practice with new mathematics standards will welcome this highly useful volume. Presented are cases of mathematics instruction drawn from research of nearly 500 classroom lessons. Readers will gain insight about how to foster a challenging, cognitively rich, and exciting classroom climate that propels students toward a richer understanding of mathematics.",2009,0,714,82,39,42,46,57,63,50,74,59,57,52
f65040c3aa910788931c27c73006c5f3bb1e7e85,,2008,10,1101,87,44,48,62,72,80,103,88,77,98,55
34fb621cf73b7bad25d77ff1229467a34f736474,"Children's number competencies over 6 time points, from the beginning of kindergarten to the middle of 1st grade, were examined in relation to their mathematics achievement over 5 later time points, from the end of 1st grade to the end of 3rd grade. The relation between early number competence and mathematics achievement was strong and significant throughout the study period. A sequential process growth curve model showed that kindergarten number competence predicted rate of growth in mathematics achievement between 1st and 3rd grades as well as achievement level through 3rd grade. Further, rate of growth in early number competence predicted mathematics performance level in 3rd grade. Although low-income children performed more poorly than their middle-income counterparts in mathematics achievement and progressed at a slower rate, their performance and growth were mediated through relatively weak kindergarten number competence. Similarly, the better performance and faster growth of children who entered kindergarten at an older age were explained by kindergarten number competence. The findings show the importance of early number competence for setting children's learning trajectories in elementary school mathematics.",2009,70,768,38,3,16,21,32,54,72,66,77,73,94
69727a18c999db42c1e0062dd75870b4751ecc90,,2002,0,1397,4,56,59,58,63,81,92,111,128,120,121
c46e0a3586addefd8ffa8aef34afb534b8c1501e,"A model of the relations among cognitive precursors, early numeracy skill, and mathematical outcomes was tested for 182 children from 4.5 to 7.5 years of age. The model integrates research from neuroimaging, clinical populations, and normal development in children and adults. It includes 3 precursor pathways: quantitative, linguistic, and spatial attention. These pathways (a) contributed independently to early numeracy skills during preschool and kindergarten and (b) related differentially to performance on a variety of mathematical outcomes 2 years later. The success of the model in accounting for performance highlights the need to understand the fundamental underlying skills that contribute to diverse forms of mathematical competence.",2010,67,510,47,1,10,10,37,46,49,59,71,66,62
06bdbd4f011e9497fddfc47654116feab28b63bd,"Between 5% and 8% of school-age children have some form of memory or cognitive deficit that interferes with their ability to learn concepts or procedures in one or more mathematical domains. A review of the arithmetical competencies of these children is provided, along with discussion of underlying memory and cognitive deficits and potential neural correlates. The deficits are discussed in terms of three subtypes of mathematics learning disability and in terms of a more general framework for linking research in mathematical cognition to research in learning disabilities.",2004,97,1068,158,5,27,28,49,42,51,68,57,83,95
c62e9c1114644b601296d860dd643ff86473071b,"Studies of teachers’ use of mathematics curriculum materials are particularly timely given the current availability of reform-inspired curriculum materials and the increasingly widespread practice of mandating the use of a single curriculum to regulate mathematics teaching. A review of the research on mathematics curriculum use over the last 25 years reveals significant variation in findings and in theoretical foundations. The aim of this review is to examine the ways that central constructs of this body of research—such as curriculum use, teaching, and curriculum materials—are conceptualized and to consider the impact of various conceptualizations on knowledge in the field. Drawing on the literature, the author offers a framework for characterizing and studying teachers’ interactions with curriculum materials.",2005,119,999,143,2,9,21,37,52,49,56,50,64,78
feeef8d91cec3a9ffe5cf135a36a7f8596426ae1,"Amid ongoing public speculation about the reasons for sex differences in careers in science and mathematics, we present a consensus statement that is based on the best available scientific evidence. Sex differences in science and math achievement and ability are smaller for the mid-range of the abilities distribution than they are for those with the highest levels of achievement and ability. Males are more variable on most measures of quantitative and visuospatial ability, which necessarily results in more males at both high- and low-ability extremes; the reasons why males are often more variable remain elusive. Successful careers in math and science require many types of cognitive abilities. Females tend to excel in verbal abilities, with large differences between females and males found when assessments include writing samples. High-level achievement in science and math requires the ability to communicate effectively and comprehend abstract ideas, so the female advantage in writing should be helpful in all academic domains. Males outperform females on most measures of visuospatial abilities, which have been implicated as contributing to sex differences on standardized exams in mathematics and science. An evolutionary account of sex differences in mathematics and science supports the conclusion that, although sex differences in math and science performance have not directly evolved, they could be indirectly related to differences in interests and specific brain and cognitive systems. We review the brain basis for sex differences in science and mathematics, describe consistent effects, and identify numerous possible correlates. Experience alters brain structures and functioning, so causal statements about brain differences and success in math and science are circular. A wide range of sociocultural forces contribute to sex differences in mathematics and science achievement and ability—including the effects of family, neighborhood, peer, and school influences; training and experience; and cultural practices. We conclude that early experience, biological factors, educational policy, and cultural context affect the number of women and men who pursue advanced study in science and math and that these effects add and interact in complex ways. There are no single or simple answers to the complex questions about sex differences in science and mathematics.",2007,486,906,89,4,19,34,48,46,75,75,61,68,69
62bcc660cbd54558d3fcd07bade3bb764a1a146c,"This study examined the effects of a computer game on students' mathematics achievement and motivation, and the role of prior mathematics knowledge, computer skill, and English language skill on their achievement and motivation as they played the game. A total of 193 students and 10 teachers participated in this study. The teachers were randomly assigned to experimental and control groups. A mixed method of quantitative and interviews were used with Multivariate Analysis of Co-Variance to analyze the data. The results indicated significant improvement of the achievement of the experimental versus control group. No significant improvement was found in the motivation of the groups. Students who played the games in their classrooms and school labs reported greater motivation compared to the ones who played the games only in the school labs. Prior knowledge, computer and English language skill did not play significant roles in achievement and motivation of the experimental group.",2010,65,509,22,4,18,29,45,44,57,67,52,69,57
8d07144332f130bcfc5a5d30716b84a7afecbf9f,"Impairments in executive function have been documented in school-age children with mathematical learning difficulties. However, the utility and specificity of preschool executive function abilities in predicting later mathematical achievement are poorly understood. This study examined linkages between children's developing executive function abilities at age 4 and children's subsequent achievement in mathematics at age 6, 1 year after school entry. The study sample consisted of a regionally representative cohort of 104 children followed prospectively from ages 2 to 6 years. At age 4, children completed a battery of executive function tasks that assessed planning, set shifting, and inhibitory control. Teachers completed the preschool version of the Behavior Rating Inventory of Executive Function. Clinical and classroom measures of children's mathematical achievement were collected at age 6. Results showed that children's performance on set shifting, inhibitory control, and general executive behavior measures during the preschool period accounted for substantial variability in children's early mathematical achievement at school. These associations persisted even after individual differences in general cognitive ability and reading achievement were taken into account. Findings suggest that early measures of executive function may be useful in identifying children who may experience difficulties learning mathematical skills and concepts. They also suggest that the scaffolding of these executive skills could potentially be a useful additional component in early mathematics education.",2010,83,506,20,1,9,33,35,40,46,52,58,55,92
d4d7370670ffa790900ff05f96c208c9eda7d58b,"Graph theory models the Internet mathematically, and a number of plausible mathematically intersecting network models for the Internet have been developed and studied. Simultaneously, Internet researchers have developed methodology to use real data to validate, or invalidate, proposed Internet models. The authors look at these parallel developments, particularly as they apply to scale-free network models of the preferential attachment type.",2009,73,228,11,8,19,28,28,24,18,26,16,16,9
af30825f0c8adf31cf82028c8b50889b716ac362,"The work is giving estimations of the discrepancy between solutions of the initial and the homogenized problems for a one{dimensional second order elliptic operators with random coeecients satisfying strong or uniform mixing conditions. We obtain several sharp estimates in terms of the corresponding mixing coeecient. Abstract. In the theory of homogenisation it is of particular interest to determine the classes of problems which are stable on taking the homogenisation limits. A notable situation where the limit enlarges the class of original problems is known as memory (nonlocal) eeects. A number of results in that direction has been obtained for linear problems. Tartar (1990) innitiated the study of the eeective equation corresponding to nonlinear equation: @ t u n + a n u 2 n = f: Signiicant progress has been hampered by the complexity of required computations needed in order to obtain the terms in power{series expansion. We propose a method which overcomes that diiculty by introducing graphs representing the domain of integration of the integrals in each term. The graphs are relatively simple, it is easy to calculate with them and they give us a clear image of the form of each term. The method allows us to discuss the form of the eeective equation and the convergence of power{series expansions. The feasibility of our method for other types of nonlinearities will be discussed as well.",2010,40,569,7,58,54,70,82,115,47,12,7,10,6
e38ac5b98197284537fca03d8592adaae48841d4,"To understand the difficulties that many students have with comprehension of mathematics, we must determine the cognitive functioning underlying the diversity of mathematical processes. What are the cognitive systems that are required to give access to mathematical objects? Are these systems common to all processes of knowledge or, on the contrary, some of them are specific to mathematical activity? Starting from the paramount importance of semiotic representation for any mathematical activity, we put forward a classification of the various registers of semiotic representations that are mobilized in mathematical processes. Thus, we can reveal two types of transformation of semiotic representations: treatment and conversion. These two types correspond to quite different cognitive processes. They are two separate sources of incomprehension in the learning of mathematics. If treatment is the more important from a mathematical point of view, conversion is basically the deciding factor for learning. Supporting empirical data, at any level of curriculum and for any area of mathematics, can be widely and methodologically gathered: some empirical evidence is presented in this paper.",2006,28,901,111,10,12,20,25,59,41,61,55,62,91
786364fdd5a792fec5c5aaf23b87acbc4b57818b,"Abstract This study examines changes in teachers’ thinking as they participated in a video club designed to help them learn to notice and interpret students’ mathematical thinking. First, we investigate changes in teachers’ talk about classroom video segments before and after participation in the video club. Second, we identify three paths along which teachers learned to notice students’ mathematical thinking in this context: Direct, Cyclical, and Incremental. Finally, we explore ways the video club context influenced teacher learning. Understanding different forms of teacher learning provides insight for research on teacher cognition and may inform the design of video-based professional development.",2008,96,735,68,7,12,19,36,34,38,64,82,69,79
fe88603a338c69f37931facd17f22d6c4b5d5fe1,"Return by mail or fax to: SIAM Connie Young, Conference Director 3600 Market Street – 6 Floor Philadelphia, PA 19104-2688 Fax: 215-386-7999 Personal Information Name: _______________________________________________________________ Affiliation: _______________________________________________________________ Conference Name: _______________________________________________________________ Conference Location: _______________________________________________________________",2010,0,457,15,29,46,51,47,51,34,34,25,16,21
e7a5ff509962afa8850e1e682ebc224018366054,"Although it is often assumed that abilities that reflect basic numerical understanding, such as numerical comparison, are related to children's mathematical abilities, this relationship has not been tested rigorously. In addition, the extent to which symbolic and nonsymbolic number processing play differential roles in this relationship is not yet understood. To address these questions, we collected mathematics achievement measures from 6- to 8-year-olds as well as reaction times from a numerical comparison task. Using the reaction times, we calculated the size of the numerical distance effect exhibited by each child. In a correlational analysis, we found that the individual differences in the distance effect were related to mathematics achievement but not to reading achievement. This relationship was found to be specific to symbolic numerical comparison. Implications for the role of basic numerical competency and the role of accessing numerical magnitude information from Arabic numerals for the development of mathematical skills and their impairment are discussed.",2009,42,588,57,20,21,40,52,53,63,70,75,63,43
cd3a45bdd2c0ebdcfe4f2353da16c8c11ae5cb7f,"Boston College is an equal opportunity, affi rmative action employer.",2004,0,1142,63,2,15,33,42,62,78,86,89,152,109
0cd7e5ea0d7d91be0c9ce76406a1b57f8b57a3f2,"Relational mathematics is to operations research and informatics what numerical mathematics is to engineering: it is intended to help modelling, reasoning, and computing. Its applications are therefore diverse, ranging from psychology, linguistics, decision aid, and ranking to machine learning and spatial reasoning. Although many developments have been made in recent years, they have rarely been shared amongst this broad community of researchers. This first comprehensive overview begins with an easy introduction to the topic, assuming a minimum of prerequisites; but it is nevertheless theoretically sound and up to date. It is suitable for applied scientists, explaining all the necessary mathematics from scratch using a multitude of visualised examples, via matrices and graphs. It ends with tangible results on the research level. The author illustrates the theory and demonstrates practical tasks in operations research, social sciences and the humanities.",2010,0,116,14,0,7,11,9,23,21,10,13,7,4
0a4cf8c0ecf60c39234d48d9d99e03c804e067db,"We're performing all possible to bring our users the most effective books like Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics Download PDF free of charge download. Both you are looking for the book in PDF or EPUB our reference brings Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematicsto you in every possible format. You can obtain the Kindle app and then from Amazon Kindle store you are able to acquire Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics. Ebook Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics and a great many other books can be plumped for divided in to the class develop our website has therefore many categories it has a primarily old collection if you are enthusiastic about the old collection then you can certainly definitely go for it. The very best internet site to obtain Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics and all types of ebooks. They have around 2.5 million books. The same PDF version of any record is available from your personal computer or cellular devices that have a web connection to get Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics Download PDF for free. All the data on this amazing site is published in excellent trust and for normal data function only. Therefore you can easily obtain Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics. There's also some books however beneath the copyright which are offered for free on our site by specific arrangement with the author, like Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics. From this website, you are able to download Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics for free and even contribute or correct. This website is one of many sites for getting free Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics Download PDF. If you're having problem downloading Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics guide or if the hyperlinks aren't functioning, please create to email. We will change it, or send it for your requirements by email. Our digital library preserves in substance nations, letting you get the most less latency age to obtain any of our books subsequent that one. Just said, the Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics Download PDF is generally compatible afterward any units to read. As acknowledged, adventure as without problem as knowledge very almost session, entertainment, as skillfully as a package could be gotten by just looking at a guide Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics Download PDF next it is maybe not directly done, you might consent a lot more very nearly that life, on the buy of the world.",2010,201,322,32,10,16,6,10,11,23,14,19,27,36
1f80d103e387aeaa3513078745c41027b0f0f2a2,"Reprinted with permission from the Fall 2005 issue of American Educator, the quarterly journal of the American Federation of Teachers, AFL-CIO.",2005,17,900,78,3,9,28,37,43,65,50,68,89,91
2c5895c47012b9c42fad64e103f0a80fdacfd635,"This study examines the magnitude, destinations, and determinants of mathematics and science teacher turnover. The data are from the nationally representative Schools and Staffing Survey and the Teacher Follow-Up Survey. Over the past two decades, rates of mathematics and science teacher turnover have increased but, contrary to conventional wisdom, have not been consistently different than those of other teachers. Also, contrary to conventional wisdom, mathematics and science teachers were also no more likely than other teachers to take noneducation jobs, such as in technological fields or to be working for private business or industry. The data also show there are large school-to-school differences in mathematics and science turnover; high-poverty, high-minority, and urban public schools have among the highest rates. In the case of cross-school migration, the data show there is an annual asymmetric reshuffling of a significant portion of the mathematics and science teaching force from poor to not-poor schools, from high-minority to low-minority schools, and from urban to suburban schools. A number of key organizational characteristics and conditions of schools accounted for these school differences. The strongest factor for mathematics teachers was the degree of individual classroom autonomy held by teachers. Net of other factors such as salaries, schools with less classroom autonomy lose math teachers at a far higher rate than other teachers. In contrast, for science teachers salary was the strongest factor, while classroom autonomy was not strongly related to their turnover.",2010,144,278,31,1,4,12,12,24,22,28,32,43,33
69e23a9a149d7550b1afc324f326b264992693ce,"This study investigated adolescents’ developmental trajectories of mathematics interest and explored related effects of gender, family, and school context.Latent growth curvemodelingwas usedtoanalyzelongitudinaldataofN 53,193students(51%female)fromgrades5to9fromall3 ability tracks of the German state school system. Annual assessments involved student questionnaires on interest in mathematics, perceptions of classroom characteristics (classroom values for mathematics, mathematics teacher enthusiasm), as well as parent questionnaires regarding family values for mathematics. Results indicated a downward trend of students’ mathematics interest that plateaued in later years, with high variability in mean levels, but little variability in the shape of the growth trajectories. Boys reported higher mathematics interest than girls, but similar downward growth trajectories. Students from the lowest ability track showed more favorable interest trajectories than students from the middle and highest tracks. Family values andclassroomcharacteristicswerepositivelyrelatedtowithin-personlevelsofinterestovertime and to average individual levels of interest, but not to growth parameters. Theoretical and practical implications are discussed.",2010,116,313,16,4,5,15,15,17,31,31,33,54,36
a16f7f1fe98951487b7b83097b47f43f9e83ac1c,"Early childhood mathematics is vitally important for young children's present and future educational success. Research demonstrates that virtually all young children have the capability to learn and become competent in mathematics. Furthermore, young children enjoy their early informal experiences with mathematics. Unfortunately, many children's potential in mathematics is not fully realized, especially those children who are economically disadvantaged. This is due, in part, to a lack of opportunities to learn mathematics in early childhood settings or through everyday experiences in the home and in their communities. Improvements in early childhood mathematics education can provide young children with the foundation for school success. Relying on a comprehensive review of the research, Mathematics Learning in Early Childhood lays out the critical areas that should be the focus of young children's early mathematics education, explores the extent to which they are currently being incorporated in early childhood settings, and identifies the changes needed to improve the quality of mathematics experiences for young children. This book serves as a call to action to improve the state of early childhood mathematics. It will be especially useful for policy makers and practitioners-those who work directly with children and their families in shaping the policies that affect the education of young children.",2009,0,439,33,4,10,17,26,46,38,56,52,34,53
e2ce8e9f362fb1caf22cf5b7ad038dc9753c1190,"In this article we discuss efforts to design and empirically test measures of teachers’ content knowledge for teaching elementary mathematics. We begin by reviewing the literature on teacher knowledge, noting how scholars have organized such knowledge. Next we describe survey items we wrote to represent knowledge for teaching mathematics and results from factor analysis and scaling work with these items. We found that teachers’ knowledge for teaching elementary mathematics was multidimensional and included knowledge of various mathematical topics (e.g., number and operations, algebra) and domains (e.g., knowledge of content, knowledge of students and content). The constructs indicated by factor analysis formed psychometrically acceptable scales.",2004,37,899,70,2,5,12,30,56,37,52,48,71,94
9d0c4389436d3ab8ed329dba8c58e8ac6737fd3b,"Many models for the spread of infectious diseases in populations have been analyzed mathematically and applied to specific diseases. Threshold theorems involving the basic reproduction number $R_{0}$, the contact number $\sigma$, and the replacement number $R$ are reviewed for the classic SIR epidemic and endemic models. Similar results with new expressions for $R_{0}$ are obtained for MSEIR and SEIR endemic models with either continuous age or age groups. Values of $R_{0}$ and $\sigma$ are estimated for various diseases including measles in Niger and pertussis in the United States. Previous models with age structure, heterogeneity, and spatial structure are surveyed.",2000,226,4881,259,0,10,20,43,55,80,121,124,129,154
d3d720baa7080594c2fad06bb2ac90cc46666735,"The goals of this chapter are (1) to outline and substantiate a broad conceptualization of what it means to think mathematically, (2) to summarize the literature relevant to understanding mathematical thinking and problem solving, and (3) to point to new directions in research, development, and assessment consonant with an emerging understanding of mathematical thinking and the goals for instruction outlined here. The use of the phrase “learning to think mathematically” in this chapter’s title is deliberately broad. Although the original charter for this chapter was to review the literature on problem solving and metacognition, the literature itself is somewhat ill defined and poorly grounded. As the literature summary will make clear, problem solving has been used with multiple meanings that range from “working rote exercises” to “doing mathematics as a professional”; metacognition has multiple and almost disjoint meanings (from knowledge about one’s thought processes to self-regulation during problem solving) that make it difficult to use as a concept. This chapter outlines the various meanings that have been ascribed to these terms and discusses their role in mathematical thinking. The discussion will not have the character of a classic literature review, which is typically encyclopedic in its references and telegraphic in its discussions of individual papers or results. It will, instead, be selective and illustrative, with main points illustrated by extended discussions of pertinent examples. Problem solving has, as predicted in the 1980 Yearbook of the National Council of Teachers of Mathematics (Krulik, 1980, p. xiv), been the theme of the 1980s. The decade began with NCTM’s widely heralded statement, in its Agenda for Action, that “problem solving must be the focus of school mathematics” (NCTM, 1980, p. 1). It concluded with the publication of Everybody Counts (National Research Council, 1989) and the Curriculum and Evaluation Standards for School Mathematics (NCTM, 1989), both of which emphasize problem solving. One might infer, then, that there is general acceptance of the idea that the primary goal of mathematics instruction should be to have students become competent problem solvers. Yet, given the multiple interpretations of the term, the goal is hardly clear. Equally unclear is the role that problem solving, once adequately characterized, should play in the larger context of school mathematics. What are the goals for mathematics instruction, and how does problem solving fit within those goals? Such questions are complex. Goals for mathematics instruction depend on one’s conceptualization of what mathematics is, and what it means to understand mathematics. Such conceptualizations vary widely. At one end of the spectrum, mathematical knowledge is seen as a body of facts and procedures dealing with quantities, magnitudes, and forms, and the relationships among them; knowing mathematics is seen as having mastered these facts and procedures. At the other end of the spectrum, mathematics is conceptualized as the “science of patterns,” an (almost) empirical discipline closely akin to the sciences in its emphasis on pattern-seeking on the basis of empirical evidence. The author’s view is that the former perspective trivializes mathematics; that a curriculum based on mastering a corpus of mathematical facts and procedures is severely impoverished—in much the same way that an English curriculum would be considered impoverished if it focused largely, if not exclusively, on issues of grammar. The author characterizes the mathematical enterprise as follows:",2009,239,2893,267,123,144,163,155,189,196,226,163,163,178
f2e713dd0a1ee11892a90e0fb448dd5981e63550,,2000,7,7984,20,159,178,250,232,270,267,306,357,411,430
d82b5eb828d803e2f3fe041db20af8536f0fe99e,Author's Preface to the Anniversary Edition Series Editor's Introduction to the Anniversary Edition A Note about the Anniversary Edition Foreword Acknowledgments Introduction 1. Subtraction With Regrouping: Approaches To Teaching A Topic 2. Multidigit Number Multiplication: Dealing With Students' Mistakes 3. Generating Representations: Division By Fractions 4. Exploring New Knowledge: The Relationship Between Perimeter And Area 5. Teachers' Subject Matter Knowledge: Profound Understanding Of Fundamental Mathematics 6. Profound Understanding Of Fundamental Mathematics: When And How Is It Attained 7. Conclusion Appendix References New to the Anniversary Edition: Journal Article #1 New to the Anniversary Edition: Journal Article #2 Author Index Subject Index,2010,0,1684,360,141,143,135,137,149,142,142,129,128,88
7f3b042c8337fe9195ed6ca0cb017b76bbf1ff7c,"868 NOTICES OF THE AMS VOLUME 47, NUMBER 8 In April 2000 the National Council of Teachers of Mathematics (NCTM) released Principles and Standards for School Mathematics—the culmination of a multifaceted, three-year effort to update NCTM’s earlier standards documents and to set forth goals and recommendations for mathematics education in the prekindergarten-through-grade-twelve years. As the chair of the Writing Group, I had the privilege to interact with all aspects of the development and review of this document and with the committed groups of people, including the members of the Writing Group, who contributed immeasurably to this process. This article provides some background about NCTM and the standards, the process of development, efforts to gather input and feedback, and ways in which feedback from the mathematics community influenced the document. The article concludes with a section that provides some suggestions for mathematicians who are interested in using Principles and Standards.",2000,17,2165,296,10,25,47,49,66,78,79,118,115,118
a9386eb6808b41238381c708f2642bcb7dc34b29,"This book is about mathematical ideas, about what mathematics means-and why. Abstract ideas, for the most part, arise via conceptual metaphor-metaphorical ideas projecting from the way we function in the everyday physical world. Where Mathematics Comes From argues that conceptual metaphor plays a central role in mathematical ideas within the cognitive unconscious-from arithmetic and algebra to sets and logic to infinity in all of its forms.",2002,40,1920,107,19,40,48,55,72,74,102,91,120,102
4526716b3789971eaaa81d507abb657a29009957,"A gender gap in mathematics achievement persists in some nations but not in others. In light of the underrepresentation of women in careers in science, technology, mathematics, and engineering, increasing research attention is being devoted to understanding gender differences in mathematics achievement, attitudes, and affect. The gender stratification hypothesis maintains that such gender differences are closely related to cultural variations in opportunity structures for girls and women. We meta-analyzed 2 major international data sets, the 2003 Trends in International Mathematics and Science Study and the Programme for International Student Assessment, representing 493,495 students 14-16 years of age, to estimate the magnitude of gender differences in mathematics achievement, attitudes, and affect across 69 nations throughout the world. Consistent with the gender similarities hypothesis, all of the mean effect sizes in mathematics achievement were very small (d < 0.15); however, national effect sizes showed considerable variability (ds = -0.42 to 0.40). Despite gender similarities in achievement, boys reported more positive math attitudes and affect (ds = 0.10 to 0.33); national effect sizes ranged from d = -0.61 to 0.89. In contrast to those of previous tests of the gender stratification hypothesis, our results point to specific domains of gender equity responsible for gender gaps in math. Gender equity in school enrollment, women's share of research jobs, and women's parliamentary representation were the most powerful predictors of cross-national variability in gender gaps in math. Results are situated within the context of existing research demonstrating apparently paradoxical effects of societal gender equity and highlight the significance of increasing girls' and women's agency cross-nationally.",2010,126,1105,71,16,49,80,93,98,97,99,98,126,108
2ed2cd231aad7ea8a2b69a60d6df7539d6ee107f,"Vol. 72: The Syntax and Semantics of lnfimtary Languages. Edited by J. Barwtse. IV, 268 pages. 1968. DM 18,I $ 5.00 Vol. 73: P. E. Conner, Lectures on the Action of a Finite Group. IV, 123 pages. 1968. DM 10,1 $ 2.80 Vol. 74:A Frohlich, Formal Groups. IV, 140pages. 1968. DM12, -I $3.30 Vol. 75: G. Lumer, Algebras de fonctions et espaces de Hardy. VI, 80 pages. 1968. DM 8,I $ 2. 20 Vol. 76: R. G. Swan, Algebraic K-Theory. IV, 262 pages. 1968. DM18,I$ 5.00",2001,497,1653,59,73,89,93,103,106,99,152,152,126,57
7385b1bcd94ed3904c0e1429e209c80249de0d2a,"In this article, we use meta-analysis to analyze gender differences in recent studies of mathematics performance. First, we meta-analyzed data from 242 studies published between 1990 and 2007, representing the testing of 1,286,350 people. Overall, d = 0.05, indicating no gender difference, and variance ratio = 1.08, indicating nearly equal male and female variances. Second, we analyzed data from large data sets based on probability sampling of U.S. adolescents over the past 20 years: the National Longitudinal Surveys of Youth, the National Education Longitudinal Study of 1988, the Longitudinal Study of American Youth, and the National Assessment of Educational Progress. Effect sizes for the gender difference ranged between -0.15 and +0.22. Variance ratios ranged from 0.88 to 1.34. Taken together, these findings support the view that males and females perform similarly in mathematics.",2010,211,625,39,0,7,22,37,57,67,61,64,74,93
f008393f240508c1686a468b2c67371a7cdcb354,,2009,0,948,91,8,35,43,56,81,101,105,96,74,112
861a8ccc4002510aa1c844ea6f2c41fba69623f4,"Abstract Working memory refers to a mental workspace, involved in controlling, regulating, and actively maintaining relevant information to accomplish complex cognitive tasks (e.g. mathematical processing). Despite the potential relevance of a relation between working memory and math for understanding developmental and individual differences in mathematical skills, the nature of this relationship is not well-understood. This paper reviews four approaches that address the relation of working memory and math: 1) dual task studies establishing the role of working memory during on-line math performance; 2) individual difference studies examining working memory in children with math difficulties; 3) studies of working memory as a predictor of mathematical outcomes; and 4) longitudinal studies of working memory and math. The goal of this review is to evaluate current information on the nature of the relationship between working memory and math provided by these four approaches, and to present some of the outstanding questions for future research.",2010,165,756,23,7,17,40,52,64,69,91,88,85,83
813c3c045849f82cac2db2f26cee0ca306349f28,"Children's mathematical skills were considered in relation to executive functions. Using multiple measures-including the Wisconsin Card Sorting Task (WCST), dual-task performance, Stroop task, and counting span-it was found that mathematical ability was significantly correlated with all measures of executive functioning, with the exception of dual-task performance. Furthermore, regression analyses revealed that each executive function measure predicted unique variance in mathematics ability. These results are discussed in terms of a central executive with diverse functions (Shallice & Burgess, 1996) and with recent evidence from Miyake, et al. (2000) showing the unity and diversity among executive functions. It is proposed that the particular difficulties for children of lower mathematical ability are lack of inhibition and poor working memory, which result in problems with switching and evaluation of new strategies for dealing with a particular task. The practical and theoretical implications of these results are discussed, along with suggestions for task changes and longitudinal studies that would clarify theoretical and developmental issues related to executive functioning.",2001,79,1320,73,0,2,5,18,38,25,30,34,54,60
deac6a43706ea11bdd9fb07a73b54a08f0c114fb,"Teachers and teacher educators interested in synthesizing their current practice with new mathematics standards will welcome this highly useful volume. Presented are cases of mathematics instruction drawn from research of nearly 500 classroom lessons. Readers will gain insight about how to foster a challenging, cognitively rich, and exciting classroom climate that propels students toward a richer understanding of mathematics.",2009,0,714,82,39,42,46,57,63,50,74,59,57,52
f65040c3aa910788931c27c73006c5f3bb1e7e85,,2008,10,1101,87,44,48,62,72,80,103,88,77,98,55
34fb621cf73b7bad25d77ff1229467a34f736474,"Children's number competencies over 6 time points, from the beginning of kindergarten to the middle of 1st grade, were examined in relation to their mathematics achievement over 5 later time points, from the end of 1st grade to the end of 3rd grade. The relation between early number competence and mathematics achievement was strong and significant throughout the study period. A sequential process growth curve model showed that kindergarten number competence predicted rate of growth in mathematics achievement between 1st and 3rd grades as well as achievement level through 3rd grade. Further, rate of growth in early number competence predicted mathematics performance level in 3rd grade. Although low-income children performed more poorly than their middle-income counterparts in mathematics achievement and progressed at a slower rate, their performance and growth were mediated through relatively weak kindergarten number competence. Similarly, the better performance and faster growth of children who entered kindergarten at an older age were explained by kindergarten number competence. The findings show the importance of early number competence for setting children's learning trajectories in elementary school mathematics.",2009,70,768,38,3,16,21,32,54,72,66,77,73,94
69727a18c999db42c1e0062dd75870b4751ecc90,,2002,0,1397,4,56,59,58,63,81,92,111,128,120,121
c46e0a3586addefd8ffa8aef34afb534b8c1501e,"A model of the relations among cognitive precursors, early numeracy skill, and mathematical outcomes was tested for 182 children from 4.5 to 7.5 years of age. The model integrates research from neuroimaging, clinical populations, and normal development in children and adults. It includes 3 precursor pathways: quantitative, linguistic, and spatial attention. These pathways (a) contributed independently to early numeracy skills during preschool and kindergarten and (b) related differentially to performance on a variety of mathematical outcomes 2 years later. The success of the model in accounting for performance highlights the need to understand the fundamental underlying skills that contribute to diverse forms of mathematical competence.",2010,67,510,47,1,10,10,37,46,49,59,71,66,62
c62e9c1114644b601296d860dd643ff86473071b,"Studies of teachers’ use of mathematics curriculum materials are particularly timely given the current availability of reform-inspired curriculum materials and the increasingly widespread practice of mandating the use of a single curriculum to regulate mathematics teaching. A review of the research on mathematics curriculum use over the last 25 years reveals significant variation in findings and in theoretical foundations. The aim of this review is to examine the ways that central constructs of this body of research—such as curriculum use, teaching, and curriculum materials—are conceptualized and to consider the impact of various conceptualizations on knowledge in the field. Drawing on the literature, the author offers a framework for characterizing and studying teachers’ interactions with curriculum materials.",2005,119,999,143,2,9,21,37,52,49,56,50,64,78
06bdbd4f011e9497fddfc47654116feab28b63bd,"Between 5% and 8% of school-age children have some form of memory or cognitive deficit that interferes with their ability to learn concepts or procedures in one or more mathematical domains. A review of the arithmetical competencies of these children is provided, along with discussion of underlying memory and cognitive deficits and potential neural correlates. The deficits are discussed in terms of three subtypes of mathematics learning disability and in terms of a more general framework for linking research in mathematical cognition to research in learning disabilities.",2004,97,1068,158,5,27,28,49,42,51,68,57,83,95
feeef8d91cec3a9ffe5cf135a36a7f8596426ae1,"Amid ongoing public speculation about the reasons for sex differences in careers in science and mathematics, we present a consensus statement that is based on the best available scientific evidence. Sex differences in science and math achievement and ability are smaller for the mid-range of the abilities distribution than they are for those with the highest levels of achievement and ability. Males are more variable on most measures of quantitative and visuospatial ability, which necessarily results in more males at both high- and low-ability extremes; the reasons why males are often more variable remain elusive. Successful careers in math and science require many types of cognitive abilities. Females tend to excel in verbal abilities, with large differences between females and males found when assessments include writing samples. High-level achievement in science and math requires the ability to communicate effectively and comprehend abstract ideas, so the female advantage in writing should be helpful in all academic domains. Males outperform females on most measures of visuospatial abilities, which have been implicated as contributing to sex differences on standardized exams in mathematics and science. An evolutionary account of sex differences in mathematics and science supports the conclusion that, although sex differences in math and science performance have not directly evolved, they could be indirectly related to differences in interests and specific brain and cognitive systems. We review the brain basis for sex differences in science and mathematics, describe consistent effects, and identify numerous possible correlates. Experience alters brain structures and functioning, so causal statements about brain differences and success in math and science are circular. A wide range of sociocultural forces contribute to sex differences in mathematics and science achievement and ability—including the effects of family, neighborhood, peer, and school influences; training and experience; and cultural practices. We conclude that early experience, biological factors, educational policy, and cultural context affect the number of women and men who pursue advanced study in science and math and that these effects add and interact in complex ways. There are no single or simple answers to the complex questions about sex differences in science and mathematics.",2007,486,906,89,4,19,34,48,46,75,75,61,68,69
62bcc660cbd54558d3fcd07bade3bb764a1a146c,"This study examined the effects of a computer game on students' mathematics achievement and motivation, and the role of prior mathematics knowledge, computer skill, and English language skill on their achievement and motivation as they played the game. A total of 193 students and 10 teachers participated in this study. The teachers were randomly assigned to experimental and control groups. A mixed method of quantitative and interviews were used with Multivariate Analysis of Co-Variance to analyze the data. The results indicated significant improvement of the achievement of the experimental versus control group. No significant improvement was found in the motivation of the groups. Students who played the games in their classrooms and school labs reported greater motivation compared to the ones who played the games only in the school labs. Prior knowledge, computer and English language skill did not play significant roles in achievement and motivation of the experimental group.",2010,65,509,22,4,18,29,45,44,57,67,52,69,57
8d07144332f130bcfc5a5d30716b84a7afecbf9f,"Impairments in executive function have been documented in school-age children with mathematical learning difficulties. However, the utility and specificity of preschool executive function abilities in predicting later mathematical achievement are poorly understood. This study examined linkages between children's developing executive function abilities at age 4 and children's subsequent achievement in mathematics at age 6, 1 year after school entry. The study sample consisted of a regionally representative cohort of 104 children followed prospectively from ages 2 to 6 years. At age 4, children completed a battery of executive function tasks that assessed planning, set shifting, and inhibitory control. Teachers completed the preschool version of the Behavior Rating Inventory of Executive Function. Clinical and classroom measures of children's mathematical achievement were collected at age 6. Results showed that children's performance on set shifting, inhibitory control, and general executive behavior measures during the preschool period accounted for substantial variability in children's early mathematical achievement at school. These associations persisted even after individual differences in general cognitive ability and reading achievement were taken into account. Findings suggest that early measures of executive function may be useful in identifying children who may experience difficulties learning mathematical skills and concepts. They also suggest that the scaffolding of these executive skills could potentially be a useful additional component in early mathematics education.",2010,83,506,20,1,9,33,35,40,46,52,58,55,92
d4d7370670ffa790900ff05f96c208c9eda7d58b,"Graph theory models the Internet mathematically, and a number of plausible mathematically intersecting network models for the Internet have been developed and studied. Simultaneously, Internet researchers have developed methodology to use real data to validate, or invalidate, proposed Internet models. The authors look at these parallel developments, particularly as they apply to scale-free network models of the preferential attachment type.",2009,73,228,11,8,19,28,28,24,18,26,16,16,9
af30825f0c8adf31cf82028c8b50889b716ac362,"The work is giving estimations of the discrepancy between solutions of the initial and the homogenized problems for a one{dimensional second order elliptic operators with random coeecients satisfying strong or uniform mixing conditions. We obtain several sharp estimates in terms of the corresponding mixing coeecient. Abstract. In the theory of homogenisation it is of particular interest to determine the classes of problems which are stable on taking the homogenisation limits. A notable situation where the limit enlarges the class of original problems is known as memory (nonlocal) eeects. A number of results in that direction has been obtained for linear problems. Tartar (1990) innitiated the study of the eeective equation corresponding to nonlinear equation: @ t u n + a n u 2 n = f: Signiicant progress has been hampered by the complexity of required computations needed in order to obtain the terms in power{series expansion. We propose a method which overcomes that diiculty by introducing graphs representing the domain of integration of the integrals in each term. The graphs are relatively simple, it is easy to calculate with them and they give us a clear image of the form of each term. The method allows us to discuss the form of the eeective equation and the convergence of power{series expansions. The feasibility of our method for other types of nonlinearities will be discussed as well.",2010,40,569,7,58,54,70,82,115,47,12,7,10,6
e38ac5b98197284537fca03d8592adaae48841d4,"To understand the difficulties that many students have with comprehension of mathematics, we must determine the cognitive functioning underlying the diversity of mathematical processes. What are the cognitive systems that are required to give access to mathematical objects? Are these systems common to all processes of knowledge or, on the contrary, some of them are specific to mathematical activity? Starting from the paramount importance of semiotic representation for any mathematical activity, we put forward a classification of the various registers of semiotic representations that are mobilized in mathematical processes. Thus, we can reveal two types of transformation of semiotic representations: treatment and conversion. These two types correspond to quite different cognitive processes. They are two separate sources of incomprehension in the learning of mathematics. If treatment is the more important from a mathematical point of view, conversion is basically the deciding factor for learning. Supporting empirical data, at any level of curriculum and for any area of mathematics, can be widely and methodologically gathered: some empirical evidence is presented in this paper.",2006,28,901,111,10,12,20,25,59,41,61,55,62,91
786364fdd5a792fec5c5aaf23b87acbc4b57818b,"Abstract This study examines changes in teachers’ thinking as they participated in a video club designed to help them learn to notice and interpret students’ mathematical thinking. First, we investigate changes in teachers’ talk about classroom video segments before and after participation in the video club. Second, we identify three paths along which teachers learned to notice students’ mathematical thinking in this context: Direct, Cyclical, and Incremental. Finally, we explore ways the video club context influenced teacher learning. Understanding different forms of teacher learning provides insight for research on teacher cognition and may inform the design of video-based professional development.",2008,96,735,68,7,12,19,36,34,38,64,82,69,79
fe88603a338c69f37931facd17f22d6c4b5d5fe1,"Return by mail or fax to: SIAM Connie Young, Conference Director 3600 Market Street – 6 Floor Philadelphia, PA 19104-2688 Fax: 215-386-7999 Personal Information Name: _______________________________________________________________ Affiliation: _______________________________________________________________ Conference Name: _______________________________________________________________ Conference Location: _______________________________________________________________",2010,0,457,15,29,46,51,47,51,34,34,25,16,21
e7a5ff509962afa8850e1e682ebc224018366054,"Although it is often assumed that abilities that reflect basic numerical understanding, such as numerical comparison, are related to children's mathematical abilities, this relationship has not been tested rigorously. In addition, the extent to which symbolic and nonsymbolic number processing play differential roles in this relationship is not yet understood. To address these questions, we collected mathematics achievement measures from 6- to 8-year-olds as well as reaction times from a numerical comparison task. Using the reaction times, we calculated the size of the numerical distance effect exhibited by each child. In a correlational analysis, we found that the individual differences in the distance effect were related to mathematics achievement but not to reading achievement. This relationship was found to be specific to symbolic numerical comparison. Implications for the role of basic numerical competency and the role of accessing numerical magnitude information from Arabic numerals for the development of mathematical skills and their impairment are discussed.",2009,42,588,57,20,21,40,52,53,63,70,75,63,43
cd3a45bdd2c0ebdcfe4f2353da16c8c11ae5cb7f,"Boston College is an equal opportunity, affi rmative action employer.",2004,0,1142,63,2,15,33,42,62,78,86,89,152,109
0cd7e5ea0d7d91be0c9ce76406a1b57f8b57a3f2,"Relational mathematics is to operations research and informatics what numerical mathematics is to engineering: it is intended to help modelling, reasoning, and computing. Its applications are therefore diverse, ranging from psychology, linguistics, decision aid, and ranking to machine learning and spatial reasoning. Although many developments have been made in recent years, they have rarely been shared amongst this broad community of researchers. This first comprehensive overview begins with an easy introduction to the topic, assuming a minimum of prerequisites; but it is nevertheless theoretically sound and up to date. It is suitable for applied scientists, explaining all the necessary mathematics from scratch using a multitude of visualised examples, via matrices and graphs. It ends with tangible results on the research level. The author illustrates the theory and demonstrates practical tasks in operations research, social sciences and the humanities.",2010,0,116,14,0,7,11,9,23,21,10,13,7,4
0a4cf8c0ecf60c39234d48d9d99e03c804e067db,"We're performing all possible to bring our users the most effective books like Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics Download PDF free of charge download. Both you are looking for the book in PDF or EPUB our reference brings Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematicsto you in every possible format. You can obtain the Kindle app and then from Amazon Kindle store you are able to acquire Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics. Ebook Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics and a great many other books can be plumped for divided in to the class develop our website has therefore many categories it has a primarily old collection if you are enthusiastic about the old collection then you can certainly definitely go for it. The very best internet site to obtain Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics and all types of ebooks. They have around 2.5 million books. The same PDF version of any record is available from your personal computer or cellular devices that have a web connection to get Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics Download PDF for free. All the data on this amazing site is published in excellent trust and for normal data function only. Therefore you can easily obtain Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics. There's also some books however beneath the copyright which are offered for free on our site by specific arrangement with the author, like Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics. From this website, you are able to download Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics for free and even contribute or correct. This website is one of many sites for getting free Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics Download PDF. If you're having problem downloading Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics guide or if the hyperlinks aren't functioning, please create to email. We will change it, or send it for your requirements by email. Our digital library preserves in substance nations, letting you get the most less latency age to obtain any of our books subsequent that one. Just said, the Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics Download PDF is generally compatible afterward any units to read. As acknowledged, adventure as without problem as knowledge very almost session, entertainment, as skillfully as a package could be gotten by just looking at a guide Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics Download PDF next it is maybe not directly done, you might consent a lot more very nearly that life, on the buy of the world.",2010,201,322,32,10,16,6,10,11,23,14,19,27,36
1f80d103e387aeaa3513078745c41027b0f0f2a2,"Reprinted with permission from the Fall 2005 issue of American Educator, the quarterly journal of the American Federation of Teachers, AFL-CIO.",2005,17,900,78,3,9,28,37,43,65,50,68,89,91
2c5895c47012b9c42fad64e103f0a80fdacfd635,"This study examines the magnitude, destinations, and determinants of mathematics and science teacher turnover. The data are from the nationally representative Schools and Staffing Survey and the Teacher Follow-Up Survey. Over the past two decades, rates of mathematics and science teacher turnover have increased but, contrary to conventional wisdom, have not been consistently different than those of other teachers. Also, contrary to conventional wisdom, mathematics and science teachers were also no more likely than other teachers to take noneducation jobs, such as in technological fields or to be working for private business or industry. The data also show there are large school-to-school differences in mathematics and science turnover; high-poverty, high-minority, and urban public schools have among the highest rates. In the case of cross-school migration, the data show there is an annual asymmetric reshuffling of a significant portion of the mathematics and science teaching force from poor to not-poor schools, from high-minority to low-minority schools, and from urban to suburban schools. A number of key organizational characteristics and conditions of schools accounted for these school differences. The strongest factor for mathematics teachers was the degree of individual classroom autonomy held by teachers. Net of other factors such as salaries, schools with less classroom autonomy lose math teachers at a far higher rate than other teachers. In contrast, for science teachers salary was the strongest factor, while classroom autonomy was not strongly related to their turnover.",2010,144,278,31,1,4,12,12,24,22,28,32,43,33
69e23a9a149d7550b1afc324f326b264992693ce,"This study investigated adolescents’ developmental trajectories of mathematics interest and explored related effects of gender, family, and school context.Latent growth curvemodelingwas usedtoanalyzelongitudinaldataofN 53,193students(51%female)fromgrades5to9fromall3 ability tracks of the German state school system. Annual assessments involved student questionnaires on interest in mathematics, perceptions of classroom characteristics (classroom values for mathematics, mathematics teacher enthusiasm), as well as parent questionnaires regarding family values for mathematics. Results indicated a downward trend of students’ mathematics interest that plateaued in later years, with high variability in mean levels, but little variability in the shape of the growth trajectories. Boys reported higher mathematics interest than girls, but similar downward growth trajectories. Students from the lowest ability track showed more favorable interest trajectories than students from the middle and highest tracks. Family values andclassroomcharacteristicswerepositivelyrelatedtowithin-personlevelsofinterestovertime and to average individual levels of interest, but not to growth parameters. Theoretical and practical implications are discussed.",2010,116,313,16,4,5,15,15,17,31,31,33,54,36
a16f7f1fe98951487b7b83097b47f43f9e83ac1c,"Early childhood mathematics is vitally important for young children's present and future educational success. Research demonstrates that virtually all young children have the capability to learn and become competent in mathematics. Furthermore, young children enjoy their early informal experiences with mathematics. Unfortunately, many children's potential in mathematics is not fully realized, especially those children who are economically disadvantaged. This is due, in part, to a lack of opportunities to learn mathematics in early childhood settings or through everyday experiences in the home and in their communities. Improvements in early childhood mathematics education can provide young children with the foundation for school success. Relying on a comprehensive review of the research, Mathematics Learning in Early Childhood lays out the critical areas that should be the focus of young children's early mathematics education, explores the extent to which they are currently being incorporated in early childhood settings, and identifies the changes needed to improve the quality of mathematics experiences for young children. This book serves as a call to action to improve the state of early childhood mathematics. It will be especially useful for policy makers and practitioners-those who work directly with children and their families in shaping the policies that affect the education of young children.",2009,0,439,33,4,10,17,26,46,38,56,52,34,53
e2ce8e9f362fb1caf22cf5b7ad038dc9753c1190,"In this article we discuss efforts to design and empirically test measures of teachers’ content knowledge for teaching elementary mathematics. We begin by reviewing the literature on teacher knowledge, noting how scholars have organized such knowledge. Next we describe survey items we wrote to represent knowledge for teaching mathematics and results from factor analysis and scaling work with these items. We found that teachers’ knowledge for teaching elementary mathematics was multidimensional and included knowledge of various mathematical topics (e.g., number and operations, algebra) and domains (e.g., knowledge of content, knowledge of students and content). The constructs indicated by factor analysis formed psychometrically acceptable scales.",2004,37,899,70,2,5,12,30,56,37,52,48,71,94
99eaa4a03d94547bfb294460ce78ff9c753e0c2b,"Using contemporary data from the U.S. and other nations, we address 3 questions: Do gender differences in mathematics performance exist in the general population? Do gender differences exist among the mathematically talented? Do females exist who possess profound mathematical talent? In regard to the first question, contemporary data indicate that girls in the U.S. have reached parity with boys in mathematics performance, a pattern that is found in some other nations as well. Focusing on the second question, studies find more males than females scoring above the 95th or 99th percentile, but this gender gap has significantly narrowed over time in the U.S. and is not found among some ethnic groups and in some nations. Furthermore, data from several studies indicate that greater male variability with respect to mathematics is not ubiquitous. Rather, its presence correlates with several measures of gender inequality. Thus, it is largely an artifact of changeable sociocultural factors, not immutable, innate biological differences between the sexes. Responding to the third question, we document the existence of females who possess profound mathematical talent. Finally, we review mounting evidence that both the magnitude of mean math gender differences and the frequency of identification of gifted and profoundly gifted females significantly correlate with sociocultural factors, including measures of gender equality across nations.",2009,56,435,21,8,16,22,30,40,36,43,24,52,60
9d0c4389436d3ab8ed329dba8c58e8ac6737fd3b,"Many models for the spread of infectious diseases in populations have been analyzed mathematically and applied to specific diseases. Threshold theorems involving the basic reproduction number $R_{0}$, the contact number $\sigma$, and the replacement number $R$ are reviewed for the classic SIR epidemic and endemic models. Similar results with new expressions for $R_{0}$ are obtained for MSEIR and SEIR endemic models with either continuous age or age groups. Values of $R_{0}$ and $\sigma$ are estimated for various diseases including measles in Niger and pertussis in the United States. Previous models with age structure, heterogeneity, and spatial structure are surveyed.",2000,226,4881,259,0,10,20,43,55,80,121,124,129,154
d3d720baa7080594c2fad06bb2ac90cc46666735,"The goals of this chapter are (1) to outline and substantiate a broad conceptualization of what it means to think mathematically, (2) to summarize the literature relevant to understanding mathematical thinking and problem solving, and (3) to point to new directions in research, development, and assessment consonant with an emerging understanding of mathematical thinking and the goals for instruction outlined here. The use of the phrase “learning to think mathematically” in this chapter’s title is deliberately broad. Although the original charter for this chapter was to review the literature on problem solving and metacognition, the literature itself is somewhat ill defined and poorly grounded. As the literature summary will make clear, problem solving has been used with multiple meanings that range from “working rote exercises” to “doing mathematics as a professional”; metacognition has multiple and almost disjoint meanings (from knowledge about one’s thought processes to self-regulation during problem solving) that make it difficult to use as a concept. This chapter outlines the various meanings that have been ascribed to these terms and discusses their role in mathematical thinking. The discussion will not have the character of a classic literature review, which is typically encyclopedic in its references and telegraphic in its discussions of individual papers or results. It will, instead, be selective and illustrative, with main points illustrated by extended discussions of pertinent examples. Problem solving has, as predicted in the 1980 Yearbook of the National Council of Teachers of Mathematics (Krulik, 1980, p. xiv), been the theme of the 1980s. The decade began with NCTM’s widely heralded statement, in its Agenda for Action, that “problem solving must be the focus of school mathematics” (NCTM, 1980, p. 1). It concluded with the publication of Everybody Counts (National Research Council, 1989) and the Curriculum and Evaluation Standards for School Mathematics (NCTM, 1989), both of which emphasize problem solving. One might infer, then, that there is general acceptance of the idea that the primary goal of mathematics instruction should be to have students become competent problem solvers. Yet, given the multiple interpretations of the term, the goal is hardly clear. Equally unclear is the role that problem solving, once adequately characterized, should play in the larger context of school mathematics. What are the goals for mathematics instruction, and how does problem solving fit within those goals? Such questions are complex. Goals for mathematics instruction depend on one’s conceptualization of what mathematics is, and what it means to understand mathematics. Such conceptualizations vary widely. At one end of the spectrum, mathematical knowledge is seen as a body of facts and procedures dealing with quantities, magnitudes, and forms, and the relationships among them; knowing mathematics is seen as having mastered these facts and procedures. At the other end of the spectrum, mathematics is conceptualized as the “science of patterns,” an (almost) empirical discipline closely akin to the sciences in its emphasis on pattern-seeking on the basis of empirical evidence. The author’s view is that the former perspective trivializes mathematics; that a curriculum based on mastering a corpus of mathematical facts and procedures is severely impoverished—in much the same way that an English curriculum would be considered impoverished if it focused largely, if not exclusively, on issues of grammar. The author characterizes the mathematical enterprise as follows:",2009,239,2893,267,123,144,163,155,189,196,226,163,163,178
f2e713dd0a1ee11892a90e0fb448dd5981e63550,,2000,7,7984,20,159,178,250,232,270,267,306,357,411,430
d82b5eb828d803e2f3fe041db20af8536f0fe99e,Author's Preface to the Anniversary Edition Series Editor's Introduction to the Anniversary Edition A Note about the Anniversary Edition Foreword Acknowledgments Introduction 1. Subtraction With Regrouping: Approaches To Teaching A Topic 2. Multidigit Number Multiplication: Dealing With Students' Mistakes 3. Generating Representations: Division By Fractions 4. Exploring New Knowledge: The Relationship Between Perimeter And Area 5. Teachers' Subject Matter Knowledge: Profound Understanding Of Fundamental Mathematics 6. Profound Understanding Of Fundamental Mathematics: When And How Is It Attained 7. Conclusion Appendix References New to the Anniversary Edition: Journal Article #1 New to the Anniversary Edition: Journal Article #2 Author Index Subject Index,2010,0,1684,360,141,143,135,137,149,142,142,129,128,88
7f3b042c8337fe9195ed6ca0cb017b76bbf1ff7c,"868 NOTICES OF THE AMS VOLUME 47, NUMBER 8 In April 2000 the National Council of Teachers of Mathematics (NCTM) released Principles and Standards for School Mathematics—the culmination of a multifaceted, three-year effort to update NCTM’s earlier standards documents and to set forth goals and recommendations for mathematics education in the prekindergarten-through-grade-twelve years. As the chair of the Writing Group, I had the privilege to interact with all aspects of the development and review of this document and with the committed groups of people, including the members of the Writing Group, who contributed immeasurably to this process. This article provides some background about NCTM and the standards, the process of development, efforts to gather input and feedback, and ways in which feedback from the mathematics community influenced the document. The article concludes with a section that provides some suggestions for mathematicians who are interested in using Principles and Standards.",2000,17,2165,296,10,25,47,49,66,78,79,118,115,118
a9386eb6808b41238381c708f2642bcb7dc34b29,"This book is about mathematical ideas, about what mathematics means-and why. Abstract ideas, for the most part, arise via conceptual metaphor-metaphorical ideas projecting from the way we function in the everyday physical world. Where Mathematics Comes From argues that conceptual metaphor plays a central role in mathematical ideas within the cognitive unconscious-from arithmetic and algebra to sets and logic to infinity in all of its forms.",2002,40,1920,107,19,40,48,55,72,74,102,91,120,102
4526716b3789971eaaa81d507abb657a29009957,"A gender gap in mathematics achievement persists in some nations but not in others. In light of the underrepresentation of women in careers in science, technology, mathematics, and engineering, increasing research attention is being devoted to understanding gender differences in mathematics achievement, attitudes, and affect. The gender stratification hypothesis maintains that such gender differences are closely related to cultural variations in opportunity structures for girls and women. We meta-analyzed 2 major international data sets, the 2003 Trends in International Mathematics and Science Study and the Programme for International Student Assessment, representing 493,495 students 14-16 years of age, to estimate the magnitude of gender differences in mathematics achievement, attitudes, and affect across 69 nations throughout the world. Consistent with the gender similarities hypothesis, all of the mean effect sizes in mathematics achievement were very small (d < 0.15); however, national effect sizes showed considerable variability (ds = -0.42 to 0.40). Despite gender similarities in achievement, boys reported more positive math attitudes and affect (ds = 0.10 to 0.33); national effect sizes ranged from d = -0.61 to 0.89. In contrast to those of previous tests of the gender stratification hypothesis, our results point to specific domains of gender equity responsible for gender gaps in math. Gender equity in school enrollment, women's share of research jobs, and women's parliamentary representation were the most powerful predictors of cross-national variability in gender gaps in math. Results are situated within the context of existing research demonstrating apparently paradoxical effects of societal gender equity and highlight the significance of increasing girls' and women's agency cross-nationally.",2010,126,1105,71,16,49,80,93,98,97,99,98,126,108
2ed2cd231aad7ea8a2b69a60d6df7539d6ee107f,"Vol. 72: The Syntax and Semantics of lnfimtary Languages. Edited by J. Barwtse. IV, 268 pages. 1968. DM 18,I $ 5.00 Vol. 73: P. E. Conner, Lectures on the Action of a Finite Group. IV, 123 pages. 1968. DM 10,1 $ 2.80 Vol. 74:A Frohlich, Formal Groups. IV, 140pages. 1968. DM12, -I $3.30 Vol. 75: G. Lumer, Algebras de fonctions et espaces de Hardy. VI, 80 pages. 1968. DM 8,I $ 2. 20 Vol. 76: R. G. Swan, Algebraic K-Theory. IV, 262 pages. 1968. DM18,I$ 5.00",2001,497,1653,59,73,89,93,103,106,99,152,152,126,57
7385b1bcd94ed3904c0e1429e209c80249de0d2a,"In this article, we use meta-analysis to analyze gender differences in recent studies of mathematics performance. First, we meta-analyzed data from 242 studies published between 1990 and 2007, representing the testing of 1,286,350 people. Overall, d = 0.05, indicating no gender difference, and variance ratio = 1.08, indicating nearly equal male and female variances. Second, we analyzed data from large data sets based on probability sampling of U.S. adolescents over the past 20 years: the National Longitudinal Surveys of Youth, the National Education Longitudinal Study of 1988, the Longitudinal Study of American Youth, and the National Assessment of Educational Progress. Effect sizes for the gender difference ranged between -0.15 and +0.22. Variance ratios ranged from 0.88 to 1.34. Taken together, these findings support the view that males and females perform similarly in mathematics.",2010,211,625,39,0,7,22,37,57,67,61,64,74,93
f008393f240508c1686a468b2c67371a7cdcb354,,2009,0,948,91,8,35,43,56,81,101,105,96,74,112
861a8ccc4002510aa1c844ea6f2c41fba69623f4,"Abstract Working memory refers to a mental workspace, involved in controlling, regulating, and actively maintaining relevant information to accomplish complex cognitive tasks (e.g. mathematical processing). Despite the potential relevance of a relation between working memory and math for understanding developmental and individual differences in mathematical skills, the nature of this relationship is not well-understood. This paper reviews four approaches that address the relation of working memory and math: 1) dual task studies establishing the role of working memory during on-line math performance; 2) individual difference studies examining working memory in children with math difficulties; 3) studies of working memory as a predictor of mathematical outcomes; and 4) longitudinal studies of working memory and math. The goal of this review is to evaluate current information on the nature of the relationship between working memory and math provided by these four approaches, and to present some of the outstanding questions for future research.",2010,165,756,23,7,17,40,52,64,69,91,88,85,83
813c3c045849f82cac2db2f26cee0ca306349f28,"Children's mathematical skills were considered in relation to executive functions. Using multiple measures-including the Wisconsin Card Sorting Task (WCST), dual-task performance, Stroop task, and counting span-it was found that mathematical ability was significantly correlated with all measures of executive functioning, with the exception of dual-task performance. Furthermore, regression analyses revealed that each executive function measure predicted unique variance in mathematics ability. These results are discussed in terms of a central executive with diverse functions (Shallice & Burgess, 1996) and with recent evidence from Miyake, et al. (2000) showing the unity and diversity among executive functions. It is proposed that the particular difficulties for children of lower mathematical ability are lack of inhibition and poor working memory, which result in problems with switching and evaluation of new strategies for dealing with a particular task. The practical and theoretical implications of these results are discussed, along with suggestions for task changes and longitudinal studies that would clarify theoretical and developmental issues related to executive functioning.",2001,79,1320,73,0,2,5,18,38,25,30,34,54,60
deac6a43706ea11bdd9fb07a73b54a08f0c114fb,"Teachers and teacher educators interested in synthesizing their current practice with new mathematics standards will welcome this highly useful volume. Presented are cases of mathematics instruction drawn from research of nearly 500 classroom lessons. Readers will gain insight about how to foster a challenging, cognitively rich, and exciting classroom climate that propels students toward a richer understanding of mathematics.",2009,0,714,82,39,42,46,57,63,50,74,59,57,52
f65040c3aa910788931c27c73006c5f3bb1e7e85,,2008,10,1101,87,44,48,62,72,80,103,88,77,98,55
34fb621cf73b7bad25d77ff1229467a34f736474,"Children's number competencies over 6 time points, from the beginning of kindergarten to the middle of 1st grade, were examined in relation to their mathematics achievement over 5 later time points, from the end of 1st grade to the end of 3rd grade. The relation between early number competence and mathematics achievement was strong and significant throughout the study period. A sequential process growth curve model showed that kindergarten number competence predicted rate of growth in mathematics achievement between 1st and 3rd grades as well as achievement level through 3rd grade. Further, rate of growth in early number competence predicted mathematics performance level in 3rd grade. Although low-income children performed more poorly than their middle-income counterparts in mathematics achievement and progressed at a slower rate, their performance and growth were mediated through relatively weak kindergarten number competence. Similarly, the better performance and faster growth of children who entered kindergarten at an older age were explained by kindergarten number competence. The findings show the importance of early number competence for setting children's learning trajectories in elementary school mathematics.",2009,70,768,38,3,16,21,32,54,72,66,77,73,94
69727a18c999db42c1e0062dd75870b4751ecc90,,2002,0,1397,4,56,59,58,63,81,92,111,128,120,121
c46e0a3586addefd8ffa8aef34afb534b8c1501e,"A model of the relations among cognitive precursors, early numeracy skill, and mathematical outcomes was tested for 182 children from 4.5 to 7.5 years of age. The model integrates research from neuroimaging, clinical populations, and normal development in children and adults. It includes 3 precursor pathways: quantitative, linguistic, and spatial attention. These pathways (a) contributed independently to early numeracy skills during preschool and kindergarten and (b) related differentially to performance on a variety of mathematical outcomes 2 years later. The success of the model in accounting for performance highlights the need to understand the fundamental underlying skills that contribute to diverse forms of mathematical competence.",2010,67,510,47,1,10,10,37,46,49,59,71,66,62
c62e9c1114644b601296d860dd643ff86473071b,"Studies of teachers’ use of mathematics curriculum materials are particularly timely given the current availability of reform-inspired curriculum materials and the increasingly widespread practice of mandating the use of a single curriculum to regulate mathematics teaching. A review of the research on mathematics curriculum use over the last 25 years reveals significant variation in findings and in theoretical foundations. The aim of this review is to examine the ways that central constructs of this body of research—such as curriculum use, teaching, and curriculum materials—are conceptualized and to consider the impact of various conceptualizations on knowledge in the field. Drawing on the literature, the author offers a framework for characterizing and studying teachers’ interactions with curriculum materials.",2005,119,999,143,2,9,21,37,52,49,56,50,64,78
06bdbd4f011e9497fddfc47654116feab28b63bd,"Between 5% and 8% of school-age children have some form of memory or cognitive deficit that interferes with their ability to learn concepts or procedures in one or more mathematical domains. A review of the arithmetical competencies of these children is provided, along with discussion of underlying memory and cognitive deficits and potential neural correlates. The deficits are discussed in terms of three subtypes of mathematics learning disability and in terms of a more general framework for linking research in mathematical cognition to research in learning disabilities.",2004,97,1068,158,5,27,28,49,42,51,68,57,83,95
feeef8d91cec3a9ffe5cf135a36a7f8596426ae1,"Amid ongoing public speculation about the reasons for sex differences in careers in science and mathematics, we present a consensus statement that is based on the best available scientific evidence. Sex differences in science and math achievement and ability are smaller for the mid-range of the abilities distribution than they are for those with the highest levels of achievement and ability. Males are more variable on most measures of quantitative and visuospatial ability, which necessarily results in more males at both high- and low-ability extremes; the reasons why males are often more variable remain elusive. Successful careers in math and science require many types of cognitive abilities. Females tend to excel in verbal abilities, with large differences between females and males found when assessments include writing samples. High-level achievement in science and math requires the ability to communicate effectively and comprehend abstract ideas, so the female advantage in writing should be helpful in all academic domains. Males outperform females on most measures of visuospatial abilities, which have been implicated as contributing to sex differences on standardized exams in mathematics and science. An evolutionary account of sex differences in mathematics and science supports the conclusion that, although sex differences in math and science performance have not directly evolved, they could be indirectly related to differences in interests and specific brain and cognitive systems. We review the brain basis for sex differences in science and mathematics, describe consistent effects, and identify numerous possible correlates. Experience alters brain structures and functioning, so causal statements about brain differences and success in math and science are circular. A wide range of sociocultural forces contribute to sex differences in mathematics and science achievement and ability—including the effects of family, neighborhood, peer, and school influences; training and experience; and cultural practices. We conclude that early experience, biological factors, educational policy, and cultural context affect the number of women and men who pursue advanced study in science and math and that these effects add and interact in complex ways. There are no single or simple answers to the complex questions about sex differences in science and mathematics.",2007,486,906,89,4,19,34,48,46,75,75,61,68,69
62bcc660cbd54558d3fcd07bade3bb764a1a146c,"This study examined the effects of a computer game on students' mathematics achievement and motivation, and the role of prior mathematics knowledge, computer skill, and English language skill on their achievement and motivation as they played the game. A total of 193 students and 10 teachers participated in this study. The teachers were randomly assigned to experimental and control groups. A mixed method of quantitative and interviews were used with Multivariate Analysis of Co-Variance to analyze the data. The results indicated significant improvement of the achievement of the experimental versus control group. No significant improvement was found in the motivation of the groups. Students who played the games in their classrooms and school labs reported greater motivation compared to the ones who played the games only in the school labs. Prior knowledge, computer and English language skill did not play significant roles in achievement and motivation of the experimental group.",2010,65,509,22,4,18,29,45,44,57,67,52,69,57
8d07144332f130bcfc5a5d30716b84a7afecbf9f,"Impairments in executive function have been documented in school-age children with mathematical learning difficulties. However, the utility and specificity of preschool executive function abilities in predicting later mathematical achievement are poorly understood. This study examined linkages between children's developing executive function abilities at age 4 and children's subsequent achievement in mathematics at age 6, 1 year after school entry. The study sample consisted of a regionally representative cohort of 104 children followed prospectively from ages 2 to 6 years. At age 4, children completed a battery of executive function tasks that assessed planning, set shifting, and inhibitory control. Teachers completed the preschool version of the Behavior Rating Inventory of Executive Function. Clinical and classroom measures of children's mathematical achievement were collected at age 6. Results showed that children's performance on set shifting, inhibitory control, and general executive behavior measures during the preschool period accounted for substantial variability in children's early mathematical achievement at school. These associations persisted even after individual differences in general cognitive ability and reading achievement were taken into account. Findings suggest that early measures of executive function may be useful in identifying children who may experience difficulties learning mathematical skills and concepts. They also suggest that the scaffolding of these executive skills could potentially be a useful additional component in early mathematics education.",2010,83,506,20,1,9,33,35,40,46,52,58,55,92
d4d7370670ffa790900ff05f96c208c9eda7d58b,"Graph theory models the Internet mathematically, and a number of plausible mathematically intersecting network models for the Internet have been developed and studied. Simultaneously, Internet researchers have developed methodology to use real data to validate, or invalidate, proposed Internet models. The authors look at these parallel developments, particularly as they apply to scale-free network models of the preferential attachment type.",2009,73,228,11,8,19,28,28,24,18,26,16,16,9
af30825f0c8adf31cf82028c8b50889b716ac362,"The work is giving estimations of the discrepancy between solutions of the initial and the homogenized problems for a one{dimensional second order elliptic operators with random coeecients satisfying strong or uniform mixing conditions. We obtain several sharp estimates in terms of the corresponding mixing coeecient. Abstract. In the theory of homogenisation it is of particular interest to determine the classes of problems which are stable on taking the homogenisation limits. A notable situation where the limit enlarges the class of original problems is known as memory (nonlocal) eeects. A number of results in that direction has been obtained for linear problems. Tartar (1990) innitiated the study of the eeective equation corresponding to nonlinear equation: @ t u n + a n u 2 n = f: Signiicant progress has been hampered by the complexity of required computations needed in order to obtain the terms in power{series expansion. We propose a method which overcomes that diiculty by introducing graphs representing the domain of integration of the integrals in each term. The graphs are relatively simple, it is easy to calculate with them and they give us a clear image of the form of each term. The method allows us to discuss the form of the eeective equation and the convergence of power{series expansions. The feasibility of our method for other types of nonlinearities will be discussed as well.",2010,40,569,7,58,54,70,82,115,47,12,7,10,6
e38ac5b98197284537fca03d8592adaae48841d4,"To understand the difficulties that many students have with comprehension of mathematics, we must determine the cognitive functioning underlying the diversity of mathematical processes. What are the cognitive systems that are required to give access to mathematical objects? Are these systems common to all processes of knowledge or, on the contrary, some of them are specific to mathematical activity? Starting from the paramount importance of semiotic representation for any mathematical activity, we put forward a classification of the various registers of semiotic representations that are mobilized in mathematical processes. Thus, we can reveal two types of transformation of semiotic representations: treatment and conversion. These two types correspond to quite different cognitive processes. They are two separate sources of incomprehension in the learning of mathematics. If treatment is the more important from a mathematical point of view, conversion is basically the deciding factor for learning. Supporting empirical data, at any level of curriculum and for any area of mathematics, can be widely and methodologically gathered: some empirical evidence is presented in this paper.",2006,28,901,111,10,12,20,25,59,41,61,55,62,91
786364fdd5a792fec5c5aaf23b87acbc4b57818b,"Abstract This study examines changes in teachers’ thinking as they participated in a video club designed to help them learn to notice and interpret students’ mathematical thinking. First, we investigate changes in teachers’ talk about classroom video segments before and after participation in the video club. Second, we identify three paths along which teachers learned to notice students’ mathematical thinking in this context: Direct, Cyclical, and Incremental. Finally, we explore ways the video club context influenced teacher learning. Understanding different forms of teacher learning provides insight for research on teacher cognition and may inform the design of video-based professional development.",2008,96,735,68,7,12,19,36,34,38,64,82,69,79
fe88603a338c69f37931facd17f22d6c4b5d5fe1,"Return by mail or fax to: SIAM Connie Young, Conference Director 3600 Market Street – 6 Floor Philadelphia, PA 19104-2688 Fax: 215-386-7999 Personal Information Name: _______________________________________________________________ Affiliation: _______________________________________________________________ Conference Name: _______________________________________________________________ Conference Location: _______________________________________________________________",2010,0,457,15,29,46,51,47,51,34,34,25,16,21
e7a5ff509962afa8850e1e682ebc224018366054,"Although it is often assumed that abilities that reflect basic numerical understanding, such as numerical comparison, are related to children's mathematical abilities, this relationship has not been tested rigorously. In addition, the extent to which symbolic and nonsymbolic number processing play differential roles in this relationship is not yet understood. To address these questions, we collected mathematics achievement measures from 6- to 8-year-olds as well as reaction times from a numerical comparison task. Using the reaction times, we calculated the size of the numerical distance effect exhibited by each child. In a correlational analysis, we found that the individual differences in the distance effect were related to mathematics achievement but not to reading achievement. This relationship was found to be specific to symbolic numerical comparison. Implications for the role of basic numerical competency and the role of accessing numerical magnitude information from Arabic numerals for the development of mathematical skills and their impairment are discussed.",2009,42,588,57,20,21,40,52,53,63,70,75,63,43
cd3a45bdd2c0ebdcfe4f2353da16c8c11ae5cb7f,"Boston College is an equal opportunity, affi rmative action employer.",2004,0,1142,63,2,15,33,42,62,78,86,89,152,109
0cd7e5ea0d7d91be0c9ce76406a1b57f8b57a3f2,"Relational mathematics is to operations research and informatics what numerical mathematics is to engineering: it is intended to help modelling, reasoning, and computing. Its applications are therefore diverse, ranging from psychology, linguistics, decision aid, and ranking to machine learning and spatial reasoning. Although many developments have been made in recent years, they have rarely been shared amongst this broad community of researchers. This first comprehensive overview begins with an easy introduction to the topic, assuming a minimum of prerequisites; but it is nevertheless theoretically sound and up to date. It is suitable for applied scientists, explaining all the necessary mathematics from scratch using a multitude of visualised examples, via matrices and graphs. It ends with tangible results on the research level. The author illustrates the theory and demonstrates practical tasks in operations research, social sciences and the humanities.",2010,0,116,14,0,7,11,9,23,21,10,13,7,4
0a4cf8c0ecf60c39234d48d9d99e03c804e067db,"We're performing all possible to bring our users the most effective books like Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics Download PDF free of charge download. Both you are looking for the book in PDF or EPUB our reference brings Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematicsto you in every possible format. You can obtain the Kindle app and then from Amazon Kindle store you are able to acquire Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics. Ebook Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics and a great many other books can be plumped for divided in to the class develop our website has therefore many categories it has a primarily old collection if you are enthusiastic about the old collection then you can certainly definitely go for it. The very best internet site to obtain Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics and all types of ebooks. They have around 2.5 million books. The same PDF version of any record is available from your personal computer or cellular devices that have a web connection to get Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics Download PDF for free. All the data on this amazing site is published in excellent trust and for normal data function only. Therefore you can easily obtain Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics. There's also some books however beneath the copyright which are offered for free on our site by specific arrangement with the author, like Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics. From this website, you are able to download Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics for free and even contribute or correct. This website is one of many sites for getting free Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics Download PDF. If you're having problem downloading Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics guide or if the hyperlinks aren't functioning, please create to email. We will change it, or send it for your requirements by email. Our digital library preserves in substance nations, letting you get the most less latency age to obtain any of our books subsequent that one. Just said, the Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics Download PDF is generally compatible afterward any units to read. As acknowledged, adventure as without problem as knowledge very almost session, entertainment, as skillfully as a package could be gotten by just looking at a guide Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics Download PDF next it is maybe not directly done, you might consent a lot more very nearly that life, on the buy of the world.",2010,201,322,32,10,16,6,10,11,23,14,19,27,36
1f80d103e387aeaa3513078745c41027b0f0f2a2,"Reprinted with permission from the Fall 2005 issue of American Educator, the quarterly journal of the American Federation of Teachers, AFL-CIO.",2005,17,900,78,3,9,28,37,43,65,50,68,89,91
2c5895c47012b9c42fad64e103f0a80fdacfd635,"This study examines the magnitude, destinations, and determinants of mathematics and science teacher turnover. The data are from the nationally representative Schools and Staffing Survey and the Teacher Follow-Up Survey. Over the past two decades, rates of mathematics and science teacher turnover have increased but, contrary to conventional wisdom, have not been consistently different than those of other teachers. Also, contrary to conventional wisdom, mathematics and science teachers were also no more likely than other teachers to take noneducation jobs, such as in technological fields or to be working for private business or industry. The data also show there are large school-to-school differences in mathematics and science turnover; high-poverty, high-minority, and urban public schools have among the highest rates. In the case of cross-school migration, the data show there is an annual asymmetric reshuffling of a significant portion of the mathematics and science teaching force from poor to not-poor schools, from high-minority to low-minority schools, and from urban to suburban schools. A number of key organizational characteristics and conditions of schools accounted for these school differences. The strongest factor for mathematics teachers was the degree of individual classroom autonomy held by teachers. Net of other factors such as salaries, schools with less classroom autonomy lose math teachers at a far higher rate than other teachers. In contrast, for science teachers salary was the strongest factor, while classroom autonomy was not strongly related to their turnover.",2010,144,278,31,1,4,12,12,24,22,28,32,43,33
69e23a9a149d7550b1afc324f326b264992693ce,"This study investigated adolescents’ developmental trajectories of mathematics interest and explored related effects of gender, family, and school context.Latent growth curvemodelingwas usedtoanalyzelongitudinaldataofN 53,193students(51%female)fromgrades5to9fromall3 ability tracks of the German state school system. Annual assessments involved student questionnaires on interest in mathematics, perceptions of classroom characteristics (classroom values for mathematics, mathematics teacher enthusiasm), as well as parent questionnaires regarding family values for mathematics. Results indicated a downward trend of students’ mathematics interest that plateaued in later years, with high variability in mean levels, but little variability in the shape of the growth trajectories. Boys reported higher mathematics interest than girls, but similar downward growth trajectories. Students from the lowest ability track showed more favorable interest trajectories than students from the middle and highest tracks. Family values andclassroomcharacteristicswerepositivelyrelatedtowithin-personlevelsofinterestovertime and to average individual levels of interest, but not to growth parameters. Theoretical and practical implications are discussed.",2010,116,313,16,4,5,15,15,17,31,31,33,54,36
a16f7f1fe98951487b7b83097b47f43f9e83ac1c,"Early childhood mathematics is vitally important for young children's present and future educational success. Research demonstrates that virtually all young children have the capability to learn and become competent in mathematics. Furthermore, young children enjoy their early informal experiences with mathematics. Unfortunately, many children's potential in mathematics is not fully realized, especially those children who are economically disadvantaged. This is due, in part, to a lack of opportunities to learn mathematics in early childhood settings or through everyday experiences in the home and in their communities. Improvements in early childhood mathematics education can provide young children with the foundation for school success. Relying on a comprehensive review of the research, Mathematics Learning in Early Childhood lays out the critical areas that should be the focus of young children's early mathematics education, explores the extent to which they are currently being incorporated in early childhood settings, and identifies the changes needed to improve the quality of mathematics experiences for young children. This book serves as a call to action to improve the state of early childhood mathematics. It will be especially useful for policy makers and practitioners-those who work directly with children and their families in shaping the policies that affect the education of young children.",2009,0,439,33,4,10,17,26,46,38,56,52,34,53
e2ce8e9f362fb1caf22cf5b7ad038dc9753c1190,"In this article we discuss efforts to design and empirically test measures of teachers’ content knowledge for teaching elementary mathematics. We begin by reviewing the literature on teacher knowledge, noting how scholars have organized such knowledge. Next we describe survey items we wrote to represent knowledge for teaching mathematics and results from factor analysis and scaling work with these items. We found that teachers’ knowledge for teaching elementary mathematics was multidimensional and included knowledge of various mathematical topics (e.g., number and operations, algebra) and domains (e.g., knowledge of content, knowledge of students and content). The constructs indicated by factor analysis formed psychometrically acceptable scales.",2004,37,899,70,2,5,12,30,56,37,52,48,71,94
9d0c4389436d3ab8ed329dba8c58e8ac6737fd3b,"Many models for the spread of infectious diseases in populations have been analyzed mathematically and applied to specific diseases. Threshold theorems involving the basic reproduction number $R_{0}$, the contact number $\sigma$, and the replacement number $R$ are reviewed for the classic SIR epidemic and endemic models. Similar results with new expressions for $R_{0}$ are obtained for MSEIR and SEIR endemic models with either continuous age or age groups. Values of $R_{0}$ and $\sigma$ are estimated for various diseases including measles in Niger and pertussis in the United States. Previous models with age structure, heterogeneity, and spatial structure are surveyed.",2000,226,4881,259,0,10,20,43,55,80,121,124,129,154
d3d720baa7080594c2fad06bb2ac90cc46666735,"The goals of this chapter are (1) to outline and substantiate a broad conceptualization of what it means to think mathematically, (2) to summarize the literature relevant to understanding mathematical thinking and problem solving, and (3) to point to new directions in research, development, and assessment consonant with an emerging understanding of mathematical thinking and the goals for instruction outlined here. The use of the phrase “learning to think mathematically” in this chapter’s title is deliberately broad. Although the original charter for this chapter was to review the literature on problem solving and metacognition, the literature itself is somewhat ill defined and poorly grounded. As the literature summary will make clear, problem solving has been used with multiple meanings that range from “working rote exercises” to “doing mathematics as a professional”; metacognition has multiple and almost disjoint meanings (from knowledge about one’s thought processes to self-regulation during problem solving) that make it difficult to use as a concept. This chapter outlines the various meanings that have been ascribed to these terms and discusses their role in mathematical thinking. The discussion will not have the character of a classic literature review, which is typically encyclopedic in its references and telegraphic in its discussions of individual papers or results. It will, instead, be selective and illustrative, with main points illustrated by extended discussions of pertinent examples. Problem solving has, as predicted in the 1980 Yearbook of the National Council of Teachers of Mathematics (Krulik, 1980, p. xiv), been the theme of the 1980s. The decade began with NCTM’s widely heralded statement, in its Agenda for Action, that “problem solving must be the focus of school mathematics” (NCTM, 1980, p. 1). It concluded with the publication of Everybody Counts (National Research Council, 1989) and the Curriculum and Evaluation Standards for School Mathematics (NCTM, 1989), both of which emphasize problem solving. One might infer, then, that there is general acceptance of the idea that the primary goal of mathematics instruction should be to have students become competent problem solvers. Yet, given the multiple interpretations of the term, the goal is hardly clear. Equally unclear is the role that problem solving, once adequately characterized, should play in the larger context of school mathematics. What are the goals for mathematics instruction, and how does problem solving fit within those goals? Such questions are complex. Goals for mathematics instruction depend on one’s conceptualization of what mathematics is, and what it means to understand mathematics. Such conceptualizations vary widely. At one end of the spectrum, mathematical knowledge is seen as a body of facts and procedures dealing with quantities, magnitudes, and forms, and the relationships among them; knowing mathematics is seen as having mastered these facts and procedures. At the other end of the spectrum, mathematics is conceptualized as the “science of patterns,” an (almost) empirical discipline closely akin to the sciences in its emphasis on pattern-seeking on the basis of empirical evidence. The author’s view is that the former perspective trivializes mathematics; that a curriculum based on mastering a corpus of mathematical facts and procedures is severely impoverished—in much the same way that an English curriculum would be considered impoverished if it focused largely, if not exclusively, on issues of grammar. The author characterizes the mathematical enterprise as follows:",2009,239,2893,267,123,144,163,155,189,196,226,163,163,178
f2e713dd0a1ee11892a90e0fb448dd5981e63550,,2000,7,7984,20,159,178,250,232,270,267,306,357,411,430
d82b5eb828d803e2f3fe041db20af8536f0fe99e,Author's Preface to the Anniversary Edition Series Editor's Introduction to the Anniversary Edition A Note about the Anniversary Edition Foreword Acknowledgments Introduction 1. Subtraction With Regrouping: Approaches To Teaching A Topic 2. Multidigit Number Multiplication: Dealing With Students' Mistakes 3. Generating Representations: Division By Fractions 4. Exploring New Knowledge: The Relationship Between Perimeter And Area 5. Teachers' Subject Matter Knowledge: Profound Understanding Of Fundamental Mathematics 6. Profound Understanding Of Fundamental Mathematics: When And How Is It Attained 7. Conclusion Appendix References New to the Anniversary Edition: Journal Article #1 New to the Anniversary Edition: Journal Article #2 Author Index Subject Index,2010,0,1684,360,141,143,135,137,149,142,142,129,128,88
7f3b042c8337fe9195ed6ca0cb017b76bbf1ff7c,"868 NOTICES OF THE AMS VOLUME 47, NUMBER 8 In April 2000 the National Council of Teachers of Mathematics (NCTM) released Principles and Standards for School Mathematics—the culmination of a multifaceted, three-year effort to update NCTM’s earlier standards documents and to set forth goals and recommendations for mathematics education in the prekindergarten-through-grade-twelve years. As the chair of the Writing Group, I had the privilege to interact with all aspects of the development and review of this document and with the committed groups of people, including the members of the Writing Group, who contributed immeasurably to this process. This article provides some background about NCTM and the standards, the process of development, efforts to gather input and feedback, and ways in which feedback from the mathematics community influenced the document. The article concludes with a section that provides some suggestions for mathematicians who are interested in using Principles and Standards.",2000,17,2165,296,10,25,47,49,66,78,79,118,115,118
a9386eb6808b41238381c708f2642bcb7dc34b29,"This book is about mathematical ideas, about what mathematics means-and why. Abstract ideas, for the most part, arise via conceptual metaphor-metaphorical ideas projecting from the way we function in the everyday physical world. Where Mathematics Comes From argues that conceptual metaphor plays a central role in mathematical ideas within the cognitive unconscious-from arithmetic and algebra to sets and logic to infinity in all of its forms.",2002,40,1920,107,19,40,48,55,72,74,102,91,120,102
4526716b3789971eaaa81d507abb657a29009957,"A gender gap in mathematics achievement persists in some nations but not in others. In light of the underrepresentation of women in careers in science, technology, mathematics, and engineering, increasing research attention is being devoted to understanding gender differences in mathematics achievement, attitudes, and affect. The gender stratification hypothesis maintains that such gender differences are closely related to cultural variations in opportunity structures for girls and women. We meta-analyzed 2 major international data sets, the 2003 Trends in International Mathematics and Science Study and the Programme for International Student Assessment, representing 493,495 students 14-16 years of age, to estimate the magnitude of gender differences in mathematics achievement, attitudes, and affect across 69 nations throughout the world. Consistent with the gender similarities hypothesis, all of the mean effect sizes in mathematics achievement were very small (d < 0.15); however, national effect sizes showed considerable variability (ds = -0.42 to 0.40). Despite gender similarities in achievement, boys reported more positive math attitudes and affect (ds = 0.10 to 0.33); national effect sizes ranged from d = -0.61 to 0.89. In contrast to those of previous tests of the gender stratification hypothesis, our results point to specific domains of gender equity responsible for gender gaps in math. Gender equity in school enrollment, women's share of research jobs, and women's parliamentary representation were the most powerful predictors of cross-national variability in gender gaps in math. Results are situated within the context of existing research demonstrating apparently paradoxical effects of societal gender equity and highlight the significance of increasing girls' and women's agency cross-nationally.",2010,126,1105,71,16,49,80,93,98,97,99,98,126,108
2ed2cd231aad7ea8a2b69a60d6df7539d6ee107f,"Vol. 72: The Syntax and Semantics of lnfimtary Languages. Edited by J. Barwtse. IV, 268 pages. 1968. DM 18,I $ 5.00 Vol. 73: P. E. Conner, Lectures on the Action of a Finite Group. IV, 123 pages. 1968. DM 10,1 $ 2.80 Vol. 74:A Frohlich, Formal Groups. IV, 140pages. 1968. DM12, -I $3.30 Vol. 75: G. Lumer, Algebras de fonctions et espaces de Hardy. VI, 80 pages. 1968. DM 8,I $ 2. 20 Vol. 76: R. G. Swan, Algebraic K-Theory. IV, 262 pages. 1968. DM18,I$ 5.00",2001,497,1653,59,73,89,93,103,106,99,152,152,126,57
7385b1bcd94ed3904c0e1429e209c80249de0d2a,"In this article, we use meta-analysis to analyze gender differences in recent studies of mathematics performance. First, we meta-analyzed data from 242 studies published between 1990 and 2007, representing the testing of 1,286,350 people. Overall, d = 0.05, indicating no gender difference, and variance ratio = 1.08, indicating nearly equal male and female variances. Second, we analyzed data from large data sets based on probability sampling of U.S. adolescents over the past 20 years: the National Longitudinal Surveys of Youth, the National Education Longitudinal Study of 1988, the Longitudinal Study of American Youth, and the National Assessment of Educational Progress. Effect sizes for the gender difference ranged between -0.15 and +0.22. Variance ratios ranged from 0.88 to 1.34. Taken together, these findings support the view that males and females perform similarly in mathematics.",2010,211,625,39,0,7,22,37,57,67,61,64,74,93
f008393f240508c1686a468b2c67371a7cdcb354,,2009,0,948,91,8,35,43,56,81,101,105,96,74,112
861a8ccc4002510aa1c844ea6f2c41fba69623f4,"Abstract Working memory refers to a mental workspace, involved in controlling, regulating, and actively maintaining relevant information to accomplish complex cognitive tasks (e.g. mathematical processing). Despite the potential relevance of a relation between working memory and math for understanding developmental and individual differences in mathematical skills, the nature of this relationship is not well-understood. This paper reviews four approaches that address the relation of working memory and math: 1) dual task studies establishing the role of working memory during on-line math performance; 2) individual difference studies examining working memory in children with math difficulties; 3) studies of working memory as a predictor of mathematical outcomes; and 4) longitudinal studies of working memory and math. The goal of this review is to evaluate current information on the nature of the relationship between working memory and math provided by these four approaches, and to present some of the outstanding questions for future research.",2010,165,756,23,7,17,40,52,64,69,91,88,85,83
813c3c045849f82cac2db2f26cee0ca306349f28,"Children's mathematical skills were considered in relation to executive functions. Using multiple measures-including the Wisconsin Card Sorting Task (WCST), dual-task performance, Stroop task, and counting span-it was found that mathematical ability was significantly correlated with all measures of executive functioning, with the exception of dual-task performance. Furthermore, regression analyses revealed that each executive function measure predicted unique variance in mathematics ability. These results are discussed in terms of a central executive with diverse functions (Shallice & Burgess, 1996) and with recent evidence from Miyake, et al. (2000) showing the unity and diversity among executive functions. It is proposed that the particular difficulties for children of lower mathematical ability are lack of inhibition and poor working memory, which result in problems with switching and evaluation of new strategies for dealing with a particular task. The practical and theoretical implications of these results are discussed, along with suggestions for task changes and longitudinal studies that would clarify theoretical and developmental issues related to executive functioning.",2001,79,1320,73,0,2,5,18,38,25,30,34,54,60
deac6a43706ea11bdd9fb07a73b54a08f0c114fb,"Teachers and teacher educators interested in synthesizing their current practice with new mathematics standards will welcome this highly useful volume. Presented are cases of mathematics instruction drawn from research of nearly 500 classroom lessons. Readers will gain insight about how to foster a challenging, cognitively rich, and exciting classroom climate that propels students toward a richer understanding of mathematics.",2009,0,714,82,39,42,46,57,63,50,74,59,57,52
f65040c3aa910788931c27c73006c5f3bb1e7e85,,2008,10,1101,87,44,48,62,72,80,103,88,77,98,55
34fb621cf73b7bad25d77ff1229467a34f736474,"Children's number competencies over 6 time points, from the beginning of kindergarten to the middle of 1st grade, were examined in relation to their mathematics achievement over 5 later time points, from the end of 1st grade to the end of 3rd grade. The relation between early number competence and mathematics achievement was strong and significant throughout the study period. A sequential process growth curve model showed that kindergarten number competence predicted rate of growth in mathematics achievement between 1st and 3rd grades as well as achievement level through 3rd grade. Further, rate of growth in early number competence predicted mathematics performance level in 3rd grade. Although low-income children performed more poorly than their middle-income counterparts in mathematics achievement and progressed at a slower rate, their performance and growth were mediated through relatively weak kindergarten number competence. Similarly, the better performance and faster growth of children who entered kindergarten at an older age were explained by kindergarten number competence. The findings show the importance of early number competence for setting children's learning trajectories in elementary school mathematics.",2009,70,768,38,3,16,21,32,54,72,66,77,73,94
69727a18c999db42c1e0062dd75870b4751ecc90,,2002,0,1397,4,56,59,58,63,81,92,111,128,120,121
c46e0a3586addefd8ffa8aef34afb534b8c1501e,"A model of the relations among cognitive precursors, early numeracy skill, and mathematical outcomes was tested for 182 children from 4.5 to 7.5 years of age. The model integrates research from neuroimaging, clinical populations, and normal development in children and adults. It includes 3 precursor pathways: quantitative, linguistic, and spatial attention. These pathways (a) contributed independently to early numeracy skills during preschool and kindergarten and (b) related differentially to performance on a variety of mathematical outcomes 2 years later. The success of the model in accounting for performance highlights the need to understand the fundamental underlying skills that contribute to diverse forms of mathematical competence.",2010,67,510,47,1,10,10,37,46,49,59,71,66,62
c62e9c1114644b601296d860dd643ff86473071b,"Studies of teachers’ use of mathematics curriculum materials are particularly timely given the current availability of reform-inspired curriculum materials and the increasingly widespread practice of mandating the use of a single curriculum to regulate mathematics teaching. A review of the research on mathematics curriculum use over the last 25 years reveals significant variation in findings and in theoretical foundations. The aim of this review is to examine the ways that central constructs of this body of research—such as curriculum use, teaching, and curriculum materials—are conceptualized and to consider the impact of various conceptualizations on knowledge in the field. Drawing on the literature, the author offers a framework for characterizing and studying teachers’ interactions with curriculum materials.",2005,119,999,143,2,9,21,37,52,49,56,50,64,78
06bdbd4f011e9497fddfc47654116feab28b63bd,"Between 5% and 8% of school-age children have some form of memory or cognitive deficit that interferes with their ability to learn concepts or procedures in one or more mathematical domains. A review of the arithmetical competencies of these children is provided, along with discussion of underlying memory and cognitive deficits and potential neural correlates. The deficits are discussed in terms of three subtypes of mathematics learning disability and in terms of a more general framework for linking research in mathematical cognition to research in learning disabilities.",2004,97,1068,158,5,27,28,49,42,51,68,57,83,95
feeef8d91cec3a9ffe5cf135a36a7f8596426ae1,"Amid ongoing public speculation about the reasons for sex differences in careers in science and mathematics, we present a consensus statement that is based on the best available scientific evidence. Sex differences in science and math achievement and ability are smaller for the mid-range of the abilities distribution than they are for those with the highest levels of achievement and ability. Males are more variable on most measures of quantitative and visuospatial ability, which necessarily results in more males at both high- and low-ability extremes; the reasons why males are often more variable remain elusive. Successful careers in math and science require many types of cognitive abilities. Females tend to excel in verbal abilities, with large differences between females and males found when assessments include writing samples. High-level achievement in science and math requires the ability to communicate effectively and comprehend abstract ideas, so the female advantage in writing should be helpful in all academic domains. Males outperform females on most measures of visuospatial abilities, which have been implicated as contributing to sex differences on standardized exams in mathematics and science. An evolutionary account of sex differences in mathematics and science supports the conclusion that, although sex differences in math and science performance have not directly evolved, they could be indirectly related to differences in interests and specific brain and cognitive systems. We review the brain basis for sex differences in science and mathematics, describe consistent effects, and identify numerous possible correlates. Experience alters brain structures and functioning, so causal statements about brain differences and success in math and science are circular. A wide range of sociocultural forces contribute to sex differences in mathematics and science achievement and ability—including the effects of family, neighborhood, peer, and school influences; training and experience; and cultural practices. We conclude that early experience, biological factors, educational policy, and cultural context affect the number of women and men who pursue advanced study in science and math and that these effects add and interact in complex ways. There are no single or simple answers to the complex questions about sex differences in science and mathematics.",2007,486,906,89,4,19,34,48,46,75,75,61,68,69
62bcc660cbd54558d3fcd07bade3bb764a1a146c,"This study examined the effects of a computer game on students' mathematics achievement and motivation, and the role of prior mathematics knowledge, computer skill, and English language skill on their achievement and motivation as they played the game. A total of 193 students and 10 teachers participated in this study. The teachers were randomly assigned to experimental and control groups. A mixed method of quantitative and interviews were used with Multivariate Analysis of Co-Variance to analyze the data. The results indicated significant improvement of the achievement of the experimental versus control group. No significant improvement was found in the motivation of the groups. Students who played the games in their classrooms and school labs reported greater motivation compared to the ones who played the games only in the school labs. Prior knowledge, computer and English language skill did not play significant roles in achievement and motivation of the experimental group.",2010,65,509,22,4,18,29,45,44,57,67,52,69,57
8d07144332f130bcfc5a5d30716b84a7afecbf9f,"Impairments in executive function have been documented in school-age children with mathematical learning difficulties. However, the utility and specificity of preschool executive function abilities in predicting later mathematical achievement are poorly understood. This study examined linkages between children's developing executive function abilities at age 4 and children's subsequent achievement in mathematics at age 6, 1 year after school entry. The study sample consisted of a regionally representative cohort of 104 children followed prospectively from ages 2 to 6 years. At age 4, children completed a battery of executive function tasks that assessed planning, set shifting, and inhibitory control. Teachers completed the preschool version of the Behavior Rating Inventory of Executive Function. Clinical and classroom measures of children's mathematical achievement were collected at age 6. Results showed that children's performance on set shifting, inhibitory control, and general executive behavior measures during the preschool period accounted for substantial variability in children's early mathematical achievement at school. These associations persisted even after individual differences in general cognitive ability and reading achievement were taken into account. Findings suggest that early measures of executive function may be useful in identifying children who may experience difficulties learning mathematical skills and concepts. They also suggest that the scaffolding of these executive skills could potentially be a useful additional component in early mathematics education.",2010,83,506,20,1,9,33,35,40,46,52,58,55,92
d4d7370670ffa790900ff05f96c208c9eda7d58b,"Graph theory models the Internet mathematically, and a number of plausible mathematically intersecting network models for the Internet have been developed and studied. Simultaneously, Internet researchers have developed methodology to use real data to validate, or invalidate, proposed Internet models. The authors look at these parallel developments, particularly as they apply to scale-free network models of the preferential attachment type.",2009,73,228,11,8,19,28,28,24,18,26,16,16,9
af30825f0c8adf31cf82028c8b50889b716ac362,"The work is giving estimations of the discrepancy between solutions of the initial and the homogenized problems for a one{dimensional second order elliptic operators with random coeecients satisfying strong or uniform mixing conditions. We obtain several sharp estimates in terms of the corresponding mixing coeecient. Abstract. In the theory of homogenisation it is of particular interest to determine the classes of problems which are stable on taking the homogenisation limits. A notable situation where the limit enlarges the class of original problems is known as memory (nonlocal) eeects. A number of results in that direction has been obtained for linear problems. Tartar (1990) innitiated the study of the eeective equation corresponding to nonlinear equation: @ t u n + a n u 2 n = f: Signiicant progress has been hampered by the complexity of required computations needed in order to obtain the terms in power{series expansion. We propose a method which overcomes that diiculty by introducing graphs representing the domain of integration of the integrals in each term. The graphs are relatively simple, it is easy to calculate with them and they give us a clear image of the form of each term. The method allows us to discuss the form of the eeective equation and the convergence of power{series expansions. The feasibility of our method for other types of nonlinearities will be discussed as well.",2010,40,569,7,58,54,70,82,115,47,12,7,10,6
e38ac5b98197284537fca03d8592adaae48841d4,"To understand the difficulties that many students have with comprehension of mathematics, we must determine the cognitive functioning underlying the diversity of mathematical processes. What are the cognitive systems that are required to give access to mathematical objects? Are these systems common to all processes of knowledge or, on the contrary, some of them are specific to mathematical activity? Starting from the paramount importance of semiotic representation for any mathematical activity, we put forward a classification of the various registers of semiotic representations that are mobilized in mathematical processes. Thus, we can reveal two types of transformation of semiotic representations: treatment and conversion. These two types correspond to quite different cognitive processes. They are two separate sources of incomprehension in the learning of mathematics. If treatment is the more important from a mathematical point of view, conversion is basically the deciding factor for learning. Supporting empirical data, at any level of curriculum and for any area of mathematics, can be widely and methodologically gathered: some empirical evidence is presented in this paper.",2006,28,901,111,10,12,20,25,59,41,61,55,62,91
786364fdd5a792fec5c5aaf23b87acbc4b57818b,"Abstract This study examines changes in teachers’ thinking as they participated in a video club designed to help them learn to notice and interpret students’ mathematical thinking. First, we investigate changes in teachers’ talk about classroom video segments before and after participation in the video club. Second, we identify three paths along which teachers learned to notice students’ mathematical thinking in this context: Direct, Cyclical, and Incremental. Finally, we explore ways the video club context influenced teacher learning. Understanding different forms of teacher learning provides insight for research on teacher cognition and may inform the design of video-based professional development.",2008,96,735,68,7,12,19,36,34,38,64,82,69,79
fe88603a338c69f37931facd17f22d6c4b5d5fe1,"Return by mail or fax to: SIAM Connie Young, Conference Director 3600 Market Street – 6 Floor Philadelphia, PA 19104-2688 Fax: 215-386-7999 Personal Information Name: _______________________________________________________________ Affiliation: _______________________________________________________________ Conference Name: _______________________________________________________________ Conference Location: _______________________________________________________________",2010,0,457,15,29,46,51,47,51,34,34,25,16,21
e7a5ff509962afa8850e1e682ebc224018366054,"Although it is often assumed that abilities that reflect basic numerical understanding, such as numerical comparison, are related to children's mathematical abilities, this relationship has not been tested rigorously. In addition, the extent to which symbolic and nonsymbolic number processing play differential roles in this relationship is not yet understood. To address these questions, we collected mathematics achievement measures from 6- to 8-year-olds as well as reaction times from a numerical comparison task. Using the reaction times, we calculated the size of the numerical distance effect exhibited by each child. In a correlational analysis, we found that the individual differences in the distance effect were related to mathematics achievement but not to reading achievement. This relationship was found to be specific to symbolic numerical comparison. Implications for the role of basic numerical competency and the role of accessing numerical magnitude information from Arabic numerals for the development of mathematical skills and their impairment are discussed.",2009,42,588,57,20,21,40,52,53,63,70,75,63,43
cd3a45bdd2c0ebdcfe4f2353da16c8c11ae5cb7f,"Boston College is an equal opportunity, affi rmative action employer.",2004,0,1142,63,2,15,33,42,62,78,86,89,152,109
0cd7e5ea0d7d91be0c9ce76406a1b57f8b57a3f2,"Relational mathematics is to operations research and informatics what numerical mathematics is to engineering: it is intended to help modelling, reasoning, and computing. Its applications are therefore diverse, ranging from psychology, linguistics, decision aid, and ranking to machine learning and spatial reasoning. Although many developments have been made in recent years, they have rarely been shared amongst this broad community of researchers. This first comprehensive overview begins with an easy introduction to the topic, assuming a minimum of prerequisites; but it is nevertheless theoretically sound and up to date. It is suitable for applied scientists, explaining all the necessary mathematics from scratch using a multitude of visualised examples, via matrices and graphs. It ends with tangible results on the research level. The author illustrates the theory and demonstrates practical tasks in operations research, social sciences and the humanities.",2010,0,116,14,0,7,11,9,23,21,10,13,7,4
0a4cf8c0ecf60c39234d48d9d99e03c804e067db,"We're performing all possible to bring our users the most effective books like Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics Download PDF free of charge download. Both you are looking for the book in PDF or EPUB our reference brings Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematicsto you in every possible format. You can obtain the Kindle app and then from Amazon Kindle store you are able to acquire Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics. Ebook Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics and a great many other books can be plumped for divided in to the class develop our website has therefore many categories it has a primarily old collection if you are enthusiastic about the old collection then you can certainly definitely go for it. The very best internet site to obtain Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics and all types of ebooks. They have around 2.5 million books. The same PDF version of any record is available from your personal computer or cellular devices that have a web connection to get Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics Download PDF for free. All the data on this amazing site is published in excellent trust and for normal data function only. Therefore you can easily obtain Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics. There's also some books however beneath the copyright which are offered for free on our site by specific arrangement with the author, like Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics. From this website, you are able to download Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics for free and even contribute or correct. This website is one of many sites for getting free Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics Download PDF. If you're having problem downloading Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics guide or if the hyperlinks aren't functioning, please create to email. We will change it, or send it for your requirements by email. Our digital library preserves in substance nations, letting you get the most less latency age to obtain any of our books subsequent that one. Just said, the Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics Download PDF is generally compatible afterward any units to read. As acknowledged, adventure as without problem as knowledge very almost session, entertainment, as skillfully as a package could be gotten by just looking at a guide Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics Download PDF next it is maybe not directly done, you might consent a lot more very nearly that life, on the buy of the world.",2010,201,322,32,10,16,6,10,11,23,14,19,27,36
1f80d103e387aeaa3513078745c41027b0f0f2a2,"Reprinted with permission from the Fall 2005 issue of American Educator, the quarterly journal of the American Federation of Teachers, AFL-CIO.",2005,17,900,78,3,9,28,37,43,65,50,68,89,91
2c5895c47012b9c42fad64e103f0a80fdacfd635,"This study examines the magnitude, destinations, and determinants of mathematics and science teacher turnover. The data are from the nationally representative Schools and Staffing Survey and the Teacher Follow-Up Survey. Over the past two decades, rates of mathematics and science teacher turnover have increased but, contrary to conventional wisdom, have not been consistently different than those of other teachers. Also, contrary to conventional wisdom, mathematics and science teachers were also no more likely than other teachers to take noneducation jobs, such as in technological fields or to be working for private business or industry. The data also show there are large school-to-school differences in mathematics and science turnover; high-poverty, high-minority, and urban public schools have among the highest rates. In the case of cross-school migration, the data show there is an annual asymmetric reshuffling of a significant portion of the mathematics and science teaching force from poor to not-poor schools, from high-minority to low-minority schools, and from urban to suburban schools. A number of key organizational characteristics and conditions of schools accounted for these school differences. The strongest factor for mathematics teachers was the degree of individual classroom autonomy held by teachers. Net of other factors such as salaries, schools with less classroom autonomy lose math teachers at a far higher rate than other teachers. In contrast, for science teachers salary was the strongest factor, while classroom autonomy was not strongly related to their turnover.",2010,144,278,31,1,4,12,12,24,22,28,32,43,33
69e23a9a149d7550b1afc324f326b264992693ce,"This study investigated adolescents’ developmental trajectories of mathematics interest and explored related effects of gender, family, and school context.Latent growth curvemodelingwas usedtoanalyzelongitudinaldataofN 53,193students(51%female)fromgrades5to9fromall3 ability tracks of the German state school system. Annual assessments involved student questionnaires on interest in mathematics, perceptions of classroom characteristics (classroom values for mathematics, mathematics teacher enthusiasm), as well as parent questionnaires regarding family values for mathematics. Results indicated a downward trend of students’ mathematics interest that plateaued in later years, with high variability in mean levels, but little variability in the shape of the growth trajectories. Boys reported higher mathematics interest than girls, but similar downward growth trajectories. Students from the lowest ability track showed more favorable interest trajectories than students from the middle and highest tracks. Family values andclassroomcharacteristicswerepositivelyrelatedtowithin-personlevelsofinterestovertime and to average individual levels of interest, but not to growth parameters. Theoretical and practical implications are discussed.",2010,116,313,16,4,5,15,15,17,31,31,33,54,36
a16f7f1fe98951487b7b83097b47f43f9e83ac1c,"Early childhood mathematics is vitally important for young children's present and future educational success. Research demonstrates that virtually all young children have the capability to learn and become competent in mathematics. Furthermore, young children enjoy their early informal experiences with mathematics. Unfortunately, many children's potential in mathematics is not fully realized, especially those children who are economically disadvantaged. This is due, in part, to a lack of opportunities to learn mathematics in early childhood settings or through everyday experiences in the home and in their communities. Improvements in early childhood mathematics education can provide young children with the foundation for school success. Relying on a comprehensive review of the research, Mathematics Learning in Early Childhood lays out the critical areas that should be the focus of young children's early mathematics education, explores the extent to which they are currently being incorporated in early childhood settings, and identifies the changes needed to improve the quality of mathematics experiences for young children. This book serves as a call to action to improve the state of early childhood mathematics. It will be especially useful for policy makers and practitioners-those who work directly with children and their families in shaping the policies that affect the education of young children.",2009,0,439,33,4,10,17,26,46,38,56,52,34,53
e2ce8e9f362fb1caf22cf5b7ad038dc9753c1190,"In this article we discuss efforts to design and empirically test measures of teachers’ content knowledge for teaching elementary mathematics. We begin by reviewing the literature on teacher knowledge, noting how scholars have organized such knowledge. Next we describe survey items we wrote to represent knowledge for teaching mathematics and results from factor analysis and scaling work with these items. We found that teachers’ knowledge for teaching elementary mathematics was multidimensional and included knowledge of various mathematical topics (e.g., number and operations, algebra) and domains (e.g., knowledge of content, knowledge of students and content). The constructs indicated by factor analysis formed psychometrically acceptable scales.",2004,37,899,70,2,5,12,30,56,37,52,48,71,94
9d0c4389436d3ab8ed329dba8c58e8ac6737fd3b,"Many models for the spread of infectious diseases in populations have been analyzed mathematically and applied to specific diseases. Threshold theorems involving the basic reproduction number $R_{0}$, the contact number $\sigma$, and the replacement number $R$ are reviewed for the classic SIR epidemic and endemic models. Similar results with new expressions for $R_{0}$ are obtained for MSEIR and SEIR endemic models with either continuous age or age groups. Values of $R_{0}$ and $\sigma$ are estimated for various diseases including measles in Niger and pertussis in the United States. Previous models with age structure, heterogeneity, and spatial structure are surveyed.",2000,226,4881,259,0,10,20,43,55,80,121,124,129,154
d3d720baa7080594c2fad06bb2ac90cc46666735,"The goals of this chapter are (1) to outline and substantiate a broad conceptualization of what it means to think mathematically, (2) to summarize the literature relevant to understanding mathematical thinking and problem solving, and (3) to point to new directions in research, development, and assessment consonant with an emerging understanding of mathematical thinking and the goals for instruction outlined here. The use of the phrase “learning to think mathematically” in this chapter’s title is deliberately broad. Although the original charter for this chapter was to review the literature on problem solving and metacognition, the literature itself is somewhat ill defined and poorly grounded. As the literature summary will make clear, problem solving has been used with multiple meanings that range from “working rote exercises” to “doing mathematics as a professional”; metacognition has multiple and almost disjoint meanings (from knowledge about one’s thought processes to self-regulation during problem solving) that make it difficult to use as a concept. This chapter outlines the various meanings that have been ascribed to these terms and discusses their role in mathematical thinking. The discussion will not have the character of a classic literature review, which is typically encyclopedic in its references and telegraphic in its discussions of individual papers or results. It will, instead, be selective and illustrative, with main points illustrated by extended discussions of pertinent examples. Problem solving has, as predicted in the 1980 Yearbook of the National Council of Teachers of Mathematics (Krulik, 1980, p. xiv), been the theme of the 1980s. The decade began with NCTM’s widely heralded statement, in its Agenda for Action, that “problem solving must be the focus of school mathematics” (NCTM, 1980, p. 1). It concluded with the publication of Everybody Counts (National Research Council, 1989) and the Curriculum and Evaluation Standards for School Mathematics (NCTM, 1989), both of which emphasize problem solving. One might infer, then, that there is general acceptance of the idea that the primary goal of mathematics instruction should be to have students become competent problem solvers. Yet, given the multiple interpretations of the term, the goal is hardly clear. Equally unclear is the role that problem solving, once adequately characterized, should play in the larger context of school mathematics. What are the goals for mathematics instruction, and how does problem solving fit within those goals? Such questions are complex. Goals for mathematics instruction depend on one’s conceptualization of what mathematics is, and what it means to understand mathematics. Such conceptualizations vary widely. At one end of the spectrum, mathematical knowledge is seen as a body of facts and procedures dealing with quantities, magnitudes, and forms, and the relationships among them; knowing mathematics is seen as having mastered these facts and procedures. At the other end of the spectrum, mathematics is conceptualized as the “science of patterns,” an (almost) empirical discipline closely akin to the sciences in its emphasis on pattern-seeking on the basis of empirical evidence. The author’s view is that the former perspective trivializes mathematics; that a curriculum based on mastering a corpus of mathematical facts and procedures is severely impoverished—in much the same way that an English curriculum would be considered impoverished if it focused largely, if not exclusively, on issues of grammar. The author characterizes the mathematical enterprise as follows:",2009,239,2893,267,123,144,163,155,189,196,226,163,163,178
f2e713dd0a1ee11892a90e0fb448dd5981e63550,,2000,7,7984,20,159,178,250,232,270,267,306,357,411,430
d82b5eb828d803e2f3fe041db20af8536f0fe99e,Author's Preface to the Anniversary Edition Series Editor's Introduction to the Anniversary Edition A Note about the Anniversary Edition Foreword Acknowledgments Introduction 1. Subtraction With Regrouping: Approaches To Teaching A Topic 2. Multidigit Number Multiplication: Dealing With Students' Mistakes 3. Generating Representations: Division By Fractions 4. Exploring New Knowledge: The Relationship Between Perimeter And Area 5. Teachers' Subject Matter Knowledge: Profound Understanding Of Fundamental Mathematics 6. Profound Understanding Of Fundamental Mathematics: When And How Is It Attained 7. Conclusion Appendix References New to the Anniversary Edition: Journal Article #1 New to the Anniversary Edition: Journal Article #2 Author Index Subject Index,2010,0,1684,360,141,143,135,137,149,142,142,129,128,88
7f3b042c8337fe9195ed6ca0cb017b76bbf1ff7c,"868 NOTICES OF THE AMS VOLUME 47, NUMBER 8 In April 2000 the National Council of Teachers of Mathematics (NCTM) released Principles and Standards for School Mathematics—the culmination of a multifaceted, three-year effort to update NCTM’s earlier standards documents and to set forth goals and recommendations for mathematics education in the prekindergarten-through-grade-twelve years. As the chair of the Writing Group, I had the privilege to interact with all aspects of the development and review of this document and with the committed groups of people, including the members of the Writing Group, who contributed immeasurably to this process. This article provides some background about NCTM and the standards, the process of development, efforts to gather input and feedback, and ways in which feedback from the mathematics community influenced the document. The article concludes with a section that provides some suggestions for mathematicians who are interested in using Principles and Standards.",2000,17,2165,296,10,25,47,49,66,78,79,118,115,118
a9386eb6808b41238381c708f2642bcb7dc34b29,"This book is about mathematical ideas, about what mathematics means-and why. Abstract ideas, for the most part, arise via conceptual metaphor-metaphorical ideas projecting from the way we function in the everyday physical world. Where Mathematics Comes From argues that conceptual metaphor plays a central role in mathematical ideas within the cognitive unconscious-from arithmetic and algebra to sets and logic to infinity in all of its forms.",2002,40,1920,107,19,40,48,55,72,74,102,91,120,102
4526716b3789971eaaa81d507abb657a29009957,"A gender gap in mathematics achievement persists in some nations but not in others. In light of the underrepresentation of women in careers in science, technology, mathematics, and engineering, increasing research attention is being devoted to understanding gender differences in mathematics achievement, attitudes, and affect. The gender stratification hypothesis maintains that such gender differences are closely related to cultural variations in opportunity structures for girls and women. We meta-analyzed 2 major international data sets, the 2003 Trends in International Mathematics and Science Study and the Programme for International Student Assessment, representing 493,495 students 14-16 years of age, to estimate the magnitude of gender differences in mathematics achievement, attitudes, and affect across 69 nations throughout the world. Consistent with the gender similarities hypothesis, all of the mean effect sizes in mathematics achievement were very small (d < 0.15); however, national effect sizes showed considerable variability (ds = -0.42 to 0.40). Despite gender similarities in achievement, boys reported more positive math attitudes and affect (ds = 0.10 to 0.33); national effect sizes ranged from d = -0.61 to 0.89. In contrast to those of previous tests of the gender stratification hypothesis, our results point to specific domains of gender equity responsible for gender gaps in math. Gender equity in school enrollment, women's share of research jobs, and women's parliamentary representation were the most powerful predictors of cross-national variability in gender gaps in math. Results are situated within the context of existing research demonstrating apparently paradoxical effects of societal gender equity and highlight the significance of increasing girls' and women's agency cross-nationally.",2010,126,1105,71,16,49,80,93,98,97,99,98,126,108
2ed2cd231aad7ea8a2b69a60d6df7539d6ee107f,"Vol. 72: The Syntax and Semantics of lnfimtary Languages. Edited by J. Barwtse. IV, 268 pages. 1968. DM 18,I $ 5.00 Vol. 73: P. E. Conner, Lectures on the Action of a Finite Group. IV, 123 pages. 1968. DM 10,1 $ 2.80 Vol. 74:A Frohlich, Formal Groups. IV, 140pages. 1968. DM12, -I $3.30 Vol. 75: G. Lumer, Algebras de fonctions et espaces de Hardy. VI, 80 pages. 1968. DM 8,I $ 2. 20 Vol. 76: R. G. Swan, Algebraic K-Theory. IV, 262 pages. 1968. DM18,I$ 5.00",2001,497,1653,59,73,89,93,103,106,99,152,152,126,57
7385b1bcd94ed3904c0e1429e209c80249de0d2a,"In this article, we use meta-analysis to analyze gender differences in recent studies of mathematics performance. First, we meta-analyzed data from 242 studies published between 1990 and 2007, representing the testing of 1,286,350 people. Overall, d = 0.05, indicating no gender difference, and variance ratio = 1.08, indicating nearly equal male and female variances. Second, we analyzed data from large data sets based on probability sampling of U.S. adolescents over the past 20 years: the National Longitudinal Surveys of Youth, the National Education Longitudinal Study of 1988, the Longitudinal Study of American Youth, and the National Assessment of Educational Progress. Effect sizes for the gender difference ranged between -0.15 and +0.22. Variance ratios ranged from 0.88 to 1.34. Taken together, these findings support the view that males and females perform similarly in mathematics.",2010,211,625,39,0,7,22,37,57,67,61,64,74,93
f008393f240508c1686a468b2c67371a7cdcb354,,2009,0,948,91,8,35,43,56,81,101,105,96,74,112
861a8ccc4002510aa1c844ea6f2c41fba69623f4,"Abstract Working memory refers to a mental workspace, involved in controlling, regulating, and actively maintaining relevant information to accomplish complex cognitive tasks (e.g. mathematical processing). Despite the potential relevance of a relation between working memory and math for understanding developmental and individual differences in mathematical skills, the nature of this relationship is not well-understood. This paper reviews four approaches that address the relation of working memory and math: 1) dual task studies establishing the role of working memory during on-line math performance; 2) individual difference studies examining working memory in children with math difficulties; 3) studies of working memory as a predictor of mathematical outcomes; and 4) longitudinal studies of working memory and math. The goal of this review is to evaluate current information on the nature of the relationship between working memory and math provided by these four approaches, and to present some of the outstanding questions for future research.",2010,165,756,23,7,17,40,52,64,69,91,88,85,83
813c3c045849f82cac2db2f26cee0ca306349f28,"Children's mathematical skills were considered in relation to executive functions. Using multiple measures-including the Wisconsin Card Sorting Task (WCST), dual-task performance, Stroop task, and counting span-it was found that mathematical ability was significantly correlated with all measures of executive functioning, with the exception of dual-task performance. Furthermore, regression analyses revealed that each executive function measure predicted unique variance in mathematics ability. These results are discussed in terms of a central executive with diverse functions (Shallice & Burgess, 1996) and with recent evidence from Miyake, et al. (2000) showing the unity and diversity among executive functions. It is proposed that the particular difficulties for children of lower mathematical ability are lack of inhibition and poor working memory, which result in problems with switching and evaluation of new strategies for dealing with a particular task. The practical and theoretical implications of these results are discussed, along with suggestions for task changes and longitudinal studies that would clarify theoretical and developmental issues related to executive functioning.",2001,79,1320,73,0,2,5,18,38,25,30,34,54,60
deac6a43706ea11bdd9fb07a73b54a08f0c114fb,"Teachers and teacher educators interested in synthesizing their current practice with new mathematics standards will welcome this highly useful volume. Presented are cases of mathematics instruction drawn from research of nearly 500 classroom lessons. Readers will gain insight about how to foster a challenging, cognitively rich, and exciting classroom climate that propels students toward a richer understanding of mathematics.",2009,0,714,82,39,42,46,57,63,50,74,59,57,52
f65040c3aa910788931c27c73006c5f3bb1e7e85,,2008,10,1101,87,44,48,62,72,80,103,88,77,98,55
34fb621cf73b7bad25d77ff1229467a34f736474,"Children's number competencies over 6 time points, from the beginning of kindergarten to the middle of 1st grade, were examined in relation to their mathematics achievement over 5 later time points, from the end of 1st grade to the end of 3rd grade. The relation between early number competence and mathematics achievement was strong and significant throughout the study period. A sequential process growth curve model showed that kindergarten number competence predicted rate of growth in mathematics achievement between 1st and 3rd grades as well as achievement level through 3rd grade. Further, rate of growth in early number competence predicted mathematics performance level in 3rd grade. Although low-income children performed more poorly than their middle-income counterparts in mathematics achievement and progressed at a slower rate, their performance and growth were mediated through relatively weak kindergarten number competence. Similarly, the better performance and faster growth of children who entered kindergarten at an older age were explained by kindergarten number competence. The findings show the importance of early number competence for setting children's learning trajectories in elementary school mathematics.",2009,70,768,38,3,16,21,32,54,72,66,77,73,94
69727a18c999db42c1e0062dd75870b4751ecc90,,2002,0,1397,4,56,59,58,63,81,92,111,128,120,121
c46e0a3586addefd8ffa8aef34afb534b8c1501e,"A model of the relations among cognitive precursors, early numeracy skill, and mathematical outcomes was tested for 182 children from 4.5 to 7.5 years of age. The model integrates research from neuroimaging, clinical populations, and normal development in children and adults. It includes 3 precursor pathways: quantitative, linguistic, and spatial attention. These pathways (a) contributed independently to early numeracy skills during preschool and kindergarten and (b) related differentially to performance on a variety of mathematical outcomes 2 years later. The success of the model in accounting for performance highlights the need to understand the fundamental underlying skills that contribute to diverse forms of mathematical competence.",2010,67,510,47,1,10,10,37,46,49,59,71,66,62
06bdbd4f011e9497fddfc47654116feab28b63bd,"Between 5% and 8% of school-age children have some form of memory or cognitive deficit that interferes with their ability to learn concepts or procedures in one or more mathematical domains. A review of the arithmetical competencies of these children is provided, along with discussion of underlying memory and cognitive deficits and potential neural correlates. The deficits are discussed in terms of three subtypes of mathematics learning disability and in terms of a more general framework for linking research in mathematical cognition to research in learning disabilities.",2004,97,1068,158,5,27,28,49,42,51,68,57,83,95
c62e9c1114644b601296d860dd643ff86473071b,"Studies of teachers’ use of mathematics curriculum materials are particularly timely given the current availability of reform-inspired curriculum materials and the increasingly widespread practice of mandating the use of a single curriculum to regulate mathematics teaching. A review of the research on mathematics curriculum use over the last 25 years reveals significant variation in findings and in theoretical foundations. The aim of this review is to examine the ways that central constructs of this body of research—such as curriculum use, teaching, and curriculum materials—are conceptualized and to consider the impact of various conceptualizations on knowledge in the field. Drawing on the literature, the author offers a framework for characterizing and studying teachers’ interactions with curriculum materials.",2005,119,999,143,2,9,21,37,52,49,56,50,64,78
feeef8d91cec3a9ffe5cf135a36a7f8596426ae1,"Amid ongoing public speculation about the reasons for sex differences in careers in science and mathematics, we present a consensus statement that is based on the best available scientific evidence. Sex differences in science and math achievement and ability are smaller for the mid-range of the abilities distribution than they are for those with the highest levels of achievement and ability. Males are more variable on most measures of quantitative and visuospatial ability, which necessarily results in more males at both high- and low-ability extremes; the reasons why males are often more variable remain elusive. Successful careers in math and science require many types of cognitive abilities. Females tend to excel in verbal abilities, with large differences between females and males found when assessments include writing samples. High-level achievement in science and math requires the ability to communicate effectively and comprehend abstract ideas, so the female advantage in writing should be helpful in all academic domains. Males outperform females on most measures of visuospatial abilities, which have been implicated as contributing to sex differences on standardized exams in mathematics and science. An evolutionary account of sex differences in mathematics and science supports the conclusion that, although sex differences in math and science performance have not directly evolved, they could be indirectly related to differences in interests and specific brain and cognitive systems. We review the brain basis for sex differences in science and mathematics, describe consistent effects, and identify numerous possible correlates. Experience alters brain structures and functioning, so causal statements about brain differences and success in math and science are circular. A wide range of sociocultural forces contribute to sex differences in mathematics and science achievement and ability—including the effects of family, neighborhood, peer, and school influences; training and experience; and cultural practices. We conclude that early experience, biological factors, educational policy, and cultural context affect the number of women and men who pursue advanced study in science and math and that these effects add and interact in complex ways. There are no single or simple answers to the complex questions about sex differences in science and mathematics.",2007,486,906,89,4,19,34,48,46,75,75,61,68,69
62bcc660cbd54558d3fcd07bade3bb764a1a146c,"This study examined the effects of a computer game on students' mathematics achievement and motivation, and the role of prior mathematics knowledge, computer skill, and English language skill on their achievement and motivation as they played the game. A total of 193 students and 10 teachers participated in this study. The teachers were randomly assigned to experimental and control groups. A mixed method of quantitative and interviews were used with Multivariate Analysis of Co-Variance to analyze the data. The results indicated significant improvement of the achievement of the experimental versus control group. No significant improvement was found in the motivation of the groups. Students who played the games in their classrooms and school labs reported greater motivation compared to the ones who played the games only in the school labs. Prior knowledge, computer and English language skill did not play significant roles in achievement and motivation of the experimental group.",2010,65,509,22,4,18,29,45,44,57,67,52,69,57
8d07144332f130bcfc5a5d30716b84a7afecbf9f,"Impairments in executive function have been documented in school-age children with mathematical learning difficulties. However, the utility and specificity of preschool executive function abilities in predicting later mathematical achievement are poorly understood. This study examined linkages between children's developing executive function abilities at age 4 and children's subsequent achievement in mathematics at age 6, 1 year after school entry. The study sample consisted of a regionally representative cohort of 104 children followed prospectively from ages 2 to 6 years. At age 4, children completed a battery of executive function tasks that assessed planning, set shifting, and inhibitory control. Teachers completed the preschool version of the Behavior Rating Inventory of Executive Function. Clinical and classroom measures of children's mathematical achievement were collected at age 6. Results showed that children's performance on set shifting, inhibitory control, and general executive behavior measures during the preschool period accounted for substantial variability in children's early mathematical achievement at school. These associations persisted even after individual differences in general cognitive ability and reading achievement were taken into account. Findings suggest that early measures of executive function may be useful in identifying children who may experience difficulties learning mathematical skills and concepts. They also suggest that the scaffolding of these executive skills could potentially be a useful additional component in early mathematics education.",2010,83,506,20,1,9,33,35,40,46,52,58,55,92
d4d7370670ffa790900ff05f96c208c9eda7d58b,"Graph theory models the Internet mathematically, and a number of plausible mathematically intersecting network models for the Internet have been developed and studied. Simultaneously, Internet researchers have developed methodology to use real data to validate, or invalidate, proposed Internet models. The authors look at these parallel developments, particularly as they apply to scale-free network models of the preferential attachment type.",2009,73,228,11,8,19,28,28,24,18,26,16,16,9
af30825f0c8adf31cf82028c8b50889b716ac362,"The work is giving estimations of the discrepancy between solutions of the initial and the homogenized problems for a one{dimensional second order elliptic operators with random coeecients satisfying strong or uniform mixing conditions. We obtain several sharp estimates in terms of the corresponding mixing coeecient. Abstract. In the theory of homogenisation it is of particular interest to determine the classes of problems which are stable on taking the homogenisation limits. A notable situation where the limit enlarges the class of original problems is known as memory (nonlocal) eeects. A number of results in that direction has been obtained for linear problems. Tartar (1990) innitiated the study of the eeective equation corresponding to nonlinear equation: @ t u n + a n u 2 n = f: Signiicant progress has been hampered by the complexity of required computations needed in order to obtain the terms in power{series expansion. We propose a method which overcomes that diiculty by introducing graphs representing the domain of integration of the integrals in each term. The graphs are relatively simple, it is easy to calculate with them and they give us a clear image of the form of each term. The method allows us to discuss the form of the eeective equation and the convergence of power{series expansions. The feasibility of our method for other types of nonlinearities will be discussed as well.",2010,40,569,7,58,54,70,82,115,47,12,7,10,6
e38ac5b98197284537fca03d8592adaae48841d4,"To understand the difficulties that many students have with comprehension of mathematics, we must determine the cognitive functioning underlying the diversity of mathematical processes. What are the cognitive systems that are required to give access to mathematical objects? Are these systems common to all processes of knowledge or, on the contrary, some of them are specific to mathematical activity? Starting from the paramount importance of semiotic representation for any mathematical activity, we put forward a classification of the various registers of semiotic representations that are mobilized in mathematical processes. Thus, we can reveal two types of transformation of semiotic representations: treatment and conversion. These two types correspond to quite different cognitive processes. They are two separate sources of incomprehension in the learning of mathematics. If treatment is the more important from a mathematical point of view, conversion is basically the deciding factor for learning. Supporting empirical data, at any level of curriculum and for any area of mathematics, can be widely and methodologically gathered: some empirical evidence is presented in this paper.",2006,28,901,111,10,12,20,25,59,41,61,55,62,91
786364fdd5a792fec5c5aaf23b87acbc4b57818b,"Abstract This study examines changes in teachers’ thinking as they participated in a video club designed to help them learn to notice and interpret students’ mathematical thinking. First, we investigate changes in teachers’ talk about classroom video segments before and after participation in the video club. Second, we identify three paths along which teachers learned to notice students’ mathematical thinking in this context: Direct, Cyclical, and Incremental. Finally, we explore ways the video club context influenced teacher learning. Understanding different forms of teacher learning provides insight for research on teacher cognition and may inform the design of video-based professional development.",2008,96,735,68,7,12,19,36,34,38,64,82,69,79
fe88603a338c69f37931facd17f22d6c4b5d5fe1,"Return by mail or fax to: SIAM Connie Young, Conference Director 3600 Market Street – 6 Floor Philadelphia, PA 19104-2688 Fax: 215-386-7999 Personal Information Name: _______________________________________________________________ Affiliation: _______________________________________________________________ Conference Name: _______________________________________________________________ Conference Location: _______________________________________________________________",2010,0,457,15,29,46,51,47,51,34,34,25,16,21
e7a5ff509962afa8850e1e682ebc224018366054,"Although it is often assumed that abilities that reflect basic numerical understanding, such as numerical comparison, are related to children's mathematical abilities, this relationship has not been tested rigorously. In addition, the extent to which symbolic and nonsymbolic number processing play differential roles in this relationship is not yet understood. To address these questions, we collected mathematics achievement measures from 6- to 8-year-olds as well as reaction times from a numerical comparison task. Using the reaction times, we calculated the size of the numerical distance effect exhibited by each child. In a correlational analysis, we found that the individual differences in the distance effect were related to mathematics achievement but not to reading achievement. This relationship was found to be specific to symbolic numerical comparison. Implications for the role of basic numerical competency and the role of accessing numerical magnitude information from Arabic numerals for the development of mathematical skills and their impairment are discussed.",2009,42,588,57,20,21,40,52,53,63,70,75,63,43
cd3a45bdd2c0ebdcfe4f2353da16c8c11ae5cb7f,"Boston College is an equal opportunity, affi rmative action employer.",2004,0,1142,63,2,15,33,42,62,78,86,89,152,109
0cd7e5ea0d7d91be0c9ce76406a1b57f8b57a3f2,"Relational mathematics is to operations research and informatics what numerical mathematics is to engineering: it is intended to help modelling, reasoning, and computing. Its applications are therefore diverse, ranging from psychology, linguistics, decision aid, and ranking to machine learning and spatial reasoning. Although many developments have been made in recent years, they have rarely been shared amongst this broad community of researchers. This first comprehensive overview begins with an easy introduction to the topic, assuming a minimum of prerequisites; but it is nevertheless theoretically sound and up to date. It is suitable for applied scientists, explaining all the necessary mathematics from scratch using a multitude of visualised examples, via matrices and graphs. It ends with tangible results on the research level. The author illustrates the theory and demonstrates practical tasks in operations research, social sciences and the humanities.",2010,0,116,14,0,7,11,9,23,21,10,13,7,4
0a4cf8c0ecf60c39234d48d9d99e03c804e067db,"We're performing all possible to bring our users the most effective books like Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics Download PDF free of charge download. Both you are looking for the book in PDF or EPUB our reference brings Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematicsto you in every possible format. You can obtain the Kindle app and then from Amazon Kindle store you are able to acquire Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics. Ebook Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics and a great many other books can be plumped for divided in to the class develop our website has therefore many categories it has a primarily old collection if you are enthusiastic about the old collection then you can certainly definitely go for it. The very best internet site to obtain Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics and all types of ebooks. They have around 2.5 million books. The same PDF version of any record is available from your personal computer or cellular devices that have a web connection to get Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics Download PDF for free. All the data on this amazing site is published in excellent trust and for normal data function only. Therefore you can easily obtain Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics. There's also some books however beneath the copyright which are offered for free on our site by specific arrangement with the author, like Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics. From this website, you are able to download Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics for free and even contribute or correct. This website is one of many sites for getting free Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics Download PDF. If you're having problem downloading Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics guide or if the hyperlinks aren't functioning, please create to email. We will change it, or send it for your requirements by email. Our digital library preserves in substance nations, letting you get the most less latency age to obtain any of our books subsequent that one. Just said, the Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics Download PDF is generally compatible afterward any units to read. As acknowledged, adventure as without problem as knowledge very almost session, entertainment, as skillfully as a package could be gotten by just looking at a guide Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics Download PDF next it is maybe not directly done, you might consent a lot more very nearly that life, on the buy of the world.",2010,201,322,32,10,16,6,10,11,23,14,19,27,36
1f80d103e387aeaa3513078745c41027b0f0f2a2,"Reprinted with permission from the Fall 2005 issue of American Educator, the quarterly journal of the American Federation of Teachers, AFL-CIO.",2005,17,900,78,3,9,28,37,43,65,50,68,89,91
2c5895c47012b9c42fad64e103f0a80fdacfd635,"This study examines the magnitude, destinations, and determinants of mathematics and science teacher turnover. The data are from the nationally representative Schools and Staffing Survey and the Teacher Follow-Up Survey. Over the past two decades, rates of mathematics and science teacher turnover have increased but, contrary to conventional wisdom, have not been consistently different than those of other teachers. Also, contrary to conventional wisdom, mathematics and science teachers were also no more likely than other teachers to take noneducation jobs, such as in technological fields or to be working for private business or industry. The data also show there are large school-to-school differences in mathematics and science turnover; high-poverty, high-minority, and urban public schools have among the highest rates. In the case of cross-school migration, the data show there is an annual asymmetric reshuffling of a significant portion of the mathematics and science teaching force from poor to not-poor schools, from high-minority to low-minority schools, and from urban to suburban schools. A number of key organizational characteristics and conditions of schools accounted for these school differences. The strongest factor for mathematics teachers was the degree of individual classroom autonomy held by teachers. Net of other factors such as salaries, schools with less classroom autonomy lose math teachers at a far higher rate than other teachers. In contrast, for science teachers salary was the strongest factor, while classroom autonomy was not strongly related to their turnover.",2010,144,278,31,1,4,12,12,24,22,28,32,43,33
69e23a9a149d7550b1afc324f326b264992693ce,"This study investigated adolescents’ developmental trajectories of mathematics interest and explored related effects of gender, family, and school context.Latent growth curvemodelingwas usedtoanalyzelongitudinaldataofN 53,193students(51%female)fromgrades5to9fromall3 ability tracks of the German state school system. Annual assessments involved student questionnaires on interest in mathematics, perceptions of classroom characteristics (classroom values for mathematics, mathematics teacher enthusiasm), as well as parent questionnaires regarding family values for mathematics. Results indicated a downward trend of students’ mathematics interest that plateaued in later years, with high variability in mean levels, but little variability in the shape of the growth trajectories. Boys reported higher mathematics interest than girls, but similar downward growth trajectories. Students from the lowest ability track showed more favorable interest trajectories than students from the middle and highest tracks. Family values andclassroomcharacteristicswerepositivelyrelatedtowithin-personlevelsofinterestovertime and to average individual levels of interest, but not to growth parameters. Theoretical and practical implications are discussed.",2010,116,313,16,4,5,15,15,17,31,31,33,54,36
a16f7f1fe98951487b7b83097b47f43f9e83ac1c,"Early childhood mathematics is vitally important for young children's present and future educational success. Research demonstrates that virtually all young children have the capability to learn and become competent in mathematics. Furthermore, young children enjoy their early informal experiences with mathematics. Unfortunately, many children's potential in mathematics is not fully realized, especially those children who are economically disadvantaged. This is due, in part, to a lack of opportunities to learn mathematics in early childhood settings or through everyday experiences in the home and in their communities. Improvements in early childhood mathematics education can provide young children with the foundation for school success. Relying on a comprehensive review of the research, Mathematics Learning in Early Childhood lays out the critical areas that should be the focus of young children's early mathematics education, explores the extent to which they are currently being incorporated in early childhood settings, and identifies the changes needed to improve the quality of mathematics experiences for young children. This book serves as a call to action to improve the state of early childhood mathematics. It will be especially useful for policy makers and practitioners-those who work directly with children and their families in shaping the policies that affect the education of young children.",2009,0,439,33,4,10,17,26,46,38,56,52,34,53
e2ce8e9f362fb1caf22cf5b7ad038dc9753c1190,"In this article we discuss efforts to design and empirically test measures of teachers’ content knowledge for teaching elementary mathematics. We begin by reviewing the literature on teacher knowledge, noting how scholars have organized such knowledge. Next we describe survey items we wrote to represent knowledge for teaching mathematics and results from factor analysis and scaling work with these items. We found that teachers’ knowledge for teaching elementary mathematics was multidimensional and included knowledge of various mathematical topics (e.g., number and operations, algebra) and domains (e.g., knowledge of content, knowledge of students and content). The constructs indicated by factor analysis formed psychometrically acceptable scales.",2004,37,899,70,2,5,12,30,56,37,52,48,71,94
9d0c4389436d3ab8ed329dba8c58e8ac6737fd3b,"Many models for the spread of infectious diseases in populations have been analyzed mathematically and applied to specific diseases. Threshold theorems involving the basic reproduction number $R_{0}$, the contact number $\sigma$, and the replacement number $R$ are reviewed for the classic SIR epidemic and endemic models. Similar results with new expressions for $R_{0}$ are obtained for MSEIR and SEIR endemic models with either continuous age or age groups. Values of $R_{0}$ and $\sigma$ are estimated for various diseases including measles in Niger and pertussis in the United States. Previous models with age structure, heterogeneity, and spatial structure are surveyed.",2000,226,4881,259,0,10,20,43,55,80,121,124,129,154
d3d720baa7080594c2fad06bb2ac90cc46666735,"The goals of this chapter are (1) to outline and substantiate a broad conceptualization of what it means to think mathematically, (2) to summarize the literature relevant to understanding mathematical thinking and problem solving, and (3) to point to new directions in research, development, and assessment consonant with an emerging understanding of mathematical thinking and the goals for instruction outlined here. The use of the phrase “learning to think mathematically” in this chapter’s title is deliberately broad. Although the original charter for this chapter was to review the literature on problem solving and metacognition, the literature itself is somewhat ill defined and poorly grounded. As the literature summary will make clear, problem solving has been used with multiple meanings that range from “working rote exercises” to “doing mathematics as a professional”; metacognition has multiple and almost disjoint meanings (from knowledge about one’s thought processes to self-regulation during problem solving) that make it difficult to use as a concept. This chapter outlines the various meanings that have been ascribed to these terms and discusses their role in mathematical thinking. The discussion will not have the character of a classic literature review, which is typically encyclopedic in its references and telegraphic in its discussions of individual papers or results. It will, instead, be selective and illustrative, with main points illustrated by extended discussions of pertinent examples. Problem solving has, as predicted in the 1980 Yearbook of the National Council of Teachers of Mathematics (Krulik, 1980, p. xiv), been the theme of the 1980s. The decade began with NCTM’s widely heralded statement, in its Agenda for Action, that “problem solving must be the focus of school mathematics” (NCTM, 1980, p. 1). It concluded with the publication of Everybody Counts (National Research Council, 1989) and the Curriculum and Evaluation Standards for School Mathematics (NCTM, 1989), both of which emphasize problem solving. One might infer, then, that there is general acceptance of the idea that the primary goal of mathematics instruction should be to have students become competent problem solvers. Yet, given the multiple interpretations of the term, the goal is hardly clear. Equally unclear is the role that problem solving, once adequately characterized, should play in the larger context of school mathematics. What are the goals for mathematics instruction, and how does problem solving fit within those goals? Such questions are complex. Goals for mathematics instruction depend on one’s conceptualization of what mathematics is, and what it means to understand mathematics. Such conceptualizations vary widely. At one end of the spectrum, mathematical knowledge is seen as a body of facts and procedures dealing with quantities, magnitudes, and forms, and the relationships among them; knowing mathematics is seen as having mastered these facts and procedures. At the other end of the spectrum, mathematics is conceptualized as the “science of patterns,” an (almost) empirical discipline closely akin to the sciences in its emphasis on pattern-seeking on the basis of empirical evidence. The author’s view is that the former perspective trivializes mathematics; that a curriculum based on mastering a corpus of mathematical facts and procedures is severely impoverished—in much the same way that an English curriculum would be considered impoverished if it focused largely, if not exclusively, on issues of grammar. The author characterizes the mathematical enterprise as follows:",2009,239,2893,267,123,144,163,155,189,196,226,163,163,178
f2e713dd0a1ee11892a90e0fb448dd5981e63550,,2000,7,7984,20,159,178,250,232,270,267,306,357,411,430
d82b5eb828d803e2f3fe041db20af8536f0fe99e,Author's Preface to the Anniversary Edition Series Editor's Introduction to the Anniversary Edition A Note about the Anniversary Edition Foreword Acknowledgments Introduction 1. Subtraction With Regrouping: Approaches To Teaching A Topic 2. Multidigit Number Multiplication: Dealing With Students' Mistakes 3. Generating Representations: Division By Fractions 4. Exploring New Knowledge: The Relationship Between Perimeter And Area 5. Teachers' Subject Matter Knowledge: Profound Understanding Of Fundamental Mathematics 6. Profound Understanding Of Fundamental Mathematics: When And How Is It Attained 7. Conclusion Appendix References New to the Anniversary Edition: Journal Article #1 New to the Anniversary Edition: Journal Article #2 Author Index Subject Index,2010,0,1684,360,141,143,135,137,149,142,142,129,128,88
7f3b042c8337fe9195ed6ca0cb017b76bbf1ff7c,"868 NOTICES OF THE AMS VOLUME 47, NUMBER 8 In April 2000 the National Council of Teachers of Mathematics (NCTM) released Principles and Standards for School Mathematics—the culmination of a multifaceted, three-year effort to update NCTM’s earlier standards documents and to set forth goals and recommendations for mathematics education in the prekindergarten-through-grade-twelve years. As the chair of the Writing Group, I had the privilege to interact with all aspects of the development and review of this document and with the committed groups of people, including the members of the Writing Group, who contributed immeasurably to this process. This article provides some background about NCTM and the standards, the process of development, efforts to gather input and feedback, and ways in which feedback from the mathematics community influenced the document. The article concludes with a section that provides some suggestions for mathematicians who are interested in using Principles and Standards.",2000,17,2165,296,10,25,47,49,66,78,79,118,115,118
a9386eb6808b41238381c708f2642bcb7dc34b29,"This book is about mathematical ideas, about what mathematics means-and why. Abstract ideas, for the most part, arise via conceptual metaphor-metaphorical ideas projecting from the way we function in the everyday physical world. Where Mathematics Comes From argues that conceptual metaphor plays a central role in mathematical ideas within the cognitive unconscious-from arithmetic and algebra to sets and logic to infinity in all of its forms.",2002,40,1920,107,19,40,48,55,72,74,102,91,120,102
4526716b3789971eaaa81d507abb657a29009957,"A gender gap in mathematics achievement persists in some nations but not in others. In light of the underrepresentation of women in careers in science, technology, mathematics, and engineering, increasing research attention is being devoted to understanding gender differences in mathematics achievement, attitudes, and affect. The gender stratification hypothesis maintains that such gender differences are closely related to cultural variations in opportunity structures for girls and women. We meta-analyzed 2 major international data sets, the 2003 Trends in International Mathematics and Science Study and the Programme for International Student Assessment, representing 493,495 students 14-16 years of age, to estimate the magnitude of gender differences in mathematics achievement, attitudes, and affect across 69 nations throughout the world. Consistent with the gender similarities hypothesis, all of the mean effect sizes in mathematics achievement were very small (d < 0.15); however, national effect sizes showed considerable variability (ds = -0.42 to 0.40). Despite gender similarities in achievement, boys reported more positive math attitudes and affect (ds = 0.10 to 0.33); national effect sizes ranged from d = -0.61 to 0.89. In contrast to those of previous tests of the gender stratification hypothesis, our results point to specific domains of gender equity responsible for gender gaps in math. Gender equity in school enrollment, women's share of research jobs, and women's parliamentary representation were the most powerful predictors of cross-national variability in gender gaps in math. Results are situated within the context of existing research demonstrating apparently paradoxical effects of societal gender equity and highlight the significance of increasing girls' and women's agency cross-nationally.",2010,126,1105,71,16,49,80,93,98,97,99,98,126,108
2ed2cd231aad7ea8a2b69a60d6df7539d6ee107f,"Vol. 72: The Syntax and Semantics of lnfimtary Languages. Edited by J. Barwtse. IV, 268 pages. 1968. DM 18,I $ 5.00 Vol. 73: P. E. Conner, Lectures on the Action of a Finite Group. IV, 123 pages. 1968. DM 10,1 $ 2.80 Vol. 74:A Frohlich, Formal Groups. IV, 140pages. 1968. DM12, -I $3.30 Vol. 75: G. Lumer, Algebras de fonctions et espaces de Hardy. VI, 80 pages. 1968. DM 8,I $ 2. 20 Vol. 76: R. G. Swan, Algebraic K-Theory. IV, 262 pages. 1968. DM18,I$ 5.00",2001,497,1653,59,73,89,93,103,106,99,152,152,126,57
7385b1bcd94ed3904c0e1429e209c80249de0d2a,"In this article, we use meta-analysis to analyze gender differences in recent studies of mathematics performance. First, we meta-analyzed data from 242 studies published between 1990 and 2007, representing the testing of 1,286,350 people. Overall, d = 0.05, indicating no gender difference, and variance ratio = 1.08, indicating nearly equal male and female variances. Second, we analyzed data from large data sets based on probability sampling of U.S. adolescents over the past 20 years: the National Longitudinal Surveys of Youth, the National Education Longitudinal Study of 1988, the Longitudinal Study of American Youth, and the National Assessment of Educational Progress. Effect sizes for the gender difference ranged between -0.15 and +0.22. Variance ratios ranged from 0.88 to 1.34. Taken together, these findings support the view that males and females perform similarly in mathematics.",2010,211,625,39,0,7,22,37,57,67,61,64,74,93
f008393f240508c1686a468b2c67371a7cdcb354,,2009,0,948,91,8,35,43,56,81,101,105,96,74,112
861a8ccc4002510aa1c844ea6f2c41fba69623f4,"Abstract Working memory refers to a mental workspace, involved in controlling, regulating, and actively maintaining relevant information to accomplish complex cognitive tasks (e.g. mathematical processing). Despite the potential relevance of a relation between working memory and math for understanding developmental and individual differences in mathematical skills, the nature of this relationship is not well-understood. This paper reviews four approaches that address the relation of working memory and math: 1) dual task studies establishing the role of working memory during on-line math performance; 2) individual difference studies examining working memory in children with math difficulties; 3) studies of working memory as a predictor of mathematical outcomes; and 4) longitudinal studies of working memory and math. The goal of this review is to evaluate current information on the nature of the relationship between working memory and math provided by these four approaches, and to present some of the outstanding questions for future research.",2010,165,756,23,7,17,40,52,64,69,91,88,85,83
813c3c045849f82cac2db2f26cee0ca306349f28,"Children's mathematical skills were considered in relation to executive functions. Using multiple measures-including the Wisconsin Card Sorting Task (WCST), dual-task performance, Stroop task, and counting span-it was found that mathematical ability was significantly correlated with all measures of executive functioning, with the exception of dual-task performance. Furthermore, regression analyses revealed that each executive function measure predicted unique variance in mathematics ability. These results are discussed in terms of a central executive with diverse functions (Shallice & Burgess, 1996) and with recent evidence from Miyake, et al. (2000) showing the unity and diversity among executive functions. It is proposed that the particular difficulties for children of lower mathematical ability are lack of inhibition and poor working memory, which result in problems with switching and evaluation of new strategies for dealing with a particular task. The practical and theoretical implications of these results are discussed, along with suggestions for task changes and longitudinal studies that would clarify theoretical and developmental issues related to executive functioning.",2001,79,1320,73,0,2,5,18,38,25,30,34,54,60
deac6a43706ea11bdd9fb07a73b54a08f0c114fb,"Teachers and teacher educators interested in synthesizing their current practice with new mathematics standards will welcome this highly useful volume. Presented are cases of mathematics instruction drawn from research of nearly 500 classroom lessons. Readers will gain insight about how to foster a challenging, cognitively rich, and exciting classroom climate that propels students toward a richer understanding of mathematics.",2009,0,714,82,39,42,46,57,63,50,74,59,57,52
f65040c3aa910788931c27c73006c5f3bb1e7e85,,2008,10,1101,87,44,48,62,72,80,103,88,77,98,55
34fb621cf73b7bad25d77ff1229467a34f736474,"Children's number competencies over 6 time points, from the beginning of kindergarten to the middle of 1st grade, were examined in relation to their mathematics achievement over 5 later time points, from the end of 1st grade to the end of 3rd grade. The relation between early number competence and mathematics achievement was strong and significant throughout the study period. A sequential process growth curve model showed that kindergarten number competence predicted rate of growth in mathematics achievement between 1st and 3rd grades as well as achievement level through 3rd grade. Further, rate of growth in early number competence predicted mathematics performance level in 3rd grade. Although low-income children performed more poorly than their middle-income counterparts in mathematics achievement and progressed at a slower rate, their performance and growth were mediated through relatively weak kindergarten number competence. Similarly, the better performance and faster growth of children who entered kindergarten at an older age were explained by kindergarten number competence. The findings show the importance of early number competence for setting children's learning trajectories in elementary school mathematics.",2009,70,768,38,3,16,21,32,54,72,66,77,73,94
69727a18c999db42c1e0062dd75870b4751ecc90,,2002,0,1397,4,56,59,58,63,81,92,111,128,120,121
c46e0a3586addefd8ffa8aef34afb534b8c1501e,"A model of the relations among cognitive precursors, early numeracy skill, and mathematical outcomes was tested for 182 children from 4.5 to 7.5 years of age. The model integrates research from neuroimaging, clinical populations, and normal development in children and adults. It includes 3 precursor pathways: quantitative, linguistic, and spatial attention. These pathways (a) contributed independently to early numeracy skills during preschool and kindergarten and (b) related differentially to performance on a variety of mathematical outcomes 2 years later. The success of the model in accounting for performance highlights the need to understand the fundamental underlying skills that contribute to diverse forms of mathematical competence.",2010,67,510,47,1,10,10,37,46,49,59,71,66,62
06bdbd4f011e9497fddfc47654116feab28b63bd,"Between 5% and 8% of school-age children have some form of memory or cognitive deficit that interferes with their ability to learn concepts or procedures in one or more mathematical domains. A review of the arithmetical competencies of these children is provided, along with discussion of underlying memory and cognitive deficits and potential neural correlates. The deficits are discussed in terms of three subtypes of mathematics learning disability and in terms of a more general framework for linking research in mathematical cognition to research in learning disabilities.",2004,97,1068,158,5,27,28,49,42,51,68,57,83,95
c62e9c1114644b601296d860dd643ff86473071b,"Studies of teachers’ use of mathematics curriculum materials are particularly timely given the current availability of reform-inspired curriculum materials and the increasingly widespread practice of mandating the use of a single curriculum to regulate mathematics teaching. A review of the research on mathematics curriculum use over the last 25 years reveals significant variation in findings and in theoretical foundations. The aim of this review is to examine the ways that central constructs of this body of research—such as curriculum use, teaching, and curriculum materials—are conceptualized and to consider the impact of various conceptualizations on knowledge in the field. Drawing on the literature, the author offers a framework for characterizing and studying teachers’ interactions with curriculum materials.",2005,119,999,143,2,9,21,37,52,49,56,50,64,78
feeef8d91cec3a9ffe5cf135a36a7f8596426ae1,"Amid ongoing public speculation about the reasons for sex differences in careers in science and mathematics, we present a consensus statement that is based on the best available scientific evidence. Sex differences in science and math achievement and ability are smaller for the mid-range of the abilities distribution than they are for those with the highest levels of achievement and ability. Males are more variable on most measures of quantitative and visuospatial ability, which necessarily results in more males at both high- and low-ability extremes; the reasons why males are often more variable remain elusive. Successful careers in math and science require many types of cognitive abilities. Females tend to excel in verbal abilities, with large differences between females and males found when assessments include writing samples. High-level achievement in science and math requires the ability to communicate effectively and comprehend abstract ideas, so the female advantage in writing should be helpful in all academic domains. Males outperform females on most measures of visuospatial abilities, which have been implicated as contributing to sex differences on standardized exams in mathematics and science. An evolutionary account of sex differences in mathematics and science supports the conclusion that, although sex differences in math and science performance have not directly evolved, they could be indirectly related to differences in interests and specific brain and cognitive systems. We review the brain basis for sex differences in science and mathematics, describe consistent effects, and identify numerous possible correlates. Experience alters brain structures and functioning, so causal statements about brain differences and success in math and science are circular. A wide range of sociocultural forces contribute to sex differences in mathematics and science achievement and ability—including the effects of family, neighborhood, peer, and school influences; training and experience; and cultural practices. We conclude that early experience, biological factors, educational policy, and cultural context affect the number of women and men who pursue advanced study in science and math and that these effects add and interact in complex ways. There are no single or simple answers to the complex questions about sex differences in science and mathematics.",2007,486,906,89,4,19,34,48,46,75,75,61,68,69
62bcc660cbd54558d3fcd07bade3bb764a1a146c,"This study examined the effects of a computer game on students' mathematics achievement and motivation, and the role of prior mathematics knowledge, computer skill, and English language skill on their achievement and motivation as they played the game. A total of 193 students and 10 teachers participated in this study. The teachers were randomly assigned to experimental and control groups. A mixed method of quantitative and interviews were used with Multivariate Analysis of Co-Variance to analyze the data. The results indicated significant improvement of the achievement of the experimental versus control group. No significant improvement was found in the motivation of the groups. Students who played the games in their classrooms and school labs reported greater motivation compared to the ones who played the games only in the school labs. Prior knowledge, computer and English language skill did not play significant roles in achievement and motivation of the experimental group.",2010,65,509,22,4,18,29,45,44,57,67,52,69,57
8d07144332f130bcfc5a5d30716b84a7afecbf9f,"Impairments in executive function have been documented in school-age children with mathematical learning difficulties. However, the utility and specificity of preschool executive function abilities in predicting later mathematical achievement are poorly understood. This study examined linkages between children's developing executive function abilities at age 4 and children's subsequent achievement in mathematics at age 6, 1 year after school entry. The study sample consisted of a regionally representative cohort of 104 children followed prospectively from ages 2 to 6 years. At age 4, children completed a battery of executive function tasks that assessed planning, set shifting, and inhibitory control. Teachers completed the preschool version of the Behavior Rating Inventory of Executive Function. Clinical and classroom measures of children's mathematical achievement were collected at age 6. Results showed that children's performance on set shifting, inhibitory control, and general executive behavior measures during the preschool period accounted for substantial variability in children's early mathematical achievement at school. These associations persisted even after individual differences in general cognitive ability and reading achievement were taken into account. Findings suggest that early measures of executive function may be useful in identifying children who may experience difficulties learning mathematical skills and concepts. They also suggest that the scaffolding of these executive skills could potentially be a useful additional component in early mathematics education.",2010,83,506,20,1,9,33,35,40,46,52,58,55,92
d4d7370670ffa790900ff05f96c208c9eda7d58b,"Graph theory models the Internet mathematically, and a number of plausible mathematically intersecting network models for the Internet have been developed and studied. Simultaneously, Internet researchers have developed methodology to use real data to validate, or invalidate, proposed Internet models. The authors look at these parallel developments, particularly as they apply to scale-free network models of the preferential attachment type.",2009,73,228,11,8,19,28,28,24,18,26,16,16,9
af30825f0c8adf31cf82028c8b50889b716ac362,"The work is giving estimations of the discrepancy between solutions of the initial and the homogenized problems for a one{dimensional second order elliptic operators with random coeecients satisfying strong or uniform mixing conditions. We obtain several sharp estimates in terms of the corresponding mixing coeecient. Abstract. In the theory of homogenisation it is of particular interest to determine the classes of problems which are stable on taking the homogenisation limits. A notable situation where the limit enlarges the class of original problems is known as memory (nonlocal) eeects. A number of results in that direction has been obtained for linear problems. Tartar (1990) innitiated the study of the eeective equation corresponding to nonlinear equation: @ t u n + a n u 2 n = f: Signiicant progress has been hampered by the complexity of required computations needed in order to obtain the terms in power{series expansion. We propose a method which overcomes that diiculty by introducing graphs representing the domain of integration of the integrals in each term. The graphs are relatively simple, it is easy to calculate with them and they give us a clear image of the form of each term. The method allows us to discuss the form of the eeective equation and the convergence of power{series expansions. The feasibility of our method for other types of nonlinearities will be discussed as well.",2010,40,569,7,58,54,70,82,115,47,12,7,10,6
e38ac5b98197284537fca03d8592adaae48841d4,"To understand the difficulties that many students have with comprehension of mathematics, we must determine the cognitive functioning underlying the diversity of mathematical processes. What are the cognitive systems that are required to give access to mathematical objects? Are these systems common to all processes of knowledge or, on the contrary, some of them are specific to mathematical activity? Starting from the paramount importance of semiotic representation for any mathematical activity, we put forward a classification of the various registers of semiotic representations that are mobilized in mathematical processes. Thus, we can reveal two types of transformation of semiotic representations: treatment and conversion. These two types correspond to quite different cognitive processes. They are two separate sources of incomprehension in the learning of mathematics. If treatment is the more important from a mathematical point of view, conversion is basically the deciding factor for learning. Supporting empirical data, at any level of curriculum and for any area of mathematics, can be widely and methodologically gathered: some empirical evidence is presented in this paper.",2006,28,901,111,10,12,20,25,59,41,61,55,62,91
786364fdd5a792fec5c5aaf23b87acbc4b57818b,"Abstract This study examines changes in teachers’ thinking as they participated in a video club designed to help them learn to notice and interpret students’ mathematical thinking. First, we investigate changes in teachers’ talk about classroom video segments before and after participation in the video club. Second, we identify three paths along which teachers learned to notice students’ mathematical thinking in this context: Direct, Cyclical, and Incremental. Finally, we explore ways the video club context influenced teacher learning. Understanding different forms of teacher learning provides insight for research on teacher cognition and may inform the design of video-based professional development.",2008,96,735,68,7,12,19,36,34,38,64,82,69,79
fe88603a338c69f37931facd17f22d6c4b5d5fe1,"Return by mail or fax to: SIAM Connie Young, Conference Director 3600 Market Street – 6 Floor Philadelphia, PA 19104-2688 Fax: 215-386-7999 Personal Information Name: _______________________________________________________________ Affiliation: _______________________________________________________________ Conference Name: _______________________________________________________________ Conference Location: _______________________________________________________________",2010,0,457,15,29,46,51,47,51,34,34,25,16,21
e7a5ff509962afa8850e1e682ebc224018366054,"Although it is often assumed that abilities that reflect basic numerical understanding, such as numerical comparison, are related to children's mathematical abilities, this relationship has not been tested rigorously. In addition, the extent to which symbolic and nonsymbolic number processing play differential roles in this relationship is not yet understood. To address these questions, we collected mathematics achievement measures from 6- to 8-year-olds as well as reaction times from a numerical comparison task. Using the reaction times, we calculated the size of the numerical distance effect exhibited by each child. In a correlational analysis, we found that the individual differences in the distance effect were related to mathematics achievement but not to reading achievement. This relationship was found to be specific to symbolic numerical comparison. Implications for the role of basic numerical competency and the role of accessing numerical magnitude information from Arabic numerals for the development of mathematical skills and their impairment are discussed.",2009,42,588,57,20,21,40,52,53,63,70,75,63,43
cd3a45bdd2c0ebdcfe4f2353da16c8c11ae5cb7f,"Boston College is an equal opportunity, affi rmative action employer.",2004,0,1142,63,2,15,33,42,62,78,86,89,152,109
0cd7e5ea0d7d91be0c9ce76406a1b57f8b57a3f2,"Relational mathematics is to operations research and informatics what numerical mathematics is to engineering: it is intended to help modelling, reasoning, and computing. Its applications are therefore diverse, ranging from psychology, linguistics, decision aid, and ranking to machine learning and spatial reasoning. Although many developments have been made in recent years, they have rarely been shared amongst this broad community of researchers. This first comprehensive overview begins with an easy introduction to the topic, assuming a minimum of prerequisites; but it is nevertheless theoretically sound and up to date. It is suitable for applied scientists, explaining all the necessary mathematics from scratch using a multitude of visualised examples, via matrices and graphs. It ends with tangible results on the research level. The author illustrates the theory and demonstrates practical tasks in operations research, social sciences and the humanities.",2010,0,116,14,0,7,11,9,23,21,10,13,7,4
0a4cf8c0ecf60c39234d48d9d99e03c804e067db,"We're performing all possible to bring our users the most effective books like Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics Download PDF free of charge download. Both you are looking for the book in PDF or EPUB our reference brings Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematicsto you in every possible format. You can obtain the Kindle app and then from Amazon Kindle store you are able to acquire Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics. Ebook Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics and a great many other books can be plumped for divided in to the class develop our website has therefore many categories it has a primarily old collection if you are enthusiastic about the old collection then you can certainly definitely go for it. The very best internet site to obtain Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics and all types of ebooks. They have around 2.5 million books. The same PDF version of any record is available from your personal computer or cellular devices that have a web connection to get Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics Download PDF for free. All the data on this amazing site is published in excellent trust and for normal data function only. Therefore you can easily obtain Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics. There's also some books however beneath the copyright which are offered for free on our site by specific arrangement with the author, like Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics. From this website, you are able to download Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics for free and even contribute or correct. This website is one of many sites for getting free Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics Download PDF. If you're having problem downloading Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics guide or if the hyperlinks aren't functioning, please create to email. We will change it, or send it for your requirements by email. Our digital library preserves in substance nations, letting you get the most less latency age to obtain any of our books subsequent that one. Just said, the Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics Download PDF is generally compatible afterward any units to read. As acknowledged, adventure as without problem as knowledge very almost session, entertainment, as skillfully as a package could be gotten by just looking at a guide Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics Download PDF next it is maybe not directly done, you might consent a lot more very nearly that life, on the buy of the world.",2010,201,322,32,10,16,6,10,11,23,14,19,27,36
1f80d103e387aeaa3513078745c41027b0f0f2a2,"Reprinted with permission from the Fall 2005 issue of American Educator, the quarterly journal of the American Federation of Teachers, AFL-CIO.",2005,17,900,78,3,9,28,37,43,65,50,68,89,91
2c5895c47012b9c42fad64e103f0a80fdacfd635,"This study examines the magnitude, destinations, and determinants of mathematics and science teacher turnover. The data are from the nationally representative Schools and Staffing Survey and the Teacher Follow-Up Survey. Over the past two decades, rates of mathematics and science teacher turnover have increased but, contrary to conventional wisdom, have not been consistently different than those of other teachers. Also, contrary to conventional wisdom, mathematics and science teachers were also no more likely than other teachers to take noneducation jobs, such as in technological fields or to be working for private business or industry. The data also show there are large school-to-school differences in mathematics and science turnover; high-poverty, high-minority, and urban public schools have among the highest rates. In the case of cross-school migration, the data show there is an annual asymmetric reshuffling of a significant portion of the mathematics and science teaching force from poor to not-poor schools, from high-minority to low-minority schools, and from urban to suburban schools. A number of key organizational characteristics and conditions of schools accounted for these school differences. The strongest factor for mathematics teachers was the degree of individual classroom autonomy held by teachers. Net of other factors such as salaries, schools with less classroom autonomy lose math teachers at a far higher rate than other teachers. In contrast, for science teachers salary was the strongest factor, while classroom autonomy was not strongly related to their turnover.",2010,144,278,31,1,4,12,12,24,22,28,32,43,33
69e23a9a149d7550b1afc324f326b264992693ce,"This study investigated adolescents’ developmental trajectories of mathematics interest and explored related effects of gender, family, and school context.Latent growth curvemodelingwas usedtoanalyzelongitudinaldataofN 53,193students(51%female)fromgrades5to9fromall3 ability tracks of the German state school system. Annual assessments involved student questionnaires on interest in mathematics, perceptions of classroom characteristics (classroom values for mathematics, mathematics teacher enthusiasm), as well as parent questionnaires regarding family values for mathematics. Results indicated a downward trend of students’ mathematics interest that plateaued in later years, with high variability in mean levels, but little variability in the shape of the growth trajectories. Boys reported higher mathematics interest than girls, but similar downward growth trajectories. Students from the lowest ability track showed more favorable interest trajectories than students from the middle and highest tracks. Family values andclassroomcharacteristicswerepositivelyrelatedtowithin-personlevelsofinterestovertime and to average individual levels of interest, but not to growth parameters. Theoretical and practical implications are discussed.",2010,116,313,16,4,5,15,15,17,31,31,33,54,36
a16f7f1fe98951487b7b83097b47f43f9e83ac1c,"Early childhood mathematics is vitally important for young children's present and future educational success. Research demonstrates that virtually all young children have the capability to learn and become competent in mathematics. Furthermore, young children enjoy their early informal experiences with mathematics. Unfortunately, many children's potential in mathematics is not fully realized, especially those children who are economically disadvantaged. This is due, in part, to a lack of opportunities to learn mathematics in early childhood settings or through everyday experiences in the home and in their communities. Improvements in early childhood mathematics education can provide young children with the foundation for school success. Relying on a comprehensive review of the research, Mathematics Learning in Early Childhood lays out the critical areas that should be the focus of young children's early mathematics education, explores the extent to which they are currently being incorporated in early childhood settings, and identifies the changes needed to improve the quality of mathematics experiences for young children. This book serves as a call to action to improve the state of early childhood mathematics. It will be especially useful for policy makers and practitioners-those who work directly with children and their families in shaping the policies that affect the education of young children.",2009,0,439,33,4,10,17,26,46,38,56,52,34,53
e2ce8e9f362fb1caf22cf5b7ad038dc9753c1190,"In this article we discuss efforts to design and empirically test measures of teachers’ content knowledge for teaching elementary mathematics. We begin by reviewing the literature on teacher knowledge, noting how scholars have organized such knowledge. Next we describe survey items we wrote to represent knowledge for teaching mathematics and results from factor analysis and scaling work with these items. We found that teachers’ knowledge for teaching elementary mathematics was multidimensional and included knowledge of various mathematical topics (e.g., number and operations, algebra) and domains (e.g., knowledge of content, knowledge of students and content). The constructs indicated by factor analysis formed psychometrically acceptable scales.",2004,37,899,70,2,5,12,30,56,37,52,48,71,94
99eaa4a03d94547bfb294460ce78ff9c753e0c2b,"Using contemporary data from the U.S. and other nations, we address 3 questions: Do gender differences in mathematics performance exist in the general population? Do gender differences exist among the mathematically talented? Do females exist who possess profound mathematical talent? In regard to the first question, contemporary data indicate that girls in the U.S. have reached parity with boys in mathematics performance, a pattern that is found in some other nations as well. Focusing on the second question, studies find more males than females scoring above the 95th or 99th percentile, but this gender gap has significantly narrowed over time in the U.S. and is not found among some ethnic groups and in some nations. Furthermore, data from several studies indicate that greater male variability with respect to mathematics is not ubiquitous. Rather, its presence correlates with several measures of gender inequality. Thus, it is largely an artifact of changeable sociocultural factors, not immutable, innate biological differences between the sexes. Responding to the third question, we document the existence of females who possess profound mathematical talent. Finally, we review mounting evidence that both the magnitude of mean math gender differences and the frequency of identification of gifted and profoundly gifted females significantly correlate with sociocultural factors, including measures of gender equality across nations.",2009,56,435,21,8,16,22,30,40,36,43,24,52,60
9d0c4389436d3ab8ed329dba8c58e8ac6737fd3b,"Many models for the spread of infectious diseases in populations have been analyzed mathematically and applied to specific diseases. Threshold theorems involving the basic reproduction number $R_{0}$, the contact number $\sigma$, and the replacement number $R$ are reviewed for the classic SIR epidemic and endemic models. Similar results with new expressions for $R_{0}$ are obtained for MSEIR and SEIR endemic models with either continuous age or age groups. Values of $R_{0}$ and $\sigma$ are estimated for various diseases including measles in Niger and pertussis in the United States. Previous models with age structure, heterogeneity, and spatial structure are surveyed.",2000,226,4881,259,0,10,20,43,55,80,121,124,129,154
d3d720baa7080594c2fad06bb2ac90cc46666735,"The goals of this chapter are (1) to outline and substantiate a broad conceptualization of what it means to think mathematically, (2) to summarize the literature relevant to understanding mathematical thinking and problem solving, and (3) to point to new directions in research, development, and assessment consonant with an emerging understanding of mathematical thinking and the goals for instruction outlined here. The use of the phrase “learning to think mathematically” in this chapter’s title is deliberately broad. Although the original charter for this chapter was to review the literature on problem solving and metacognition, the literature itself is somewhat ill defined and poorly grounded. As the literature summary will make clear, problem solving has been used with multiple meanings that range from “working rote exercises” to “doing mathematics as a professional”; metacognition has multiple and almost disjoint meanings (from knowledge about one’s thought processes to self-regulation during problem solving) that make it difficult to use as a concept. This chapter outlines the various meanings that have been ascribed to these terms and discusses their role in mathematical thinking. The discussion will not have the character of a classic literature review, which is typically encyclopedic in its references and telegraphic in its discussions of individual papers or results. It will, instead, be selective and illustrative, with main points illustrated by extended discussions of pertinent examples. Problem solving has, as predicted in the 1980 Yearbook of the National Council of Teachers of Mathematics (Krulik, 1980, p. xiv), been the theme of the 1980s. The decade began with NCTM’s widely heralded statement, in its Agenda for Action, that “problem solving must be the focus of school mathematics” (NCTM, 1980, p. 1). It concluded with the publication of Everybody Counts (National Research Council, 1989) and the Curriculum and Evaluation Standards for School Mathematics (NCTM, 1989), both of which emphasize problem solving. One might infer, then, that there is general acceptance of the idea that the primary goal of mathematics instruction should be to have students become competent problem solvers. Yet, given the multiple interpretations of the term, the goal is hardly clear. Equally unclear is the role that problem solving, once adequately characterized, should play in the larger context of school mathematics. What are the goals for mathematics instruction, and how does problem solving fit within those goals? Such questions are complex. Goals for mathematics instruction depend on one’s conceptualization of what mathematics is, and what it means to understand mathematics. Such conceptualizations vary widely. At one end of the spectrum, mathematical knowledge is seen as a body of facts and procedures dealing with quantities, magnitudes, and forms, and the relationships among them; knowing mathematics is seen as having mastered these facts and procedures. At the other end of the spectrum, mathematics is conceptualized as the “science of patterns,” an (almost) empirical discipline closely akin to the sciences in its emphasis on pattern-seeking on the basis of empirical evidence. The author’s view is that the former perspective trivializes mathematics; that a curriculum based on mastering a corpus of mathematical facts and procedures is severely impoverished—in much the same way that an English curriculum would be considered impoverished if it focused largely, if not exclusively, on issues of grammar. The author characterizes the mathematical enterprise as follows:",2009,239,2893,267,123,144,163,155,189,196,226,163,163,178
f2e713dd0a1ee11892a90e0fb448dd5981e63550,,2000,7,7984,20,159,178,250,232,270,267,306,357,411,430
d82b5eb828d803e2f3fe041db20af8536f0fe99e,Author's Preface to the Anniversary Edition Series Editor's Introduction to the Anniversary Edition A Note about the Anniversary Edition Foreword Acknowledgments Introduction 1. Subtraction With Regrouping: Approaches To Teaching A Topic 2. Multidigit Number Multiplication: Dealing With Students' Mistakes 3. Generating Representations: Division By Fractions 4. Exploring New Knowledge: The Relationship Between Perimeter And Area 5. Teachers' Subject Matter Knowledge: Profound Understanding Of Fundamental Mathematics 6. Profound Understanding Of Fundamental Mathematics: When And How Is It Attained 7. Conclusion Appendix References New to the Anniversary Edition: Journal Article #1 New to the Anniversary Edition: Journal Article #2 Author Index Subject Index,2010,0,1684,360,141,143,135,137,149,142,142,129,128,88
7f3b042c8337fe9195ed6ca0cb017b76bbf1ff7c,"868 NOTICES OF THE AMS VOLUME 47, NUMBER 8 In April 2000 the National Council of Teachers of Mathematics (NCTM) released Principles and Standards for School Mathematics—the culmination of a multifaceted, three-year effort to update NCTM’s earlier standards documents and to set forth goals and recommendations for mathematics education in the prekindergarten-through-grade-twelve years. As the chair of the Writing Group, I had the privilege to interact with all aspects of the development and review of this document and with the committed groups of people, including the members of the Writing Group, who contributed immeasurably to this process. This article provides some background about NCTM and the standards, the process of development, efforts to gather input and feedback, and ways in which feedback from the mathematics community influenced the document. The article concludes with a section that provides some suggestions for mathematicians who are interested in using Principles and Standards.",2000,17,2165,296,10,25,47,49,66,78,79,118,115,118
a9386eb6808b41238381c708f2642bcb7dc34b29,"This book is about mathematical ideas, about what mathematics means-and why. Abstract ideas, for the most part, arise via conceptual metaphor-metaphorical ideas projecting from the way we function in the everyday physical world. Where Mathematics Comes From argues that conceptual metaphor plays a central role in mathematical ideas within the cognitive unconscious-from arithmetic and algebra to sets and logic to infinity in all of its forms.",2002,40,1920,107,19,40,48,55,72,74,102,91,120,102
4526716b3789971eaaa81d507abb657a29009957,"A gender gap in mathematics achievement persists in some nations but not in others. In light of the underrepresentation of women in careers in science, technology, mathematics, and engineering, increasing research attention is being devoted to understanding gender differences in mathematics achievement, attitudes, and affect. The gender stratification hypothesis maintains that such gender differences are closely related to cultural variations in opportunity structures for girls and women. We meta-analyzed 2 major international data sets, the 2003 Trends in International Mathematics and Science Study and the Programme for International Student Assessment, representing 493,495 students 14-16 years of age, to estimate the magnitude of gender differences in mathematics achievement, attitudes, and affect across 69 nations throughout the world. Consistent with the gender similarities hypothesis, all of the mean effect sizes in mathematics achievement were very small (d < 0.15); however, national effect sizes showed considerable variability (ds = -0.42 to 0.40). Despite gender similarities in achievement, boys reported more positive math attitudes and affect (ds = 0.10 to 0.33); national effect sizes ranged from d = -0.61 to 0.89. In contrast to those of previous tests of the gender stratification hypothesis, our results point to specific domains of gender equity responsible for gender gaps in math. Gender equity in school enrollment, women's share of research jobs, and women's parliamentary representation were the most powerful predictors of cross-national variability in gender gaps in math. Results are situated within the context of existing research demonstrating apparently paradoxical effects of societal gender equity and highlight the significance of increasing girls' and women's agency cross-nationally.",2010,126,1105,71,16,49,80,93,98,97,99,98,126,108
2ed2cd231aad7ea8a2b69a60d6df7539d6ee107f,"Vol. 72: The Syntax and Semantics of lnfimtary Languages. Edited by J. Barwtse. IV, 268 pages. 1968. DM 18,I $ 5.00 Vol. 73: P. E. Conner, Lectures on the Action of a Finite Group. IV, 123 pages. 1968. DM 10,1 $ 2.80 Vol. 74:A Frohlich, Formal Groups. IV, 140pages. 1968. DM12, -I $3.30 Vol. 75: G. Lumer, Algebras de fonctions et espaces de Hardy. VI, 80 pages. 1968. DM 8,I $ 2. 20 Vol. 76: R. G. Swan, Algebraic K-Theory. IV, 262 pages. 1968. DM18,I$ 5.00",2001,497,1653,59,73,89,93,103,106,99,152,152,126,57
7385b1bcd94ed3904c0e1429e209c80249de0d2a,"In this article, we use meta-analysis to analyze gender differences in recent studies of mathematics performance. First, we meta-analyzed data from 242 studies published between 1990 and 2007, representing the testing of 1,286,350 people. Overall, d = 0.05, indicating no gender difference, and variance ratio = 1.08, indicating nearly equal male and female variances. Second, we analyzed data from large data sets based on probability sampling of U.S. adolescents over the past 20 years: the National Longitudinal Surveys of Youth, the National Education Longitudinal Study of 1988, the Longitudinal Study of American Youth, and the National Assessment of Educational Progress. Effect sizes for the gender difference ranged between -0.15 and +0.22. Variance ratios ranged from 0.88 to 1.34. Taken together, these findings support the view that males and females perform similarly in mathematics.",2010,211,625,39,0,7,22,37,57,67,61,64,74,93
f008393f240508c1686a468b2c67371a7cdcb354,,2009,0,948,91,8,35,43,56,81,101,105,96,74,112
861a8ccc4002510aa1c844ea6f2c41fba69623f4,"Abstract Working memory refers to a mental workspace, involved in controlling, regulating, and actively maintaining relevant information to accomplish complex cognitive tasks (e.g. mathematical processing). Despite the potential relevance of a relation between working memory and math for understanding developmental and individual differences in mathematical skills, the nature of this relationship is not well-understood. This paper reviews four approaches that address the relation of working memory and math: 1) dual task studies establishing the role of working memory during on-line math performance; 2) individual difference studies examining working memory in children with math difficulties; 3) studies of working memory as a predictor of mathematical outcomes; and 4) longitudinal studies of working memory and math. The goal of this review is to evaluate current information on the nature of the relationship between working memory and math provided by these four approaches, and to present some of the outstanding questions for future research.",2010,165,756,23,7,17,40,52,64,69,91,88,85,83
813c3c045849f82cac2db2f26cee0ca306349f28,"Children's mathematical skills were considered in relation to executive functions. Using multiple measures-including the Wisconsin Card Sorting Task (WCST), dual-task performance, Stroop task, and counting span-it was found that mathematical ability was significantly correlated with all measures of executive functioning, with the exception of dual-task performance. Furthermore, regression analyses revealed that each executive function measure predicted unique variance in mathematics ability. These results are discussed in terms of a central executive with diverse functions (Shallice & Burgess, 1996) and with recent evidence from Miyake, et al. (2000) showing the unity and diversity among executive functions. It is proposed that the particular difficulties for children of lower mathematical ability are lack of inhibition and poor working memory, which result in problems with switching and evaluation of new strategies for dealing with a particular task. The practical and theoretical implications of these results are discussed, along with suggestions for task changes and longitudinal studies that would clarify theoretical and developmental issues related to executive functioning.",2001,79,1320,73,0,2,5,18,38,25,30,34,54,60
deac6a43706ea11bdd9fb07a73b54a08f0c114fb,"Teachers and teacher educators interested in synthesizing their current practice with new mathematics standards will welcome this highly useful volume. Presented are cases of mathematics instruction drawn from research of nearly 500 classroom lessons. Readers will gain insight about how to foster a challenging, cognitively rich, and exciting classroom climate that propels students toward a richer understanding of mathematics.",2009,0,714,82,39,42,46,57,63,50,74,59,57,52
f65040c3aa910788931c27c73006c5f3bb1e7e85,,2008,10,1101,87,44,48,62,72,80,103,88,77,98,55
34fb621cf73b7bad25d77ff1229467a34f736474,"Children's number competencies over 6 time points, from the beginning of kindergarten to the middle of 1st grade, were examined in relation to their mathematics achievement over 5 later time points, from the end of 1st grade to the end of 3rd grade. The relation between early number competence and mathematics achievement was strong and significant throughout the study period. A sequential process growth curve model showed that kindergarten number competence predicted rate of growth in mathematics achievement between 1st and 3rd grades as well as achievement level through 3rd grade. Further, rate of growth in early number competence predicted mathematics performance level in 3rd grade. Although low-income children performed more poorly than their middle-income counterparts in mathematics achievement and progressed at a slower rate, their performance and growth were mediated through relatively weak kindergarten number competence. Similarly, the better performance and faster growth of children who entered kindergarten at an older age were explained by kindergarten number competence. The findings show the importance of early number competence for setting children's learning trajectories in elementary school mathematics.",2009,70,768,38,3,16,21,32,54,72,66,77,73,94
69727a18c999db42c1e0062dd75870b4751ecc90,,2002,0,1397,4,56,59,58,63,81,92,111,128,120,121
c46e0a3586addefd8ffa8aef34afb534b8c1501e,"A model of the relations among cognitive precursors, early numeracy skill, and mathematical outcomes was tested for 182 children from 4.5 to 7.5 years of age. The model integrates research from neuroimaging, clinical populations, and normal development in children and adults. It includes 3 precursor pathways: quantitative, linguistic, and spatial attention. These pathways (a) contributed independently to early numeracy skills during preschool and kindergarten and (b) related differentially to performance on a variety of mathematical outcomes 2 years later. The success of the model in accounting for performance highlights the need to understand the fundamental underlying skills that contribute to diverse forms of mathematical competence.",2010,67,510,47,1,10,10,37,46,49,59,71,66,62
c62e9c1114644b601296d860dd643ff86473071b,"Studies of teachers’ use of mathematics curriculum materials are particularly timely given the current availability of reform-inspired curriculum materials and the increasingly widespread practice of mandating the use of a single curriculum to regulate mathematics teaching. A review of the research on mathematics curriculum use over the last 25 years reveals significant variation in findings and in theoretical foundations. The aim of this review is to examine the ways that central constructs of this body of research—such as curriculum use, teaching, and curriculum materials—are conceptualized and to consider the impact of various conceptualizations on knowledge in the field. Drawing on the literature, the author offers a framework for characterizing and studying teachers’ interactions with curriculum materials.",2005,119,999,143,2,9,21,37,52,49,56,50,64,78
06bdbd4f011e9497fddfc47654116feab28b63bd,"Between 5% and 8% of school-age children have some form of memory or cognitive deficit that interferes with their ability to learn concepts or procedures in one or more mathematical domains. A review of the arithmetical competencies of these children is provided, along with discussion of underlying memory and cognitive deficits and potential neural correlates. The deficits are discussed in terms of three subtypes of mathematics learning disability and in terms of a more general framework for linking research in mathematical cognition to research in learning disabilities.",2004,97,1068,158,5,27,28,49,42,51,68,57,83,95
feeef8d91cec3a9ffe5cf135a36a7f8596426ae1,"Amid ongoing public speculation about the reasons for sex differences in careers in science and mathematics, we present a consensus statement that is based on the best available scientific evidence. Sex differences in science and math achievement and ability are smaller for the mid-range of the abilities distribution than they are for those with the highest levels of achievement and ability. Males are more variable on most measures of quantitative and visuospatial ability, which necessarily results in more males at both high- and low-ability extremes; the reasons why males are often more variable remain elusive. Successful careers in math and science require many types of cognitive abilities. Females tend to excel in verbal abilities, with large differences between females and males found when assessments include writing samples. High-level achievement in science and math requires the ability to communicate effectively and comprehend abstract ideas, so the female advantage in writing should be helpful in all academic domains. Males outperform females on most measures of visuospatial abilities, which have been implicated as contributing to sex differences on standardized exams in mathematics and science. An evolutionary account of sex differences in mathematics and science supports the conclusion that, although sex differences in math and science performance have not directly evolved, they could be indirectly related to differences in interests and specific brain and cognitive systems. We review the brain basis for sex differences in science and mathematics, describe consistent effects, and identify numerous possible correlates. Experience alters brain structures and functioning, so causal statements about brain differences and success in math and science are circular. A wide range of sociocultural forces contribute to sex differences in mathematics and science achievement and ability—including the effects of family, neighborhood, peer, and school influences; training and experience; and cultural practices. We conclude that early experience, biological factors, educational policy, and cultural context affect the number of women and men who pursue advanced study in science and math and that these effects add and interact in complex ways. There are no single or simple answers to the complex questions about sex differences in science and mathematics.",2007,486,906,89,4,19,34,48,46,75,75,61,68,69
62bcc660cbd54558d3fcd07bade3bb764a1a146c,"This study examined the effects of a computer game on students' mathematics achievement and motivation, and the role of prior mathematics knowledge, computer skill, and English language skill on their achievement and motivation as they played the game. A total of 193 students and 10 teachers participated in this study. The teachers were randomly assigned to experimental and control groups. A mixed method of quantitative and interviews were used with Multivariate Analysis of Co-Variance to analyze the data. The results indicated significant improvement of the achievement of the experimental versus control group. No significant improvement was found in the motivation of the groups. Students who played the games in their classrooms and school labs reported greater motivation compared to the ones who played the games only in the school labs. Prior knowledge, computer and English language skill did not play significant roles in achievement and motivation of the experimental group.",2010,65,509,22,4,18,29,45,44,57,67,52,69,57
8d07144332f130bcfc5a5d30716b84a7afecbf9f,"Impairments in executive function have been documented in school-age children with mathematical learning difficulties. However, the utility and specificity of preschool executive function abilities in predicting later mathematical achievement are poorly understood. This study examined linkages between children's developing executive function abilities at age 4 and children's subsequent achievement in mathematics at age 6, 1 year after school entry. The study sample consisted of a regionally representative cohort of 104 children followed prospectively from ages 2 to 6 years. At age 4, children completed a battery of executive function tasks that assessed planning, set shifting, and inhibitory control. Teachers completed the preschool version of the Behavior Rating Inventory of Executive Function. Clinical and classroom measures of children's mathematical achievement were collected at age 6. Results showed that children's performance on set shifting, inhibitory control, and general executive behavior measures during the preschool period accounted for substantial variability in children's early mathematical achievement at school. These associations persisted even after individual differences in general cognitive ability and reading achievement were taken into account. Findings suggest that early measures of executive function may be useful in identifying children who may experience difficulties learning mathematical skills and concepts. They also suggest that the scaffolding of these executive skills could potentially be a useful additional component in early mathematics education.",2010,83,506,20,1,9,33,35,40,46,52,58,55,92
d4d7370670ffa790900ff05f96c208c9eda7d58b,"Graph theory models the Internet mathematically, and a number of plausible mathematically intersecting network models for the Internet have been developed and studied. Simultaneously, Internet researchers have developed methodology to use real data to validate, or invalidate, proposed Internet models. The authors look at these parallel developments, particularly as they apply to scale-free network models of the preferential attachment type.",2009,73,228,11,8,19,28,28,24,18,26,16,16,9
af30825f0c8adf31cf82028c8b50889b716ac362,"The work is giving estimations of the discrepancy between solutions of the initial and the homogenized problems for a one{dimensional second order elliptic operators with random coeecients satisfying strong or uniform mixing conditions. We obtain several sharp estimates in terms of the corresponding mixing coeecient. Abstract. In the theory of homogenisation it is of particular interest to determine the classes of problems which are stable on taking the homogenisation limits. A notable situation where the limit enlarges the class of original problems is known as memory (nonlocal) eeects. A number of results in that direction has been obtained for linear problems. Tartar (1990) innitiated the study of the eeective equation corresponding to nonlinear equation: @ t u n + a n u 2 n = f: Signiicant progress has been hampered by the complexity of required computations needed in order to obtain the terms in power{series expansion. We propose a method which overcomes that diiculty by introducing graphs representing the domain of integration of the integrals in each term. The graphs are relatively simple, it is easy to calculate with them and they give us a clear image of the form of each term. The method allows us to discuss the form of the eeective equation and the convergence of power{series expansions. The feasibility of our method for other types of nonlinearities will be discussed as well.",2010,40,569,7,58,54,70,82,115,47,12,7,10,6
e38ac5b98197284537fca03d8592adaae48841d4,"To understand the difficulties that many students have with comprehension of mathematics, we must determine the cognitive functioning underlying the diversity of mathematical processes. What are the cognitive systems that are required to give access to mathematical objects? Are these systems common to all processes of knowledge or, on the contrary, some of them are specific to mathematical activity? Starting from the paramount importance of semiotic representation for any mathematical activity, we put forward a classification of the various registers of semiotic representations that are mobilized in mathematical processes. Thus, we can reveal two types of transformation of semiotic representations: treatment and conversion. These two types correspond to quite different cognitive processes. They are two separate sources of incomprehension in the learning of mathematics. If treatment is the more important from a mathematical point of view, conversion is basically the deciding factor for learning. Supporting empirical data, at any level of curriculum and for any area of mathematics, can be widely and methodologically gathered: some empirical evidence is presented in this paper.",2006,28,901,111,10,12,20,25,59,41,61,55,62,91
786364fdd5a792fec5c5aaf23b87acbc4b57818b,"Abstract This study examines changes in teachers’ thinking as they participated in a video club designed to help them learn to notice and interpret students’ mathematical thinking. First, we investigate changes in teachers’ talk about classroom video segments before and after participation in the video club. Second, we identify three paths along which teachers learned to notice students’ mathematical thinking in this context: Direct, Cyclical, and Incremental. Finally, we explore ways the video club context influenced teacher learning. Understanding different forms of teacher learning provides insight for research on teacher cognition and may inform the design of video-based professional development.",2008,96,735,68,7,12,19,36,34,38,64,82,69,79
fe88603a338c69f37931facd17f22d6c4b5d5fe1,"Return by mail or fax to: SIAM Connie Young, Conference Director 3600 Market Street – 6 Floor Philadelphia, PA 19104-2688 Fax: 215-386-7999 Personal Information Name: _______________________________________________________________ Affiliation: _______________________________________________________________ Conference Name: _______________________________________________________________ Conference Location: _______________________________________________________________",2010,0,457,15,29,46,51,47,51,34,34,25,16,21
e7a5ff509962afa8850e1e682ebc224018366054,"Although it is often assumed that abilities that reflect basic numerical understanding, such as numerical comparison, are related to children's mathematical abilities, this relationship has not been tested rigorously. In addition, the extent to which symbolic and nonsymbolic number processing play differential roles in this relationship is not yet understood. To address these questions, we collected mathematics achievement measures from 6- to 8-year-olds as well as reaction times from a numerical comparison task. Using the reaction times, we calculated the size of the numerical distance effect exhibited by each child. In a correlational analysis, we found that the individual differences in the distance effect were related to mathematics achievement but not to reading achievement. This relationship was found to be specific to symbolic numerical comparison. Implications for the role of basic numerical competency and the role of accessing numerical magnitude information from Arabic numerals for the development of mathematical skills and their impairment are discussed.",2009,42,588,57,20,21,40,52,53,63,70,75,63,43
cd3a45bdd2c0ebdcfe4f2353da16c8c11ae5cb7f,"Boston College is an equal opportunity, affi rmative action employer.",2004,0,1142,63,2,15,33,42,62,78,86,89,152,109
0cd7e5ea0d7d91be0c9ce76406a1b57f8b57a3f2,"Relational mathematics is to operations research and informatics what numerical mathematics is to engineering: it is intended to help modelling, reasoning, and computing. Its applications are therefore diverse, ranging from psychology, linguistics, decision aid, and ranking to machine learning and spatial reasoning. Although many developments have been made in recent years, they have rarely been shared amongst this broad community of researchers. This first comprehensive overview begins with an easy introduction to the topic, assuming a minimum of prerequisites; but it is nevertheless theoretically sound and up to date. It is suitable for applied scientists, explaining all the necessary mathematics from scratch using a multitude of visualised examples, via matrices and graphs. It ends with tangible results on the research level. The author illustrates the theory and demonstrates practical tasks in operations research, social sciences and the humanities.",2010,0,116,14,0,7,11,9,23,21,10,13,7,4
0a4cf8c0ecf60c39234d48d9d99e03c804e067db,"We're performing all possible to bring our users the most effective books like Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics Download PDF free of charge download. Both you are looking for the book in PDF or EPUB our reference brings Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematicsto you in every possible format. You can obtain the Kindle app and then from Amazon Kindle store you are able to acquire Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics. Ebook Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics and a great many other books can be plumped for divided in to the class develop our website has therefore many categories it has a primarily old collection if you are enthusiastic about the old collection then you can certainly definitely go for it. The very best internet site to obtain Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics and all types of ebooks. They have around 2.5 million books. The same PDF version of any record is available from your personal computer or cellular devices that have a web connection to get Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics Download PDF for free. All the data on this amazing site is published in excellent trust and for normal data function only. Therefore you can easily obtain Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics. There's also some books however beneath the copyright which are offered for free on our site by specific arrangement with the author, like Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics. From this website, you are able to download Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics for free and even contribute or correct. This website is one of many sites for getting free Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics Download PDF. If you're having problem downloading Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics guide or if the hyperlinks aren't functioning, please create to email. We will change it, or send it for your requirements by email. Our digital library preserves in substance nations, letting you get the most less latency age to obtain any of our books subsequent that one. Just said, the Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics Download PDF is generally compatible afterward any units to read. As acknowledged, adventure as without problem as knowledge very almost session, entertainment, as skillfully as a package could be gotten by just looking at a guide Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics Download PDF next it is maybe not directly done, you might consent a lot more very nearly that life, on the buy of the world.",2010,201,322,32,10,16,6,10,11,23,14,19,27,36
1f80d103e387aeaa3513078745c41027b0f0f2a2,"Reprinted with permission from the Fall 2005 issue of American Educator, the quarterly journal of the American Federation of Teachers, AFL-CIO.",2005,17,900,78,3,9,28,37,43,65,50,68,89,91
2c5895c47012b9c42fad64e103f0a80fdacfd635,"This study examines the magnitude, destinations, and determinants of mathematics and science teacher turnover. The data are from the nationally representative Schools and Staffing Survey and the Teacher Follow-Up Survey. Over the past two decades, rates of mathematics and science teacher turnover have increased but, contrary to conventional wisdom, have not been consistently different than those of other teachers. Also, contrary to conventional wisdom, mathematics and science teachers were also no more likely than other teachers to take noneducation jobs, such as in technological fields or to be working for private business or industry. The data also show there are large school-to-school differences in mathematics and science turnover; high-poverty, high-minority, and urban public schools have among the highest rates. In the case of cross-school migration, the data show there is an annual asymmetric reshuffling of a significant portion of the mathematics and science teaching force from poor to not-poor schools, from high-minority to low-minority schools, and from urban to suburban schools. A number of key organizational characteristics and conditions of schools accounted for these school differences. The strongest factor for mathematics teachers was the degree of individual classroom autonomy held by teachers. Net of other factors such as salaries, schools with less classroom autonomy lose math teachers at a far higher rate than other teachers. In contrast, for science teachers salary was the strongest factor, while classroom autonomy was not strongly related to their turnover.",2010,144,278,31,1,4,12,12,24,22,28,32,43,33
69e23a9a149d7550b1afc324f326b264992693ce,"This study investigated adolescents’ developmental trajectories of mathematics interest and explored related effects of gender, family, and school context.Latent growth curvemodelingwas usedtoanalyzelongitudinaldataofN 53,193students(51%female)fromgrades5to9fromall3 ability tracks of the German state school system. Annual assessments involved student questionnaires on interest in mathematics, perceptions of classroom characteristics (classroom values for mathematics, mathematics teacher enthusiasm), as well as parent questionnaires regarding family values for mathematics. Results indicated a downward trend of students’ mathematics interest that plateaued in later years, with high variability in mean levels, but little variability in the shape of the growth trajectories. Boys reported higher mathematics interest than girls, but similar downward growth trajectories. Students from the lowest ability track showed more favorable interest trajectories than students from the middle and highest tracks. Family values andclassroomcharacteristicswerepositivelyrelatedtowithin-personlevelsofinterestovertime and to average individual levels of interest, but not to growth parameters. Theoretical and practical implications are discussed.",2010,116,313,16,4,5,15,15,17,31,31,33,54,36
a16f7f1fe98951487b7b83097b47f43f9e83ac1c,"Early childhood mathematics is vitally important for young children's present and future educational success. Research demonstrates that virtually all young children have the capability to learn and become competent in mathematics. Furthermore, young children enjoy their early informal experiences with mathematics. Unfortunately, many children's potential in mathematics is not fully realized, especially those children who are economically disadvantaged. This is due, in part, to a lack of opportunities to learn mathematics in early childhood settings or through everyday experiences in the home and in their communities. Improvements in early childhood mathematics education can provide young children with the foundation for school success. Relying on a comprehensive review of the research, Mathematics Learning in Early Childhood lays out the critical areas that should be the focus of young children's early mathematics education, explores the extent to which they are currently being incorporated in early childhood settings, and identifies the changes needed to improve the quality of mathematics experiences for young children. This book serves as a call to action to improve the state of early childhood mathematics. It will be especially useful for policy makers and practitioners-those who work directly with children and their families in shaping the policies that affect the education of young children.",2009,0,439,33,4,10,17,26,46,38,56,52,34,53
e2ce8e9f362fb1caf22cf5b7ad038dc9753c1190,"In this article we discuss efforts to design and empirically test measures of teachers’ content knowledge for teaching elementary mathematics. We begin by reviewing the literature on teacher knowledge, noting how scholars have organized such knowledge. Next we describe survey items we wrote to represent knowledge for teaching mathematics and results from factor analysis and scaling work with these items. We found that teachers’ knowledge for teaching elementary mathematics was multidimensional and included knowledge of various mathematical topics (e.g., number and operations, algebra) and domains (e.g., knowledge of content, knowledge of students and content). The constructs indicated by factor analysis formed psychometrically acceptable scales.",2004,37,899,70,2,5,12,30,56,37,52,48,71,94
99eaa4a03d94547bfb294460ce78ff9c753e0c2b,"Using contemporary data from the U.S. and other nations, we address 3 questions: Do gender differences in mathematics performance exist in the general population? Do gender differences exist among the mathematically talented? Do females exist who possess profound mathematical talent? In regard to the first question, contemporary data indicate that girls in the U.S. have reached parity with boys in mathematics performance, a pattern that is found in some other nations as well. Focusing on the second question, studies find more males than females scoring above the 95th or 99th percentile, but this gender gap has significantly narrowed over time in the U.S. and is not found among some ethnic groups and in some nations. Furthermore, data from several studies indicate that greater male variability with respect to mathematics is not ubiquitous. Rather, its presence correlates with several measures of gender inequality. Thus, it is largely an artifact of changeable sociocultural factors, not immutable, innate biological differences between the sexes. Responding to the third question, we document the existence of females who possess profound mathematical talent. Finally, we review mounting evidence that both the magnitude of mean math gender differences and the frequency of identification of gifted and profoundly gifted females significantly correlate with sociocultural factors, including measures of gender equality across nations.",2009,56,435,21,8,16,22,30,40,36,43,24,52,60
9d0c4389436d3ab8ed329dba8c58e8ac6737fd3b,"Many models for the spread of infectious diseases in populations have been analyzed mathematically and applied to specific diseases. Threshold theorems involving the basic reproduction number $R_{0}$, the contact number $\sigma$, and the replacement number $R$ are reviewed for the classic SIR epidemic and endemic models. Similar results with new expressions for $R_{0}$ are obtained for MSEIR and SEIR endemic models with either continuous age or age groups. Values of $R_{0}$ and $\sigma$ are estimated for various diseases including measles in Niger and pertussis in the United States. Previous models with age structure, heterogeneity, and spatial structure are surveyed.",2000,226,4881,259,0,10,20,43,55,80,121,124,129,154
d3d720baa7080594c2fad06bb2ac90cc46666735,"The goals of this chapter are (1) to outline and substantiate a broad conceptualization of what it means to think mathematically, (2) to summarize the literature relevant to understanding mathematical thinking and problem solving, and (3) to point to new directions in research, development, and assessment consonant with an emerging understanding of mathematical thinking and the goals for instruction outlined here. The use of the phrase “learning to think mathematically” in this chapter’s title is deliberately broad. Although the original charter for this chapter was to review the literature on problem solving and metacognition, the literature itself is somewhat ill defined and poorly grounded. As the literature summary will make clear, problem solving has been used with multiple meanings that range from “working rote exercises” to “doing mathematics as a professional”; metacognition has multiple and almost disjoint meanings (from knowledge about one’s thought processes to self-regulation during problem solving) that make it difficult to use as a concept. This chapter outlines the various meanings that have been ascribed to these terms and discusses their role in mathematical thinking. The discussion will not have the character of a classic literature review, which is typically encyclopedic in its references and telegraphic in its discussions of individual papers or results. It will, instead, be selective and illustrative, with main points illustrated by extended discussions of pertinent examples. Problem solving has, as predicted in the 1980 Yearbook of the National Council of Teachers of Mathematics (Krulik, 1980, p. xiv), been the theme of the 1980s. The decade began with NCTM’s widely heralded statement, in its Agenda for Action, that “problem solving must be the focus of school mathematics” (NCTM, 1980, p. 1). It concluded with the publication of Everybody Counts (National Research Council, 1989) and the Curriculum and Evaluation Standards for School Mathematics (NCTM, 1989), both of which emphasize problem solving. One might infer, then, that there is general acceptance of the idea that the primary goal of mathematics instruction should be to have students become competent problem solvers. Yet, given the multiple interpretations of the term, the goal is hardly clear. Equally unclear is the role that problem solving, once adequately characterized, should play in the larger context of school mathematics. What are the goals for mathematics instruction, and how does problem solving fit within those goals? Such questions are complex. Goals for mathematics instruction depend on one’s conceptualization of what mathematics is, and what it means to understand mathematics. Such conceptualizations vary widely. At one end of the spectrum, mathematical knowledge is seen as a body of facts and procedures dealing with quantities, magnitudes, and forms, and the relationships among them; knowing mathematics is seen as having mastered these facts and procedures. At the other end of the spectrum, mathematics is conceptualized as the “science of patterns,” an (almost) empirical discipline closely akin to the sciences in its emphasis on pattern-seeking on the basis of empirical evidence. The author’s view is that the former perspective trivializes mathematics; that a curriculum based on mastering a corpus of mathematical facts and procedures is severely impoverished—in much the same way that an English curriculum would be considered impoverished if it focused largely, if not exclusively, on issues of grammar. The author characterizes the mathematical enterprise as follows:",2009,239,2893,267,123,144,163,155,189,196,226,163,163,178
f2e713dd0a1ee11892a90e0fb448dd5981e63550,,2000,7,7984,20,159,178,250,232,270,267,306,357,411,430
d82b5eb828d803e2f3fe041db20af8536f0fe99e,Author's Preface to the Anniversary Edition Series Editor's Introduction to the Anniversary Edition A Note about the Anniversary Edition Foreword Acknowledgments Introduction 1. Subtraction With Regrouping: Approaches To Teaching A Topic 2. Multidigit Number Multiplication: Dealing With Students' Mistakes 3. Generating Representations: Division By Fractions 4. Exploring New Knowledge: The Relationship Between Perimeter And Area 5. Teachers' Subject Matter Knowledge: Profound Understanding Of Fundamental Mathematics 6. Profound Understanding Of Fundamental Mathematics: When And How Is It Attained 7. Conclusion Appendix References New to the Anniversary Edition: Journal Article #1 New to the Anniversary Edition: Journal Article #2 Author Index Subject Index,2010,0,1684,360,141,143,135,137,149,142,142,129,128,88
7f3b042c8337fe9195ed6ca0cb017b76bbf1ff7c,"868 NOTICES OF THE AMS VOLUME 47, NUMBER 8 In April 2000 the National Council of Teachers of Mathematics (NCTM) released Principles and Standards for School Mathematics—the culmination of a multifaceted, three-year effort to update NCTM’s earlier standards documents and to set forth goals and recommendations for mathematics education in the prekindergarten-through-grade-twelve years. As the chair of the Writing Group, I had the privilege to interact with all aspects of the development and review of this document and with the committed groups of people, including the members of the Writing Group, who contributed immeasurably to this process. This article provides some background about NCTM and the standards, the process of development, efforts to gather input and feedback, and ways in which feedback from the mathematics community influenced the document. The article concludes with a section that provides some suggestions for mathematicians who are interested in using Principles and Standards.",2000,17,2165,296,10,25,47,49,66,78,79,118,115,118
a9386eb6808b41238381c708f2642bcb7dc34b29,"This book is about mathematical ideas, about what mathematics means-and why. Abstract ideas, for the most part, arise via conceptual metaphor-metaphorical ideas projecting from the way we function in the everyday physical world. Where Mathematics Comes From argues that conceptual metaphor plays a central role in mathematical ideas within the cognitive unconscious-from arithmetic and algebra to sets and logic to infinity in all of its forms.",2002,40,1920,107,19,40,48,55,72,74,102,91,120,102
4526716b3789971eaaa81d507abb657a29009957,"A gender gap in mathematics achievement persists in some nations but not in others. In light of the underrepresentation of women in careers in science, technology, mathematics, and engineering, increasing research attention is being devoted to understanding gender differences in mathematics achievement, attitudes, and affect. The gender stratification hypothesis maintains that such gender differences are closely related to cultural variations in opportunity structures for girls and women. We meta-analyzed 2 major international data sets, the 2003 Trends in International Mathematics and Science Study and the Programme for International Student Assessment, representing 493,495 students 14-16 years of age, to estimate the magnitude of gender differences in mathematics achievement, attitudes, and affect across 69 nations throughout the world. Consistent with the gender similarities hypothesis, all of the mean effect sizes in mathematics achievement were very small (d < 0.15); however, national effect sizes showed considerable variability (ds = -0.42 to 0.40). Despite gender similarities in achievement, boys reported more positive math attitudes and affect (ds = 0.10 to 0.33); national effect sizes ranged from d = -0.61 to 0.89. In contrast to those of previous tests of the gender stratification hypothesis, our results point to specific domains of gender equity responsible for gender gaps in math. Gender equity in school enrollment, women's share of research jobs, and women's parliamentary representation were the most powerful predictors of cross-national variability in gender gaps in math. Results are situated within the context of existing research demonstrating apparently paradoxical effects of societal gender equity and highlight the significance of increasing girls' and women's agency cross-nationally.",2010,126,1105,71,16,49,80,93,98,97,99,98,126,108
2ed2cd231aad7ea8a2b69a60d6df7539d6ee107f,"Vol. 72: The Syntax and Semantics of lnfimtary Languages. Edited by J. Barwtse. IV, 268 pages. 1968. DM 18,I $ 5.00 Vol. 73: P. E. Conner, Lectures on the Action of a Finite Group. IV, 123 pages. 1968. DM 10,1 $ 2.80 Vol. 74:A Frohlich, Formal Groups. IV, 140pages. 1968. DM12, -I $3.30 Vol. 75: G. Lumer, Algebras de fonctions et espaces de Hardy. VI, 80 pages. 1968. DM 8,I $ 2. 20 Vol. 76: R. G. Swan, Algebraic K-Theory. IV, 262 pages. 1968. DM18,I$ 5.00",2001,497,1653,59,73,89,93,103,106,99,152,152,126,57
7385b1bcd94ed3904c0e1429e209c80249de0d2a,"In this article, we use meta-analysis to analyze gender differences in recent studies of mathematics performance. First, we meta-analyzed data from 242 studies published between 1990 and 2007, representing the testing of 1,286,350 people. Overall, d = 0.05, indicating no gender difference, and variance ratio = 1.08, indicating nearly equal male and female variances. Second, we analyzed data from large data sets based on probability sampling of U.S. adolescents over the past 20 years: the National Longitudinal Surveys of Youth, the National Education Longitudinal Study of 1988, the Longitudinal Study of American Youth, and the National Assessment of Educational Progress. Effect sizes for the gender difference ranged between -0.15 and +0.22. Variance ratios ranged from 0.88 to 1.34. Taken together, these findings support the view that males and females perform similarly in mathematics.",2010,211,625,39,0,7,22,37,57,67,61,64,74,93
f008393f240508c1686a468b2c67371a7cdcb354,,2009,0,948,91,8,35,43,56,81,101,105,96,74,112
861a8ccc4002510aa1c844ea6f2c41fba69623f4,"Abstract Working memory refers to a mental workspace, involved in controlling, regulating, and actively maintaining relevant information to accomplish complex cognitive tasks (e.g. mathematical processing). Despite the potential relevance of a relation between working memory and math for understanding developmental and individual differences in mathematical skills, the nature of this relationship is not well-understood. This paper reviews four approaches that address the relation of working memory and math: 1) dual task studies establishing the role of working memory during on-line math performance; 2) individual difference studies examining working memory in children with math difficulties; 3) studies of working memory as a predictor of mathematical outcomes; and 4) longitudinal studies of working memory and math. The goal of this review is to evaluate current information on the nature of the relationship between working memory and math provided by these four approaches, and to present some of the outstanding questions for future research.",2010,165,756,23,7,17,40,52,64,69,91,88,85,83
813c3c045849f82cac2db2f26cee0ca306349f28,"Children's mathematical skills were considered in relation to executive functions. Using multiple measures-including the Wisconsin Card Sorting Task (WCST), dual-task performance, Stroop task, and counting span-it was found that mathematical ability was significantly correlated with all measures of executive functioning, with the exception of dual-task performance. Furthermore, regression analyses revealed that each executive function measure predicted unique variance in mathematics ability. These results are discussed in terms of a central executive with diverse functions (Shallice & Burgess, 1996) and with recent evidence from Miyake, et al. (2000) showing the unity and diversity among executive functions. It is proposed that the particular difficulties for children of lower mathematical ability are lack of inhibition and poor working memory, which result in problems with switching and evaluation of new strategies for dealing with a particular task. The practical and theoretical implications of these results are discussed, along with suggestions for task changes and longitudinal studies that would clarify theoretical and developmental issues related to executive functioning.",2001,79,1320,73,0,2,5,18,38,25,30,34,54,60
deac6a43706ea11bdd9fb07a73b54a08f0c114fb,"Teachers and teacher educators interested in synthesizing their current practice with new mathematics standards will welcome this highly useful volume. Presented are cases of mathematics instruction drawn from research of nearly 500 classroom lessons. Readers will gain insight about how to foster a challenging, cognitively rich, and exciting classroom climate that propels students toward a richer understanding of mathematics.",2009,0,714,82,39,42,46,57,63,50,74,59,57,52
f65040c3aa910788931c27c73006c5f3bb1e7e85,,2008,10,1101,87,44,48,62,72,80,103,88,77,98,55
34fb621cf73b7bad25d77ff1229467a34f736474,"Children's number competencies over 6 time points, from the beginning of kindergarten to the middle of 1st grade, were examined in relation to their mathematics achievement over 5 later time points, from the end of 1st grade to the end of 3rd grade. The relation between early number competence and mathematics achievement was strong and significant throughout the study period. A sequential process growth curve model showed that kindergarten number competence predicted rate of growth in mathematics achievement between 1st and 3rd grades as well as achievement level through 3rd grade. Further, rate of growth in early number competence predicted mathematics performance level in 3rd grade. Although low-income children performed more poorly than their middle-income counterparts in mathematics achievement and progressed at a slower rate, their performance and growth were mediated through relatively weak kindergarten number competence. Similarly, the better performance and faster growth of children who entered kindergarten at an older age were explained by kindergarten number competence. The findings show the importance of early number competence for setting children's learning trajectories in elementary school mathematics.",2009,70,768,38,3,16,21,32,54,72,66,77,73,94
69727a18c999db42c1e0062dd75870b4751ecc90,,2002,0,1397,4,56,59,58,63,81,92,111,128,120,121
c46e0a3586addefd8ffa8aef34afb534b8c1501e,"A model of the relations among cognitive precursors, early numeracy skill, and mathematical outcomes was tested for 182 children from 4.5 to 7.5 years of age. The model integrates research from neuroimaging, clinical populations, and normal development in children and adults. It includes 3 precursor pathways: quantitative, linguistic, and spatial attention. These pathways (a) contributed independently to early numeracy skills during preschool and kindergarten and (b) related differentially to performance on a variety of mathematical outcomes 2 years later. The success of the model in accounting for performance highlights the need to understand the fundamental underlying skills that contribute to diverse forms of mathematical competence.",2010,67,510,47,1,10,10,37,46,49,59,71,66,62
c62e9c1114644b601296d860dd643ff86473071b,"Studies of teachers’ use of mathematics curriculum materials are particularly timely given the current availability of reform-inspired curriculum materials and the increasingly widespread practice of mandating the use of a single curriculum to regulate mathematics teaching. A review of the research on mathematics curriculum use over the last 25 years reveals significant variation in findings and in theoretical foundations. The aim of this review is to examine the ways that central constructs of this body of research—such as curriculum use, teaching, and curriculum materials—are conceptualized and to consider the impact of various conceptualizations on knowledge in the field. Drawing on the literature, the author offers a framework for characterizing and studying teachers’ interactions with curriculum materials.",2005,119,999,143,2,9,21,37,52,49,56,50,64,78
06bdbd4f011e9497fddfc47654116feab28b63bd,"Between 5% and 8% of school-age children have some form of memory or cognitive deficit that interferes with their ability to learn concepts or procedures in one or more mathematical domains. A review of the arithmetical competencies of these children is provided, along with discussion of underlying memory and cognitive deficits and potential neural correlates. The deficits are discussed in terms of three subtypes of mathematics learning disability and in terms of a more general framework for linking research in mathematical cognition to research in learning disabilities.",2004,97,1068,158,5,27,28,49,42,51,68,57,83,95
feeef8d91cec3a9ffe5cf135a36a7f8596426ae1,"Amid ongoing public speculation about the reasons for sex differences in careers in science and mathematics, we present a consensus statement that is based on the best available scientific evidence. Sex differences in science and math achievement and ability are smaller for the mid-range of the abilities distribution than they are for those with the highest levels of achievement and ability. Males are more variable on most measures of quantitative and visuospatial ability, which necessarily results in more males at both high- and low-ability extremes; the reasons why males are often more variable remain elusive. Successful careers in math and science require many types of cognitive abilities. Females tend to excel in verbal abilities, with large differences between females and males found when assessments include writing samples. High-level achievement in science and math requires the ability to communicate effectively and comprehend abstract ideas, so the female advantage in writing should be helpful in all academic domains. Males outperform females on most measures of visuospatial abilities, which have been implicated as contributing to sex differences on standardized exams in mathematics and science. An evolutionary account of sex differences in mathematics and science supports the conclusion that, although sex differences in math and science performance have not directly evolved, they could be indirectly related to differences in interests and specific brain and cognitive systems. We review the brain basis for sex differences in science and mathematics, describe consistent effects, and identify numerous possible correlates. Experience alters brain structures and functioning, so causal statements about brain differences and success in math and science are circular. A wide range of sociocultural forces contribute to sex differences in mathematics and science achievement and ability—including the effects of family, neighborhood, peer, and school influences; training and experience; and cultural practices. We conclude that early experience, biological factors, educational policy, and cultural context affect the number of women and men who pursue advanced study in science and math and that these effects add and interact in complex ways. There are no single or simple answers to the complex questions about sex differences in science and mathematics.",2007,486,906,89,4,19,34,48,46,75,75,61,68,69
62bcc660cbd54558d3fcd07bade3bb764a1a146c,"This study examined the effects of a computer game on students' mathematics achievement and motivation, and the role of prior mathematics knowledge, computer skill, and English language skill on their achievement and motivation as they played the game. A total of 193 students and 10 teachers participated in this study. The teachers were randomly assigned to experimental and control groups. A mixed method of quantitative and interviews were used with Multivariate Analysis of Co-Variance to analyze the data. The results indicated significant improvement of the achievement of the experimental versus control group. No significant improvement was found in the motivation of the groups. Students who played the games in their classrooms and school labs reported greater motivation compared to the ones who played the games only in the school labs. Prior knowledge, computer and English language skill did not play significant roles in achievement and motivation of the experimental group.",2010,65,509,22,4,18,29,45,44,57,67,52,69,57
8d07144332f130bcfc5a5d30716b84a7afecbf9f,"Impairments in executive function have been documented in school-age children with mathematical learning difficulties. However, the utility and specificity of preschool executive function abilities in predicting later mathematical achievement are poorly understood. This study examined linkages between children's developing executive function abilities at age 4 and children's subsequent achievement in mathematics at age 6, 1 year after school entry. The study sample consisted of a regionally representative cohort of 104 children followed prospectively from ages 2 to 6 years. At age 4, children completed a battery of executive function tasks that assessed planning, set shifting, and inhibitory control. Teachers completed the preschool version of the Behavior Rating Inventory of Executive Function. Clinical and classroom measures of children's mathematical achievement were collected at age 6. Results showed that children's performance on set shifting, inhibitory control, and general executive behavior measures during the preschool period accounted for substantial variability in children's early mathematical achievement at school. These associations persisted even after individual differences in general cognitive ability and reading achievement were taken into account. Findings suggest that early measures of executive function may be useful in identifying children who may experience difficulties learning mathematical skills and concepts. They also suggest that the scaffolding of these executive skills could potentially be a useful additional component in early mathematics education.",2010,83,506,20,1,9,33,35,40,46,52,58,55,92
d4d7370670ffa790900ff05f96c208c9eda7d58b,"Graph theory models the Internet mathematically, and a number of plausible mathematically intersecting network models for the Internet have been developed and studied. Simultaneously, Internet researchers have developed methodology to use real data to validate, or invalidate, proposed Internet models. The authors look at these parallel developments, particularly as they apply to scale-free network models of the preferential attachment type.",2009,73,228,11,8,19,28,28,24,18,26,16,16,9
af30825f0c8adf31cf82028c8b50889b716ac362,"The work is giving estimations of the discrepancy between solutions of the initial and the homogenized problems for a one{dimensional second order elliptic operators with random coeecients satisfying strong or uniform mixing conditions. We obtain several sharp estimates in terms of the corresponding mixing coeecient. Abstract. In the theory of homogenisation it is of particular interest to determine the classes of problems which are stable on taking the homogenisation limits. A notable situation where the limit enlarges the class of original problems is known as memory (nonlocal) eeects. A number of results in that direction has been obtained for linear problems. Tartar (1990) innitiated the study of the eeective equation corresponding to nonlinear equation: @ t u n + a n u 2 n = f: Signiicant progress has been hampered by the complexity of required computations needed in order to obtain the terms in power{series expansion. We propose a method which overcomes that diiculty by introducing graphs representing the domain of integration of the integrals in each term. The graphs are relatively simple, it is easy to calculate with them and they give us a clear image of the form of each term. The method allows us to discuss the form of the eeective equation and the convergence of power{series expansions. The feasibility of our method for other types of nonlinearities will be discussed as well.",2010,40,569,7,58,54,70,82,115,47,12,7,10,6
e38ac5b98197284537fca03d8592adaae48841d4,"To understand the difficulties that many students have with comprehension of mathematics, we must determine the cognitive functioning underlying the diversity of mathematical processes. What are the cognitive systems that are required to give access to mathematical objects? Are these systems common to all processes of knowledge or, on the contrary, some of them are specific to mathematical activity? Starting from the paramount importance of semiotic representation for any mathematical activity, we put forward a classification of the various registers of semiotic representations that are mobilized in mathematical processes. Thus, we can reveal two types of transformation of semiotic representations: treatment and conversion. These two types correspond to quite different cognitive processes. They are two separate sources of incomprehension in the learning of mathematics. If treatment is the more important from a mathematical point of view, conversion is basically the deciding factor for learning. Supporting empirical data, at any level of curriculum and for any area of mathematics, can be widely and methodologically gathered: some empirical evidence is presented in this paper.",2006,28,901,111,10,12,20,25,59,41,61,55,62,91
786364fdd5a792fec5c5aaf23b87acbc4b57818b,"Abstract This study examines changes in teachers’ thinking as they participated in a video club designed to help them learn to notice and interpret students’ mathematical thinking. First, we investigate changes in teachers’ talk about classroom video segments before and after participation in the video club. Second, we identify three paths along which teachers learned to notice students’ mathematical thinking in this context: Direct, Cyclical, and Incremental. Finally, we explore ways the video club context influenced teacher learning. Understanding different forms of teacher learning provides insight for research on teacher cognition and may inform the design of video-based professional development.",2008,96,735,68,7,12,19,36,34,38,64,82,69,79
fe88603a338c69f37931facd17f22d6c4b5d5fe1,"Return by mail or fax to: SIAM Connie Young, Conference Director 3600 Market Street – 6 Floor Philadelphia, PA 19104-2688 Fax: 215-386-7999 Personal Information Name: _______________________________________________________________ Affiliation: _______________________________________________________________ Conference Name: _______________________________________________________________ Conference Location: _______________________________________________________________",2010,0,457,15,29,46,51,47,51,34,34,25,16,21
e7a5ff509962afa8850e1e682ebc224018366054,"Although it is often assumed that abilities that reflect basic numerical understanding, such as numerical comparison, are related to children's mathematical abilities, this relationship has not been tested rigorously. In addition, the extent to which symbolic and nonsymbolic number processing play differential roles in this relationship is not yet understood. To address these questions, we collected mathematics achievement measures from 6- to 8-year-olds as well as reaction times from a numerical comparison task. Using the reaction times, we calculated the size of the numerical distance effect exhibited by each child. In a correlational analysis, we found that the individual differences in the distance effect were related to mathematics achievement but not to reading achievement. This relationship was found to be specific to symbolic numerical comparison. Implications for the role of basic numerical competency and the role of accessing numerical magnitude information from Arabic numerals for the development of mathematical skills and their impairment are discussed.",2009,42,588,57,20,21,40,52,53,63,70,75,63,43
cd3a45bdd2c0ebdcfe4f2353da16c8c11ae5cb7f,"Boston College is an equal opportunity, affi rmative action employer.",2004,0,1142,63,2,15,33,42,62,78,86,89,152,109
0cd7e5ea0d7d91be0c9ce76406a1b57f8b57a3f2,"Relational mathematics is to operations research and informatics what numerical mathematics is to engineering: it is intended to help modelling, reasoning, and computing. Its applications are therefore diverse, ranging from psychology, linguistics, decision aid, and ranking to machine learning and spatial reasoning. Although many developments have been made in recent years, they have rarely been shared amongst this broad community of researchers. This first comprehensive overview begins with an easy introduction to the topic, assuming a minimum of prerequisites; but it is nevertheless theoretically sound and up to date. It is suitable for applied scientists, explaining all the necessary mathematics from scratch using a multitude of visualised examples, via matrices and graphs. It ends with tangible results on the research level. The author illustrates the theory and demonstrates practical tasks in operations research, social sciences and the humanities.",2010,0,116,14,0,7,11,9,23,21,10,13,7,4
0a4cf8c0ecf60c39234d48d9d99e03c804e067db,"We're performing all possible to bring our users the most effective books like Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics Download PDF free of charge download. Both you are looking for the book in PDF or EPUB our reference brings Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematicsto you in every possible format. You can obtain the Kindle app and then from Amazon Kindle store you are able to acquire Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics. Ebook Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics and a great many other books can be plumped for divided in to the class develop our website has therefore many categories it has a primarily old collection if you are enthusiastic about the old collection then you can certainly definitely go for it. The very best internet site to obtain Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics and all types of ebooks. They have around 2.5 million books. The same PDF version of any record is available from your personal computer or cellular devices that have a web connection to get Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics Download PDF for free. All the data on this amazing site is published in excellent trust and for normal data function only. Therefore you can easily obtain Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics. There's also some books however beneath the copyright which are offered for free on our site by specific arrangement with the author, like Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics. From this website, you are able to download Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics for free and even contribute or correct. This website is one of many sites for getting free Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics Download PDF. If you're having problem downloading Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics guide or if the hyperlinks aren't functioning, please create to email. We will change it, or send it for your requirements by email. Our digital library preserves in substance nations, letting you get the most less latency age to obtain any of our books subsequent that one. Just said, the Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics Download PDF is generally compatible afterward any units to read. As acknowledged, adventure as without problem as knowledge very almost session, entertainment, as skillfully as a package could be gotten by just looking at a guide Mathematical Aspects Of Geometric Modeling Cbms Nsf Regional Conference Series In Applied Mathematics Download PDF next it is maybe not directly done, you might consent a lot more very nearly that life, on the buy of the world.",2010,201,322,32,10,16,6,10,11,23,14,19,27,36
1f80d103e387aeaa3513078745c41027b0f0f2a2,"Reprinted with permission from the Fall 2005 issue of American Educator, the quarterly journal of the American Federation of Teachers, AFL-CIO.",2005,17,900,78,3,9,28,37,43,65,50,68,89,91
2c5895c47012b9c42fad64e103f0a80fdacfd635,"This study examines the magnitude, destinations, and determinants of mathematics and science teacher turnover. The data are from the nationally representative Schools and Staffing Survey and the Teacher Follow-Up Survey. Over the past two decades, rates of mathematics and science teacher turnover have increased but, contrary to conventional wisdom, have not been consistently different than those of other teachers. Also, contrary to conventional wisdom, mathematics and science teachers were also no more likely than other teachers to take noneducation jobs, such as in technological fields or to be working for private business or industry. The data also show there are large school-to-school differences in mathematics and science turnover; high-poverty, high-minority, and urban public schools have among the highest rates. In the case of cross-school migration, the data show there is an annual asymmetric reshuffling of a significant portion of the mathematics and science teaching force from poor to not-poor schools, from high-minority to low-minority schools, and from urban to suburban schools. A number of key organizational characteristics and conditions of schools accounted for these school differences. The strongest factor for mathematics teachers was the degree of individual classroom autonomy held by teachers. Net of other factors such as salaries, schools with less classroom autonomy lose math teachers at a far higher rate than other teachers. In contrast, for science teachers salary was the strongest factor, while classroom autonomy was not strongly related to their turnover.",2010,144,278,31,1,4,12,12,24,22,28,32,43,33
69e23a9a149d7550b1afc324f326b264992693ce,"This study investigated adolescents’ developmental trajectories of mathematics interest and explored related effects of gender, family, and school context.Latent growth curvemodelingwas usedtoanalyzelongitudinaldataofN 53,193students(51%female)fromgrades5to9fromall3 ability tracks of the German state school system. Annual assessments involved student questionnaires on interest in mathematics, perceptions of classroom characteristics (classroom values for mathematics, mathematics teacher enthusiasm), as well as parent questionnaires regarding family values for mathematics. Results indicated a downward trend of students’ mathematics interest that plateaued in later years, with high variability in mean levels, but little variability in the shape of the growth trajectories. Boys reported higher mathematics interest than girls, but similar downward growth trajectories. Students from the lowest ability track showed more favorable interest trajectories than students from the middle and highest tracks. Family values andclassroomcharacteristicswerepositivelyrelatedtowithin-personlevelsofinterestovertime and to average individual levels of interest, but not to growth parameters. Theoretical and practical implications are discussed.",2010,116,313,16,4,5,15,15,17,31,31,33,54,36
a16f7f1fe98951487b7b83097b47f43f9e83ac1c,"Early childhood mathematics is vitally important for young children's present and future educational success. Research demonstrates that virtually all young children have the capability to learn and become competent in mathematics. Furthermore, young children enjoy their early informal experiences with mathematics. Unfortunately, many children's potential in mathematics is not fully realized, especially those children who are economically disadvantaged. This is due, in part, to a lack of opportunities to learn mathematics in early childhood settings or through everyday experiences in the home and in their communities. Improvements in early childhood mathematics education can provide young children with the foundation for school success. Relying on a comprehensive review of the research, Mathematics Learning in Early Childhood lays out the critical areas that should be the focus of young children's early mathematics education, explores the extent to which they are currently being incorporated in early childhood settings, and identifies the changes needed to improve the quality of mathematics experiences for young children. This book serves as a call to action to improve the state of early childhood mathematics. It will be especially useful for policy makers and practitioners-those who work directly with children and their families in shaping the policies that affect the education of young children.",2009,0,439,33,4,10,17,26,46,38,56,52,34,53
e2ce8e9f362fb1caf22cf5b7ad038dc9753c1190,"In this article we discuss efforts to design and empirically test measures of teachers’ content knowledge for teaching elementary mathematics. We begin by reviewing the literature on teacher knowledge, noting how scholars have organized such knowledge. Next we describe survey items we wrote to represent knowledge for teaching mathematics and results from factor analysis and scaling work with these items. We found that teachers’ knowledge for teaching elementary mathematics was multidimensional and included knowledge of various mathematical topics (e.g., number and operations, algebra) and domains (e.g., knowledge of content, knowledge of students and content). The constructs indicated by factor analysis formed psychometrically acceptable scales.",2004,37,899,70,2,5,12,30,56,37,52,48,71,94
99eaa4a03d94547bfb294460ce78ff9c753e0c2b,"Using contemporary data from the U.S. and other nations, we address 3 questions: Do gender differences in mathematics performance exist in the general population? Do gender differences exist among the mathematically talented? Do females exist who possess profound mathematical talent? In regard to the first question, contemporary data indicate that girls in the U.S. have reached parity with boys in mathematics performance, a pattern that is found in some other nations as well. Focusing on the second question, studies find more males than females scoring above the 95th or 99th percentile, but this gender gap has significantly narrowed over time in the U.S. and is not found among some ethnic groups and in some nations. Furthermore, data from several studies indicate that greater male variability with respect to mathematics is not ubiquitous. Rather, its presence correlates with several measures of gender inequality. Thus, it is largely an artifact of changeable sociocultural factors, not immutable, innate biological differences between the sexes. Responding to the third question, we document the existence of females who possess profound mathematical talent. Finally, we review mounting evidence that both the magnitude of mean math gender differences and the frequency of identification of gifted and profoundly gifted females significantly correlate with sociocultural factors, including measures of gender equality across nations.",2009,56,435,21,8,16,22,30,40,36,43,24,52,60
c8831d7d318b8d59f9b958d250a58f253f08bd8a,"This article is about a curious phenomenon. Suppose we have a data matrix, which is the superposition of a low-rank component and a sparse component. Can we recover each component individually? We prove that under some suitable assumptions, it is possible to recover both the low-rank and the sparse components exactly by solving a very convenient convex program called Principal Component Pursuit; among all feasible decompositions, simply minimize a weighted combination of the nuclear norm and of the ℓ1 norm. This suggests the possibility of a principled approach to robust principal component analysis since our methodology and results assert that one can recover the principal components of a data matrix even though a positive fraction of its entries are arbitrarily corrupted. This extends to the situation where a fraction of the entries are missing as well. We discuss an algorithm for solving this optimization problem, and present applications in the area of video surveillance, where our methodology allows for the detection of objects in a cluttered background, and in the area of face recognition, where it offers a principled way of removing shadows and specularities in images of faces.",2009,90,5547,1043,9,66,155,236,340,507,532,647,665,703
70b48fd1a0c3d9fef98600578308e1e033c0c67a,Supplementary Figure 1 Overview of the analysis pipeline. Supplementary Table 1 Details of conventionally raised and conventionalized mouse samples. Supplementary Discussion Expanded discussion of QIIME analyses presented in the main text; Sequencing of 16S rRNA gene amplicons; QIIME analysis notes; Expanded Figure 1 legend; Links to raw data and processed output from the runs with and without denoising.,2010,30,23951,2769,0,0,0,0,0,1,2,4,98,3003
e5136e9306bf1b0e3d4be0cea384ee9a969a44fa,"Thematic analysis is a poorly demarcated, rarely acknowledged, yet widely used qualitative analytic method within psychology. In this paper, we argue that it offers an accessible and theoretically flexible approach to analysing qualitative data. We outline what thematic analysis is, locating it in relation to other qualitative analytic methods that search for themes or patterns, and in relation to different epistemological and ontological positions. We then provide clear guidelines to those wanting to start thematic analysis, or conduct it in a more deliberate and rigorous way, and consider potential pitfalls in conducting thematic analysis. Finally, we outline the disadvantages and advantages of thematic analysis. We conclude by advocating thematic analysis as a useful and flexible method for qualitative research in and beyond psychology.",2006,110,75769,5318,0,0,0,0,0,0,1,0,0,0
67556c4f0cfdd1f09fff373768b03638f949be0d,"Chapter 3 deals with probability distributions, discrete and continuous densities, distribution functions, bivariate distributions, means, variances, covariance, correlation, and some random process material. Chapter 4 is a detailed study of the concept of utility including the psychological aspects, risk, attributes, rules for utilities, multidimensional utility, and normal form of analysis. Chapter 5 treats games and optimization, linear optimization, and mixed strategies. Entropy is the topic of Chapter 6 with sections devoted to entropy, disorder, information, Shannon’s theorem, demon’s roulette, Maxwell– Boltzmann distribution, Schrodinger’s nutshell, maximum entropy probability distributions, blackbodies, and Bose–Einstein distribution. Chapter 7 is standard statistical fare including transformations of random variables, characteristic functions, generating functions, and the classic limit theorems such as the central limit theorem and the laws of large numbers. Chapter 8 is about exchangeability and inference with sections on Bayesian techniques and classical inference. Partial exchangeability is also treated. Chapter 9 considers such things as order statistics, extreme value, intensity, hazard functions, and Poisson processes. Chapter 10 covers basic elements of risk and reliability, while Chapter 11 is devoted to curve fitting, regression, and Monte Carlo simulation. There is an ample number of exercises at the ends of the chapters with answers or comments on many of them in an appendix in the back of the book. Other appendices are on the common discrete and continuous distributions and mathematical aspects of integration.",2007,0,18912,4802,0,0,0,0,0,0,0,1,7,889
ec3d71a2fdd01968a6dc638ee261715a0f118c1e,"Summary: It is expected that emerging digital gene expression (DGE) technologies will overtake microarray technologies in the near future for many functional genomics applications. One of the fundamental data analysis tasks, especially for gene expression studies, involves determining whether there is evidence that counts for a transcript or exon are significantly different across experimental conditions. edgeR is a Bioconductor software package for examining differential expression of replicated count data. An overdispersed Poisson model is used to account for both biological and technical variability. Empirical Bayes methods are used to moderate the degree of overdispersion across transcripts, improving the reliability of inference. The methodology can be used even with the most minimal levels of replication, provided at least one phenotype or experimental condition is replicated. The software may have other applications beyond sequencing data, such as proteome peptide count data. Availability: The package is freely available under the LGPL licence from the Bioconductor web site (http://bioconductor.org). Contact: mrobinson@wehi.edu.au",2009,10,21553,1162,0,0,0,0,0,0,1,1,7,64
a2893118e14c29a23472b02249b4641b9971786b,"Although genomewide RNA expression analysis has become a routine tool in biomedical research, extracting biological insight from such information remains a major challenge. Here, we describe a powerful analytical method called Gene Set Enrichment Analysis (GSEA) for interpreting gene expression data. The method derives its power by focusing on gene sets, that is, groups of genes that share common biological function, chromosomal location, or regulation. We demonstrate how GSEA yields insights into several cancer-related data sets, including leukemia and lung cancer. Notably, where single-gene analysis finds little similarity between two independent studies of patient survival in lung cancer, GSEA reveals many biological pathways in common. The GSEA method is embodied in a freely available software package, together with an initial database of 1,325 biologically defined gene sets.",2005,85,26903,2908,0,0,0,0,0,0,0,0,0,0
9529c25408dc86194d417aed73d49ae0e418f1be,"32.03 MB Free download Econometric Analysis of Cross Section and Panel Data book PDF, FB2, EPUB and MOBI. Read online Econometric Analysis of Cross Section and Panel Data which classified as Other that has 776 pages that contain constructive material with lovely reading experience. Reading online Econometric Analysis of Cross Section and Panel Data book will be provide using wonderful book reader and it's might gives you some access to identifying the book content before you download the book.",2002,0,21019,2368,0,0,0,0,0,0,0,3,0,4
d17669e4f3f4dd3a180bde84dd54a508d0dc22f4,"A comprehensive, but simple-to-use software package for executing a range of standard numerical analysis and operations used in quantitative paleontology has been developed. The program, called PAST (PAleontological STatistics), runs on standard Windows computers and is available free of charge. PAST integrates spreadsheet-type data entry with univariate and multivariate statistics, curve fitting, timeseries analysis, data plotting, and simple phylogenetic analysis. Many of the functions are specific to paleontology and ecology, and these functions are not found in standard, more extensive, statistical packages. PAST also includes fourteen case studies (data files and exercises) illustrating use of the program for paleontological problems, making it a complete educational package for courses in quantitative methods.",2001,17,17969,3587,0,0,0,0,0,0,0,0,0,0
89fe2ca0bc4ea3f53f5745de6a88e094b8734a2b,1 Introduction: Models and Model Building Section I Understanding and Preparing for Multivariate Analysis 2 Cleaning and Transforming Data 3 Factor Analysis Section II Analysis Using Dependece Techniques 4 Simple and Multiple Regression Analysis 5 Canonical correlation 6 Conjoint analysis 7 Multiple Discriminant Analysis and Logistic Regression 8 ANOVA and MANOVA Section III Analysis using Interdependence Techniques 9 Group data and Cluster Analysis 10 MDS and Correspondence Analysis Structural Equation Modeling 11 SEM: An Introduction 12 Application of SEM,2010,0,6831,1353,53,154,275,450,587,635,645,725,827,809
0ad5733eafb41274895bf1dce6b92ae8f3d68c60,,2004,0,18831,2817,1,3,6,2,10,713,1440,1290,1233,1117
0d6cf3cd3794bc31a4e5a8ded4d4ba83bb20f9b0,"BOOK REVIEW: Constructing grounded theory. A practical guide through qualitative analysis Kathy Charmaz, 2006, 208 pp. London: Sage. ISBN 2005928035",2006,0,10716,2252,0,0,0,1,365,666,939,1134,1328,847
7bd23e6ec32cb1507a385c21a21150e9c332682f,"genalex is a user-friendly cross-platform package that runs within Microsoft Excel, enabling population genetic analyses of codominant, haploid and binary data. Allele frequency-based analyses include heterozygosity, F statistics, Nei's genetic distance, population assignment, probabilities of identity and pairwise relatedness. Distance-based calculations include amova, principal coordinates analysis (PCA), Mantel tests, multivariate and 2D spatial autocorrelation and twogener. More than 20 different graphs summarize data and aid exploration. Sequence and genotype data can be imported from automated sequencers, and exported to other software. Initially designed as tool for teaching, genalex 6 now offers features for researchers as well. Documentation and the program are available at http://www.anu.edu.au/BoZo/GenAlEx/",2006,12,14558,3330,0,0,0,0,0,0,3,972,1332,1368
895860c6083736508d2541900cdf0960eb11592f,"The design, implementation, and capabilities of an extensible visualization system, UCSF Chimera, are discussed. Chimera is segmented into a core that provides basic services and visualization, and extensions that provide most higher level functionality. This architecture ensures that the extension mechanism satisfies the demands of outside developers who wish to incorporate new features. Two unusual extensions are presented: Multiscale, which adds the ability to visualize large‐scale molecular assemblies such as viral coats, and Collaboratory, which allows researchers to share a Chimera session interactively despite being at separate locales. Other extensions include Multalign Viewer, for showing multiple sequence alignments and associated structures; ViewDock, for screening docked ligand orientations; Movie, for replaying molecular dynamics trajectories; and Volume Viewer, for display and analysis of volumetric data. A discussion of the usage of Chimera in real‐world situations is given, along with anticipated future directions. Chimera includes full user documentation, is free to academic and nonprofit users, and is available for Microsoft Windows, Linux, Apple Mac OS X, SGI IRIX, and HP Tru64 Unix from http://www.cgl.ucsf.edu/chimera/. © 2004 Wiley Periodicals, Inc. J Comput Chem 25: 1605–1612, 2004",2004,70,28327,1713,0,0,0,0,1,0,0,0,0,0
e7c8aa2cb2223f17615c1b1ae3b33095466e95cc,"The two most commonly used methods to analyze data from real-time, quantitative PCR experiments are absolute quantification and relative quantification. Absolute quantification determines the input copy number, usually by relating the PCR signal to a standard curve. Relative quantification relates the PCR signal of the target transcript in a treatment group to that of another sample such as an untreated control. The 2(-Delta Delta C(T)) method is a convenient way to analyze the relative changes in gene expression from real-time quantitative PCR experiments. The purpose of this report is to present the derivation, assumptions, and applications of the 2(-Delta Delta C(T)) method. In addition, we present the derivation and applications of two variations of the 2(-Delta Delta C(T)) method that may be useful in the analysis of real-time, quantitative PCR data.",2001,21,115916,1656,0,0,0,0,0,0,0,0,1,0
05abdc87bcaf2963fd511672e64ab39d02239aaf,,2007,30,24491,2512,0,1,0,0,1,0,5,6,535,2032
2d6f573c36c5e2153b65859fb080523fc4d842d0,"We announce the release of the fourth version of MEGA software, which expands on the existing facilities for editing DNA sequence data from autosequencers, mining Web-databases, performing automatic and manual sequence alignment, analyzing sequence alignments to estimate evolutionary distances, inferring phylogenetic trees, and testing evolutionary hypotheses. Version 4 includes a unique facility to generate captions, written in figure legend format, in order to provide natural language descriptions of the models and methods used in the analyses. This facility aims to promote a better understanding of the underlying assumptions used in analyses, and of the results generated. Another new feature is the Maximum Composite Likelihood (MCL) method for estimating evolutionary distances between all pairs of sequences simultaneously, with and without incorporating rate variation among sites and substitution pattern heterogeneities among lineages. This MCL method also can be used to estimate transition/transversion bias and nucleotide substitution pattern without knowledge of the phylogenetic tree. This new version is a native 32-bit Windows application with multi-threading and multi-user supports, and it is also available to run in a Linux desktop environment (via the Wine compatibility layer) and on Intel-based Macintosh computers under the Parallels program. The current version of MEGA is available free of charge at (http://www.megasoftware.net).",2007,10,28423,6043,0,0,0,0,1,18,2034,2152,1667,1255
4e2f43dab69d690dc86422949e410ebf37f522d4,"Bayesian methods have garnered huge interest in cognitive science as an approach to models of cognition and perception. On the other hand, Bayesian methods for data analysis have not yet made much headway in cognitive science against the institutionalized inertia of 20th century null hypothesis significance testing (NHST). Ironically, specific Bayesian models of cognition and perception may not long endure the ravages of empirical verification, but generic Bayesian methods for data analysis will eventually dominate. It is time that Bayesian data analysis became the norm for empirical methods in cognitive science. This article reviews a fatal flaw of NHST and introduces the reader to some benefits of Bayesian data analysis. The article presents illustrative examples of multiple comparisons in Bayesian analysis of variance and Bayesian approaches to statistical power. Copyright © 2010 John Wiley & Sons, Ltd. For further resources related to this article, please visit the WIREs website.",2010,87,5662,709,296,287,323,345,347,434,424,416,498,498
57e7a7323f58a35f5e2cc33bf17d4ac9cdcafdd4,"DAVID bioinformatics resources consists of an integrated biological knowledgebase and analytic tools aimed at systematically extracting biological meaning from large gene/protein lists. This protocol explains how to use DAVID, a high-throughput and integrated data-mining environment, to analyze gene lists derived from high-throughput genomic experiments. The procedure first requires uploading a gene list containing any number of common gene identifiers followed by analysis using one or more text and pathway-mining tools such as gene functional classification, functional annotation chart or clustering and functional annotation table. By following this protocol, investigators are able to gain an in-depth understanding of the biological themes in lists of genes that are enriched in genome-scale studies.",2008,16,27514,2132,0,0,0,0,0,0,0,0,7,39
e09bb0025f4939a4bd233a70937584b4d7bdd0a7,"BackgroundThe evolutionary analysis of molecular sequence variation is a statistical enterprise. This is reflected in the increased use of probabilistic models for phylogenetic inference, multiple sequence alignment, and molecular population genetics. Here we present BEAST: a fast, flexible software architecture for Bayesian analysis of molecular sequences related by an evolutionary tree. A large number of popular stochastic models of sequence evolution are provided and tree-based models suitable for both within- and between-species sequence data are implemented.ResultsBEAST version 1.4.6 consists of 81000 lines of Java source code, 779 classes and 81 packages. It provides models for DNA and protein sequence evolution, highly parametric coalescent analysis, relaxed clock phylogenetics, non-contemporaneous sequence data, statistical alignment and a wide range of options for prior distributions. BEAST source code is object-oriented, modular in design and freely available at http://beast-mcmc.googlecode.com/ under the GNU LGPL license.ConclusionBEAST is a powerful and flexible evolutionary analysis package for molecular sequence variation. It also provides a resource for the further development of new models and statistical methods of evolutionary analysis.",2007,45,11140,3504,0,0,1,247,973,1270,1219,1114,1018,941
cad327e1e3a0799202cb40da5da51d7b0616b64e,"Arlequin ver 3.0 is a software package integrating several basic and advanced methods for population genetics data analysis, like the computation of standard genetic diversity indices, the estimation of allele and haplotype frequencies, tests of departure from linkage equilibrium, departure from selective neutrality and demographic equilibrium, estimation or parameters from past population expansions, and thorough analyses of population subdivision under the AMOVA framework. Arlequin 3 introduces a completely new graphical interface written in C++, a more robust semantic analysis of input files, and two new methods: a Bayesian estimation of gametic phase from multi-locus genotypes, and an estimation of the parameters of an instantaneous spatial expansion from DNA sequence polymorphism. Arlequin can handle several data types like DNA sequences, microsatellite data, or standard multi-locus genotypes. A Windows version of the software is freely available on http://cmpg.unibe.ch/software/arlequin3.",2007,148,12556,4438,1,1,21,1207,1437,1392,1211,1052,891,751
80935b370bac09ce615a002caabc30fbb26f029b,"With its theoretical basis firmly established in molecular evolutionary and population genetics, the comparative DNA and protein sequence analysis plays a central role in reconstructing the evolutionary histories of species and multigene families, estimating rates of molecular evolution, and inferring the nature and extent of selective forces shaping the evolution of genes and genomes. The scope of these investigations has now expanded greatly owing to the development of high-throughput sequencing techniques and novel statistical and computational methods. These methods require easy-to-use computer programs. One such effort has been to produce Molecular Evolutionary Genetics Analysis (MEGA) software, with its focus on facilitating the exploration and analysis of the DNA and protein sequence variation from an evolutionary perspective. Currently in its third major release, MEGA3 contains facilities for automatic and manual sequence alignment, web-based mining of databases, inference of the phylogenetic trees, estimation of evolutionary distances and testing evolutionary hypotheses. This paper provides an overview of the statistical methods, computational tools, and visual exploration modules for data input and the results obtainable in MEGA.",2004,73,12037,3302,1,0,26,1588,2150,1625,1243,879,678,475
4c97d9b9eb7c158e682844b394b42924af3c5b3f,"Interpretative phenomenological analysis (IPA) is an increasingly popular approach to qualitative inquiry. This handy text covers its theoretical foundations and provides a detailed guide to conducting IPA research. 
 
Extended worked examples from the authors' own studies in health, sexuality, psychological distress and identity illustrate the breadth and depth of IPA research. 
 
Each of the chapters also offers a guide to other good exemplars of IPA research in the designated area. The final section of the book considers how IPA connects with other contemporary qualitative approaches like discourse and narrative analysis and how it addresses issues to do with validity. The book is written in an accessible style and will be extremely useful to students and researchers in psychology and related disciplines in the health and social sciences.",2009,7,6197,1589,6,76,172,280,438,624,709,699,792,811
001c07aefcc186013184009e0c83847f28867e08,"ggplot2: Elegant Graphics for Data Analysis is a new addition to the UseR! series by Springer, probably the fastest expanding source of resources for computational statistics at the current moment. The books in this series are all linked with R, either presenting a new package developed by the own authors of the book or describing how to applying statistical techniques with the different packages available in R. ggplot2 is an implementation in R of The Grammar of Graphics (Wilkinson 2005) a systematic approach to the specification of statistical graphics that was introduced in a book previously reviewed in the Journal of Statistical Software by Cox (2007). This implementation has been developed by Hadley Wickham, who is also the author of the book reviewed here.",2010,1,4911,435,9,20,22,56,87,94,178,255,446,795
7ea9b1915072f2adff3762b59b7c7d79805fee8e,"If radiocarbon measurements are to be used at all for chronological purposes, we have to use statistical methods for calibration. The most widely used method of calibration can be seen as a simple application of Bayesian statistics, which uses both the information from the new measurement and information from the 14C calibration curve. In most dating applications, however, we have larger numbers of 14C measurements and we wish to relate those to events in the past. Bayesian statistics provides a coherent framework in which such analysis can be performed and is becoming a core element in many 14C dating projects. This article gives an overview of the main model components used in chronological analysis, their mathematical formulation, and examples of how such analyses can be performed using the latest version of the OxCal software (v4). Many such models can be put together, in a modular fashion, from simple elements, with defined constraints and groupings. In other cases, the commonly used ""uniform phase"" models might not be appropriate, and ramped, exponential, or normal distributions of events might be more useful. When considering analyses of these kinds, it is useful to be able run simulations on synthetic data. Methods for performing such tests are discussed here along with other methods of diagnosing possible problems with statistical models of this kind.",2009,69,4539,1446,11,103,201,275,402,450,446,453,577,449
87ccc438b0c73fcfdea48485fcdb091a8ecaa89c,"High-throughput sequencing assays such as RNA-Seq, ChIP-Seq or barcode counting provide quantitative readouts in the form of count data. To infer differential signal in such data correctly and with good statistical power, estimation of data variability throughout the dynamic range and a suitable error model are required. We propose a method based on the negative binomial distribution, with variance and mean linked by local regression and present an implementation, DESeq, as an R/Bioconductor package.",2010,80,9807,1096,9,65,225,483,806,957,981,1071,1172,1372
b9544a1bf4b02c6648dbd12702bc10c00e20e197,"Content analysis is a widely used qualitative research technique. Rather than being a single method, current applications of content analysis show three distinct approaches: conventional, directed, or summative. All three approaches are used to interpret meaning from the content of text data and, hence, adhere to the naturalistic paradigm. The major differences among the approaches are coding schemes, origins of codes, and threats to trustworthiness. In conventional content analysis, coding categories are derived directly from the text data. With a directed approach, analysis starts with a theory or relevant research findings as guidance for initial codes. A summative content analysis involves counting and comparisons, usually of keywords or content, followed by the interpretation of the underlying context. The authors delineate analytic procedures specific to each approach and techniques addressing trustworthiness with hypothetical examples drawn from the area of end-of-life care.",2005,57,24913,943,0,0,0,0,0,0,0,0,0,0
2fcf90089d9f95025e8953812a43f0db2de3af7c,,2009,0,10343,2663,0,0,263,430,655,922,1128,1232,1332,1349
fc448a7db5a2fac242705bd8e37ae1fc4a858643,"The human genome holds an extraordinary trove of information about human development, physiology, medicine and evolution. Here we report the results of an international collaboration to produce and make freely available a draft sequence of the human genome. We also present an initial analysis of the data, describing some of the insights that can be gleaned from the sequence.",2001,431,17459,430,5,1,4,2,1,2,8,504,764,774
d76bde423b71f1cb900b988311bd2d71b700d506,"The extent of heterogeneity in a meta-analysis partly determines the difficulty in drawing overall conclusions. This extent may be measured by estimating a between-study variance, but interpretation is then specific to a particular treatment effect metric. A test for the existence of heterogeneity exists, but depends on the number of studies in the meta-analysis. We develop measures of the impact of heterogeneity on a meta-analysis, from mathematical criteria, that are independent of the number of studies and the treatment effect metric. We derive and propose three suitable statistics: H is the square root of the chi2 heterogeneity statistic divided by its degrees of freedom; R is the ratio of the standard error of the underlying mean from a random effects meta-analysis to the standard error of a fixed effect meta-analytic estimate, and I2 is a transformation of (H) that describes the proportion of total variation in study estimates that is due to heterogeneity. We discuss interpretation, interval estimates and other properties of these measures and examine them in five example data sets showing different amounts of heterogeneity. We conclude that H and I2, which can usually be calculated for published meta-analyses, are particularly useful summaries of the impact of heterogeneity. One or both should be presented in published meta-analyses in preference to the test for heterogeneity.",2002,35,21386,493,0,0,0,0,1,0,1,0,1,1
1a77e19441f3a0e030998fb2d11d9dd774582403,"The techniques available for the interrogation and analysis of neuroimaging data have a large influence in determining the flexibility, sensitivity, and scope of neuroimaging experiments. The development of such methodologies has allowed investigators to address scientific questions that could not previously be answered and, as such, has become an important research area in its own right. In this paper, we present a review of the research carried out by the Analysis Group at the Oxford Centre for Functional MRI of the Brain (FMRIB). This research has focussed on the development of new methodologies for the analysis of both structural and functional magnetic resonance imaging data. The majority of the research laid out in this paper has been implemented as freely available software tools within FMRIB's Software Library (FSL).",2004,52,10646,1541,0,0,0,0,0,77,419,577,673,764
76ad159a2887b008e5a7335d124c148c13e65465,"We have developed a toolbox and graphic user interface, EEGLAB, running under the crossplatform MATLAB environment (The Mathworks, Inc.) for processing collections of single-trial and/or averaged EEG data of any number of channels. Available functions include EEG data, channel and event information importing, data visualization (scrolling, scalp map and dipole model plotting, plus multi-trial ERP-image plots), preprocessing (including artifact rejection, filtering, epoch selection, and averaging), independent component analysis (ICA) and time/frequency decompositions including channel and component cross-coherence supported by bootstrap statistical methods based on data resampling. EEGLAB functions are organized into three layers. Top-layer functions allow users to interact with the data through the graphic interface without needing to use MATLAB syntax. Menu options allow users to tune the behavior of EEGLAB to available memory. Middle-layer functions allow users to customize data processing using command history and interactive 'pop' functions. Experienced MATLAB users can use EEGLAB data structures and stand-alone signal processing functions to write custom and/or batch analysis scripts. Extensive function help and tutorial information are included. A 'plug-in' facility allows easy incorporation of new EEG modules into the main menu. EEGLAB is freely available (http://www.sccn.ucsd.edu/eeglab/) under the GNU public license for noncommercial use and open source development, together with sample data, user tutorial and extensive documentation.",2004,85,14460,1914,0,0,0,0,0,0,0,0,0,0
e250c4b0cc0180af9f47b97f3b9ff1727a2767aa,"New software, OLEX2, has been developed for the determination, visualization and analysis of molecular crystal structures. The software has a portable mouse-driven workflow-oriented and fully comprehensive graphical user interface for structure solution, refinement and report generation, as well as novel tools for structure analysis. OLEX2 seamlessly links all aspects of the structure solution, refinement and publication process and presents them in a single workflow-driven package, with the ultimate goal of producing an application which will be useful to both chemists and crystallographers.",2009,10,13162,496,0,0,0,0,0,0,3,653,1471,1660
42abddd227d653a0375d7d037ddb885f6c07f66f,"We present Model-based Analysis of ChIP-Seq data, MACS, which analyzes data generated by short read sequencers such as Solexa's Genome Analyzer. MACS empirically models the shift size of ChIP-Seq tags, and uses it to improve the spatial resolution of predicted binding sites. MACS also uses a dynamic Poisson distribution to effectively capture local biases in the genome, allowing for more robust predictions. MACS compares favorably to existing ChIP-Seq peak-finding algorithms, and is freely available.",2008,17,9866,1179,6,43,122,233,339,455,628,662,729,980
20aeb2357e9e215787c7e0d0acfe7a6b598c9103,"This book describes ggplot2, a new data visualization package for R that uses the insights from Leland Wilkisons Grammar of Graphics to create a powerful and flexible system for creating data graphics. With ggplot2, its easy to: produce handsome, publication-quality plots, with automatic legends created from the plot specification superpose multiple layers (points, lines, maps, tiles, box plots to name a few) from different data sources, with automatically adjusted common scales add customisable smoothers that use the powerful modelling capabilities of R, such as loess, linear models, generalised additive models and robust regression save any ggplot2 plot (or part thereof) for later modification or reuse create custom themes that capture in-house or journal style requirements, and that can easily be applied to multiple plots approach your graph from a visual perspective, thinking about how each component of the data is represented on the final plot. This book will be useful to everyone who has struggled with displaying their data in an informative and attractive way. You will need some basic knowledge of R (i.e. you should be able to get your data into R), but ggplot2 is a mini-language specifically tailored for producing graphics, and youll learn everything you need in the book. After reading this book youll be able to produce graphics customized precisely for your problems,and youll find it easy to get graphics out of your head and on to the screen or page.",2009,0,20904,1807,0,0,0,0,0,1,2,0,3,9
7a6142cfa79cc01ceced5e144bd0e01a0f241a74,,2009,43,7893,2014,377,456,500,626,706,655,723,661,657,644
94559c249d204110296c39ed4af2042cc4468e68,"The Karhunen-Lo eve basis functions, more frequently referred to as principal components or empirical orthogonal functions (EOFs), of the noise response of the climate system are an important tool for geophysical studies. Many researchers have used this tool to examine the geophysical and climatological phenomena. Perhaps more frequent use of EOFs in recent studies is in conjunction with the development of the signal detection and estimation methods of the background uctuations of a detection variable serve as an orthogonal basis set and are used to design optimal techniques for detecting and estimating signals. A detection and prediction approach is to design a lter or optimal weights for the signal to be detected. It has been reported that weighted averaging of data over the surface of the Earth improved the detectability of climatic changes (Hasselmann 1979; Stefanick 1981; Bell 1982). Since the signal-to-noise ratio (SNR) varies geographically, there exists an optimal geographical weighting of the signal which maximizes the SNR. The design of an optimal weighting function may require detailed knowledge on the natural uctuation of the climate system. A conceptually similar approach is to employ a particular pattern (or patterns) of climatic change for detection and prediction (e.g., Barnett and Hasselmann 1979; Hasselmann 1979). The patterns of interest (also called the predictors) may include the principal components (empirical orthogonal functions) (e. von Storch 1990) among others. This approach also requires complete knowledge of the natural variability of the climate system. To test and improve the detection and prediction techniques addressed above, a complete cross-spectral covariance matrix, or similarly, a complete set of the principal components of natural uctuations of the climate system for each frequency band of the spectrum is necessary. In reality, a reliable spectrum of observational covariance matrix is not available because observations are not suuciently long and sampling errors contaminate the observational records (Preisendorfer and Barnett 1977; North et al. 1982). Further, inadequate spatial coverage of observations may introduce bias. Therefore, the covariance matrix of the noise response is often estimated from a simple stochastic model. Kim and North (1991, 1992) examined the covariance matrix in terms of various second-moment statistics earlier. Examined here are the principal components of the covariance matrix of the surface temperature uctuations in a simple coupled climate model in comparison with observations. The principal components not only are an",2009,52,14117,1668,1,0,3,13,175,903,1082,1144,1134,1081
da7ab2f1b6278472f3671a7430c9a72bad07781f,"PAML, currently in version 4, is a package of programs for phylogenetic analyses of DNA and protein sequences using maximum likelihood (ML). The programs may be used to compare and test phylogenetic trees, but their main strengths lie in the rich repertoire of evolutionary models implemented, which can be used to estimate parameters in models of sequence evolution and to test interesting biological hypotheses. Uses of the programs include estimation of synonymous and nonsynonymous rates (d(N) and d(S)) between two protein-coding DNA sequences, inference of positive Darwinian selection through phylogenetic comparison of protein-coding genes, reconstruction of ancestral genes and proteins for molecular restoration studies of extinct life forms, combined analysis of heterogeneous data sets from multiple gene loci, and estimation of species divergence times incorporating uncertainties in fossil calibrations. This note discusses some of the major applications of the package, which includes example data sets to demonstrate their use. The package is written in ANSI C, and runs under Windows, Mac OSX, and UNIX systems. It is available at -- (http://abacus.gene.ucl.ac.uk/software/paml.html).",2007,203,9021,1777,10,131,298,412,471,583,614,666,638,749
d40ee5dd758c525dfb9932d726bb4e844b7b8478,"Receiver operating characteristics (ROC) graphs are useful for organizing classifiers and visualizing their performance. ROC graphs are commonly used in medical decision making, and in recent years have been used increasingly in machine learning and data mining research. Although ROC graphs are apparently simple, there are some common misconceptions and pitfalls when using them in practice. The purpose of this article is to serve as an introduction to ROC graphs and as a guide for using them in research.",2006,45,14314,1234,0,0,0,0,0,0,1,4,75,1122
c98386ddf2fe4973da42187a9e3c9167095acf4e,"During the past 30 years, meta-analysis has been an indispensable tool for revealing the hidden meaning of our research literatures. The four articles in this special section on meta-analysis illustrate some of the complexities entailed in meta-analysis methods. Although meta-analysis is a powerful tool for advancing cumulative knowledge, researchers can be confused by the complicated issues involved in the methodology. Each of these four articles contributes both to advancing this methodology and to the increasing complexities that can befuddle researchers. In these comments, the author attempts to clarify both of these aspects and provide a perspective on the methodological issues examined in these articles.",2008,114,15161,703,0,0,0,0,0,0,0,0,0,4
b6fbb3a44a8e946b4a231118a737a396517c83de,"AIM
This paper is a description of inductive and deductive content analysis.


BACKGROUND
Content analysis is a method that may be used with either qualitative or quantitative data and in an inductive or deductive way. Qualitative content analysis is commonly used in nursing studies but little has been published on the analysis process and many research books generally only provide a short description of this method.


DISCUSSION
When using content analysis, the aim was to build a model to describe the phenomenon in a conceptual form. Both inductive and deductive analysis processes are represented as three main phases: preparation, organizing and reporting. The preparation phase is similar in both approaches. The concepts are derived from the data in inductive content analysis. Deductive content analysis is used when the structure of analysis is operationalized on the basis of previous knowledge.


CONCLUSION
Inductive content analysis is used in cases where there are no previous studies dealing with the phenomenon or when it is fragmented. A deductive approach is useful if the general aim was to test a previous theory in a different situation or to compare categories at different time periods.",2008,65,11840,609,0,0,0,0,0,1,379,1016,1090,1290
39dae53515afb42664369c291ec6d1ce34d778bd,"BackgroundCorrelation networks are increasingly being used in bioinformatics applications. For example, weighted gene co-expression network analysis is a systems biology method for describing the correlation patterns among genes across microarray samples. Weighted correlation network analysis (WGCNA) can be used for finding clusters (modules) of highly correlated genes, for summarizing such clusters using the module eigengene or an intramodular hub gene, for relating modules to one another and to external sample traits (using eigengene network methodology), and for calculating module membership measures. Correlation networks facilitate network based gene screening methods that can be used to identify candidate biomarkers or therapeutic targets. These methods have been successfully applied in various biological contexts, e.g. cancer, mouse genetics, yeast genetics, and analysis of brain imaging data. While parts of the correlation network methodology have been described in separate publications, there is a need to provide a user-friendly, comprehensive, and consistent software implementation and an accompanying tutorial.ResultsThe WGCNA R software package is a comprehensive collection of R functions for performing various aspects of weighted correlation network analysis. The package includes functions for network construction, module detection, gene selection, calculations of topological properties, data simulation, visualization, and interfacing with external software. Along with the R package we also present R software tutorials. While the methods development was motivated by gene expression data, the underlying data mining approach can be applied to a variety of different settings.ConclusionThe WGCNA package provides R functions for weighted correlation network analysis, e.g. co-expression network analysis of gene expression data. The R package along with its source code and additional material are freely available at http://www.genetics.ucla.edu/labs/horvath/CoexpressionNetwork/Rpackages/WGCNA.",2008,51,9025,1051,2,9,29,60,112,163,263,361,592,783
0e2532c31c992ac0930998561932f198b467572d,"This article examines the function of documents as a data source in qualitative research and discusses document analysis procedure in the context of actual research experiences. Targeted to research novices, the article takes a nuts‐and‐bolts approach to document analysis. It describes the nature and forms of documents, outlines the advantages and limitations of document analysis, and offers specific examples of the use of documents in the research process. The application of document analysis to a grounded theory study is illustrated.",2009,34,4574,534,0,12,16,59,127,198,275,417,534,725
dd1b3a3793619cec8994cc7cca10e6dee656fb7b,"UNLABELLED
Research over the last few years has revealed significant haplotype structure in the human genome. The characterization of these patterns, particularly in the context of medical genetic association studies, is becoming a routine research activity. Haploview is a software package that provides computation of linkage disequilibrium statistics and population haplotype patterns from primary genotype data in a visually appealing and interactive interface.


AVAILABILITY
http://www.broad.mit.edu/mpg/haploview/


CONTACT
jcbarret@broad.mit.edu",2005,12,13390,1399,0,0,0,1,74,1111,1159,1137,1018,973
6fb968167f3c9c76d00d085a57b265cb912ad012,"Data Mining Methods and Models is the second volume of a three-book series on data mining authored by Larose. The following review was performed independently of LaRose’s other two books. Paraphrasing from the Preface, the goal of this book is to “explore the process of data mining from the point of view of model building.” Nevertheless, the reader will soon be aware that this book is not intended to provide a systematic or comprehensive coverage of various data mining algorithms. Instead, it considers supervised learning or predictive modeling only, and it walks the reader through the data mining process merely with a few selected modeling methods such as (generalized) linear modeling and the Bayesian approach. The book has seven chapters. Chapter 1 introduces dimension reduction, with a focus on principal components analysis (PCA) types of techniques. Chapters 2, 3, and 4 provide a detailed coverage of simple linear regression, multiple linear regression, and logistic regression, respectively. Chapter 5 introduces naive Bayes estimation and Bayesian networks. In Chapter 6, the basic idea of genetic algorithms is discussed. Finally, Chapter 7 presents a case study example of modeling response to direct mail marketing within the CRISP (crossindustry standard process) framework. This book is very easy to read, and this is absolutely the strength which many readers, especially those nonstatistically oriented ones, will greatly appreciate. Predictive modeling is perhaps the most technical part in a data mining process. The author has done an excellent job in making this difficult topic accessible to a broad audience. For example, I like the way in which Bayesian networks are introduced in Chapter 5. After the reader goes through a churn example on naive Bayes estimation in a step-by-step manner, Bayesian belief networks become easily understood as natural extensions. The overall style of the book is clear and patient. The main limitation of the book is its limited coverage. An inspired reader would expect to see a much more extended list of topics. Hastie, Tibishirani, and Friedman (2001) gave a full and more technical account of various data mining algorithms. The inclusion of genetic algorithms in Chapter 6 seems novel when compared to Hastie, Tibishirani, and Friedman (2001), but at the same time, a little unexpected as a separate chapter, since a genetic algorithm involves a stochastics search scheme, which is somewhat involved given the elementary nature of this text. Another noteworthy issue is that the author does not make an attempt to distinguish between conventional statistical analysis and data mining. I found a few errors. On Page 25, for example, it should be ai = 1, instead of ai = 1/4. Also, in the frame on the top of Page 211, it might have been “Posterior Odds,” instead of “Posterior Odds Ratio.” The book uses three different software packages to implement the ideas including SPSS with Clementine, Minitab, and WEKA, which might not be appealing. On the other hand, it is justifiable as it allows one to perform data mining with affordable costs. In summary, I recommend this fairly readable book for adoption in a graduate-level introductory course on data mining, especially when the students come from varied backgrounds.",2008,5,6081,1832,57,100,190,265,350,401,473,572,669,712
85dfac3a261fbdea3b4e1a6f3264c6384bbc4485,"Qualitative content analysis as described in published literature shows conflicting opinions and unsolved issues regarding meaning and use of concepts, procedures and interpretation. This paper provides an overview of important concepts (manifest and latent content, unit of analysis, meaning unit, condensation, abstraction, content area, code, category and theme) related to qualitative content analysis; illustrates the use of concepts related to the research procedure; and proposes measures to achieve trustworthiness (credibility, dependability and transferability) throughout the steps of the research procedure. Interpretation in qualitative content analysis is discussed in light of Watzlawick et al.'s [Pragmatics of Human Communication. A Study of Interactional Patterns, Pathologies and Paradoxes. W.W. Norton & Company, New York, London] theory of communication.",2004,58,14412,1104,0,0,0,0,0,0,0,0,0,4
d96faee1898de7a052115ecfe533a5b2fd1151c0,"This paper develops a new approach to the problem of testing the existence of a level relationship between a dependent variable and a set of regressors, when it is not known with certainty whether the underlying regressors are trend- or first-difference stationary. The proposed tests are based on standard F- and t-statistics used to test the significance of the lagged levels of the variables in a univariate equilibrium correction mechanism. The asymptotic distributions of these statistics are non-standard under the null hypothesis that there exists no level relationship, irrespective of whether the regressors are I(0) or I(1). Two sets of asymptotic critical values are provided: one when all regressors are purely I(1) and the other if they are all purely I(0). These two sets of critical values provide a band covering all possible classifications of the regressors into purely I(0), purely I(1) or mutually cointegrated. Accordingly, various bounds testing procedures are proposed. It is shown that the proposed tests are consistent, and their asymptotic distribution under the null and suitably defined local alternatives are derived. The empirical relevance of the bounds procedures is demonstrated by a re-examination of the earnings equation included in the UK Treasury macroeconometric model. Copyright © 2001 John Wiley & Sons, Ltd.",2001,46,11403,2343,0,0,0,0,0,0,0,0,0,2
a82d7e0dc7b2d3a1b159e0902bb9f3017788a786,"A comprehensive, but simple-to-use software package for executing a range of standard numerical analysis and operations used in quantitative paleontology has been developed. The program, called PAST (PAleontological STatistics), runs on standard Windows computers and is available free of charge. PAST integrates spreadsheet-type data entry with univariate and multivariate statistics, curve fitting, timeseries analysis, data plotting, and simple phylogenetic analysis. Many of the functions are specific to paleontology and ecology, and these functions are not found in standard, more extensive, statistical packages. PAST also includes fourteen case studies (data files and exercises) illustrating use of the program for paleontological problems, making it a complete educational package for courses in quantitative methods.",2001,31,10400,1798,0,0,0,0,0,0,0,0,0,3
39dfeda235027e1bed00ab33bcb2ad16831677f8,"Hypothesis-testing methods for multivariate data are needed to make rigorous probability statements about the effects of factors and their interactions in experiments. Analysis of variance is particularly powerful for the analysis of univariate data. The traditional multivariate analogues, however, are too stringent in their assumptions for most ecological multivariate data sets. Non-parametric methods, based on permutation tests, are preferable. This paper describes a new non-parametric method for multivariate analysis of variance, after McArdle and Anderson (in press). It is given here, with several applications in ecology, to provide an alternative and perhaps more intuitive formulation for ANOVA (based on sums of squared distances) to complement the description pro- vided by McArdle and Anderson (in press) for the analysis of any linear model. It is an improvement on previous non-parametric methods because it allows a direct additive partitioning of variation for complex models. It does this while maintaining the flexibility and lack of formal assumptions of other non-parametric methods. The test- statistic is a multivariate analogue to Fisher's F-ratio and is calculated directly from any symmetric distance or dissimilarity matrix. P-values are then obtained using permutations. Some examples of the method are given for tests involving several factors, including factorial and hierarchical (nested) designs and tests of interactions.",2001,127,10965,1444,0,0,0,0,0,0,0,0,0,158
21c41fcec6ac8a7f55c539ac199247f200633753,"Microarrays can measure the expression of thousands of genes to identify changes in expression between different biological states. Methods are needed to determine the significance of these changes while accounting for the enormous number of genes. We describe a method, Significance Analysis of Microarrays (SAM), that assigns a score to each gene on the basis of change in gene expression relative to the standard deviation of repeated measurements. For genes with scores greater than an adjustable threshold, SAM uses permutations of the repeated measurements to estimate the percentage of genes identified by chance, the false discovery rate (FDR). When the transcriptional response of human cells to ionizing radiation was measured by microarrays, SAM identified 34 genes that changed at least 1.5-fold with an estimated FDR of 12%, compared with FDRs of 60 and 84% by using conventional methods of analysis. Of the 34 genes, 19 were involved in cell cycle regulation and 3 in apoptosis. Surprisingly, four nucleotide excision repair genes were induced, suggesting that this repair pathway for UV-damaged DNA might play a previously unrecognized role in repairing DNA damaged by ionizing radiation.",2001,54,11566,1626,0,0,1,3,249,864,864,894,921,881
c8831d7d318b8d59f9b958d250a58f253f08bd8a,"This article is about a curious phenomenon. Suppose we have a data matrix, which is the superposition of a low-rank component and a sparse component. Can we recover each component individually? We prove that under some suitable assumptions, it is possible to recover both the low-rank and the sparse components exactly by solving a very convenient convex program called Principal Component Pursuit; among all feasible decompositions, simply minimize a weighted combination of the nuclear norm and of the ℓ1 norm. This suggests the possibility of a principled approach to robust principal component analysis since our methodology and results assert that one can recover the principal components of a data matrix even though a positive fraction of its entries are arbitrarily corrupted. This extends to the situation where a fraction of the entries are missing as well. We discuss an algorithm for solving this optimization problem, and present applications in the area of video surveillance, where our methodology allows for the detection of objects in a cluttered background, and in the area of face recognition, where it offers a principled way of removing shadows and specularities in images of faces.",2009,90,5547,1043,9,66,155,236,340,507,532,647,665,703
70b48fd1a0c3d9fef98600578308e1e033c0c67a,Supplementary Figure 1 Overview of the analysis pipeline. Supplementary Table 1 Details of conventionally raised and conventionalized mouse samples. Supplementary Discussion Expanded discussion of QIIME analyses presented in the main text; Sequencing of 16S rRNA gene amplicons; QIIME analysis notes; Expanded Figure 1 legend; Links to raw data and processed output from the runs with and without denoising.,2010,30,23951,2769,0,0,0,0,0,1,2,4,98,3003
e5136e9306bf1b0e3d4be0cea384ee9a969a44fa,"Thematic analysis is a poorly demarcated, rarely acknowledged, yet widely used qualitative analytic method within psychology. In this paper, we argue that it offers an accessible and theoretically flexible approach to analysing qualitative data. We outline what thematic analysis is, locating it in relation to other qualitative analytic methods that search for themes or patterns, and in relation to different epistemological and ontological positions. We then provide clear guidelines to those wanting to start thematic analysis, or conduct it in a more deliberate and rigorous way, and consider potential pitfalls in conducting thematic analysis. Finally, we outline the disadvantages and advantages of thematic analysis. We conclude by advocating thematic analysis as a useful and flexible method for qualitative research in and beyond psychology.",2006,110,75769,5318,0,0,0,0,0,0,1,0,0,0
67556c4f0cfdd1f09fff373768b03638f949be0d,"Chapter 3 deals with probability distributions, discrete and continuous densities, distribution functions, bivariate distributions, means, variances, covariance, correlation, and some random process material. Chapter 4 is a detailed study of the concept of utility including the psychological aspects, risk, attributes, rules for utilities, multidimensional utility, and normal form of analysis. Chapter 5 treats games and optimization, linear optimization, and mixed strategies. Entropy is the topic of Chapter 6 with sections devoted to entropy, disorder, information, Shannon’s theorem, demon’s roulette, Maxwell– Boltzmann distribution, Schrodinger’s nutshell, maximum entropy probability distributions, blackbodies, and Bose–Einstein distribution. Chapter 7 is standard statistical fare including transformations of random variables, characteristic functions, generating functions, and the classic limit theorems such as the central limit theorem and the laws of large numbers. Chapter 8 is about exchangeability and inference with sections on Bayesian techniques and classical inference. Partial exchangeability is also treated. Chapter 9 considers such things as order statistics, extreme value, intensity, hazard functions, and Poisson processes. Chapter 10 covers basic elements of risk and reliability, while Chapter 11 is devoted to curve fitting, regression, and Monte Carlo simulation. There is an ample number of exercises at the ends of the chapters with answers or comments on many of them in an appendix in the back of the book. Other appendices are on the common discrete and continuous distributions and mathematical aspects of integration.",2007,0,18912,4802,0,0,0,0,0,0,0,1,7,889
ec3d71a2fdd01968a6dc638ee261715a0f118c1e,"Summary: It is expected that emerging digital gene expression (DGE) technologies will overtake microarray technologies in the near future for many functional genomics applications. One of the fundamental data analysis tasks, especially for gene expression studies, involves determining whether there is evidence that counts for a transcript or exon are significantly different across experimental conditions. edgeR is a Bioconductor software package for examining differential expression of replicated count data. An overdispersed Poisson model is used to account for both biological and technical variability. Empirical Bayes methods are used to moderate the degree of overdispersion across transcripts, improving the reliability of inference. The methodology can be used even with the most minimal levels of replication, provided at least one phenotype or experimental condition is replicated. The software may have other applications beyond sequencing data, such as proteome peptide count data. Availability: The package is freely available under the LGPL licence from the Bioconductor web site (http://bioconductor.org). Contact: mrobinson@wehi.edu.au",2009,10,21553,1162,0,0,0,0,0,0,1,1,7,64
a2893118e14c29a23472b02249b4641b9971786b,"Although genomewide RNA expression analysis has become a routine tool in biomedical research, extracting biological insight from such information remains a major challenge. Here, we describe a powerful analytical method called Gene Set Enrichment Analysis (GSEA) for interpreting gene expression data. The method derives its power by focusing on gene sets, that is, groups of genes that share common biological function, chromosomal location, or regulation. We demonstrate how GSEA yields insights into several cancer-related data sets, including leukemia and lung cancer. Notably, where single-gene analysis finds little similarity between two independent studies of patient survival in lung cancer, GSEA reveals many biological pathways in common. The GSEA method is embodied in a freely available software package, together with an initial database of 1,325 biologically defined gene sets.",2005,85,26903,2908,0,0,0,0,0,0,0,0,0,0
9529c25408dc86194d417aed73d49ae0e418f1be,"32.03 MB Free download Econometric Analysis of Cross Section and Panel Data book PDF, FB2, EPUB and MOBI. Read online Econometric Analysis of Cross Section and Panel Data which classified as Other that has 776 pages that contain constructive material with lovely reading experience. Reading online Econometric Analysis of Cross Section and Panel Data book will be provide using wonderful book reader and it's might gives you some access to identifying the book content before you download the book.",2002,0,21019,2368,0,0,0,0,0,0,0,3,0,4
d17669e4f3f4dd3a180bde84dd54a508d0dc22f4,"A comprehensive, but simple-to-use software package for executing a range of standard numerical analysis and operations used in quantitative paleontology has been developed. The program, called PAST (PAleontological STatistics), runs on standard Windows computers and is available free of charge. PAST integrates spreadsheet-type data entry with univariate and multivariate statistics, curve fitting, timeseries analysis, data plotting, and simple phylogenetic analysis. Many of the functions are specific to paleontology and ecology, and these functions are not found in standard, more extensive, statistical packages. PAST also includes fourteen case studies (data files and exercises) illustrating use of the program for paleontological problems, making it a complete educational package for courses in quantitative methods.",2001,17,17969,3587,0,0,0,0,0,0,0,0,0,0
89fe2ca0bc4ea3f53f5745de6a88e094b8734a2b,1 Introduction: Models and Model Building Section I Understanding and Preparing for Multivariate Analysis 2 Cleaning and Transforming Data 3 Factor Analysis Section II Analysis Using Dependece Techniques 4 Simple and Multiple Regression Analysis 5 Canonical correlation 6 Conjoint analysis 7 Multiple Discriminant Analysis and Logistic Regression 8 ANOVA and MANOVA Section III Analysis using Interdependence Techniques 9 Group data and Cluster Analysis 10 MDS and Correspondence Analysis Structural Equation Modeling 11 SEM: An Introduction 12 Application of SEM,2010,0,6831,1353,53,154,275,450,587,635,645,725,827,809
0ad5733eafb41274895bf1dce6b92ae8f3d68c60,,2004,0,18831,2817,1,3,6,2,10,713,1440,1290,1233,1117
0d6cf3cd3794bc31a4e5a8ded4d4ba83bb20f9b0,"BOOK REVIEW: Constructing grounded theory. A practical guide through qualitative analysis Kathy Charmaz, 2006, 208 pp. London: Sage. ISBN 2005928035",2006,0,10716,2252,0,0,0,1,365,666,939,1134,1328,847
7bd23e6ec32cb1507a385c21a21150e9c332682f,"genalex is a user-friendly cross-platform package that runs within Microsoft Excel, enabling population genetic analyses of codominant, haploid and binary data. Allele frequency-based analyses include heterozygosity, F statistics, Nei's genetic distance, population assignment, probabilities of identity and pairwise relatedness. Distance-based calculations include amova, principal coordinates analysis (PCA), Mantel tests, multivariate and 2D spatial autocorrelation and twogener. More than 20 different graphs summarize data and aid exploration. Sequence and genotype data can be imported from automated sequencers, and exported to other software. Initially designed as tool for teaching, genalex 6 now offers features for researchers as well. Documentation and the program are available at http://www.anu.edu.au/BoZo/GenAlEx/",2006,12,14558,3330,0,0,0,0,0,0,3,972,1332,1368
895860c6083736508d2541900cdf0960eb11592f,"The design, implementation, and capabilities of an extensible visualization system, UCSF Chimera, are discussed. Chimera is segmented into a core that provides basic services and visualization, and extensions that provide most higher level functionality. This architecture ensures that the extension mechanism satisfies the demands of outside developers who wish to incorporate new features. Two unusual extensions are presented: Multiscale, which adds the ability to visualize large‐scale molecular assemblies such as viral coats, and Collaboratory, which allows researchers to share a Chimera session interactively despite being at separate locales. Other extensions include Multalign Viewer, for showing multiple sequence alignments and associated structures; ViewDock, for screening docked ligand orientations; Movie, for replaying molecular dynamics trajectories; and Volume Viewer, for display and analysis of volumetric data. A discussion of the usage of Chimera in real‐world situations is given, along with anticipated future directions. Chimera includes full user documentation, is free to academic and nonprofit users, and is available for Microsoft Windows, Linux, Apple Mac OS X, SGI IRIX, and HP Tru64 Unix from http://www.cgl.ucsf.edu/chimera/. © 2004 Wiley Periodicals, Inc. J Comput Chem 25: 1605–1612, 2004",2004,70,28327,1713,0,0,0,0,1,0,0,0,0,0
e7c8aa2cb2223f17615c1b1ae3b33095466e95cc,"The two most commonly used methods to analyze data from real-time, quantitative PCR experiments are absolute quantification and relative quantification. Absolute quantification determines the input copy number, usually by relating the PCR signal to a standard curve. Relative quantification relates the PCR signal of the target transcript in a treatment group to that of another sample such as an untreated control. The 2(-Delta Delta C(T)) method is a convenient way to analyze the relative changes in gene expression from real-time quantitative PCR experiments. The purpose of this report is to present the derivation, assumptions, and applications of the 2(-Delta Delta C(T)) method. In addition, we present the derivation and applications of two variations of the 2(-Delta Delta C(T)) method that may be useful in the analysis of real-time, quantitative PCR data.",2001,21,115916,1656,0,0,0,0,0,0,0,0,1,0
2d6f573c36c5e2153b65859fb080523fc4d842d0,"We announce the release of the fourth version of MEGA software, which expands on the existing facilities for editing DNA sequence data from autosequencers, mining Web-databases, performing automatic and manual sequence alignment, analyzing sequence alignments to estimate evolutionary distances, inferring phylogenetic trees, and testing evolutionary hypotheses. Version 4 includes a unique facility to generate captions, written in figure legend format, in order to provide natural language descriptions of the models and methods used in the analyses. This facility aims to promote a better understanding of the underlying assumptions used in analyses, and of the results generated. Another new feature is the Maximum Composite Likelihood (MCL) method for estimating evolutionary distances between all pairs of sequences simultaneously, with and without incorporating rate variation among sites and substitution pattern heterogeneities among lineages. This MCL method also can be used to estimate transition/transversion bias and nucleotide substitution pattern without knowledge of the phylogenetic tree. This new version is a native 32-bit Windows application with multi-threading and multi-user supports, and it is also available to run in a Linux desktop environment (via the Wine compatibility layer) and on Intel-based Macintosh computers under the Parallels program. The current version of MEGA is available free of charge at (http://www.megasoftware.net).",2007,10,28423,6043,0,0,0,0,1,18,2034,2152,1667,1255
05abdc87bcaf2963fd511672e64ab39d02239aaf,,2007,30,24491,2512,0,1,0,0,1,0,5,6,535,2032
4e2f43dab69d690dc86422949e410ebf37f522d4,"Bayesian methods have garnered huge interest in cognitive science as an approach to models of cognition and perception. On the other hand, Bayesian methods for data analysis have not yet made much headway in cognitive science against the institutionalized inertia of 20th century null hypothesis significance testing (NHST). Ironically, specific Bayesian models of cognition and perception may not long endure the ravages of empirical verification, but generic Bayesian methods for data analysis will eventually dominate. It is time that Bayesian data analysis became the norm for empirical methods in cognitive science. This article reviews a fatal flaw of NHST and introduces the reader to some benefits of Bayesian data analysis. The article presents illustrative examples of multiple comparisons in Bayesian analysis of variance and Bayesian approaches to statistical power. Copyright © 2010 John Wiley & Sons, Ltd. For further resources related to this article, please visit the WIREs website.",2010,87,5662,709,296,287,323,345,347,434,424,416,498,498
57e7a7323f58a35f5e2cc33bf17d4ac9cdcafdd4,"DAVID bioinformatics resources consists of an integrated biological knowledgebase and analytic tools aimed at systematically extracting biological meaning from large gene/protein lists. This protocol explains how to use DAVID, a high-throughput and integrated data-mining environment, to analyze gene lists derived from high-throughput genomic experiments. The procedure first requires uploading a gene list containing any number of common gene identifiers followed by analysis using one or more text and pathway-mining tools such as gene functional classification, functional annotation chart or clustering and functional annotation table. By following this protocol, investigators are able to gain an in-depth understanding of the biological themes in lists of genes that are enriched in genome-scale studies.",2008,16,27514,2132,0,0,0,0,0,0,0,0,7,39
cad327e1e3a0799202cb40da5da51d7b0616b64e,"Arlequin ver 3.0 is a software package integrating several basic and advanced methods for population genetics data analysis, like the computation of standard genetic diversity indices, the estimation of allele and haplotype frequencies, tests of departure from linkage equilibrium, departure from selective neutrality and demographic equilibrium, estimation or parameters from past population expansions, and thorough analyses of population subdivision under the AMOVA framework. Arlequin 3 introduces a completely new graphical interface written in C++, a more robust semantic analysis of input files, and two new methods: a Bayesian estimation of gametic phase from multi-locus genotypes, and an estimation of the parameters of an instantaneous spatial expansion from DNA sequence polymorphism. Arlequin can handle several data types like DNA sequences, microsatellite data, or standard multi-locus genotypes. A Windows version of the software is freely available on http://cmpg.unibe.ch/software/arlequin3.",2007,148,12556,4438,1,1,21,1207,1437,1392,1211,1052,891,751
e09bb0025f4939a4bd233a70937584b4d7bdd0a7,"BackgroundThe evolutionary analysis of molecular sequence variation is a statistical enterprise. This is reflected in the increased use of probabilistic models for phylogenetic inference, multiple sequence alignment, and molecular population genetics. Here we present BEAST: a fast, flexible software architecture for Bayesian analysis of molecular sequences related by an evolutionary tree. A large number of popular stochastic models of sequence evolution are provided and tree-based models suitable for both within- and between-species sequence data are implemented.ResultsBEAST version 1.4.6 consists of 81000 lines of Java source code, 779 classes and 81 packages. It provides models for DNA and protein sequence evolution, highly parametric coalescent analysis, relaxed clock phylogenetics, non-contemporaneous sequence data, statistical alignment and a wide range of options for prior distributions. BEAST source code is object-oriented, modular in design and freely available at http://beast-mcmc.googlecode.com/ under the GNU LGPL license.ConclusionBEAST is a powerful and flexible evolutionary analysis package for molecular sequence variation. It also provides a resource for the further development of new models and statistical methods of evolutionary analysis.",2007,45,11140,3504,0,0,1,247,973,1270,1219,1114,1018,941
80935b370bac09ce615a002caabc30fbb26f029b,"With its theoretical basis firmly established in molecular evolutionary and population genetics, the comparative DNA and protein sequence analysis plays a central role in reconstructing the evolutionary histories of species and multigene families, estimating rates of molecular evolution, and inferring the nature and extent of selective forces shaping the evolution of genes and genomes. The scope of these investigations has now expanded greatly owing to the development of high-throughput sequencing techniques and novel statistical and computational methods. These methods require easy-to-use computer programs. One such effort has been to produce Molecular Evolutionary Genetics Analysis (MEGA) software, with its focus on facilitating the exploration and analysis of the DNA and protein sequence variation from an evolutionary perspective. Currently in its third major release, MEGA3 contains facilities for automatic and manual sequence alignment, web-based mining of databases, inference of the phylogenetic trees, estimation of evolutionary distances and testing evolutionary hypotheses. This paper provides an overview of the statistical methods, computational tools, and visual exploration modules for data input and the results obtainable in MEGA.",2004,73,12037,3302,1,0,26,1588,2150,1625,1243,879,678,475
4c97d9b9eb7c158e682844b394b42924af3c5b3f,"Interpretative phenomenological analysis (IPA) is an increasingly popular approach to qualitative inquiry. This handy text covers its theoretical foundations and provides a detailed guide to conducting IPA research. 
 
Extended worked examples from the authors' own studies in health, sexuality, psychological distress and identity illustrate the breadth and depth of IPA research. 
 
Each of the chapters also offers a guide to other good exemplars of IPA research in the designated area. The final section of the book considers how IPA connects with other contemporary qualitative approaches like discourse and narrative analysis and how it addresses issues to do with validity. The book is written in an accessible style and will be extremely useful to students and researchers in psychology and related disciplines in the health and social sciences.",2009,7,6197,1589,6,76,172,280,438,624,709,699,792,811
001c07aefcc186013184009e0c83847f28867e08,"ggplot2: Elegant Graphics for Data Analysis is a new addition to the UseR! series by Springer, probably the fastest expanding source of resources for computational statistics at the current moment. The books in this series are all linked with R, either presenting a new package developed by the own authors of the book or describing how to applying statistical techniques with the different packages available in R. ggplot2 is an implementation in R of The Grammar of Graphics (Wilkinson 2005) a systematic approach to the specification of statistical graphics that was introduced in a book previously reviewed in the Journal of Statistical Software by Cox (2007). This implementation has been developed by Hadley Wickham, who is also the author of the book reviewed here.",2010,1,4911,435,9,20,22,56,87,94,178,255,446,795
7ea9b1915072f2adff3762b59b7c7d79805fee8e,"If radiocarbon measurements are to be used at all for chronological purposes, we have to use statistical methods for calibration. The most widely used method of calibration can be seen as a simple application of Bayesian statistics, which uses both the information from the new measurement and information from the 14C calibration curve. In most dating applications, however, we have larger numbers of 14C measurements and we wish to relate those to events in the past. Bayesian statistics provides a coherent framework in which such analysis can be performed and is becoming a core element in many 14C dating projects. This article gives an overview of the main model components used in chronological analysis, their mathematical formulation, and examples of how such analyses can be performed using the latest version of the OxCal software (v4). Many such models can be put together, in a modular fashion, from simple elements, with defined constraints and groupings. In other cases, the commonly used ""uniform phase"" models might not be appropriate, and ramped, exponential, or normal distributions of events might be more useful. When considering analyses of these kinds, it is useful to be able run simulations on synthetic data. Methods for performing such tests are discussed here along with other methods of diagnosing possible problems with statistical models of this kind.",2009,69,4539,1446,11,103,201,275,402,450,446,453,577,449
87ccc438b0c73fcfdea48485fcdb091a8ecaa89c,"High-throughput sequencing assays such as RNA-Seq, ChIP-Seq or barcode counting provide quantitative readouts in the form of count data. To infer differential signal in such data correctly and with good statistical power, estimation of data variability throughout the dynamic range and a suitable error model are required. We propose a method based on the negative binomial distribution, with variance and mean linked by local regression and present an implementation, DESeq, as an R/Bioconductor package.",2010,80,9807,1096,9,65,225,483,806,957,981,1071,1172,1372
b9544a1bf4b02c6648dbd12702bc10c00e20e197,"Content analysis is a widely used qualitative research technique. Rather than being a single method, current applications of content analysis show three distinct approaches: conventional, directed, or summative. All three approaches are used to interpret meaning from the content of text data and, hence, adhere to the naturalistic paradigm. The major differences among the approaches are coding schemes, origins of codes, and threats to trustworthiness. In conventional content analysis, coding categories are derived directly from the text data. With a directed approach, analysis starts with a theory or relevant research findings as guidance for initial codes. A summative content analysis involves counting and comparisons, usually of keywords or content, followed by the interpretation of the underlying context. The authors delineate analytic procedures specific to each approach and techniques addressing trustworthiness with hypothetical examples drawn from the area of end-of-life care.",2005,57,24913,943,0,0,0,0,0,0,0,0,0,0
2fcf90089d9f95025e8953812a43f0db2de3af7c,,2009,0,10344,2663,0,0,263,430,655,922,1128,1232,1332,1349
d76bde423b71f1cb900b988311bd2d71b700d506,"The extent of heterogeneity in a meta-analysis partly determines the difficulty in drawing overall conclusions. This extent may be measured by estimating a between-study variance, but interpretation is then specific to a particular treatment effect metric. A test for the existence of heterogeneity exists, but depends on the number of studies in the meta-analysis. We develop measures of the impact of heterogeneity on a meta-analysis, from mathematical criteria, that are independent of the number of studies and the treatment effect metric. We derive and propose three suitable statistics: H is the square root of the chi2 heterogeneity statistic divided by its degrees of freedom; R is the ratio of the standard error of the underlying mean from a random effects meta-analysis to the standard error of a fixed effect meta-analytic estimate, and I2 is a transformation of (H) that describes the proportion of total variation in study estimates that is due to heterogeneity. We discuss interpretation, interval estimates and other properties of these measures and examine them in five example data sets showing different amounts of heterogeneity. We conclude that H and I2, which can usually be calculated for published meta-analyses, are particularly useful summaries of the impact of heterogeneity. One or both should be presented in published meta-analyses in preference to the test for heterogeneity.",2002,35,21386,493,0,0,0,0,1,0,1,0,1,1
fc448a7db5a2fac242705bd8e37ae1fc4a858643,"The human genome holds an extraordinary trove of information about human development, physiology, medicine and evolution. Here we report the results of an international collaboration to produce and make freely available a draft sequence of the human genome. We also present an initial analysis of the data, describing some of the insights that can be gleaned from the sequence.",2001,431,17459,430,5,1,4,2,1,2,8,504,764,774
1a77e19441f3a0e030998fb2d11d9dd774582403,"The techniques available for the interrogation and analysis of neuroimaging data have a large influence in determining the flexibility, sensitivity, and scope of neuroimaging experiments. The development of such methodologies has allowed investigators to address scientific questions that could not previously be answered and, as such, has become an important research area in its own right. In this paper, we present a review of the research carried out by the Analysis Group at the Oxford Centre for Functional MRI of the Brain (FMRIB). This research has focussed on the development of new methodologies for the analysis of both structural and functional magnetic resonance imaging data. The majority of the research laid out in this paper has been implemented as freely available software tools within FMRIB's Software Library (FSL).",2004,52,10646,1541,0,0,0,0,0,77,419,577,673,764
76ad159a2887b008e5a7335d124c148c13e65465,"We have developed a toolbox and graphic user interface, EEGLAB, running under the crossplatform MATLAB environment (The Mathworks, Inc.) for processing collections of single-trial and/or averaged EEG data of any number of channels. Available functions include EEG data, channel and event information importing, data visualization (scrolling, scalp map and dipole model plotting, plus multi-trial ERP-image plots), preprocessing (including artifact rejection, filtering, epoch selection, and averaging), independent component analysis (ICA) and time/frequency decompositions including channel and component cross-coherence supported by bootstrap statistical methods based on data resampling. EEGLAB functions are organized into three layers. Top-layer functions allow users to interact with the data through the graphic interface without needing to use MATLAB syntax. Menu options allow users to tune the behavior of EEGLAB to available memory. Middle-layer functions allow users to customize data processing using command history and interactive 'pop' functions. Experienced MATLAB users can use EEGLAB data structures and stand-alone signal processing functions to write custom and/or batch analysis scripts. Extensive function help and tutorial information are included. A 'plug-in' facility allows easy incorporation of new EEG modules into the main menu. EEGLAB is freely available (http://www.sccn.ucsd.edu/eeglab/) under the GNU public license for noncommercial use and open source development, together with sample data, user tutorial and extensive documentation.",2004,85,14460,1914,0,0,0,0,0,0,0,0,0,0
e250c4b0cc0180af9f47b97f3b9ff1727a2767aa,"New software, OLEX2, has been developed for the determination, visualization and analysis of molecular crystal structures. The software has a portable mouse-driven workflow-oriented and fully comprehensive graphical user interface for structure solution, refinement and report generation, as well as novel tools for structure analysis. OLEX2 seamlessly links all aspects of the structure solution, refinement and publication process and presents them in a single workflow-driven package, with the ultimate goal of producing an application which will be useful to both chemists and crystallographers.",2009,10,13162,496,0,0,0,0,0,0,3,653,1471,1660
42abddd227d653a0375d7d037ddb885f6c07f66f,"We present Model-based Analysis of ChIP-Seq data, MACS, which analyzes data generated by short read sequencers such as Solexa's Genome Analyzer. MACS empirically models the shift size of ChIP-Seq tags, and uses it to improve the spatial resolution of predicted binding sites. MACS also uses a dynamic Poisson distribution to effectively capture local biases in the genome, allowing for more robust predictions. MACS compares favorably to existing ChIP-Seq peak-finding algorithms, and is freely available.",2008,17,9866,1179,6,43,122,233,339,455,628,662,729,980
20aeb2357e9e215787c7e0d0acfe7a6b598c9103,"This book describes ggplot2, a new data visualization package for R that uses the insights from Leland Wilkisons Grammar of Graphics to create a powerful and flexible system for creating data graphics. With ggplot2, its easy to: produce handsome, publication-quality plots, with automatic legends created from the plot specification superpose multiple layers (points, lines, maps, tiles, box plots to name a few) from different data sources, with automatically adjusted common scales add customisable smoothers that use the powerful modelling capabilities of R, such as loess, linear models, generalised additive models and robust regression save any ggplot2 plot (or part thereof) for later modification or reuse create custom themes that capture in-house or journal style requirements, and that can easily be applied to multiple plots approach your graph from a visual perspective, thinking about how each component of the data is represented on the final plot. This book will be useful to everyone who has struggled with displaying their data in an informative and attractive way. You will need some basic knowledge of R (i.e. you should be able to get your data into R), but ggplot2 is a mini-language specifically tailored for producing graphics, and youll learn everything you need in the book. After reading this book youll be able to produce graphics customized precisely for your problems,and youll find it easy to get graphics out of your head and on to the screen or page.",2009,0,20903,1807,0,0,0,0,0,1,2,0,3,9
7a6142cfa79cc01ceced5e144bd0e01a0f241a74,,2009,43,7893,2014,377,456,500,626,706,655,723,661,657,644
94559c249d204110296c39ed4af2042cc4468e68,"The Karhunen-Lo eve basis functions, more frequently referred to as principal components or empirical orthogonal functions (EOFs), of the noise response of the climate system are an important tool for geophysical studies. Many researchers have used this tool to examine the geophysical and climatological phenomena. Perhaps more frequent use of EOFs in recent studies is in conjunction with the development of the signal detection and estimation methods of the background uctuations of a detection variable serve as an orthogonal basis set and are used to design optimal techniques for detecting and estimating signals. A detection and prediction approach is to design a lter or optimal weights for the signal to be detected. It has been reported that weighted averaging of data over the surface of the Earth improved the detectability of climatic changes (Hasselmann 1979; Stefanick 1981; Bell 1982). Since the signal-to-noise ratio (SNR) varies geographically, there exists an optimal geographical weighting of the signal which maximizes the SNR. The design of an optimal weighting function may require detailed knowledge on the natural uctuation of the climate system. A conceptually similar approach is to employ a particular pattern (or patterns) of climatic change for detection and prediction (e.g., Barnett and Hasselmann 1979; Hasselmann 1979). The patterns of interest (also called the predictors) may include the principal components (empirical orthogonal functions) (e. von Storch 1990) among others. This approach also requires complete knowledge of the natural variability of the climate system. To test and improve the detection and prediction techniques addressed above, a complete cross-spectral covariance matrix, or similarly, a complete set of the principal components of natural uctuations of the climate system for each frequency band of the spectrum is necessary. In reality, a reliable spectrum of observational covariance matrix is not available because observations are not suuciently long and sampling errors contaminate the observational records (Preisendorfer and Barnett 1977; North et al. 1982). Further, inadequate spatial coverage of observations may introduce bias. Therefore, the covariance matrix of the noise response is often estimated from a simple stochastic model. Kim and North (1991, 1992) examined the covariance matrix in terms of various second-moment statistics earlier. Examined here are the principal components of the covariance matrix of the surface temperature uctuations in a simple coupled climate model in comparison with observations. The principal components not only are an",2009,52,14117,1668,1,0,3,13,175,903,1082,1144,1134,1081
da7ab2f1b6278472f3671a7430c9a72bad07781f,"PAML, currently in version 4, is a package of programs for phylogenetic analyses of DNA and protein sequences using maximum likelihood (ML). The programs may be used to compare and test phylogenetic trees, but their main strengths lie in the rich repertoire of evolutionary models implemented, which can be used to estimate parameters in models of sequence evolution and to test interesting biological hypotheses. Uses of the programs include estimation of synonymous and nonsynonymous rates (d(N) and d(S)) between two protein-coding DNA sequences, inference of positive Darwinian selection through phylogenetic comparison of protein-coding genes, reconstruction of ancestral genes and proteins for molecular restoration studies of extinct life forms, combined analysis of heterogeneous data sets from multiple gene loci, and estimation of species divergence times incorporating uncertainties in fossil calibrations. This note discusses some of the major applications of the package, which includes example data sets to demonstrate their use. The package is written in ANSI C, and runs under Windows, Mac OSX, and UNIX systems. It is available at -- (http://abacus.gene.ucl.ac.uk/software/paml.html).",2007,203,9021,1777,10,131,298,412,471,583,614,666,638,749
d40ee5dd758c525dfb9932d726bb4e844b7b8478,"Receiver operating characteristics (ROC) graphs are useful for organizing classifiers and visualizing their performance. ROC graphs are commonly used in medical decision making, and in recent years have been used increasingly in machine learning and data mining research. Although ROC graphs are apparently simple, there are some common misconceptions and pitfalls when using them in practice. The purpose of this article is to serve as an introduction to ROC graphs and as a guide for using them in research.",2006,45,14314,1234,0,0,0,0,0,0,1,4,75,1122
215579acece24b34f6ab91fab62bac8ba7ccfe03,,2002,0,16249,1013,1,1,5,5,9,12,517,1114,1268,1194
c98386ddf2fe4973da42187a9e3c9167095acf4e,"During the past 30 years, meta-analysis has been an indispensable tool for revealing the hidden meaning of our research literatures. The four articles in this special section on meta-analysis illustrate some of the complexities entailed in meta-analysis methods. Although meta-analysis is a powerful tool for advancing cumulative knowledge, researchers can be confused by the complicated issues involved in the methodology. Each of these four articles contributes both to advancing this methodology and to the increasing complexities that can befuddle researchers. In these comments, the author attempts to clarify both of these aspects and provide a perspective on the methodological issues examined in these articles.",2008,114,15161,703,0,0,0,0,0,0,0,0,0,4
b6fbb3a44a8e946b4a231118a737a396517c83de,"AIM
This paper is a description of inductive and deductive content analysis.


BACKGROUND
Content analysis is a method that may be used with either qualitative or quantitative data and in an inductive or deductive way. Qualitative content analysis is commonly used in nursing studies but little has been published on the analysis process and many research books generally only provide a short description of this method.


DISCUSSION
When using content analysis, the aim was to build a model to describe the phenomenon in a conceptual form. Both inductive and deductive analysis processes are represented as three main phases: preparation, organizing and reporting. The preparation phase is similar in both approaches. The concepts are derived from the data in inductive content analysis. Deductive content analysis is used when the structure of analysis is operationalized on the basis of previous knowledge.


CONCLUSION
Inductive content analysis is used in cases where there are no previous studies dealing with the phenomenon or when it is fragmented. A deductive approach is useful if the general aim was to test a previous theory in a different situation or to compare categories at different time periods.",2008,65,11840,609,0,0,0,0,0,1,379,1016,1090,1290
39dae53515afb42664369c291ec6d1ce34d778bd,"BackgroundCorrelation networks are increasingly being used in bioinformatics applications. For example, weighted gene co-expression network analysis is a systems biology method for describing the correlation patterns among genes across microarray samples. Weighted correlation network analysis (WGCNA) can be used for finding clusters (modules) of highly correlated genes, for summarizing such clusters using the module eigengene or an intramodular hub gene, for relating modules to one another and to external sample traits (using eigengene network methodology), and for calculating module membership measures. Correlation networks facilitate network based gene screening methods that can be used to identify candidate biomarkers or therapeutic targets. These methods have been successfully applied in various biological contexts, e.g. cancer, mouse genetics, yeast genetics, and analysis of brain imaging data. While parts of the correlation network methodology have been described in separate publications, there is a need to provide a user-friendly, comprehensive, and consistent software implementation and an accompanying tutorial.ResultsThe WGCNA R software package is a comprehensive collection of R functions for performing various aspects of weighted correlation network analysis. The package includes functions for network construction, module detection, gene selection, calculations of topological properties, data simulation, visualization, and interfacing with external software. Along with the R package we also present R software tutorials. While the methods development was motivated by gene expression data, the underlying data mining approach can be applied to a variety of different settings.ConclusionThe WGCNA package provides R functions for weighted correlation network analysis, e.g. co-expression network analysis of gene expression data. The R package along with its source code and additional material are freely available at http://www.genetics.ucla.edu/labs/horvath/CoexpressionNetwork/Rpackages/WGCNA.",2008,51,9025,1051,2,9,29,60,112,163,263,361,592,783
0e2532c31c992ac0930998561932f198b467572d,"This article examines the function of documents as a data source in qualitative research and discusses document analysis procedure in the context of actual research experiences. Targeted to research novices, the article takes a nuts‐and‐bolts approach to document analysis. It describes the nature and forms of documents, outlines the advantages and limitations of document analysis, and offers specific examples of the use of documents in the research process. The application of document analysis to a grounded theory study is illustrated.",2009,34,4574,534,0,12,16,59,127,198,275,417,534,725
dd1b3a3793619cec8994cc7cca10e6dee656fb7b,"UNLABELLED
Research over the last few years has revealed significant haplotype structure in the human genome. The characterization of these patterns, particularly in the context of medical genetic association studies, is becoming a routine research activity. Haploview is a software package that provides computation of linkage disequilibrium statistics and population haplotype patterns from primary genotype data in a visually appealing and interactive interface.


AVAILABILITY
http://www.broad.mit.edu/mpg/haploview/


CONTACT
jcbarret@broad.mit.edu",2005,12,13390,1399,0,0,0,1,74,1111,1159,1137,1018,973
6fb968167f3c9c76d00d085a57b265cb912ad012,"Data Mining Methods and Models is the second volume of a three-book series on data mining authored by Larose. The following review was performed independently of LaRose’s other two books. Paraphrasing from the Preface, the goal of this book is to “explore the process of data mining from the point of view of model building.” Nevertheless, the reader will soon be aware that this book is not intended to provide a systematic or comprehensive coverage of various data mining algorithms. Instead, it considers supervised learning or predictive modeling only, and it walks the reader through the data mining process merely with a few selected modeling methods such as (generalized) linear modeling and the Bayesian approach. The book has seven chapters. Chapter 1 introduces dimension reduction, with a focus on principal components analysis (PCA) types of techniques. Chapters 2, 3, and 4 provide a detailed coverage of simple linear regression, multiple linear regression, and logistic regression, respectively. Chapter 5 introduces naive Bayes estimation and Bayesian networks. In Chapter 6, the basic idea of genetic algorithms is discussed. Finally, Chapter 7 presents a case study example of modeling response to direct mail marketing within the CRISP (crossindustry standard process) framework. This book is very easy to read, and this is absolutely the strength which many readers, especially those nonstatistically oriented ones, will greatly appreciate. Predictive modeling is perhaps the most technical part in a data mining process. The author has done an excellent job in making this difficult topic accessible to a broad audience. For example, I like the way in which Bayesian networks are introduced in Chapter 5. After the reader goes through a churn example on naive Bayes estimation in a step-by-step manner, Bayesian belief networks become easily understood as natural extensions. The overall style of the book is clear and patient. The main limitation of the book is its limited coverage. An inspired reader would expect to see a much more extended list of topics. Hastie, Tibishirani, and Friedman (2001) gave a full and more technical account of various data mining algorithms. The inclusion of genetic algorithms in Chapter 6 seems novel when compared to Hastie, Tibishirani, and Friedman (2001), but at the same time, a little unexpected as a separate chapter, since a genetic algorithm involves a stochastics search scheme, which is somewhat involved given the elementary nature of this text. Another noteworthy issue is that the author does not make an attempt to distinguish between conventional statistical analysis and data mining. I found a few errors. On Page 25, for example, it should be ai = 1, instead of ai = 1/4. Also, in the frame on the top of Page 211, it might have been “Posterior Odds,” instead of “Posterior Odds Ratio.” The book uses three different software packages to implement the ideas including SPSS with Clementine, Minitab, and WEKA, which might not be appealing. On the other hand, it is justifiable as it allows one to perform data mining with affordable costs. In summary, I recommend this fairly readable book for adoption in a graduate-level introductory course on data mining, especially when the students come from varied backgrounds.",2008,5,6081,1832,57,100,190,265,350,401,473,572,669,712
85dfac3a261fbdea3b4e1a6f3264c6384bbc4485,"Qualitative content analysis as described in published literature shows conflicting opinions and unsolved issues regarding meaning and use of concepts, procedures and interpretation. This paper provides an overview of important concepts (manifest and latent content, unit of analysis, meaning unit, condensation, abstraction, content area, code, category and theme) related to qualitative content analysis; illustrates the use of concepts related to the research procedure; and proposes measures to achieve trustworthiness (credibility, dependability and transferability) throughout the steps of the research procedure. Interpretation in qualitative content analysis is discussed in light of Watzlawick et al.'s [Pragmatics of Human Communication. A Study of Interactional Patterns, Pathologies and Paradoxes. W.W. Norton & Company, New York, London] theory of communication.",2004,58,14412,1104,0,0,0,0,0,0,0,0,0,4
d96faee1898de7a052115ecfe533a5b2fd1151c0,"This paper develops a new approach to the problem of testing the existence of a level relationship between a dependent variable and a set of regressors, when it is not known with certainty whether the underlying regressors are trend- or first-difference stationary. The proposed tests are based on standard F- and t-statistics used to test the significance of the lagged levels of the variables in a univariate equilibrium correction mechanism. The asymptotic distributions of these statistics are non-standard under the null hypothesis that there exists no level relationship, irrespective of whether the regressors are I(0) or I(1). Two sets of asymptotic critical values are provided: one when all regressors are purely I(1) and the other if they are all purely I(0). These two sets of critical values provide a band covering all possible classifications of the regressors into purely I(0), purely I(1) or mutually cointegrated. Accordingly, various bounds testing procedures are proposed. It is shown that the proposed tests are consistent, and their asymptotic distribution under the null and suitably defined local alternatives are derived. The empirical relevance of the bounds procedures is demonstrated by a re-examination of the earnings equation included in the UK Treasury macroeconometric model. Copyright © 2001 John Wiley & Sons, Ltd.",2001,46,11403,2343,0,0,0,0,0,0,0,0,0,2
39dfeda235027e1bed00ab33bcb2ad16831677f8,"Hypothesis-testing methods for multivariate data are needed to make rigorous probability statements about the effects of factors and their interactions in experiments. Analysis of variance is particularly powerful for the analysis of univariate data. The traditional multivariate analogues, however, are too stringent in their assumptions for most ecological multivariate data sets. Non-parametric methods, based on permutation tests, are preferable. This paper describes a new non-parametric method for multivariate analysis of variance, after McArdle and Anderson (in press). It is given here, with several applications in ecology, to provide an alternative and perhaps more intuitive formulation for ANOVA (based on sums of squared distances) to complement the description pro- vided by McArdle and Anderson (in press) for the analysis of any linear model. It is an improvement on previous non-parametric methods because it allows a direct additive partitioning of variation for complex models. It does this while maintaining the flexibility and lack of formal assumptions of other non-parametric methods. The test- statistic is a multivariate analogue to Fisher's F-ratio and is calculated directly from any symmetric distance or dissimilarity matrix. P-values are then obtained using permutations. Some examples of the method are given for tests involving several factors, including factorial and hierarchical (nested) designs and tests of interactions.",2001,127,10965,1444,0,0,0,0,0,0,0,0,0,158
a82d7e0dc7b2d3a1b159e0902bb9f3017788a786,"A comprehensive, but simple-to-use software package for executing a range of standard numerical analysis and operations used in quantitative paleontology has been developed. The program, called PAST (PAleontological STatistics), runs on standard Windows computers and is available free of charge. PAST integrates spreadsheet-type data entry with univariate and multivariate statistics, curve fitting, timeseries analysis, data plotting, and simple phylogenetic analysis. Many of the functions are specific to paleontology and ecology, and these functions are not found in standard, more extensive, statistical packages. PAST also includes fourteen case studies (data files and exercises) illustrating use of the program for paleontological problems, making it a complete educational package for courses in quantitative methods.",2001,31,10400,1798,0,0,0,0,0,0,0,0,0,3
21c41fcec6ac8a7f55c539ac199247f200633753,"Microarrays can measure the expression of thousands of genes to identify changes in expression between different biological states. Methods are needed to determine the significance of these changes while accounting for the enormous number of genes. We describe a method, Significance Analysis of Microarrays (SAM), that assigns a score to each gene on the basis of change in gene expression relative to the standard deviation of repeated measurements. For genes with scores greater than an adjustable threshold, SAM uses permutations of the repeated measurements to estimate the percentage of genes identified by chance, the false discovery rate (FDR). When the transcriptional response of human cells to ionizing radiation was measured by microarrays, SAM identified 34 genes that changed at least 1.5-fold with an estimated FDR of 12%, compared with FDRs of 60 and 84% by using conventional methods of analysis. Of the 34 genes, 19 were involved in cell cycle regulation and 3 in apoptosis. Surprisingly, four nucleotide excision repair genes were induced, suggesting that this repair pathway for UV-damaged DNA might play a previously unrecognized role in repairing DNA damaged by ionizing radiation.",2001,54,11566,1626,0,0,1,3,249,864,864,894,921,881
c8831d7d318b8d59f9b958d250a58f253f08bd8a,"This article is about a curious phenomenon. Suppose we have a data matrix, which is the superposition of a low-rank component and a sparse component. Can we recover each component individually? We prove that under some suitable assumptions, it is possible to recover both the low-rank and the sparse components exactly by solving a very convenient convex program called Principal Component Pursuit; among all feasible decompositions, simply minimize a weighted combination of the nuclear norm and of the ℓ1 norm. This suggests the possibility of a principled approach to robust principal component analysis since our methodology and results assert that one can recover the principal components of a data matrix even though a positive fraction of its entries are arbitrarily corrupted. This extends to the situation where a fraction of the entries are missing as well. We discuss an algorithm for solving this optimization problem, and present applications in the area of video surveillance, where our methodology allows for the detection of objects in a cluttered background, and in the area of face recognition, where it offers a principled way of removing shadows and specularities in images of faces.",2009,90,5547,1043,9,66,155,236,340,507,532,647,665,703
70b48fd1a0c3d9fef98600578308e1e033c0c67a,Supplementary Figure 1 Overview of the analysis pipeline. Supplementary Table 1 Details of conventionally raised and conventionalized mouse samples. Supplementary Discussion Expanded discussion of QIIME analyses presented in the main text; Sequencing of 16S rRNA gene amplicons; QIIME analysis notes; Expanded Figure 1 legend; Links to raw data and processed output from the runs with and without denoising.,2010,30,23951,2769,0,0,0,0,0,1,2,4,98,3004
e5136e9306bf1b0e3d4be0cea384ee9a969a44fa,"Thematic analysis is a poorly demarcated, rarely acknowledged, yet widely used qualitative analytic method within psychology. In this paper, we argue that it offers an accessible and theoretically flexible approach to analysing qualitative data. We outline what thematic analysis is, locating it in relation to other qualitative analytic methods that search for themes or patterns, and in relation to different epistemological and ontological positions. We then provide clear guidelines to those wanting to start thematic analysis, or conduct it in a more deliberate and rigorous way, and consider potential pitfalls in conducting thematic analysis. Finally, we outline the disadvantages and advantages of thematic analysis. We conclude by advocating thematic analysis as a useful and flexible method for qualitative research in and beyond psychology.",2006,110,75769,5318,0,0,0,0,0,0,1,0,0,0
67556c4f0cfdd1f09fff373768b03638f949be0d,"Chapter 3 deals with probability distributions, discrete and continuous densities, distribution functions, bivariate distributions, means, variances, covariance, correlation, and some random process material. Chapter 4 is a detailed study of the concept of utility including the psychological aspects, risk, attributes, rules for utilities, multidimensional utility, and normal form of analysis. Chapter 5 treats games and optimization, linear optimization, and mixed strategies. Entropy is the topic of Chapter 6 with sections devoted to entropy, disorder, information, Shannon’s theorem, demon’s roulette, Maxwell– Boltzmann distribution, Schrodinger’s nutshell, maximum entropy probability distributions, blackbodies, and Bose–Einstein distribution. Chapter 7 is standard statistical fare including transformations of random variables, characteristic functions, generating functions, and the classic limit theorems such as the central limit theorem and the laws of large numbers. Chapter 8 is about exchangeability and inference with sections on Bayesian techniques and classical inference. Partial exchangeability is also treated. Chapter 9 considers such things as order statistics, extreme value, intensity, hazard functions, and Poisson processes. Chapter 10 covers basic elements of risk and reliability, while Chapter 11 is devoted to curve fitting, regression, and Monte Carlo simulation. There is an ample number of exercises at the ends of the chapters with answers or comments on many of them in an appendix in the back of the book. Other appendices are on the common discrete and continuous distributions and mathematical aspects of integration.",2007,0,18912,4802,0,0,0,0,0,0,0,1,7,889
ec3d71a2fdd01968a6dc638ee261715a0f118c1e,"Summary: It is expected that emerging digital gene expression (DGE) technologies will overtake microarray technologies in the near future for many functional genomics applications. One of the fundamental data analysis tasks, especially for gene expression studies, involves determining whether there is evidence that counts for a transcript or exon are significantly different across experimental conditions. edgeR is a Bioconductor software package for examining differential expression of replicated count data. An overdispersed Poisson model is used to account for both biological and technical variability. Empirical Bayes methods are used to moderate the degree of overdispersion across transcripts, improving the reliability of inference. The methodology can be used even with the most minimal levels of replication, provided at least one phenotype or experimental condition is replicated. The software may have other applications beyond sequencing data, such as proteome peptide count data. Availability: The package is freely available under the LGPL licence from the Bioconductor web site (http://bioconductor.org). Contact: mrobinson@wehi.edu.au",2009,10,21553,1162,0,0,0,0,0,0,1,1,7,64
a2893118e14c29a23472b02249b4641b9971786b,"Although genomewide RNA expression analysis has become a routine tool in biomedical research, extracting biological insight from such information remains a major challenge. Here, we describe a powerful analytical method called Gene Set Enrichment Analysis (GSEA) for interpreting gene expression data. The method derives its power by focusing on gene sets, that is, groups of genes that share common biological function, chromosomal location, or regulation. We demonstrate how GSEA yields insights into several cancer-related data sets, including leukemia and lung cancer. Notably, where single-gene analysis finds little similarity between two independent studies of patient survival in lung cancer, GSEA reveals many biological pathways in common. The GSEA method is embodied in a freely available software package, together with an initial database of 1,325 biologically defined gene sets.",2005,85,26903,2908,0,0,0,0,0,0,0,0,0,0
d17669e4f3f4dd3a180bde84dd54a508d0dc22f4,"A comprehensive, but simple-to-use software package for executing a range of standard numerical analysis and operations used in quantitative paleontology has been developed. The program, called PAST (PAleontological STatistics), runs on standard Windows computers and is available free of charge. PAST integrates spreadsheet-type data entry with univariate and multivariate statistics, curve fitting, timeseries analysis, data plotting, and simple phylogenetic analysis. Many of the functions are specific to paleontology and ecology, and these functions are not found in standard, more extensive, statistical packages. PAST also includes fourteen case studies (data files and exercises) illustrating use of the program for paleontological problems, making it a complete educational package for courses in quantitative methods.",2001,17,17969,3587,0,0,0,0,0,0,0,0,0,0
9529c25408dc86194d417aed73d49ae0e418f1be,"32.03 MB Free download Econometric Analysis of Cross Section and Panel Data book PDF, FB2, EPUB and MOBI. Read online Econometric Analysis of Cross Section and Panel Data which classified as Other that has 776 pages that contain constructive material with lovely reading experience. Reading online Econometric Analysis of Cross Section and Panel Data book will be provide using wonderful book reader and it's might gives you some access to identifying the book content before you download the book.",2002,0,21019,2368,0,0,0,0,0,0,0,3,0,4
89fe2ca0bc4ea3f53f5745de6a88e094b8734a2b,1 Introduction: Models and Model Building Section I Understanding and Preparing for Multivariate Analysis 2 Cleaning and Transforming Data 3 Factor Analysis Section II Analysis Using Dependece Techniques 4 Simple and Multiple Regression Analysis 5 Canonical correlation 6 Conjoint analysis 7 Multiple Discriminant Analysis and Logistic Regression 8 ANOVA and MANOVA Section III Analysis using Interdependence Techniques 9 Group data and Cluster Analysis 10 MDS and Correspondence Analysis Structural Equation Modeling 11 SEM: An Introduction 12 Application of SEM,2010,0,6831,1353,53,154,275,450,587,635,645,725,827,809
0ad5733eafb41274895bf1dce6b92ae8f3d68c60,,2004,0,18831,2817,1,3,6,2,10,713,1440,1290,1233,1117
0d6cf3cd3794bc31a4e5a8ded4d4ba83bb20f9b0,"BOOK REVIEW: Constructing grounded theory. A practical guide through qualitative analysis Kathy Charmaz, 2006, 208 pp. London: Sage. ISBN 2005928035",2006,0,10716,2252,0,0,0,1,365,666,939,1134,1328,847
7bd23e6ec32cb1507a385c21a21150e9c332682f,"genalex is a user-friendly cross-platform package that runs within Microsoft Excel, enabling population genetic analyses of codominant, haploid and binary data. Allele frequency-based analyses include heterozygosity, F statistics, Nei's genetic distance, population assignment, probabilities of identity and pairwise relatedness. Distance-based calculations include amova, principal coordinates analysis (PCA), Mantel tests, multivariate and 2D spatial autocorrelation and twogener. More than 20 different graphs summarize data and aid exploration. Sequence and genotype data can be imported from automated sequencers, and exported to other software. Initially designed as tool for teaching, genalex 6 now offers features for researchers as well. Documentation and the program are available at http://www.anu.edu.au/BoZo/GenAlEx/",2006,12,14558,3330,0,0,0,0,0,0,3,972,1332,1368
895860c6083736508d2541900cdf0960eb11592f,"The design, implementation, and capabilities of an extensible visualization system, UCSF Chimera, are discussed. Chimera is segmented into a core that provides basic services and visualization, and extensions that provide most higher level functionality. This architecture ensures that the extension mechanism satisfies the demands of outside developers who wish to incorporate new features. Two unusual extensions are presented: Multiscale, which adds the ability to visualize large‐scale molecular assemblies such as viral coats, and Collaboratory, which allows researchers to share a Chimera session interactively despite being at separate locales. Other extensions include Multalign Viewer, for showing multiple sequence alignments and associated structures; ViewDock, for screening docked ligand orientations; Movie, for replaying molecular dynamics trajectories; and Volume Viewer, for display and analysis of volumetric data. A discussion of the usage of Chimera in real‐world situations is given, along with anticipated future directions. Chimera includes full user documentation, is free to academic and nonprofit users, and is available for Microsoft Windows, Linux, Apple Mac OS X, SGI IRIX, and HP Tru64 Unix from http://www.cgl.ucsf.edu/chimera/. © 2004 Wiley Periodicals, Inc. J Comput Chem 25: 1605–1612, 2004",2004,70,28327,1713,0,0,0,0,1,0,0,0,0,0
e7c8aa2cb2223f17615c1b1ae3b33095466e95cc,"The two most commonly used methods to analyze data from real-time, quantitative PCR experiments are absolute quantification and relative quantification. Absolute quantification determines the input copy number, usually by relating the PCR signal to a standard curve. Relative quantification relates the PCR signal of the target transcript in a treatment group to that of another sample such as an untreated control. The 2(-Delta Delta C(T)) method is a convenient way to analyze the relative changes in gene expression from real-time quantitative PCR experiments. The purpose of this report is to present the derivation, assumptions, and applications of the 2(-Delta Delta C(T)) method. In addition, we present the derivation and applications of two variations of the 2(-Delta Delta C(T)) method that may be useful in the analysis of real-time, quantitative PCR data.",2001,21,115916,1656,0,0,0,0,0,0,0,0,1,0
05abdc87bcaf2963fd511672e64ab39d02239aaf,,2007,30,24491,2512,0,1,0,0,1,0,5,6,535,2032
2d6f573c36c5e2153b65859fb080523fc4d842d0,"We announce the release of the fourth version of MEGA software, which expands on the existing facilities for editing DNA sequence data from autosequencers, mining Web-databases, performing automatic and manual sequence alignment, analyzing sequence alignments to estimate evolutionary distances, inferring phylogenetic trees, and testing evolutionary hypotheses. Version 4 includes a unique facility to generate captions, written in figure legend format, in order to provide natural language descriptions of the models and methods used in the analyses. This facility aims to promote a better understanding of the underlying assumptions used in analyses, and of the results generated. Another new feature is the Maximum Composite Likelihood (MCL) method for estimating evolutionary distances between all pairs of sequences simultaneously, with and without incorporating rate variation among sites and substitution pattern heterogeneities among lineages. This MCL method also can be used to estimate transition/transversion bias and nucleotide substitution pattern without knowledge of the phylogenetic tree. This new version is a native 32-bit Windows application with multi-threading and multi-user supports, and it is also available to run in a Linux desktop environment (via the Wine compatibility layer) and on Intel-based Macintosh computers under the Parallels program. The current version of MEGA is available free of charge at (http://www.megasoftware.net).",2007,10,28423,6043,0,0,0,0,1,18,2034,2152,1667,1255
4e2f43dab69d690dc86422949e410ebf37f522d4,"Bayesian methods have garnered huge interest in cognitive science as an approach to models of cognition and perception. On the other hand, Bayesian methods for data analysis have not yet made much headway in cognitive science against the institutionalized inertia of 20th century null hypothesis significance testing (NHST). Ironically, specific Bayesian models of cognition and perception may not long endure the ravages of empirical verification, but generic Bayesian methods for data analysis will eventually dominate. It is time that Bayesian data analysis became the norm for empirical methods in cognitive science. This article reviews a fatal flaw of NHST and introduces the reader to some benefits of Bayesian data analysis. The article presents illustrative examples of multiple comparisons in Bayesian analysis of variance and Bayesian approaches to statistical power. Copyright © 2010 John Wiley & Sons, Ltd. For further resources related to this article, please visit the WIREs website.",2010,87,5662,709,296,287,323,345,347,434,424,416,498,498
57e7a7323f58a35f5e2cc33bf17d4ac9cdcafdd4,"DAVID bioinformatics resources consists of an integrated biological knowledgebase and analytic tools aimed at systematically extracting biological meaning from large gene/protein lists. This protocol explains how to use DAVID, a high-throughput and integrated data-mining environment, to analyze gene lists derived from high-throughput genomic experiments. The procedure first requires uploading a gene list containing any number of common gene identifiers followed by analysis using one or more text and pathway-mining tools such as gene functional classification, functional annotation chart or clustering and functional annotation table. By following this protocol, investigators are able to gain an in-depth understanding of the biological themes in lists of genes that are enriched in genome-scale studies.",2008,16,27514,2132,0,0,0,0,0,0,0,0,7,39
e09bb0025f4939a4bd233a70937584b4d7bdd0a7,"BackgroundThe evolutionary analysis of molecular sequence variation is a statistical enterprise. This is reflected in the increased use of probabilistic models for phylogenetic inference, multiple sequence alignment, and molecular population genetics. Here we present BEAST: a fast, flexible software architecture for Bayesian analysis of molecular sequences related by an evolutionary tree. A large number of popular stochastic models of sequence evolution are provided and tree-based models suitable for both within- and between-species sequence data are implemented.ResultsBEAST version 1.4.6 consists of 81000 lines of Java source code, 779 classes and 81 packages. It provides models for DNA and protein sequence evolution, highly parametric coalescent analysis, relaxed clock phylogenetics, non-contemporaneous sequence data, statistical alignment and a wide range of options for prior distributions. BEAST source code is object-oriented, modular in design and freely available at http://beast-mcmc.googlecode.com/ under the GNU LGPL license.ConclusionBEAST is a powerful and flexible evolutionary analysis package for molecular sequence variation. It also provides a resource for the further development of new models and statistical methods of evolutionary analysis.",2007,45,11140,3504,0,0,1,247,973,1270,1219,1114,1018,941
cad327e1e3a0799202cb40da5da51d7b0616b64e,"Arlequin ver 3.0 is a software package integrating several basic and advanced methods for population genetics data analysis, like the computation of standard genetic diversity indices, the estimation of allele and haplotype frequencies, tests of departure from linkage equilibrium, departure from selective neutrality and demographic equilibrium, estimation or parameters from past population expansions, and thorough analyses of population subdivision under the AMOVA framework. Arlequin 3 introduces a completely new graphical interface written in C++, a more robust semantic analysis of input files, and two new methods: a Bayesian estimation of gametic phase from multi-locus genotypes, and an estimation of the parameters of an instantaneous spatial expansion from DNA sequence polymorphism. Arlequin can handle several data types like DNA sequences, microsatellite data, or standard multi-locus genotypes. A Windows version of the software is freely available on http://cmpg.unibe.ch/software/arlequin3.",2007,148,12556,4438,1,1,21,1207,1437,1392,1211,1052,891,751
80935b370bac09ce615a002caabc30fbb26f029b,"With its theoretical basis firmly established in molecular evolutionary and population genetics, the comparative DNA and protein sequence analysis plays a central role in reconstructing the evolutionary histories of species and multigene families, estimating rates of molecular evolution, and inferring the nature and extent of selective forces shaping the evolution of genes and genomes. The scope of these investigations has now expanded greatly owing to the development of high-throughput sequencing techniques and novel statistical and computational methods. These methods require easy-to-use computer programs. One such effort has been to produce Molecular Evolutionary Genetics Analysis (MEGA) software, with its focus on facilitating the exploration and analysis of the DNA and protein sequence variation from an evolutionary perspective. Currently in its third major release, MEGA3 contains facilities for automatic and manual sequence alignment, web-based mining of databases, inference of the phylogenetic trees, estimation of evolutionary distances and testing evolutionary hypotheses. This paper provides an overview of the statistical methods, computational tools, and visual exploration modules for data input and the results obtainable in MEGA.",2004,73,12037,3302,1,0,26,1588,2150,1625,1243,879,678,475
4c97d9b9eb7c158e682844b394b42924af3c5b3f,"Interpretative phenomenological analysis (IPA) is an increasingly popular approach to qualitative inquiry. This handy text covers its theoretical foundations and provides a detailed guide to conducting IPA research. 
 
Extended worked examples from the authors' own studies in health, sexuality, psychological distress and identity illustrate the breadth and depth of IPA research. 
 
Each of the chapters also offers a guide to other good exemplars of IPA research in the designated area. The final section of the book considers how IPA connects with other contemporary qualitative approaches like discourse and narrative analysis and how it addresses issues to do with validity. The book is written in an accessible style and will be extremely useful to students and researchers in psychology and related disciplines in the health and social sciences.",2009,7,6197,1589,6,76,172,280,438,624,709,699,792,811
001c07aefcc186013184009e0c83847f28867e08,"ggplot2: Elegant Graphics for Data Analysis is a new addition to the UseR! series by Springer, probably the fastest expanding source of resources for computational statistics at the current moment. The books in this series are all linked with R, either presenting a new package developed by the own authors of the book or describing how to applying statistical techniques with the different packages available in R. ggplot2 is an implementation in R of The Grammar of Graphics (Wilkinson 2005) a systematic approach to the specification of statistical graphics that was introduced in a book previously reviewed in the Journal of Statistical Software by Cox (2007). This implementation has been developed by Hadley Wickham, who is also the author of the book reviewed here.",2010,1,4911,435,9,20,22,56,87,94,178,255,446,795
7ea9b1915072f2adff3762b59b7c7d79805fee8e,"If radiocarbon measurements are to be used at all for chronological purposes, we have to use statistical methods for calibration. The most widely used method of calibration can be seen as a simple application of Bayesian statistics, which uses both the information from the new measurement and information from the 14C calibration curve. In most dating applications, however, we have larger numbers of 14C measurements and we wish to relate those to events in the past. Bayesian statistics provides a coherent framework in which such analysis can be performed and is becoming a core element in many 14C dating projects. This article gives an overview of the main model components used in chronological analysis, their mathematical formulation, and examples of how such analyses can be performed using the latest version of the OxCal software (v4). Many such models can be put together, in a modular fashion, from simple elements, with defined constraints and groupings. In other cases, the commonly used ""uniform phase"" models might not be appropriate, and ramped, exponential, or normal distributions of events might be more useful. When considering analyses of these kinds, it is useful to be able run simulations on synthetic data. Methods for performing such tests are discussed here along with other methods of diagnosing possible problems with statistical models of this kind.",2009,69,4539,1446,11,103,201,275,402,450,446,453,577,449
87ccc438b0c73fcfdea48485fcdb091a8ecaa89c,"High-throughput sequencing assays such as RNA-Seq, ChIP-Seq or barcode counting provide quantitative readouts in the form of count data. To infer differential signal in such data correctly and with good statistical power, estimation of data variability throughout the dynamic range and a suitable error model are required. We propose a method based on the negative binomial distribution, with variance and mean linked by local regression and present an implementation, DESeq, as an R/Bioconductor package.",2010,80,9807,1096,9,65,225,483,806,957,981,1071,1172,1372
b9544a1bf4b02c6648dbd12702bc10c00e20e197,"Content analysis is a widely used qualitative research technique. Rather than being a single method, current applications of content analysis show three distinct approaches: conventional, directed, or summative. All three approaches are used to interpret meaning from the content of text data and, hence, adhere to the naturalistic paradigm. The major differences among the approaches are coding schemes, origins of codes, and threats to trustworthiness. In conventional content analysis, coding categories are derived directly from the text data. With a directed approach, analysis starts with a theory or relevant research findings as guidance for initial codes. A summative content analysis involves counting and comparisons, usually of keywords or content, followed by the interpretation of the underlying context. The authors delineate analytic procedures specific to each approach and techniques addressing trustworthiness with hypothetical examples drawn from the area of end-of-life care.",2005,57,24913,943,0,0,0,0,0,0,0,0,0,0
2fcf90089d9f95025e8953812a43f0db2de3af7c,,2009,0,10344,2663,0,0,262,430,655,922,1128,1232,1332,1349
d76bde423b71f1cb900b988311bd2d71b700d506,"The extent of heterogeneity in a meta-analysis partly determines the difficulty in drawing overall conclusions. This extent may be measured by estimating a between-study variance, but interpretation is then specific to a particular treatment effect metric. A test for the existence of heterogeneity exists, but depends on the number of studies in the meta-analysis. We develop measures of the impact of heterogeneity on a meta-analysis, from mathematical criteria, that are independent of the number of studies and the treatment effect metric. We derive and propose three suitable statistics: H is the square root of the chi2 heterogeneity statistic divided by its degrees of freedom; R is the ratio of the standard error of the underlying mean from a random effects meta-analysis to the standard error of a fixed effect meta-analytic estimate, and I2 is a transformation of (H) that describes the proportion of total variation in study estimates that is due to heterogeneity. We discuss interpretation, interval estimates and other properties of these measures and examine them in five example data sets showing different amounts of heterogeneity. We conclude that H and I2, which can usually be calculated for published meta-analyses, are particularly useful summaries of the impact of heterogeneity. One or both should be presented in published meta-analyses in preference to the test for heterogeneity.",2002,35,21386,493,0,0,0,0,1,0,1,0,1,1
fc448a7db5a2fac242705bd8e37ae1fc4a858643,"The human genome holds an extraordinary trove of information about human development, physiology, medicine and evolution. Here we report the results of an international collaboration to produce and make freely available a draft sequence of the human genome. We also present an initial analysis of the data, describing some of the insights that can be gleaned from the sequence.",2001,431,17459,430,5,1,4,2,1,2,8,504,764,774
76ad159a2887b008e5a7335d124c148c13e65465,"We have developed a toolbox and graphic user interface, EEGLAB, running under the crossplatform MATLAB environment (The Mathworks, Inc.) for processing collections of single-trial and/or averaged EEG data of any number of channels. Available functions include EEG data, channel and event information importing, data visualization (scrolling, scalp map and dipole model plotting, plus multi-trial ERP-image plots), preprocessing (including artifact rejection, filtering, epoch selection, and averaging), independent component analysis (ICA) and time/frequency decompositions including channel and component cross-coherence supported by bootstrap statistical methods based on data resampling. EEGLAB functions are organized into three layers. Top-layer functions allow users to interact with the data through the graphic interface without needing to use MATLAB syntax. Menu options allow users to tune the behavior of EEGLAB to available memory. Middle-layer functions allow users to customize data processing using command history and interactive 'pop' functions. Experienced MATLAB users can use EEGLAB data structures and stand-alone signal processing functions to write custom and/or batch analysis scripts. Extensive function help and tutorial information are included. A 'plug-in' facility allows easy incorporation of new EEG modules into the main menu. EEGLAB is freely available (http://www.sccn.ucsd.edu/eeglab/) under the GNU public license for noncommercial use and open source development, together with sample data, user tutorial and extensive documentation.",2004,85,14460,1914,0,0,0,0,0,0,0,0,0,0
1a77e19441f3a0e030998fb2d11d9dd774582403,"The techniques available for the interrogation and analysis of neuroimaging data have a large influence in determining the flexibility, sensitivity, and scope of neuroimaging experiments. The development of such methodologies has allowed investigators to address scientific questions that could not previously be answered and, as such, has become an important research area in its own right. In this paper, we present a review of the research carried out by the Analysis Group at the Oxford Centre for Functional MRI of the Brain (FMRIB). This research has focussed on the development of new methodologies for the analysis of both structural and functional magnetic resonance imaging data. The majority of the research laid out in this paper has been implemented as freely available software tools within FMRIB's Software Library (FSL).",2004,52,10646,1541,0,0,0,0,0,77,419,577,673,764
e250c4b0cc0180af9f47b97f3b9ff1727a2767aa,"New software, OLEX2, has been developed for the determination, visualization and analysis of molecular crystal structures. The software has a portable mouse-driven workflow-oriented and fully comprehensive graphical user interface for structure solution, refinement and report generation, as well as novel tools for structure analysis. OLEX2 seamlessly links all aspects of the structure solution, refinement and publication process and presents them in a single workflow-driven package, with the ultimate goal of producing an application which will be useful to both chemists and crystallographers.",2009,10,13162,496,0,0,0,0,0,0,3,653,1471,1660
42abddd227d653a0375d7d037ddb885f6c07f66f,"We present Model-based Analysis of ChIP-Seq data, MACS, which analyzes data generated by short read sequencers such as Solexa's Genome Analyzer. MACS empirically models the shift size of ChIP-Seq tags, and uses it to improve the spatial resolution of predicted binding sites. MACS also uses a dynamic Poisson distribution to effectively capture local biases in the genome, allowing for more robust predictions. MACS compares favorably to existing ChIP-Seq peak-finding algorithms, and is freely available.",2008,17,9866,1179,6,43,122,233,339,455,628,662,729,980
94559c249d204110296c39ed4af2042cc4468e68,"The Karhunen-Lo eve basis functions, more frequently referred to as principal components or empirical orthogonal functions (EOFs), of the noise response of the climate system are an important tool for geophysical studies. Many researchers have used this tool to examine the geophysical and climatological phenomena. Perhaps more frequent use of EOFs in recent studies is in conjunction with the development of the signal detection and estimation methods of the background uctuations of a detection variable serve as an orthogonal basis set and are used to design optimal techniques for detecting and estimating signals. A detection and prediction approach is to design a lter or optimal weights for the signal to be detected. It has been reported that weighted averaging of data over the surface of the Earth improved the detectability of climatic changes (Hasselmann 1979; Stefanick 1981; Bell 1982). Since the signal-to-noise ratio (SNR) varies geographically, there exists an optimal geographical weighting of the signal which maximizes the SNR. The design of an optimal weighting function may require detailed knowledge on the natural uctuation of the climate system. A conceptually similar approach is to employ a particular pattern (or patterns) of climatic change for detection and prediction (e.g., Barnett and Hasselmann 1979; Hasselmann 1979). The patterns of interest (also called the predictors) may include the principal components (empirical orthogonal functions) (e. von Storch 1990) among others. This approach also requires complete knowledge of the natural variability of the climate system. To test and improve the detection and prediction techniques addressed above, a complete cross-spectral covariance matrix, or similarly, a complete set of the principal components of natural uctuations of the climate system for each frequency band of the spectrum is necessary. In reality, a reliable spectrum of observational covariance matrix is not available because observations are not suuciently long and sampling errors contaminate the observational records (Preisendorfer and Barnett 1977; North et al. 1982). Further, inadequate spatial coverage of observations may introduce bias. Therefore, the covariance matrix of the noise response is often estimated from a simple stochastic model. Kim and North (1991, 1992) examined the covariance matrix in terms of various second-moment statistics earlier. Examined here are the principal components of the covariance matrix of the surface temperature uctuations in a simple coupled climate model in comparison with observations. The principal components not only are an",2009,52,14117,1668,1,0,3,13,175,903,1082,1144,1134,1081
7a6142cfa79cc01ceced5e144bd0e01a0f241a74,,2009,43,7893,2014,377,456,500,626,706,655,723,661,657,644
20aeb2357e9e215787c7e0d0acfe7a6b598c9103,"This book describes ggplot2, a new data visualization package for R that uses the insights from Leland Wilkisons Grammar of Graphics to create a powerful and flexible system for creating data graphics. With ggplot2, its easy to: produce handsome, publication-quality plots, with automatic legends created from the plot specification superpose multiple layers (points, lines, maps, tiles, box plots to name a few) from different data sources, with automatically adjusted common scales add customisable smoothers that use the powerful modelling capabilities of R, such as loess, linear models, generalised additive models and robust regression save any ggplot2 plot (or part thereof) for later modification or reuse create custom themes that capture in-house or journal style requirements, and that can easily be applied to multiple plots approach your graph from a visual perspective, thinking about how each component of the data is represented on the final plot. This book will be useful to everyone who has struggled with displaying their data in an informative and attractive way. You will need some basic knowledge of R (i.e. you should be able to get your data into R), but ggplot2 is a mini-language specifically tailored for producing graphics, and youll learn everything you need in the book. After reading this book youll be able to produce graphics customized precisely for your problems,and youll find it easy to get graphics out of your head and on to the screen or page.",2009,0,20903,1807,0,0,0,0,0,1,2,0,3,9
da7ab2f1b6278472f3671a7430c9a72bad07781f,"PAML, currently in version 4, is a package of programs for phylogenetic analyses of DNA and protein sequences using maximum likelihood (ML). The programs may be used to compare and test phylogenetic trees, but their main strengths lie in the rich repertoire of evolutionary models implemented, which can be used to estimate parameters in models of sequence evolution and to test interesting biological hypotheses. Uses of the programs include estimation of synonymous and nonsynonymous rates (d(N) and d(S)) between two protein-coding DNA sequences, inference of positive Darwinian selection through phylogenetic comparison of protein-coding genes, reconstruction of ancestral genes and proteins for molecular restoration studies of extinct life forms, combined analysis of heterogeneous data sets from multiple gene loci, and estimation of species divergence times incorporating uncertainties in fossil calibrations. This note discusses some of the major applications of the package, which includes example data sets to demonstrate their use. The package is written in ANSI C, and runs under Windows, Mac OSX, and UNIX systems. It is available at -- (http://abacus.gene.ucl.ac.uk/software/paml.html).",2007,203,9021,1777,10,131,298,412,471,583,614,666,638,749
d40ee5dd758c525dfb9932d726bb4e844b7b8478,"Receiver operating characteristics (ROC) graphs are useful for organizing classifiers and visualizing their performance. ROC graphs are commonly used in medical decision making, and in recent years have been used increasingly in machine learning and data mining research. Although ROC graphs are apparently simple, there are some common misconceptions and pitfalls when using them in practice. The purpose of this article is to serve as an introduction to ROC graphs and as a guide for using them in research.",2006,45,14314,1234,0,0,0,0,0,0,1,4,75,1122
39dae53515afb42664369c291ec6d1ce34d778bd,"BackgroundCorrelation networks are increasingly being used in bioinformatics applications. For example, weighted gene co-expression network analysis is a systems biology method for describing the correlation patterns among genes across microarray samples. Weighted correlation network analysis (WGCNA) can be used for finding clusters (modules) of highly correlated genes, for summarizing such clusters using the module eigengene or an intramodular hub gene, for relating modules to one another and to external sample traits (using eigengene network methodology), and for calculating module membership measures. Correlation networks facilitate network based gene screening methods that can be used to identify candidate biomarkers or therapeutic targets. These methods have been successfully applied in various biological contexts, e.g. cancer, mouse genetics, yeast genetics, and analysis of brain imaging data. While parts of the correlation network methodology have been described in separate publications, there is a need to provide a user-friendly, comprehensive, and consistent software implementation and an accompanying tutorial.ResultsThe WGCNA R software package is a comprehensive collection of R functions for performing various aspects of weighted correlation network analysis. The package includes functions for network construction, module detection, gene selection, calculations of topological properties, data simulation, visualization, and interfacing with external software. Along with the R package we also present R software tutorials. While the methods development was motivated by gene expression data, the underlying data mining approach can be applied to a variety of different settings.ConclusionThe WGCNA package provides R functions for weighted correlation network analysis, e.g. co-expression network analysis of gene expression data. The R package along with its source code and additional material are freely available at http://www.genetics.ucla.edu/labs/horvath/CoexpressionNetwork/Rpackages/WGCNA.",2008,51,9025,1051,2,9,29,60,112,163,263,361,592,783
c98386ddf2fe4973da42187a9e3c9167095acf4e,"During the past 30 years, meta-analysis has been an indispensable tool for revealing the hidden meaning of our research literatures. The four articles in this special section on meta-analysis illustrate some of the complexities entailed in meta-analysis methods. Although meta-analysis is a powerful tool for advancing cumulative knowledge, researchers can be confused by the complicated issues involved in the methodology. Each of these four articles contributes both to advancing this methodology and to the increasing complexities that can befuddle researchers. In these comments, the author attempts to clarify both of these aspects and provide a perspective on the methodological issues examined in these articles.",2008,114,15161,703,0,0,0,0,0,0,0,0,0,4
b6fbb3a44a8e946b4a231118a737a396517c83de,"AIM
This paper is a description of inductive and deductive content analysis.


BACKGROUND
Content analysis is a method that may be used with either qualitative or quantitative data and in an inductive or deductive way. Qualitative content analysis is commonly used in nursing studies but little has been published on the analysis process and many research books generally only provide a short description of this method.


DISCUSSION
When using content analysis, the aim was to build a model to describe the phenomenon in a conceptual form. Both inductive and deductive analysis processes are represented as three main phases: preparation, organizing and reporting. The preparation phase is similar in both approaches. The concepts are derived from the data in inductive content analysis. Deductive content analysis is used when the structure of analysis is operationalized on the basis of previous knowledge.


CONCLUSION
Inductive content analysis is used in cases where there are no previous studies dealing with the phenomenon or when it is fragmented. A deductive approach is useful if the general aim was to test a previous theory in a different situation or to compare categories at different time periods.",2008,65,11840,609,0,0,0,0,0,1,379,1016,1090,1290
0e2532c31c992ac0930998561932f198b467572d,"This article examines the function of documents as a data source in qualitative research and discusses document analysis procedure in the context of actual research experiences. Targeted to research novices, the article takes a nuts‐and‐bolts approach to document analysis. It describes the nature and forms of documents, outlines the advantages and limitations of document analysis, and offers specific examples of the use of documents in the research process. The application of document analysis to a grounded theory study is illustrated.",2009,34,4574,534,0,12,16,59,127,198,275,417,534,725
dd1b3a3793619cec8994cc7cca10e6dee656fb7b,"UNLABELLED
Research over the last few years has revealed significant haplotype structure in the human genome. The characterization of these patterns, particularly in the context of medical genetic association studies, is becoming a routine research activity. Haploview is a software package that provides computation of linkage disequilibrium statistics and population haplotype patterns from primary genotype data in a visually appealing and interactive interface.


AVAILABILITY
http://www.broad.mit.edu/mpg/haploview/


CONTACT
jcbarret@broad.mit.edu",2005,12,13390,1399,0,0,0,1,74,1111,1159,1137,1018,973
6fb968167f3c9c76d00d085a57b265cb912ad012,"Data Mining Methods and Models is the second volume of a three-book series on data mining authored by Larose. The following review was performed independently of LaRose’s other two books. Paraphrasing from the Preface, the goal of this book is to “explore the process of data mining from the point of view of model building.” Nevertheless, the reader will soon be aware that this book is not intended to provide a systematic or comprehensive coverage of various data mining algorithms. Instead, it considers supervised learning or predictive modeling only, and it walks the reader through the data mining process merely with a few selected modeling methods such as (generalized) linear modeling and the Bayesian approach. The book has seven chapters. Chapter 1 introduces dimension reduction, with a focus on principal components analysis (PCA) types of techniques. Chapters 2, 3, and 4 provide a detailed coverage of simple linear regression, multiple linear regression, and logistic regression, respectively. Chapter 5 introduces naive Bayes estimation and Bayesian networks. In Chapter 6, the basic idea of genetic algorithms is discussed. Finally, Chapter 7 presents a case study example of modeling response to direct mail marketing within the CRISP (crossindustry standard process) framework. This book is very easy to read, and this is absolutely the strength which many readers, especially those nonstatistically oriented ones, will greatly appreciate. Predictive modeling is perhaps the most technical part in a data mining process. The author has done an excellent job in making this difficult topic accessible to a broad audience. For example, I like the way in which Bayesian networks are introduced in Chapter 5. After the reader goes through a churn example on naive Bayes estimation in a step-by-step manner, Bayesian belief networks become easily understood as natural extensions. The overall style of the book is clear and patient. The main limitation of the book is its limited coverage. An inspired reader would expect to see a much more extended list of topics. Hastie, Tibishirani, and Friedman (2001) gave a full and more technical account of various data mining algorithms. The inclusion of genetic algorithms in Chapter 6 seems novel when compared to Hastie, Tibishirani, and Friedman (2001), but at the same time, a little unexpected as a separate chapter, since a genetic algorithm involves a stochastics search scheme, which is somewhat involved given the elementary nature of this text. Another noteworthy issue is that the author does not make an attempt to distinguish between conventional statistical analysis and data mining. I found a few errors. On Page 25, for example, it should be ai = 1, instead of ai = 1/4. Also, in the frame on the top of Page 211, it might have been “Posterior Odds,” instead of “Posterior Odds Ratio.” The book uses three different software packages to implement the ideas including SPSS with Clementine, Minitab, and WEKA, which might not be appealing. On the other hand, it is justifiable as it allows one to perform data mining with affordable costs. In summary, I recommend this fairly readable book for adoption in a graduate-level introductory course on data mining, especially when the students come from varied backgrounds.",2008,5,6081,1832,57,100,190,265,350,401,473,572,669,712
85dfac3a261fbdea3b4e1a6f3264c6384bbc4485,"Qualitative content analysis as described in published literature shows conflicting opinions and unsolved issues regarding meaning and use of concepts, procedures and interpretation. This paper provides an overview of important concepts (manifest and latent content, unit of analysis, meaning unit, condensation, abstraction, content area, code, category and theme) related to qualitative content analysis; illustrates the use of concepts related to the research procedure; and proposes measures to achieve trustworthiness (credibility, dependability and transferability) throughout the steps of the research procedure. Interpretation in qualitative content analysis is discussed in light of Watzlawick et al.'s [Pragmatics of Human Communication. A Study of Interactional Patterns, Pathologies and Paradoxes. W.W. Norton & Company, New York, London] theory of communication.",2004,58,14412,1104,0,0,0,0,0,0,0,0,0,4
d96faee1898de7a052115ecfe533a5b2fd1151c0,"This paper develops a new approach to the problem of testing the existence of a level relationship between a dependent variable and a set of regressors, when it is not known with certainty whether the underlying regressors are trend- or first-difference stationary. The proposed tests are based on standard F- and t-statistics used to test the significance of the lagged levels of the variables in a univariate equilibrium correction mechanism. The asymptotic distributions of these statistics are non-standard under the null hypothesis that there exists no level relationship, irrespective of whether the regressors are I(0) or I(1). Two sets of asymptotic critical values are provided: one when all regressors are purely I(1) and the other if they are all purely I(0). These two sets of critical values provide a band covering all possible classifications of the regressors into purely I(0), purely I(1) or mutually cointegrated. Accordingly, various bounds testing procedures are proposed. It is shown that the proposed tests are consistent, and their asymptotic distribution under the null and suitably defined local alternatives are derived. The empirical relevance of the bounds procedures is demonstrated by a re-examination of the earnings equation included in the UK Treasury macroeconometric model. Copyright © 2001 John Wiley & Sons, Ltd.",2001,46,11403,2343,0,0,0,0,0,0,0,0,0,2
39dfeda235027e1bed00ab33bcb2ad16831677f8,"Hypothesis-testing methods for multivariate data are needed to make rigorous probability statements about the effects of factors and their interactions in experiments. Analysis of variance is particularly powerful for the analysis of univariate data. The traditional multivariate analogues, however, are too stringent in their assumptions for most ecological multivariate data sets. Non-parametric methods, based on permutation tests, are preferable. This paper describes a new non-parametric method for multivariate analysis of variance, after McArdle and Anderson (in press). It is given here, with several applications in ecology, to provide an alternative and perhaps more intuitive formulation for ANOVA (based on sums of squared distances) to complement the description pro- vided by McArdle and Anderson (in press) for the analysis of any linear model. It is an improvement on previous non-parametric methods because it allows a direct additive partitioning of variation for complex models. It does this while maintaining the flexibility and lack of formal assumptions of other non-parametric methods. The test- statistic is a multivariate analogue to Fisher's F-ratio and is calculated directly from any symmetric distance or dissimilarity matrix. P-values are then obtained using permutations. Some examples of the method are given for tests involving several factors, including factorial and hierarchical (nested) designs and tests of interactions.",2001,127,10965,1444,0,0,0,0,0,0,0,0,0,158
a82d7e0dc7b2d3a1b159e0902bb9f3017788a786,"A comprehensive, but simple-to-use software package for executing a range of standard numerical analysis and operations used in quantitative paleontology has been developed. The program, called PAST (PAleontological STatistics), runs on standard Windows computers and is available free of charge. PAST integrates spreadsheet-type data entry with univariate and multivariate statistics, curve fitting, timeseries analysis, data plotting, and simple phylogenetic analysis. Many of the functions are specific to paleontology and ecology, and these functions are not found in standard, more extensive, statistical packages. PAST also includes fourteen case studies (data files and exercises) illustrating use of the program for paleontological problems, making it a complete educational package for courses in quantitative methods.",2001,31,10400,1798,0,0,0,0,0,0,0,0,0,3
21c41fcec6ac8a7f55c539ac199247f200633753,"Microarrays can measure the expression of thousands of genes to identify changes in expression between different biological states. Methods are needed to determine the significance of these changes while accounting for the enormous number of genes. We describe a method, Significance Analysis of Microarrays (SAM), that assigns a score to each gene on the basis of change in gene expression relative to the standard deviation of repeated measurements. For genes with scores greater than an adjustable threshold, SAM uses permutations of the repeated measurements to estimate the percentage of genes identified by chance, the false discovery rate (FDR). When the transcriptional response of human cells to ionizing radiation was measured by microarrays, SAM identified 34 genes that changed at least 1.5-fold with an estimated FDR of 12%, compared with FDRs of 60 and 84% by using conventional methods of analysis. Of the 34 genes, 19 were involved in cell cycle regulation and 3 in apoptosis. Surprisingly, four nucleotide excision repair genes were induced, suggesting that this repair pathway for UV-damaged DNA might play a previously unrecognized role in repairing DNA damaged by ionizing radiation.",2001,54,11566,1626,0,0,1,3,249,864,864,894,921,881
c8831d7d318b8d59f9b958d250a58f253f08bd8a,"This article is about a curious phenomenon. Suppose we have a data matrix, which is the superposition of a low-rank component and a sparse component. Can we recover each component individually? We prove that under some suitable assumptions, it is possible to recover both the low-rank and the sparse components exactly by solving a very convenient convex program called Principal Component Pursuit; among all feasible decompositions, simply minimize a weighted combination of the nuclear norm and of the ℓ1 norm. This suggests the possibility of a principled approach to robust principal component analysis since our methodology and results assert that one can recover the principal components of a data matrix even though a positive fraction of its entries are arbitrarily corrupted. This extends to the situation where a fraction of the entries are missing as well. We discuss an algorithm for solving this optimization problem, and present applications in the area of video surveillance, where our methodology allows for the detection of objects in a cluttered background, and in the area of face recognition, where it offers a principled way of removing shadows and specularities in images of faces.",2009,90,5547,1043,9,66,155,236,340,507,532,647,665,703
70b48fd1a0c3d9fef98600578308e1e033c0c67a,Supplementary Figure 1 Overview of the analysis pipeline. Supplementary Table 1 Details of conventionally raised and conventionalized mouse samples. Supplementary Discussion Expanded discussion of QIIME analyses presented in the main text; Sequencing of 16S rRNA gene amplicons; QIIME analysis notes; Expanded Figure 1 legend; Links to raw data and processed output from the runs with and without denoising.,2010,30,23951,2769,0,0,0,0,0,1,2,4,98,3004
e5136e9306bf1b0e3d4be0cea384ee9a969a44fa,"Thematic analysis is a poorly demarcated, rarely acknowledged, yet widely used qualitative analytic method within psychology. In this paper, we argue that it offers an accessible and theoretically flexible approach to analysing qualitative data. We outline what thematic analysis is, locating it in relation to other qualitative analytic methods that search for themes or patterns, and in relation to different epistemological and ontological positions. We then provide clear guidelines to those wanting to start thematic analysis, or conduct it in a more deliberate and rigorous way, and consider potential pitfalls in conducting thematic analysis. Finally, we outline the disadvantages and advantages of thematic analysis. We conclude by advocating thematic analysis as a useful and flexible method for qualitative research in and beyond psychology.",2006,110,75770,5318,0,0,0,0,0,0,1,0,0,0
67556c4f0cfdd1f09fff373768b03638f949be0d,"Chapter 3 deals with probability distributions, discrete and continuous densities, distribution functions, bivariate distributions, means, variances, covariance, correlation, and some random process material. Chapter 4 is a detailed study of the concept of utility including the psychological aspects, risk, attributes, rules for utilities, multidimensional utility, and normal form of analysis. Chapter 5 treats games and optimization, linear optimization, and mixed strategies. Entropy is the topic of Chapter 6 with sections devoted to entropy, disorder, information, Shannon’s theorem, demon’s roulette, Maxwell– Boltzmann distribution, Schrodinger’s nutshell, maximum entropy probability distributions, blackbodies, and Bose–Einstein distribution. Chapter 7 is standard statistical fare including transformations of random variables, characteristic functions, generating functions, and the classic limit theorems such as the central limit theorem and the laws of large numbers. Chapter 8 is about exchangeability and inference with sections on Bayesian techniques and classical inference. Partial exchangeability is also treated. Chapter 9 considers such things as order statistics, extreme value, intensity, hazard functions, and Poisson processes. Chapter 10 covers basic elements of risk and reliability, while Chapter 11 is devoted to curve fitting, regression, and Monte Carlo simulation. There is an ample number of exercises at the ends of the chapters with answers or comments on many of them in an appendix in the back of the book. Other appendices are on the common discrete and continuous distributions and mathematical aspects of integration.",2007,0,18913,4802,0,0,0,0,0,0,0,1,7,889
ec3d71a2fdd01968a6dc638ee261715a0f118c1e,"Summary: It is expected that emerging digital gene expression (DGE) technologies will overtake microarray technologies in the near future for many functional genomics applications. One of the fundamental data analysis tasks, especially for gene expression studies, involves determining whether there is evidence that counts for a transcript or exon are significantly different across experimental conditions. edgeR is a Bioconductor software package for examining differential expression of replicated count data. An overdispersed Poisson model is used to account for both biological and technical variability. Empirical Bayes methods are used to moderate the degree of overdispersion across transcripts, improving the reliability of inference. The methodology can be used even with the most minimal levels of replication, provided at least one phenotype or experimental condition is replicated. The software may have other applications beyond sequencing data, such as proteome peptide count data. Availability: The package is freely available under the LGPL licence from the Bioconductor web site (http://bioconductor.org). Contact: mrobinson@wehi.edu.au",2009,10,21553,1162,0,0,0,0,0,0,1,1,7,64
a2893118e14c29a23472b02249b4641b9971786b,"Although genomewide RNA expression analysis has become a routine tool in biomedical research, extracting biological insight from such information remains a major challenge. Here, we describe a powerful analytical method called Gene Set Enrichment Analysis (GSEA) for interpreting gene expression data. The method derives its power by focusing on gene sets, that is, groups of genes that share common biological function, chromosomal location, or regulation. We demonstrate how GSEA yields insights into several cancer-related data sets, including leukemia and lung cancer. Notably, where single-gene analysis finds little similarity between two independent studies of patient survival in lung cancer, GSEA reveals many biological pathways in common. The GSEA method is embodied in a freely available software package, together with an initial database of 1,325 biologically defined gene sets.",2005,85,26903,2908,0,0,0,0,0,0,0,0,0,0
d17669e4f3f4dd3a180bde84dd54a508d0dc22f4,"A comprehensive, but simple-to-use software package for executing a range of standard numerical analysis and operations used in quantitative paleontology has been developed. The program, called PAST (PAleontological STatistics), runs on standard Windows computers and is available free of charge. PAST integrates spreadsheet-type data entry with univariate and multivariate statistics, curve fitting, timeseries analysis, data plotting, and simple phylogenetic analysis. Many of the functions are specific to paleontology and ecology, and these functions are not found in standard, more extensive, statistical packages. PAST also includes fourteen case studies (data files and exercises) illustrating use of the program for paleontological problems, making it a complete educational package for courses in quantitative methods.",2001,17,17969,3587,0,0,0,0,0,0,0,0,0,0
9529c25408dc86194d417aed73d49ae0e418f1be,"32.03 MB Free download Econometric Analysis of Cross Section and Panel Data book PDF, FB2, EPUB and MOBI. Read online Econometric Analysis of Cross Section and Panel Data which classified as Other that has 776 pages that contain constructive material with lovely reading experience. Reading online Econometric Analysis of Cross Section and Panel Data book will be provide using wonderful book reader and it's might gives you some access to identifying the book content before you download the book.",2002,0,21019,2368,0,0,0,0,0,0,0,3,0,4
89fe2ca0bc4ea3f53f5745de6a88e094b8734a2b,1 Introduction: Models and Model Building Section I Understanding and Preparing for Multivariate Analysis 2 Cleaning and Transforming Data 3 Factor Analysis Section II Analysis Using Dependece Techniques 4 Simple and Multiple Regression Analysis 5 Canonical correlation 6 Conjoint analysis 7 Multiple Discriminant Analysis and Logistic Regression 8 ANOVA and MANOVA Section III Analysis using Interdependence Techniques 9 Group data and Cluster Analysis 10 MDS and Correspondence Analysis Structural Equation Modeling 11 SEM: An Introduction 12 Application of SEM,2010,0,6831,1353,53,154,275,450,587,635,645,725,827,809
0ad5733eafb41274895bf1dce6b92ae8f3d68c60,,2004,0,18831,2817,1,3,6,2,10,713,1440,1290,1233,1117
0d6cf3cd3794bc31a4e5a8ded4d4ba83bb20f9b0,"BOOK REVIEW: Constructing grounded theory. A practical guide through qualitative analysis Kathy Charmaz, 2006, 208 pp. London: Sage. ISBN 2005928035",2006,0,10716,2252,0,0,0,1,365,666,939,1134,1328,847
7bd23e6ec32cb1507a385c21a21150e9c332682f,"genalex is a user-friendly cross-platform package that runs within Microsoft Excel, enabling population genetic analyses of codominant, haploid and binary data. Allele frequency-based analyses include heterozygosity, F statistics, Nei's genetic distance, population assignment, probabilities of identity and pairwise relatedness. Distance-based calculations include amova, principal coordinates analysis (PCA), Mantel tests, multivariate and 2D spatial autocorrelation and twogener. More than 20 different graphs summarize data and aid exploration. Sequence and genotype data can be imported from automated sequencers, and exported to other software. Initially designed as tool for teaching, genalex 6 now offers features for researchers as well. Documentation and the program are available at http://www.anu.edu.au/BoZo/GenAlEx/",2006,12,14558,3330,0,0,0,0,0,0,3,972,1332,1368
895860c6083736508d2541900cdf0960eb11592f,"The design, implementation, and capabilities of an extensible visualization system, UCSF Chimera, are discussed. Chimera is segmented into a core that provides basic services and visualization, and extensions that provide most higher level functionality. This architecture ensures that the extension mechanism satisfies the demands of outside developers who wish to incorporate new features. Two unusual extensions are presented: Multiscale, which adds the ability to visualize large‐scale molecular assemblies such as viral coats, and Collaboratory, which allows researchers to share a Chimera session interactively despite being at separate locales. Other extensions include Multalign Viewer, for showing multiple sequence alignments and associated structures; ViewDock, for screening docked ligand orientations; Movie, for replaying molecular dynamics trajectories; and Volume Viewer, for display and analysis of volumetric data. A discussion of the usage of Chimera in real‐world situations is given, along with anticipated future directions. Chimera includes full user documentation, is free to academic and nonprofit users, and is available for Microsoft Windows, Linux, Apple Mac OS X, SGI IRIX, and HP Tru64 Unix from http://www.cgl.ucsf.edu/chimera/. © 2004 Wiley Periodicals, Inc. J Comput Chem 25: 1605–1612, 2004",2004,70,28327,1713,0,0,0,0,1,0,0,0,0,0
e7c8aa2cb2223f17615c1b1ae3b33095466e95cc,"The two most commonly used methods to analyze data from real-time, quantitative PCR experiments are absolute quantification and relative quantification. Absolute quantification determines the input copy number, usually by relating the PCR signal to a standard curve. Relative quantification relates the PCR signal of the target transcript in a treatment group to that of another sample such as an untreated control. The 2(-Delta Delta C(T)) method is a convenient way to analyze the relative changes in gene expression from real-time quantitative PCR experiments. The purpose of this report is to present the derivation, assumptions, and applications of the 2(-Delta Delta C(T)) method. In addition, we present the derivation and applications of two variations of the 2(-Delta Delta C(T)) method that may be useful in the analysis of real-time, quantitative PCR data.",2001,21,115916,1656,0,0,0,0,0,0,0,0,1,0
05abdc87bcaf2963fd511672e64ab39d02239aaf,,2007,30,24491,2512,0,1,0,0,1,0,5,6,535,2032
2d6f573c36c5e2153b65859fb080523fc4d842d0,"We announce the release of the fourth version of MEGA software, which expands on the existing facilities for editing DNA sequence data from autosequencers, mining Web-databases, performing automatic and manual sequence alignment, analyzing sequence alignments to estimate evolutionary distances, inferring phylogenetic trees, and testing evolutionary hypotheses. Version 4 includes a unique facility to generate captions, written in figure legend format, in order to provide natural language descriptions of the models and methods used in the analyses. This facility aims to promote a better understanding of the underlying assumptions used in analyses, and of the results generated. Another new feature is the Maximum Composite Likelihood (MCL) method for estimating evolutionary distances between all pairs of sequences simultaneously, with and without incorporating rate variation among sites and substitution pattern heterogeneities among lineages. This MCL method also can be used to estimate transition/transversion bias and nucleotide substitution pattern without knowledge of the phylogenetic tree. This new version is a native 32-bit Windows application with multi-threading and multi-user supports, and it is also available to run in a Linux desktop environment (via the Wine compatibility layer) and on Intel-based Macintosh computers under the Parallels program. The current version of MEGA is available free of charge at (http://www.megasoftware.net).",2007,10,28423,6043,0,0,0,0,1,18,2034,2152,1667,1255
4e2f43dab69d690dc86422949e410ebf37f522d4,"Bayesian methods have garnered huge interest in cognitive science as an approach to models of cognition and perception. On the other hand, Bayesian methods for data analysis have not yet made much headway in cognitive science against the institutionalized inertia of 20th century null hypothesis significance testing (NHST). Ironically, specific Bayesian models of cognition and perception may not long endure the ravages of empirical verification, but generic Bayesian methods for data analysis will eventually dominate. It is time that Bayesian data analysis became the norm for empirical methods in cognitive science. This article reviews a fatal flaw of NHST and introduces the reader to some benefits of Bayesian data analysis. The article presents illustrative examples of multiple comparisons in Bayesian analysis of variance and Bayesian approaches to statistical power. Copyright © 2010 John Wiley & Sons, Ltd. For further resources related to this article, please visit the WIREs website.",2010,87,5662,709,296,287,323,345,347,434,424,416,498,498
57e7a7323f58a35f5e2cc33bf17d4ac9cdcafdd4,"DAVID bioinformatics resources consists of an integrated biological knowledgebase and analytic tools aimed at systematically extracting biological meaning from large gene/protein lists. This protocol explains how to use DAVID, a high-throughput and integrated data-mining environment, to analyze gene lists derived from high-throughput genomic experiments. The procedure first requires uploading a gene list containing any number of common gene identifiers followed by analysis using one or more text and pathway-mining tools such as gene functional classification, functional annotation chart or clustering and functional annotation table. By following this protocol, investigators are able to gain an in-depth understanding of the biological themes in lists of genes that are enriched in genome-scale studies.",2008,16,27514,2132,0,0,0,0,0,0,0,0,7,39
e09bb0025f4939a4bd233a70937584b4d7bdd0a7,"BackgroundThe evolutionary analysis of molecular sequence variation is a statistical enterprise. This is reflected in the increased use of probabilistic models for phylogenetic inference, multiple sequence alignment, and molecular population genetics. Here we present BEAST: a fast, flexible software architecture for Bayesian analysis of molecular sequences related by an evolutionary tree. A large number of popular stochastic models of sequence evolution are provided and tree-based models suitable for both within- and between-species sequence data are implemented.ResultsBEAST version 1.4.6 consists of 81000 lines of Java source code, 779 classes and 81 packages. It provides models for DNA and protein sequence evolution, highly parametric coalescent analysis, relaxed clock phylogenetics, non-contemporaneous sequence data, statistical alignment and a wide range of options for prior distributions. BEAST source code is object-oriented, modular in design and freely available at http://beast-mcmc.googlecode.com/ under the GNU LGPL license.ConclusionBEAST is a powerful and flexible evolutionary analysis package for molecular sequence variation. It also provides a resource for the further development of new models and statistical methods of evolutionary analysis.",2007,45,11140,3504,0,0,1,247,973,1270,1219,1114,1018,941
cad327e1e3a0799202cb40da5da51d7b0616b64e,"Arlequin ver 3.0 is a software package integrating several basic and advanced methods for population genetics data analysis, like the computation of standard genetic diversity indices, the estimation of allele and haplotype frequencies, tests of departure from linkage equilibrium, departure from selective neutrality and demographic equilibrium, estimation or parameters from past population expansions, and thorough analyses of population subdivision under the AMOVA framework. Arlequin 3 introduces a completely new graphical interface written in C++, a more robust semantic analysis of input files, and two new methods: a Bayesian estimation of gametic phase from multi-locus genotypes, and an estimation of the parameters of an instantaneous spatial expansion from DNA sequence polymorphism. Arlequin can handle several data types like DNA sequences, microsatellite data, or standard multi-locus genotypes. A Windows version of the software is freely available on http://cmpg.unibe.ch/software/arlequin3.",2007,148,12556,4438,1,1,21,1207,1437,1392,1211,1052,891,751
80935b370bac09ce615a002caabc30fbb26f029b,"With its theoretical basis firmly established in molecular evolutionary and population genetics, the comparative DNA and protein sequence analysis plays a central role in reconstructing the evolutionary histories of species and multigene families, estimating rates of molecular evolution, and inferring the nature and extent of selective forces shaping the evolution of genes and genomes. The scope of these investigations has now expanded greatly owing to the development of high-throughput sequencing techniques and novel statistical and computational methods. These methods require easy-to-use computer programs. One such effort has been to produce Molecular Evolutionary Genetics Analysis (MEGA) software, with its focus on facilitating the exploration and analysis of the DNA and protein sequence variation from an evolutionary perspective. Currently in its third major release, MEGA3 contains facilities for automatic and manual sequence alignment, web-based mining of databases, inference of the phylogenetic trees, estimation of evolutionary distances and testing evolutionary hypotheses. This paper provides an overview of the statistical methods, computational tools, and visual exploration modules for data input and the results obtainable in MEGA.",2004,73,12037,3302,1,0,26,1588,2150,1625,1243,879,678,475
4c97d9b9eb7c158e682844b394b42924af3c5b3f,"Interpretative phenomenological analysis (IPA) is an increasingly popular approach to qualitative inquiry. This handy text covers its theoretical foundations and provides a detailed guide to conducting IPA research. 
 
Extended worked examples from the authors' own studies in health, sexuality, psychological distress and identity illustrate the breadth and depth of IPA research. 
 
Each of the chapters also offers a guide to other good exemplars of IPA research in the designated area. The final section of the book considers how IPA connects with other contemporary qualitative approaches like discourse and narrative analysis and how it addresses issues to do with validity. The book is written in an accessible style and will be extremely useful to students and researchers in psychology and related disciplines in the health and social sciences.",2009,7,6197,1589,6,76,172,280,438,624,709,699,792,811
001c07aefcc186013184009e0c83847f28867e08,"ggplot2: Elegant Graphics for Data Analysis is a new addition to the UseR! series by Springer, probably the fastest expanding source of resources for computational statistics at the current moment. The books in this series are all linked with R, either presenting a new package developed by the own authors of the book or describing how to applying statistical techniques with the different packages available in R. ggplot2 is an implementation in R of The Grammar of Graphics (Wilkinson 2005) a systematic approach to the specification of statistical graphics that was introduced in a book previously reviewed in the Journal of Statistical Software by Cox (2007). This implementation has been developed by Hadley Wickham, who is also the author of the book reviewed here.",2010,1,4911,435,9,20,22,56,87,94,178,255,446,795
7ea9b1915072f2adff3762b59b7c7d79805fee8e,"If radiocarbon measurements are to be used at all for chronological purposes, we have to use statistical methods for calibration. The most widely used method of calibration can be seen as a simple application of Bayesian statistics, which uses both the information from the new measurement and information from the 14C calibration curve. In most dating applications, however, we have larger numbers of 14C measurements and we wish to relate those to events in the past. Bayesian statistics provides a coherent framework in which such analysis can be performed and is becoming a core element in many 14C dating projects. This article gives an overview of the main model components used in chronological analysis, their mathematical formulation, and examples of how such analyses can be performed using the latest version of the OxCal software (v4). Many such models can be put together, in a modular fashion, from simple elements, with defined constraints and groupings. In other cases, the commonly used ""uniform phase"" models might not be appropriate, and ramped, exponential, or normal distributions of events might be more useful. When considering analyses of these kinds, it is useful to be able run simulations on synthetic data. Methods for performing such tests are discussed here along with other methods of diagnosing possible problems with statistical models of this kind.",2009,69,4539,1446,11,103,201,275,402,450,446,453,577,449
87ccc438b0c73fcfdea48485fcdb091a8ecaa89c,"High-throughput sequencing assays such as RNA-Seq, ChIP-Seq or barcode counting provide quantitative readouts in the form of count data. To infer differential signal in such data correctly and with good statistical power, estimation of data variability throughout the dynamic range and a suitable error model are required. We propose a method based on the negative binomial distribution, with variance and mean linked by local regression and present an implementation, DESeq, as an R/Bioconductor package.",2010,80,9807,1096,9,65,225,483,806,957,981,1071,1172,1372
b9544a1bf4b02c6648dbd12702bc10c00e20e197,"Content analysis is a widely used qualitative research technique. Rather than being a single method, current applications of content analysis show three distinct approaches: conventional, directed, or summative. All three approaches are used to interpret meaning from the content of text data and, hence, adhere to the naturalistic paradigm. The major differences among the approaches are coding schemes, origins of codes, and threats to trustworthiness. In conventional content analysis, coding categories are derived directly from the text data. With a directed approach, analysis starts with a theory or relevant research findings as guidance for initial codes. A summative content analysis involves counting and comparisons, usually of keywords or content, followed by the interpretation of the underlying context. The authors delineate analytic procedures specific to each approach and techniques addressing trustworthiness with hypothetical examples drawn from the area of end-of-life care.",2005,57,24913,943,0,0,0,0,0,0,0,0,0,0
2fcf90089d9f95025e8953812a43f0db2de3af7c,,2009,0,10344,2663,0,0,262,430,655,922,1128,1232,1332,1349
fc448a7db5a2fac242705bd8e37ae1fc4a858643,"The human genome holds an extraordinary trove of information about human development, physiology, medicine and evolution. Here we report the results of an international collaboration to produce and make freely available a draft sequence of the human genome. We also present an initial analysis of the data, describing some of the insights that can be gleaned from the sequence.",2001,431,17459,430,5,1,4,2,1,2,8,504,764,774
d76bde423b71f1cb900b988311bd2d71b700d506,"The extent of heterogeneity in a meta-analysis partly determines the difficulty in drawing overall conclusions. This extent may be measured by estimating a between-study variance, but interpretation is then specific to a particular treatment effect metric. A test for the existence of heterogeneity exists, but depends on the number of studies in the meta-analysis. We develop measures of the impact of heterogeneity on a meta-analysis, from mathematical criteria, that are independent of the number of studies and the treatment effect metric. We derive and propose three suitable statistics: H is the square root of the chi2 heterogeneity statistic divided by its degrees of freedom; R is the ratio of the standard error of the underlying mean from a random effects meta-analysis to the standard error of a fixed effect meta-analytic estimate, and I2 is a transformation of (H) that describes the proportion of total variation in study estimates that is due to heterogeneity. We discuss interpretation, interval estimates and other properties of these measures and examine them in five example data sets showing different amounts of heterogeneity. We conclude that H and I2, which can usually be calculated for published meta-analyses, are particularly useful summaries of the impact of heterogeneity. One or both should be presented in published meta-analyses in preference to the test for heterogeneity.",2002,35,21386,493,0,0,0,0,1,0,1,0,1,1
76ad159a2887b008e5a7335d124c148c13e65465,"We have developed a toolbox and graphic user interface, EEGLAB, running under the crossplatform MATLAB environment (The Mathworks, Inc.) for processing collections of single-trial and/or averaged EEG data of any number of channels. Available functions include EEG data, channel and event information importing, data visualization (scrolling, scalp map and dipole model plotting, plus multi-trial ERP-image plots), preprocessing (including artifact rejection, filtering, epoch selection, and averaging), independent component analysis (ICA) and time/frequency decompositions including channel and component cross-coherence supported by bootstrap statistical methods based on data resampling. EEGLAB functions are organized into three layers. Top-layer functions allow users to interact with the data through the graphic interface without needing to use MATLAB syntax. Menu options allow users to tune the behavior of EEGLAB to available memory. Middle-layer functions allow users to customize data processing using command history and interactive 'pop' functions. Experienced MATLAB users can use EEGLAB data structures and stand-alone signal processing functions to write custom and/or batch analysis scripts. Extensive function help and tutorial information are included. A 'plug-in' facility allows easy incorporation of new EEG modules into the main menu. EEGLAB is freely available (http://www.sccn.ucsd.edu/eeglab/) under the GNU public license for noncommercial use and open source development, together with sample data, user tutorial and extensive documentation.",2004,85,14460,1914,0,0,0,0,0,0,0,0,0,0
1a77e19441f3a0e030998fb2d11d9dd774582403,"The techniques available for the interrogation and analysis of neuroimaging data have a large influence in determining the flexibility, sensitivity, and scope of neuroimaging experiments. The development of such methodologies has allowed investigators to address scientific questions that could not previously be answered and, as such, has become an important research area in its own right. In this paper, we present a review of the research carried out by the Analysis Group at the Oxford Centre for Functional MRI of the Brain (FMRIB). This research has focussed on the development of new methodologies for the analysis of both structural and functional magnetic resonance imaging data. The majority of the research laid out in this paper has been implemented as freely available software tools within FMRIB's Software Library (FSL).",2004,52,10646,1541,0,0,0,0,0,77,419,577,673,764
e250c4b0cc0180af9f47b97f3b9ff1727a2767aa,"New software, OLEX2, has been developed for the determination, visualization and analysis of molecular crystal structures. The software has a portable mouse-driven workflow-oriented and fully comprehensive graphical user interface for structure solution, refinement and report generation, as well as novel tools for structure analysis. OLEX2 seamlessly links all aspects of the structure solution, refinement and publication process and presents them in a single workflow-driven package, with the ultimate goal of producing an application which will be useful to both chemists and crystallographers.",2009,10,13162,496,0,0,0,0,0,0,3,653,1471,1660
42abddd227d653a0375d7d037ddb885f6c07f66f,"We present Model-based Analysis of ChIP-Seq data, MACS, which analyzes data generated by short read sequencers such as Solexa's Genome Analyzer. MACS empirically models the shift size of ChIP-Seq tags, and uses it to improve the spatial resolution of predicted binding sites. MACS also uses a dynamic Poisson distribution to effectively capture local biases in the genome, allowing for more robust predictions. MACS compares favorably to existing ChIP-Seq peak-finding algorithms, and is freely available.",2008,17,9866,1179,6,43,122,233,339,455,628,662,729,980
7a6142cfa79cc01ceced5e144bd0e01a0f241a74,,2009,43,7893,2014,377,456,500,626,706,655,723,661,657,644
94559c249d204110296c39ed4af2042cc4468e68,"The Karhunen-Lo eve basis functions, more frequently referred to as principal components or empirical orthogonal functions (EOFs), of the noise response of the climate system are an important tool for geophysical studies. Many researchers have used this tool to examine the geophysical and climatological phenomena. Perhaps more frequent use of EOFs in recent studies is in conjunction with the development of the signal detection and estimation methods of the background uctuations of a detection variable serve as an orthogonal basis set and are used to design optimal techniques for detecting and estimating signals. A detection and prediction approach is to design a lter or optimal weights for the signal to be detected. It has been reported that weighted averaging of data over the surface of the Earth improved the detectability of climatic changes (Hasselmann 1979; Stefanick 1981; Bell 1982). Since the signal-to-noise ratio (SNR) varies geographically, there exists an optimal geographical weighting of the signal which maximizes the SNR. The design of an optimal weighting function may require detailed knowledge on the natural uctuation of the climate system. A conceptually similar approach is to employ a particular pattern (or patterns) of climatic change for detection and prediction (e.g., Barnett and Hasselmann 1979; Hasselmann 1979). The patterns of interest (also called the predictors) may include the principal components (empirical orthogonal functions) (e. von Storch 1990) among others. This approach also requires complete knowledge of the natural variability of the climate system. To test and improve the detection and prediction techniques addressed above, a complete cross-spectral covariance matrix, or similarly, a complete set of the principal components of natural uctuations of the climate system for each frequency band of the spectrum is necessary. In reality, a reliable spectrum of observational covariance matrix is not available because observations are not suuciently long and sampling errors contaminate the observational records (Preisendorfer and Barnett 1977; North et al. 1982). Further, inadequate spatial coverage of observations may introduce bias. Therefore, the covariance matrix of the noise response is often estimated from a simple stochastic model. Kim and North (1991, 1992) examined the covariance matrix in terms of various second-moment statistics earlier. Examined here are the principal components of the covariance matrix of the surface temperature uctuations in a simple coupled climate model in comparison with observations. The principal components not only are an",2009,52,14117,1668,1,0,3,13,175,903,1082,1144,1134,1081
20aeb2357e9e215787c7e0d0acfe7a6b598c9103,"This book describes ggplot2, a new data visualization package for R that uses the insights from Leland Wilkisons Grammar of Graphics to create a powerful and flexible system for creating data graphics. With ggplot2, its easy to: produce handsome, publication-quality plots, with automatic legends created from the plot specification superpose multiple layers (points, lines, maps, tiles, box plots to name a few) from different data sources, with automatically adjusted common scales add customisable smoothers that use the powerful modelling capabilities of R, such as loess, linear models, generalised additive models and robust regression save any ggplot2 plot (or part thereof) for later modification or reuse create custom themes that capture in-house or journal style requirements, and that can easily be applied to multiple plots approach your graph from a visual perspective, thinking about how each component of the data is represented on the final plot. This book will be useful to everyone who has struggled with displaying their data in an informative and attractive way. You will need some basic knowledge of R (i.e. you should be able to get your data into R), but ggplot2 is a mini-language specifically tailored for producing graphics, and youll learn everything you need in the book. After reading this book youll be able to produce graphics customized precisely for your problems,and youll find it easy to get graphics out of your head and on to the screen or page.",2009,0,20904,1807,0,0,0,0,0,1,2,0,3,9
da7ab2f1b6278472f3671a7430c9a72bad07781f,"PAML, currently in version 4, is a package of programs for phylogenetic analyses of DNA and protein sequences using maximum likelihood (ML). The programs may be used to compare and test phylogenetic trees, but their main strengths lie in the rich repertoire of evolutionary models implemented, which can be used to estimate parameters in models of sequence evolution and to test interesting biological hypotheses. Uses of the programs include estimation of synonymous and nonsynonymous rates (d(N) and d(S)) between two protein-coding DNA sequences, inference of positive Darwinian selection through phylogenetic comparison of protein-coding genes, reconstruction of ancestral genes and proteins for molecular restoration studies of extinct life forms, combined analysis of heterogeneous data sets from multiple gene loci, and estimation of species divergence times incorporating uncertainties in fossil calibrations. This note discusses some of the major applications of the package, which includes example data sets to demonstrate their use. The package is written in ANSI C, and runs under Windows, Mac OSX, and UNIX systems. It is available at -- (http://abacus.gene.ucl.ac.uk/software/paml.html).",2007,203,9021,1777,10,131,298,412,471,583,614,666,638,749
d40ee5dd758c525dfb9932d726bb4e844b7b8478,"Receiver operating characteristics (ROC) graphs are useful for organizing classifiers and visualizing their performance. ROC graphs are commonly used in medical decision making, and in recent years have been used increasingly in machine learning and data mining research. Although ROC graphs are apparently simple, there are some common misconceptions and pitfalls when using them in practice. The purpose of this article is to serve as an introduction to ROC graphs and as a guide for using them in research.",2006,45,14314,1234,0,0,0,0,0,0,1,4,75,1122
215579acece24b34f6ab91fab62bac8ba7ccfe03,,2002,0,16249,1013,1,1,5,5,9,12,517,1114,1268,1194
c98386ddf2fe4973da42187a9e3c9167095acf4e,"During the past 30 years, meta-analysis has been an indispensable tool for revealing the hidden meaning of our research literatures. The four articles in this special section on meta-analysis illustrate some of the complexities entailed in meta-analysis methods. Although meta-analysis is a powerful tool for advancing cumulative knowledge, researchers can be confused by the complicated issues involved in the methodology. Each of these four articles contributes both to advancing this methodology and to the increasing complexities that can befuddle researchers. In these comments, the author attempts to clarify both of these aspects and provide a perspective on the methodological issues examined in these articles.",2008,114,15161,703,0,0,0,0,0,0,0,0,0,4
39dae53515afb42664369c291ec6d1ce34d778bd,"BackgroundCorrelation networks are increasingly being used in bioinformatics applications. For example, weighted gene co-expression network analysis is a systems biology method for describing the correlation patterns among genes across microarray samples. Weighted correlation network analysis (WGCNA) can be used for finding clusters (modules) of highly correlated genes, for summarizing such clusters using the module eigengene or an intramodular hub gene, for relating modules to one another and to external sample traits (using eigengene network methodology), and for calculating module membership measures. Correlation networks facilitate network based gene screening methods that can be used to identify candidate biomarkers or therapeutic targets. These methods have been successfully applied in various biological contexts, e.g. cancer, mouse genetics, yeast genetics, and analysis of brain imaging data. While parts of the correlation network methodology have been described in separate publications, there is a need to provide a user-friendly, comprehensive, and consistent software implementation and an accompanying tutorial.ResultsThe WGCNA R software package is a comprehensive collection of R functions for performing various aspects of weighted correlation network analysis. The package includes functions for network construction, module detection, gene selection, calculations of topological properties, data simulation, visualization, and interfacing with external software. Along with the R package we also present R software tutorials. While the methods development was motivated by gene expression data, the underlying data mining approach can be applied to a variety of different settings.ConclusionThe WGCNA package provides R functions for weighted correlation network analysis, e.g. co-expression network analysis of gene expression data. The R package along with its source code and additional material are freely available at http://www.genetics.ucla.edu/labs/horvath/CoexpressionNetwork/Rpackages/WGCNA.",2008,51,9025,1051,2,9,29,60,112,163,263,361,592,783
b6fbb3a44a8e946b4a231118a737a396517c83de,"AIM
This paper is a description of inductive and deductive content analysis.


BACKGROUND
Content analysis is a method that may be used with either qualitative or quantitative data and in an inductive or deductive way. Qualitative content analysis is commonly used in nursing studies but little has been published on the analysis process and many research books generally only provide a short description of this method.


DISCUSSION
When using content analysis, the aim was to build a model to describe the phenomenon in a conceptual form. Both inductive and deductive analysis processes are represented as three main phases: preparation, organizing and reporting. The preparation phase is similar in both approaches. The concepts are derived from the data in inductive content analysis. Deductive content analysis is used when the structure of analysis is operationalized on the basis of previous knowledge.


CONCLUSION
Inductive content analysis is used in cases where there are no previous studies dealing with the phenomenon or when it is fragmented. A deductive approach is useful if the general aim was to test a previous theory in a different situation or to compare categories at different time periods.",2008,65,11840,609,0,0,0,0,0,1,379,1016,1090,1290
0e2532c31c992ac0930998561932f198b467572d,"This article examines the function of documents as a data source in qualitative research and discusses document analysis procedure in the context of actual research experiences. Targeted to research novices, the article takes a nuts‐and‐bolts approach to document analysis. It describes the nature and forms of documents, outlines the advantages and limitations of document analysis, and offers specific examples of the use of documents in the research process. The application of document analysis to a grounded theory study is illustrated.",2009,34,4574,534,0,12,16,59,127,198,275,417,534,725
dd1b3a3793619cec8994cc7cca10e6dee656fb7b,"UNLABELLED
Research over the last few years has revealed significant haplotype structure in the human genome. The characterization of these patterns, particularly in the context of medical genetic association studies, is becoming a routine research activity. Haploview is a software package that provides computation of linkage disequilibrium statistics and population haplotype patterns from primary genotype data in a visually appealing and interactive interface.


AVAILABILITY
http://www.broad.mit.edu/mpg/haploview/


CONTACT
jcbarret@broad.mit.edu",2005,12,13390,1399,0,0,0,1,74,1111,1159,1137,1018,973
6fb968167f3c9c76d00d085a57b265cb912ad012,"Data Mining Methods and Models is the second volume of a three-book series on data mining authored by Larose. The following review was performed independently of LaRose’s other two books. Paraphrasing from the Preface, the goal of this book is to “explore the process of data mining from the point of view of model building.” Nevertheless, the reader will soon be aware that this book is not intended to provide a systematic or comprehensive coverage of various data mining algorithms. Instead, it considers supervised learning or predictive modeling only, and it walks the reader through the data mining process merely with a few selected modeling methods such as (generalized) linear modeling and the Bayesian approach. The book has seven chapters. Chapter 1 introduces dimension reduction, with a focus on principal components analysis (PCA) types of techniques. Chapters 2, 3, and 4 provide a detailed coverage of simple linear regression, multiple linear regression, and logistic regression, respectively. Chapter 5 introduces naive Bayes estimation and Bayesian networks. In Chapter 6, the basic idea of genetic algorithms is discussed. Finally, Chapter 7 presents a case study example of modeling response to direct mail marketing within the CRISP (crossindustry standard process) framework. This book is very easy to read, and this is absolutely the strength which many readers, especially those nonstatistically oriented ones, will greatly appreciate. Predictive modeling is perhaps the most technical part in a data mining process. The author has done an excellent job in making this difficult topic accessible to a broad audience. For example, I like the way in which Bayesian networks are introduced in Chapter 5. After the reader goes through a churn example on naive Bayes estimation in a step-by-step manner, Bayesian belief networks become easily understood as natural extensions. The overall style of the book is clear and patient. The main limitation of the book is its limited coverage. An inspired reader would expect to see a much more extended list of topics. Hastie, Tibishirani, and Friedman (2001) gave a full and more technical account of various data mining algorithms. The inclusion of genetic algorithms in Chapter 6 seems novel when compared to Hastie, Tibishirani, and Friedman (2001), but at the same time, a little unexpected as a separate chapter, since a genetic algorithm involves a stochastics search scheme, which is somewhat involved given the elementary nature of this text. Another noteworthy issue is that the author does not make an attempt to distinguish between conventional statistical analysis and data mining. I found a few errors. On Page 25, for example, it should be ai = 1, instead of ai = 1/4. Also, in the frame on the top of Page 211, it might have been “Posterior Odds,” instead of “Posterior Odds Ratio.” The book uses three different software packages to implement the ideas including SPSS with Clementine, Minitab, and WEKA, which might not be appealing. On the other hand, it is justifiable as it allows one to perform data mining with affordable costs. In summary, I recommend this fairly readable book for adoption in a graduate-level introductory course on data mining, especially when the students come from varied backgrounds.",2008,5,6081,1832,57,100,190,265,350,401,473,572,669,712
85dfac3a261fbdea3b4e1a6f3264c6384bbc4485,"Qualitative content analysis as described in published literature shows conflicting opinions and unsolved issues regarding meaning and use of concepts, procedures and interpretation. This paper provides an overview of important concepts (manifest and latent content, unit of analysis, meaning unit, condensation, abstraction, content area, code, category and theme) related to qualitative content analysis; illustrates the use of concepts related to the research procedure; and proposes measures to achieve trustworthiness (credibility, dependability and transferability) throughout the steps of the research procedure. Interpretation in qualitative content analysis is discussed in light of Watzlawick et al.'s [Pragmatics of Human Communication. A Study of Interactional Patterns, Pathologies and Paradoxes. W.W. Norton & Company, New York, London] theory of communication.",2004,58,14412,1104,0,0,0,0,0,0,0,0,0,4
d96faee1898de7a052115ecfe533a5b2fd1151c0,"This paper develops a new approach to the problem of testing the existence of a level relationship between a dependent variable and a set of regressors, when it is not known with certainty whether the underlying regressors are trend- or first-difference stationary. The proposed tests are based on standard F- and t-statistics used to test the significance of the lagged levels of the variables in a univariate equilibrium correction mechanism. The asymptotic distributions of these statistics are non-standard under the null hypothesis that there exists no level relationship, irrespective of whether the regressors are I(0) or I(1). Two sets of asymptotic critical values are provided: one when all regressors are purely I(1) and the other if they are all purely I(0). These two sets of critical values provide a band covering all possible classifications of the regressors into purely I(0), purely I(1) or mutually cointegrated. Accordingly, various bounds testing procedures are proposed. It is shown that the proposed tests are consistent, and their asymptotic distribution under the null and suitably defined local alternatives are derived. The empirical relevance of the bounds procedures is demonstrated by a re-examination of the earnings equation included in the UK Treasury macroeconometric model. Copyright © 2001 John Wiley & Sons, Ltd.",2001,46,11403,2343,0,0,0,0,0,0,0,0,0,2
21c41fcec6ac8a7f55c539ac199247f200633753,"Microarrays can measure the expression of thousands of genes to identify changes in expression between different biological states. Methods are needed to determine the significance of these changes while accounting for the enormous number of genes. We describe a method, Significance Analysis of Microarrays (SAM), that assigns a score to each gene on the basis of change in gene expression relative to the standard deviation of repeated measurements. For genes with scores greater than an adjustable threshold, SAM uses permutations of the repeated measurements to estimate the percentage of genes identified by chance, the false discovery rate (FDR). When the transcriptional response of human cells to ionizing radiation was measured by microarrays, SAM identified 34 genes that changed at least 1.5-fold with an estimated FDR of 12%, compared with FDRs of 60 and 84% by using conventional methods of analysis. Of the 34 genes, 19 were involved in cell cycle regulation and 3 in apoptosis. Surprisingly, four nucleotide excision repair genes were induced, suggesting that this repair pathway for UV-damaged DNA might play a previously unrecognized role in repairing DNA damaged by ionizing radiation.",2001,54,11566,1626,0,0,1,3,249,864,864,894,921,881
39dfeda235027e1bed00ab33bcb2ad16831677f8,"Hypothesis-testing methods for multivariate data are needed to make rigorous probability statements about the effects of factors and their interactions in experiments. Analysis of variance is particularly powerful for the analysis of univariate data. The traditional multivariate analogues, however, are too stringent in their assumptions for most ecological multivariate data sets. Non-parametric methods, based on permutation tests, are preferable. This paper describes a new non-parametric method for multivariate analysis of variance, after McArdle and Anderson (in press). It is given here, with several applications in ecology, to provide an alternative and perhaps more intuitive formulation for ANOVA (based on sums of squared distances) to complement the description pro- vided by McArdle and Anderson (in press) for the analysis of any linear model. It is an improvement on previous non-parametric methods because it allows a direct additive partitioning of variation for complex models. It does this while maintaining the flexibility and lack of formal assumptions of other non-parametric methods. The test- statistic is a multivariate analogue to Fisher's F-ratio and is calculated directly from any symmetric distance or dissimilarity matrix. P-values are then obtained using permutations. Some examples of the method are given for tests involving several factors, including factorial and hierarchical (nested) designs and tests of interactions.",2001,127,10965,1444,0,0,0,0,0,0,0,0,0,158
c8831d7d318b8d59f9b958d250a58f253f08bd8a,"This article is about a curious phenomenon. Suppose we have a data matrix, which is the superposition of a low-rank component and a sparse component. Can we recover each component individually? We prove that under some suitable assumptions, it is possible to recover both the low-rank and the sparse components exactly by solving a very convenient convex program called Principal Component Pursuit; among all feasible decompositions, simply minimize a weighted combination of the nuclear norm and of the ℓ1 norm. This suggests the possibility of a principled approach to robust principal component analysis since our methodology and results assert that one can recover the principal components of a data matrix even though a positive fraction of its entries are arbitrarily corrupted. This extends to the situation where a fraction of the entries are missing as well. We discuss an algorithm for solving this optimization problem, and present applications in the area of video surveillance, where our methodology allows for the detection of objects in a cluttered background, and in the area of face recognition, where it offers a principled way of removing shadows and specularities in images of faces.",2009,90,5547,1043,9,66,155,236,340,507,532,647,665,703
70b48fd1a0c3d9fef98600578308e1e033c0c67a,Supplementary Figure 1 Overview of the analysis pipeline. Supplementary Table 1 Details of conventionally raised and conventionalized mouse samples. Supplementary Discussion Expanded discussion of QIIME analyses presented in the main text; Sequencing of 16S rRNA gene amplicons; QIIME analysis notes; Expanded Figure 1 legend; Links to raw data and processed output from the runs with and without denoising.,2010,30,23951,2769,0,0,0,0,0,1,2,4,98,3004
e5136e9306bf1b0e3d4be0cea384ee9a969a44fa,"Thematic analysis is a poorly demarcated, rarely acknowledged, yet widely used qualitative analytic method within psychology. In this paper, we argue that it offers an accessible and theoretically flexible approach to analysing qualitative data. We outline what thematic analysis is, locating it in relation to other qualitative analytic methods that search for themes or patterns, and in relation to different epistemological and ontological positions. We then provide clear guidelines to those wanting to start thematic analysis, or conduct it in a more deliberate and rigorous way, and consider potential pitfalls in conducting thematic analysis. Finally, we outline the disadvantages and advantages of thematic analysis. We conclude by advocating thematic analysis as a useful and flexible method for qualitative research in and beyond psychology.",2006,110,75770,5318,0,0,0,0,0,0,1,0,0,0
67556c4f0cfdd1f09fff373768b03638f949be0d,"Chapter 3 deals with probability distributions, discrete and continuous densities, distribution functions, bivariate distributions, means, variances, covariance, correlation, and some random process material. Chapter 4 is a detailed study of the concept of utility including the psychological aspects, risk, attributes, rules for utilities, multidimensional utility, and normal form of analysis. Chapter 5 treats games and optimization, linear optimization, and mixed strategies. Entropy is the topic of Chapter 6 with sections devoted to entropy, disorder, information, Shannon’s theorem, demon’s roulette, Maxwell– Boltzmann distribution, Schrodinger’s nutshell, maximum entropy probability distributions, blackbodies, and Bose–Einstein distribution. Chapter 7 is standard statistical fare including transformations of random variables, characteristic functions, generating functions, and the classic limit theorems such as the central limit theorem and the laws of large numbers. Chapter 8 is about exchangeability and inference with sections on Bayesian techniques and classical inference. Partial exchangeability is also treated. Chapter 9 considers such things as order statistics, extreme value, intensity, hazard functions, and Poisson processes. Chapter 10 covers basic elements of risk and reliability, while Chapter 11 is devoted to curve fitting, regression, and Monte Carlo simulation. There is an ample number of exercises at the ends of the chapters with answers or comments on many of them in an appendix in the back of the book. Other appendices are on the common discrete and continuous distributions and mathematical aspects of integration.",2007,0,18913,4802,0,0,0,0,0,0,0,1,7,889
ec3d71a2fdd01968a6dc638ee261715a0f118c1e,"Summary: It is expected that emerging digital gene expression (DGE) technologies will overtake microarray technologies in the near future for many functional genomics applications. One of the fundamental data analysis tasks, especially for gene expression studies, involves determining whether there is evidence that counts for a transcript or exon are significantly different across experimental conditions. edgeR is a Bioconductor software package for examining differential expression of replicated count data. An overdispersed Poisson model is used to account for both biological and technical variability. Empirical Bayes methods are used to moderate the degree of overdispersion across transcripts, improving the reliability of inference. The methodology can be used even with the most minimal levels of replication, provided at least one phenotype or experimental condition is replicated. The software may have other applications beyond sequencing data, such as proteome peptide count data. Availability: The package is freely available under the LGPL licence from the Bioconductor web site (http://bioconductor.org). Contact: mrobinson@wehi.edu.au",2009,10,21553,1162,0,0,0,0,0,0,1,1,7,64
a2893118e14c29a23472b02249b4641b9971786b,"Although genomewide RNA expression analysis has become a routine tool in biomedical research, extracting biological insight from such information remains a major challenge. Here, we describe a powerful analytical method called Gene Set Enrichment Analysis (GSEA) for interpreting gene expression data. The method derives its power by focusing on gene sets, that is, groups of genes that share common biological function, chromosomal location, or regulation. We demonstrate how GSEA yields insights into several cancer-related data sets, including leukemia and lung cancer. Notably, where single-gene analysis finds little similarity between two independent studies of patient survival in lung cancer, GSEA reveals many biological pathways in common. The GSEA method is embodied in a freely available software package, together with an initial database of 1,325 biologically defined gene sets.",2005,85,26903,2908,0,0,0,0,0,0,0,0,0,0
9529c25408dc86194d417aed73d49ae0e418f1be,"32.03 MB Free download Econometric Analysis of Cross Section and Panel Data book PDF, FB2, EPUB and MOBI. Read online Econometric Analysis of Cross Section and Panel Data which classified as Other that has 776 pages that contain constructive material with lovely reading experience. Reading online Econometric Analysis of Cross Section and Panel Data book will be provide using wonderful book reader and it's might gives you some access to identifying the book content before you download the book.",2002,0,21019,2368,0,0,0,0,0,0,0,3,0,4
d17669e4f3f4dd3a180bde84dd54a508d0dc22f4,"A comprehensive, but simple-to-use software package for executing a range of standard numerical analysis and operations used in quantitative paleontology has been developed. The program, called PAST (PAleontological STatistics), runs on standard Windows computers and is available free of charge. PAST integrates spreadsheet-type data entry with univariate and multivariate statistics, curve fitting, timeseries analysis, data plotting, and simple phylogenetic analysis. Many of the functions are specific to paleontology and ecology, and these functions are not found in standard, more extensive, statistical packages. PAST also includes fourteen case studies (data files and exercises) illustrating use of the program for paleontological problems, making it a complete educational package for courses in quantitative methods.",2001,17,17969,3587,0,0,0,0,0,0,0,0,0,0
89fe2ca0bc4ea3f53f5745de6a88e094b8734a2b,1 Introduction: Models and Model Building Section I Understanding and Preparing for Multivariate Analysis 2 Cleaning and Transforming Data 3 Factor Analysis Section II Analysis Using Dependece Techniques 4 Simple and Multiple Regression Analysis 5 Canonical correlation 6 Conjoint analysis 7 Multiple Discriminant Analysis and Logistic Regression 8 ANOVA and MANOVA Section III Analysis using Interdependence Techniques 9 Group data and Cluster Analysis 10 MDS and Correspondence Analysis Structural Equation Modeling 11 SEM: An Introduction 12 Application of SEM,2010,0,6831,1353,53,154,275,450,587,635,645,725,827,809
0ad5733eafb41274895bf1dce6b92ae8f3d68c60,,2004,0,18831,2817,1,3,6,2,10,713,1440,1290,1233,1117
0d6cf3cd3794bc31a4e5a8ded4d4ba83bb20f9b0,"BOOK REVIEW: Constructing grounded theory. A practical guide through qualitative analysis Kathy Charmaz, 2006, 208 pp. London: Sage. ISBN 2005928035",2006,0,10716,2252,0,0,0,1,365,666,939,1134,1328,847
7bd23e6ec32cb1507a385c21a21150e9c332682f,"genalex is a user-friendly cross-platform package that runs within Microsoft Excel, enabling population genetic analyses of codominant, haploid and binary data. Allele frequency-based analyses include heterozygosity, F statistics, Nei's genetic distance, population assignment, probabilities of identity and pairwise relatedness. Distance-based calculations include amova, principal coordinates analysis (PCA), Mantel tests, multivariate and 2D spatial autocorrelation and twogener. More than 20 different graphs summarize data and aid exploration. Sequence and genotype data can be imported from automated sequencers, and exported to other software. Initially designed as tool for teaching, genalex 6 now offers features for researchers as well. Documentation and the program are available at http://www.anu.edu.au/BoZo/GenAlEx/",2006,12,14558,3330,0,0,0,0,0,0,3,972,1332,1368
895860c6083736508d2541900cdf0960eb11592f,"The design, implementation, and capabilities of an extensible visualization system, UCSF Chimera, are discussed. Chimera is segmented into a core that provides basic services and visualization, and extensions that provide most higher level functionality. This architecture ensures that the extension mechanism satisfies the demands of outside developers who wish to incorporate new features. Two unusual extensions are presented: Multiscale, which adds the ability to visualize large‐scale molecular assemblies such as viral coats, and Collaboratory, which allows researchers to share a Chimera session interactively despite being at separate locales. Other extensions include Multalign Viewer, for showing multiple sequence alignments and associated structures; ViewDock, for screening docked ligand orientations; Movie, for replaying molecular dynamics trajectories; and Volume Viewer, for display and analysis of volumetric data. A discussion of the usage of Chimera in real‐world situations is given, along with anticipated future directions. Chimera includes full user documentation, is free to academic and nonprofit users, and is available for Microsoft Windows, Linux, Apple Mac OS X, SGI IRIX, and HP Tru64 Unix from http://www.cgl.ucsf.edu/chimera/. © 2004 Wiley Periodicals, Inc. J Comput Chem 25: 1605–1612, 2004",2004,70,28327,1713,0,0,0,0,1,0,0,0,0,0
e7c8aa2cb2223f17615c1b1ae3b33095466e95cc,"The two most commonly used methods to analyze data from real-time, quantitative PCR experiments are absolute quantification and relative quantification. Absolute quantification determines the input copy number, usually by relating the PCR signal to a standard curve. Relative quantification relates the PCR signal of the target transcript in a treatment group to that of another sample such as an untreated control. The 2(-Delta Delta C(T)) method is a convenient way to analyze the relative changes in gene expression from real-time quantitative PCR experiments. The purpose of this report is to present the derivation, assumptions, and applications of the 2(-Delta Delta C(T)) method. In addition, we present the derivation and applications of two variations of the 2(-Delta Delta C(T)) method that may be useful in the analysis of real-time, quantitative PCR data.",2001,21,115916,1656,0,0,0,0,0,0,0,0,1,0
05abdc87bcaf2963fd511672e64ab39d02239aaf,,2007,30,24491,2512,0,1,0,0,1,0,5,6,535,2032
2d6f573c36c5e2153b65859fb080523fc4d842d0,"We announce the release of the fourth version of MEGA software, which expands on the existing facilities for editing DNA sequence data from autosequencers, mining Web-databases, performing automatic and manual sequence alignment, analyzing sequence alignments to estimate evolutionary distances, inferring phylogenetic trees, and testing evolutionary hypotheses. Version 4 includes a unique facility to generate captions, written in figure legend format, in order to provide natural language descriptions of the models and methods used in the analyses. This facility aims to promote a better understanding of the underlying assumptions used in analyses, and of the results generated. Another new feature is the Maximum Composite Likelihood (MCL) method for estimating evolutionary distances between all pairs of sequences simultaneously, with and without incorporating rate variation among sites and substitution pattern heterogeneities among lineages. This MCL method also can be used to estimate transition/transversion bias and nucleotide substitution pattern without knowledge of the phylogenetic tree. This new version is a native 32-bit Windows application with multi-threading and multi-user supports, and it is also available to run in a Linux desktop environment (via the Wine compatibility layer) and on Intel-based Macintosh computers under the Parallels program. The current version of MEGA is available free of charge at (http://www.megasoftware.net).",2007,10,28423,6043,0,0,0,0,1,18,2034,2152,1667,1255
4e2f43dab69d690dc86422949e410ebf37f522d4,"Bayesian methods have garnered huge interest in cognitive science as an approach to models of cognition and perception. On the other hand, Bayesian methods for data analysis have not yet made much headway in cognitive science against the institutionalized inertia of 20th century null hypothesis significance testing (NHST). Ironically, specific Bayesian models of cognition and perception may not long endure the ravages of empirical verification, but generic Bayesian methods for data analysis will eventually dominate. It is time that Bayesian data analysis became the norm for empirical methods in cognitive science. This article reviews a fatal flaw of NHST and introduces the reader to some benefits of Bayesian data analysis. The article presents illustrative examples of multiple comparisons in Bayesian analysis of variance and Bayesian approaches to statistical power. Copyright © 2010 John Wiley & Sons, Ltd. For further resources related to this article, please visit the WIREs website.",2010,87,5662,709,296,287,323,345,347,434,424,416,498,498
57e7a7323f58a35f5e2cc33bf17d4ac9cdcafdd4,"DAVID bioinformatics resources consists of an integrated biological knowledgebase and analytic tools aimed at systematically extracting biological meaning from large gene/protein lists. This protocol explains how to use DAVID, a high-throughput and integrated data-mining environment, to analyze gene lists derived from high-throughput genomic experiments. The procedure first requires uploading a gene list containing any number of common gene identifiers followed by analysis using one or more text and pathway-mining tools such as gene functional classification, functional annotation chart or clustering and functional annotation table. By following this protocol, investigators are able to gain an in-depth understanding of the biological themes in lists of genes that are enriched in genome-scale studies.",2008,16,27514,2132,0,0,0,0,0,0,0,0,7,39
cad327e1e3a0799202cb40da5da51d7b0616b64e,"Arlequin ver 3.0 is a software package integrating several basic and advanced methods for population genetics data analysis, like the computation of standard genetic diversity indices, the estimation of allele and haplotype frequencies, tests of departure from linkage equilibrium, departure from selective neutrality and demographic equilibrium, estimation or parameters from past population expansions, and thorough analyses of population subdivision under the AMOVA framework. Arlequin 3 introduces a completely new graphical interface written in C++, a more robust semantic analysis of input files, and two new methods: a Bayesian estimation of gametic phase from multi-locus genotypes, and an estimation of the parameters of an instantaneous spatial expansion from DNA sequence polymorphism. Arlequin can handle several data types like DNA sequences, microsatellite data, or standard multi-locus genotypes. A Windows version of the software is freely available on http://cmpg.unibe.ch/software/arlequin3.",2007,148,12556,4438,1,1,21,1207,1437,1392,1211,1052,891,751
e09bb0025f4939a4bd233a70937584b4d7bdd0a7,"BackgroundThe evolutionary analysis of molecular sequence variation is a statistical enterprise. This is reflected in the increased use of probabilistic models for phylogenetic inference, multiple sequence alignment, and molecular population genetics. Here we present BEAST: a fast, flexible software architecture for Bayesian analysis of molecular sequences related by an evolutionary tree. A large number of popular stochastic models of sequence evolution are provided and tree-based models suitable for both within- and between-species sequence data are implemented.ResultsBEAST version 1.4.6 consists of 81000 lines of Java source code, 779 classes and 81 packages. It provides models for DNA and protein sequence evolution, highly parametric coalescent analysis, relaxed clock phylogenetics, non-contemporaneous sequence data, statistical alignment and a wide range of options for prior distributions. BEAST source code is object-oriented, modular in design and freely available at http://beast-mcmc.googlecode.com/ under the GNU LGPL license.ConclusionBEAST is a powerful and flexible evolutionary analysis package for molecular sequence variation. It also provides a resource for the further development of new models and statistical methods of evolutionary analysis.",2007,45,11140,3504,0,0,1,247,973,1270,1219,1114,1018,941
80935b370bac09ce615a002caabc30fbb26f029b,"With its theoretical basis firmly established in molecular evolutionary and population genetics, the comparative DNA and protein sequence analysis plays a central role in reconstructing the evolutionary histories of species and multigene families, estimating rates of molecular evolution, and inferring the nature and extent of selective forces shaping the evolution of genes and genomes. The scope of these investigations has now expanded greatly owing to the development of high-throughput sequencing techniques and novel statistical and computational methods. These methods require easy-to-use computer programs. One such effort has been to produce Molecular Evolutionary Genetics Analysis (MEGA) software, with its focus on facilitating the exploration and analysis of the DNA and protein sequence variation from an evolutionary perspective. Currently in its third major release, MEGA3 contains facilities for automatic and manual sequence alignment, web-based mining of databases, inference of the phylogenetic trees, estimation of evolutionary distances and testing evolutionary hypotheses. This paper provides an overview of the statistical methods, computational tools, and visual exploration modules for data input and the results obtainable in MEGA.",2004,73,12037,3302,1,0,26,1588,2150,1625,1243,879,678,475
4c97d9b9eb7c158e682844b394b42924af3c5b3f,"Interpretative phenomenological analysis (IPA) is an increasingly popular approach to qualitative inquiry. This handy text covers its theoretical foundations and provides a detailed guide to conducting IPA research. 
 
Extended worked examples from the authors' own studies in health, sexuality, psychological distress and identity illustrate the breadth and depth of IPA research. 
 
Each of the chapters also offers a guide to other good exemplars of IPA research in the designated area. The final section of the book considers how IPA connects with other contemporary qualitative approaches like discourse and narrative analysis and how it addresses issues to do with validity. The book is written in an accessible style and will be extremely useful to students and researchers in psychology and related disciplines in the health and social sciences.",2009,7,6197,1589,6,76,172,280,438,624,709,699,792,811
001c07aefcc186013184009e0c83847f28867e08,"ggplot2: Elegant Graphics for Data Analysis is a new addition to the UseR! series by Springer, probably the fastest expanding source of resources for computational statistics at the current moment. The books in this series are all linked with R, either presenting a new package developed by the own authors of the book or describing how to applying statistical techniques with the different packages available in R. ggplot2 is an implementation in R of The Grammar of Graphics (Wilkinson 2005) a systematic approach to the specification of statistical graphics that was introduced in a book previously reviewed in the Journal of Statistical Software by Cox (2007). This implementation has been developed by Hadley Wickham, who is also the author of the book reviewed here.",2010,1,4911,435,9,20,22,56,87,94,178,255,446,795
7ea9b1915072f2adff3762b59b7c7d79805fee8e,"If radiocarbon measurements are to be used at all for chronological purposes, we have to use statistical methods for calibration. The most widely used method of calibration can be seen as a simple application of Bayesian statistics, which uses both the information from the new measurement and information from the 14C calibration curve. In most dating applications, however, we have larger numbers of 14C measurements and we wish to relate those to events in the past. Bayesian statistics provides a coherent framework in which such analysis can be performed and is becoming a core element in many 14C dating projects. This article gives an overview of the main model components used in chronological analysis, their mathematical formulation, and examples of how such analyses can be performed using the latest version of the OxCal software (v4). Many such models can be put together, in a modular fashion, from simple elements, with defined constraints and groupings. In other cases, the commonly used ""uniform phase"" models might not be appropriate, and ramped, exponential, or normal distributions of events might be more useful. When considering analyses of these kinds, it is useful to be able run simulations on synthetic data. Methods for performing such tests are discussed here along with other methods of diagnosing possible problems with statistical models of this kind.",2009,69,4539,1446,11,103,201,275,402,450,446,453,577,449
87ccc438b0c73fcfdea48485fcdb091a8ecaa89c,"High-throughput sequencing assays such as RNA-Seq, ChIP-Seq or barcode counting provide quantitative readouts in the form of count data. To infer differential signal in such data correctly and with good statistical power, estimation of data variability throughout the dynamic range and a suitable error model are required. We propose a method based on the negative binomial distribution, with variance and mean linked by local regression and present an implementation, DESeq, as an R/Bioconductor package.",2010,80,9807,1096,9,65,225,483,806,957,981,1071,1172,1372
b9544a1bf4b02c6648dbd12702bc10c00e20e197,"Content analysis is a widely used qualitative research technique. Rather than being a single method, current applications of content analysis show three distinct approaches: conventional, directed, or summative. All three approaches are used to interpret meaning from the content of text data and, hence, adhere to the naturalistic paradigm. The major differences among the approaches are coding schemes, origins of codes, and threats to trustworthiness. In conventional content analysis, coding categories are derived directly from the text data. With a directed approach, analysis starts with a theory or relevant research findings as guidance for initial codes. A summative content analysis involves counting and comparisons, usually of keywords or content, followed by the interpretation of the underlying context. The authors delineate analytic procedures specific to each approach and techniques addressing trustworthiness with hypothetical examples drawn from the area of end-of-life care.",2005,57,24913,943,0,0,0,0,0,0,0,0,0,0
2fcf90089d9f95025e8953812a43f0db2de3af7c,,2009,0,10344,2663,0,0,262,430,655,922,1128,1232,1332,1349
d76bde423b71f1cb900b988311bd2d71b700d506,"The extent of heterogeneity in a meta-analysis partly determines the difficulty in drawing overall conclusions. This extent may be measured by estimating a between-study variance, but interpretation is then specific to a particular treatment effect metric. A test for the existence of heterogeneity exists, but depends on the number of studies in the meta-analysis. We develop measures of the impact of heterogeneity on a meta-analysis, from mathematical criteria, that are independent of the number of studies and the treatment effect metric. We derive and propose three suitable statistics: H is the square root of the chi2 heterogeneity statistic divided by its degrees of freedom; R is the ratio of the standard error of the underlying mean from a random effects meta-analysis to the standard error of a fixed effect meta-analytic estimate, and I2 is a transformation of (H) that describes the proportion of total variation in study estimates that is due to heterogeneity. We discuss interpretation, interval estimates and other properties of these measures and examine them in five example data sets showing different amounts of heterogeneity. We conclude that H and I2, which can usually be calculated for published meta-analyses, are particularly useful summaries of the impact of heterogeneity. One or both should be presented in published meta-analyses in preference to the test for heterogeneity.",2002,35,21386,493,0,0,0,0,1,0,1,0,1,1
fc448a7db5a2fac242705bd8e37ae1fc4a858643,"The human genome holds an extraordinary trove of information about human development, physiology, medicine and evolution. Here we report the results of an international collaboration to produce and make freely available a draft sequence of the human genome. We also present an initial analysis of the data, describing some of the insights that can be gleaned from the sequence.",2001,431,17459,430,5,1,4,2,1,2,8,504,764,774
1a77e19441f3a0e030998fb2d11d9dd774582403,"The techniques available for the interrogation and analysis of neuroimaging data have a large influence in determining the flexibility, sensitivity, and scope of neuroimaging experiments. The development of such methodologies has allowed investigators to address scientific questions that could not previously be answered and, as such, has become an important research area in its own right. In this paper, we present a review of the research carried out by the Analysis Group at the Oxford Centre for Functional MRI of the Brain (FMRIB). This research has focussed on the development of new methodologies for the analysis of both structural and functional magnetic resonance imaging data. The majority of the research laid out in this paper has been implemented as freely available software tools within FMRIB's Software Library (FSL).",2004,52,10646,1541,0,0,0,0,0,77,419,577,673,764
76ad159a2887b008e5a7335d124c148c13e65465,"We have developed a toolbox and graphic user interface, EEGLAB, running under the crossplatform MATLAB environment (The Mathworks, Inc.) for processing collections of single-trial and/or averaged EEG data of any number of channels. Available functions include EEG data, channel and event information importing, data visualization (scrolling, scalp map and dipole model plotting, plus multi-trial ERP-image plots), preprocessing (including artifact rejection, filtering, epoch selection, and averaging), independent component analysis (ICA) and time/frequency decompositions including channel and component cross-coherence supported by bootstrap statistical methods based on data resampling. EEGLAB functions are organized into three layers. Top-layer functions allow users to interact with the data through the graphic interface without needing to use MATLAB syntax. Menu options allow users to tune the behavior of EEGLAB to available memory. Middle-layer functions allow users to customize data processing using command history and interactive 'pop' functions. Experienced MATLAB users can use EEGLAB data structures and stand-alone signal processing functions to write custom and/or batch analysis scripts. Extensive function help and tutorial information are included. A 'plug-in' facility allows easy incorporation of new EEG modules into the main menu. EEGLAB is freely available (http://www.sccn.ucsd.edu/eeglab/) under the GNU public license for noncommercial use and open source development, together with sample data, user tutorial and extensive documentation.",2004,85,14460,1914,0,0,0,0,0,0,0,0,0,0
e250c4b0cc0180af9f47b97f3b9ff1727a2767aa,"New software, OLEX2, has been developed for the determination, visualization and analysis of molecular crystal structures. The software has a portable mouse-driven workflow-oriented and fully comprehensive graphical user interface for structure solution, refinement and report generation, as well as novel tools for structure analysis. OLEX2 seamlessly links all aspects of the structure solution, refinement and publication process and presents them in a single workflow-driven package, with the ultimate goal of producing an application which will be useful to both chemists and crystallographers.",2009,10,13162,496,0,0,0,0,0,0,3,653,1471,1660
42abddd227d653a0375d7d037ddb885f6c07f66f,"We present Model-based Analysis of ChIP-Seq data, MACS, which analyzes data generated by short read sequencers such as Solexa's Genome Analyzer. MACS empirically models the shift size of ChIP-Seq tags, and uses it to improve the spatial resolution of predicted binding sites. MACS also uses a dynamic Poisson distribution to effectively capture local biases in the genome, allowing for more robust predictions. MACS compares favorably to existing ChIP-Seq peak-finding algorithms, and is freely available.",2008,17,9866,1179,6,43,122,233,339,455,628,662,729,980
94559c249d204110296c39ed4af2042cc4468e68,"The Karhunen-Lo eve basis functions, more frequently referred to as principal components or empirical orthogonal functions (EOFs), of the noise response of the climate system are an important tool for geophysical studies. Many researchers have used this tool to examine the geophysical and climatological phenomena. Perhaps more frequent use of EOFs in recent studies is in conjunction with the development of the signal detection and estimation methods of the background uctuations of a detection variable serve as an orthogonal basis set and are used to design optimal techniques for detecting and estimating signals. A detection and prediction approach is to design a lter or optimal weights for the signal to be detected. It has been reported that weighted averaging of data over the surface of the Earth improved the detectability of climatic changes (Hasselmann 1979; Stefanick 1981; Bell 1982). Since the signal-to-noise ratio (SNR) varies geographically, there exists an optimal geographical weighting of the signal which maximizes the SNR. The design of an optimal weighting function may require detailed knowledge on the natural uctuation of the climate system. A conceptually similar approach is to employ a particular pattern (or patterns) of climatic change for detection and prediction (e.g., Barnett and Hasselmann 1979; Hasselmann 1979). The patterns of interest (also called the predictors) may include the principal components (empirical orthogonal functions) (e. von Storch 1990) among others. This approach also requires complete knowledge of the natural variability of the climate system. To test and improve the detection and prediction techniques addressed above, a complete cross-spectral covariance matrix, or similarly, a complete set of the principal components of natural uctuations of the climate system for each frequency band of the spectrum is necessary. In reality, a reliable spectrum of observational covariance matrix is not available because observations are not suuciently long and sampling errors contaminate the observational records (Preisendorfer and Barnett 1977; North et al. 1982). Further, inadequate spatial coverage of observations may introduce bias. Therefore, the covariance matrix of the noise response is often estimated from a simple stochastic model. Kim and North (1991, 1992) examined the covariance matrix in terms of various second-moment statistics earlier. Examined here are the principal components of the covariance matrix of the surface temperature uctuations in a simple coupled climate model in comparison with observations. The principal components not only are an",2009,52,14117,1668,1,0,3,13,175,903,1082,1144,1134,1081
20aeb2357e9e215787c7e0d0acfe7a6b598c9103,"This book describes ggplot2, a new data visualization package for R that uses the insights from Leland Wilkisons Grammar of Graphics to create a powerful and flexible system for creating data graphics. With ggplot2, its easy to: produce handsome, publication-quality plots, with automatic legends created from the plot specification superpose multiple layers (points, lines, maps, tiles, box plots to name a few) from different data sources, with automatically adjusted common scales add customisable smoothers that use the powerful modelling capabilities of R, such as loess, linear models, generalised additive models and robust regression save any ggplot2 plot (or part thereof) for later modification or reuse create custom themes that capture in-house or journal style requirements, and that can easily be applied to multiple plots approach your graph from a visual perspective, thinking about how each component of the data is represented on the final plot. This book will be useful to everyone who has struggled with displaying their data in an informative and attractive way. You will need some basic knowledge of R (i.e. you should be able to get your data into R), but ggplot2 is a mini-language specifically tailored for producing graphics, and youll learn everything you need in the book. After reading this book youll be able to produce graphics customized precisely for your problems,and youll find it easy to get graphics out of your head and on to the screen or page.",2009,0,20904,1807,0,0,0,0,0,1,2,0,3,9
7a6142cfa79cc01ceced5e144bd0e01a0f241a74,,2009,43,7893,2014,377,456,500,626,706,655,723,661,657,644
da7ab2f1b6278472f3671a7430c9a72bad07781f,"PAML, currently in version 4, is a package of programs for phylogenetic analyses of DNA and protein sequences using maximum likelihood (ML). The programs may be used to compare and test phylogenetic trees, but their main strengths lie in the rich repertoire of evolutionary models implemented, which can be used to estimate parameters in models of sequence evolution and to test interesting biological hypotheses. Uses of the programs include estimation of synonymous and nonsynonymous rates (d(N) and d(S)) between two protein-coding DNA sequences, inference of positive Darwinian selection through phylogenetic comparison of protein-coding genes, reconstruction of ancestral genes and proteins for molecular restoration studies of extinct life forms, combined analysis of heterogeneous data sets from multiple gene loci, and estimation of species divergence times incorporating uncertainties in fossil calibrations. This note discusses some of the major applications of the package, which includes example data sets to demonstrate their use. The package is written in ANSI C, and runs under Windows, Mac OSX, and UNIX systems. It is available at -- (http://abacus.gene.ucl.ac.uk/software/paml.html).",2007,203,9021,1777,10,131,298,412,471,583,614,666,638,749
d40ee5dd758c525dfb9932d726bb4e844b7b8478,"Receiver operating characteristics (ROC) graphs are useful for organizing classifiers and visualizing their performance. ROC graphs are commonly used in medical decision making, and in recent years have been used increasingly in machine learning and data mining research. Although ROC graphs are apparently simple, there are some common misconceptions and pitfalls when using them in practice. The purpose of this article is to serve as an introduction to ROC graphs and as a guide for using them in research.",2006,45,14314,1234,0,0,0,0,0,0,1,4,75,1122
215579acece24b34f6ab91fab62bac8ba7ccfe03,,2002,0,16249,1013,1,1,5,5,9,12,517,1114,1268,1194
c98386ddf2fe4973da42187a9e3c9167095acf4e,"During the past 30 years, meta-analysis has been an indispensable tool for revealing the hidden meaning of our research literatures. The four articles in this special section on meta-analysis illustrate some of the complexities entailed in meta-analysis methods. Although meta-analysis is a powerful tool for advancing cumulative knowledge, researchers can be confused by the complicated issues involved in the methodology. Each of these four articles contributes both to advancing this methodology and to the increasing complexities that can befuddle researchers. In these comments, the author attempts to clarify both of these aspects and provide a perspective on the methodological issues examined in these articles.",2008,114,15161,703,0,0,0,0,0,0,0,0,0,4
39dae53515afb42664369c291ec6d1ce34d778bd,"BackgroundCorrelation networks are increasingly being used in bioinformatics applications. For example, weighted gene co-expression network analysis is a systems biology method for describing the correlation patterns among genes across microarray samples. Weighted correlation network analysis (WGCNA) can be used for finding clusters (modules) of highly correlated genes, for summarizing such clusters using the module eigengene or an intramodular hub gene, for relating modules to one another and to external sample traits (using eigengene network methodology), and for calculating module membership measures. Correlation networks facilitate network based gene screening methods that can be used to identify candidate biomarkers or therapeutic targets. These methods have been successfully applied in various biological contexts, e.g. cancer, mouse genetics, yeast genetics, and analysis of brain imaging data. While parts of the correlation network methodology have been described in separate publications, there is a need to provide a user-friendly, comprehensive, and consistent software implementation and an accompanying tutorial.ResultsThe WGCNA R software package is a comprehensive collection of R functions for performing various aspects of weighted correlation network analysis. The package includes functions for network construction, module detection, gene selection, calculations of topological properties, data simulation, visualization, and interfacing with external software. Along with the R package we also present R software tutorials. While the methods development was motivated by gene expression data, the underlying data mining approach can be applied to a variety of different settings.ConclusionThe WGCNA package provides R functions for weighted correlation network analysis, e.g. co-expression network analysis of gene expression data. The R package along with its source code and additional material are freely available at http://www.genetics.ucla.edu/labs/horvath/CoexpressionNetwork/Rpackages/WGCNA.",2008,51,9025,1051,2,9,29,60,112,163,263,361,592,783
b6fbb3a44a8e946b4a231118a737a396517c83de,"AIM
This paper is a description of inductive and deductive content analysis.


BACKGROUND
Content analysis is a method that may be used with either qualitative or quantitative data and in an inductive or deductive way. Qualitative content analysis is commonly used in nursing studies but little has been published on the analysis process and many research books generally only provide a short description of this method.


DISCUSSION
When using content analysis, the aim was to build a model to describe the phenomenon in a conceptual form. Both inductive and deductive analysis processes are represented as three main phases: preparation, organizing and reporting. The preparation phase is similar in both approaches. The concepts are derived from the data in inductive content analysis. Deductive content analysis is used when the structure of analysis is operationalized on the basis of previous knowledge.


CONCLUSION
Inductive content analysis is used in cases where there are no previous studies dealing with the phenomenon or when it is fragmented. A deductive approach is useful if the general aim was to test a previous theory in a different situation or to compare categories at different time periods.",2008,65,11840,609,0,0,0,0,0,1,379,1016,1090,1290
0e2532c31c992ac0930998561932f198b467572d,"This article examines the function of documents as a data source in qualitative research and discusses document analysis procedure in the context of actual research experiences. Targeted to research novices, the article takes a nuts‐and‐bolts approach to document analysis. It describes the nature and forms of documents, outlines the advantages and limitations of document analysis, and offers specific examples of the use of documents in the research process. The application of document analysis to a grounded theory study is illustrated.",2009,34,4574,534,0,12,16,59,127,198,275,417,534,725
dd1b3a3793619cec8994cc7cca10e6dee656fb7b,"UNLABELLED
Research over the last few years has revealed significant haplotype structure in the human genome. The characterization of these patterns, particularly in the context of medical genetic association studies, is becoming a routine research activity. Haploview is a software package that provides computation of linkage disequilibrium statistics and population haplotype patterns from primary genotype data in a visually appealing and interactive interface.


AVAILABILITY
http://www.broad.mit.edu/mpg/haploview/


CONTACT
jcbarret@broad.mit.edu",2005,12,13390,1399,0,0,0,1,74,1111,1159,1137,1018,973
6fb968167f3c9c76d00d085a57b265cb912ad012,"Data Mining Methods and Models is the second volume of a three-book series on data mining authored by Larose. The following review was performed independently of LaRose’s other two books. Paraphrasing from the Preface, the goal of this book is to “explore the process of data mining from the point of view of model building.” Nevertheless, the reader will soon be aware that this book is not intended to provide a systematic or comprehensive coverage of various data mining algorithms. Instead, it considers supervised learning or predictive modeling only, and it walks the reader through the data mining process merely with a few selected modeling methods such as (generalized) linear modeling and the Bayesian approach. The book has seven chapters. Chapter 1 introduces dimension reduction, with a focus on principal components analysis (PCA) types of techniques. Chapters 2, 3, and 4 provide a detailed coverage of simple linear regression, multiple linear regression, and logistic regression, respectively. Chapter 5 introduces naive Bayes estimation and Bayesian networks. In Chapter 6, the basic idea of genetic algorithms is discussed. Finally, Chapter 7 presents a case study example of modeling response to direct mail marketing within the CRISP (crossindustry standard process) framework. This book is very easy to read, and this is absolutely the strength which many readers, especially those nonstatistically oriented ones, will greatly appreciate. Predictive modeling is perhaps the most technical part in a data mining process. The author has done an excellent job in making this difficult topic accessible to a broad audience. For example, I like the way in which Bayesian networks are introduced in Chapter 5. After the reader goes through a churn example on naive Bayes estimation in a step-by-step manner, Bayesian belief networks become easily understood as natural extensions. The overall style of the book is clear and patient. The main limitation of the book is its limited coverage. An inspired reader would expect to see a much more extended list of topics. Hastie, Tibishirani, and Friedman (2001) gave a full and more technical account of various data mining algorithms. The inclusion of genetic algorithms in Chapter 6 seems novel when compared to Hastie, Tibishirani, and Friedman (2001), but at the same time, a little unexpected as a separate chapter, since a genetic algorithm involves a stochastics search scheme, which is somewhat involved given the elementary nature of this text. Another noteworthy issue is that the author does not make an attempt to distinguish between conventional statistical analysis and data mining. I found a few errors. On Page 25, for example, it should be ai = 1, instead of ai = 1/4. Also, in the frame on the top of Page 211, it might have been “Posterior Odds,” instead of “Posterior Odds Ratio.” The book uses three different software packages to implement the ideas including SPSS with Clementine, Minitab, and WEKA, which might not be appealing. On the other hand, it is justifiable as it allows one to perform data mining with affordable costs. In summary, I recommend this fairly readable book for adoption in a graduate-level introductory course on data mining, especially when the students come from varied backgrounds.",2008,5,6081,1832,57,100,190,265,350,401,473,572,669,712
85dfac3a261fbdea3b4e1a6f3264c6384bbc4485,"Qualitative content analysis as described in published literature shows conflicting opinions and unsolved issues regarding meaning and use of concepts, procedures and interpretation. This paper provides an overview of important concepts (manifest and latent content, unit of analysis, meaning unit, condensation, abstraction, content area, code, category and theme) related to qualitative content analysis; illustrates the use of concepts related to the research procedure; and proposes measures to achieve trustworthiness (credibility, dependability and transferability) throughout the steps of the research procedure. Interpretation in qualitative content analysis is discussed in light of Watzlawick et al.'s [Pragmatics of Human Communication. A Study of Interactional Patterns, Pathologies and Paradoxes. W.W. Norton & Company, New York, London] theory of communication.",2004,58,14412,1104,0,0,0,0,0,0,0,0,0,4
d96faee1898de7a052115ecfe533a5b2fd1151c0,"This paper develops a new approach to the problem of testing the existence of a level relationship between a dependent variable and a set of regressors, when it is not known with certainty whether the underlying regressors are trend- or first-difference stationary. The proposed tests are based on standard F- and t-statistics used to test the significance of the lagged levels of the variables in a univariate equilibrium correction mechanism. The asymptotic distributions of these statistics are non-standard under the null hypothesis that there exists no level relationship, irrespective of whether the regressors are I(0) or I(1). Two sets of asymptotic critical values are provided: one when all regressors are purely I(1) and the other if they are all purely I(0). These two sets of critical values provide a band covering all possible classifications of the regressors into purely I(0), purely I(1) or mutually cointegrated. Accordingly, various bounds testing procedures are proposed. It is shown that the proposed tests are consistent, and their asymptotic distribution under the null and suitably defined local alternatives are derived. The empirical relevance of the bounds procedures is demonstrated by a re-examination of the earnings equation included in the UK Treasury macroeconometric model. Copyright © 2001 John Wiley & Sons, Ltd.",2001,46,11403,2343,0,0,0,0,0,0,0,0,0,2
a82d7e0dc7b2d3a1b159e0902bb9f3017788a786,"A comprehensive, but simple-to-use software package for executing a range of standard numerical analysis and operations used in quantitative paleontology has been developed. The program, called PAST (PAleontological STatistics), runs on standard Windows computers and is available free of charge. PAST integrates spreadsheet-type data entry with univariate and multivariate statistics, curve fitting, timeseries analysis, data plotting, and simple phylogenetic analysis. Many of the functions are specific to paleontology and ecology, and these functions are not found in standard, more extensive, statistical packages. PAST also includes fourteen case studies (data files and exercises) illustrating use of the program for paleontological problems, making it a complete educational package for courses in quantitative methods.",2001,31,10400,1798,0,0,0,0,0,0,0,0,0,3
39dfeda235027e1bed00ab33bcb2ad16831677f8,"Hypothesis-testing methods for multivariate data are needed to make rigorous probability statements about the effects of factors and their interactions in experiments. Analysis of variance is particularly powerful for the analysis of univariate data. The traditional multivariate analogues, however, are too stringent in their assumptions for most ecological multivariate data sets. Non-parametric methods, based on permutation tests, are preferable. This paper describes a new non-parametric method for multivariate analysis of variance, after McArdle and Anderson (in press). It is given here, with several applications in ecology, to provide an alternative and perhaps more intuitive formulation for ANOVA (based on sums of squared distances) to complement the description pro- vided by McArdle and Anderson (in press) for the analysis of any linear model. It is an improvement on previous non-parametric methods because it allows a direct additive partitioning of variation for complex models. It does this while maintaining the flexibility and lack of formal assumptions of other non-parametric methods. The test- statistic is a multivariate analogue to Fisher's F-ratio and is calculated directly from any symmetric distance or dissimilarity matrix. P-values are then obtained using permutations. Some examples of the method are given for tests involving several factors, including factorial and hierarchical (nested) designs and tests of interactions.",2001,127,10965,1444,0,0,0,0,0,0,0,0,0,158
21c41fcec6ac8a7f55c539ac199247f200633753,"Microarrays can measure the expression of thousands of genes to identify changes in expression between different biological states. Methods are needed to determine the significance of these changes while accounting for the enormous number of genes. We describe a method, Significance Analysis of Microarrays (SAM), that assigns a score to each gene on the basis of change in gene expression relative to the standard deviation of repeated measurements. For genes with scores greater than an adjustable threshold, SAM uses permutations of the repeated measurements to estimate the percentage of genes identified by chance, the false discovery rate (FDR). When the transcriptional response of human cells to ionizing radiation was measured by microarrays, SAM identified 34 genes that changed at least 1.5-fold with an estimated FDR of 12%, compared with FDRs of 60 and 84% by using conventional methods of analysis. Of the 34 genes, 19 were involved in cell cycle regulation and 3 in apoptosis. Surprisingly, four nucleotide excision repair genes were induced, suggesting that this repair pathway for UV-damaged DNA might play a previously unrecognized role in repairing DNA damaged by ionizing radiation.",2001,54,11566,1626,0,0,1,3,249,864,864,894,921,881
c8831d7d318b8d59f9b958d250a58f253f08bd8a,"This article is about a curious phenomenon. Suppose we have a data matrix, which is the superposition of a low-rank component and a sparse component. Can we recover each component individually? We prove that under some suitable assumptions, it is possible to recover both the low-rank and the sparse components exactly by solving a very convenient convex program called Principal Component Pursuit; among all feasible decompositions, simply minimize a weighted combination of the nuclear norm and of the ℓ1 norm. This suggests the possibility of a principled approach to robust principal component analysis since our methodology and results assert that one can recover the principal components of a data matrix even though a positive fraction of its entries are arbitrarily corrupted. This extends to the situation where a fraction of the entries are missing as well. We discuss an algorithm for solving this optimization problem, and present applications in the area of video surveillance, where our methodology allows for the detection of objects in a cluttered background, and in the area of face recognition, where it offers a principled way of removing shadows and specularities in images of faces.",2009,90,5547,1043,9,66,155,236,340,507,532,647,665,703
70b48fd1a0c3d9fef98600578308e1e033c0c67a,Supplementary Figure 1 Overview of the analysis pipeline. Supplementary Table 1 Details of conventionally raised and conventionalized mouse samples. Supplementary Discussion Expanded discussion of QIIME analyses presented in the main text; Sequencing of 16S rRNA gene amplicons; QIIME analysis notes; Expanded Figure 1 legend; Links to raw data and processed output from the runs with and without denoising.,2010,30,23951,2769,0,0,0,0,0,1,2,4,98,3004
e5136e9306bf1b0e3d4be0cea384ee9a969a44fa,"Thematic analysis is a poorly demarcated, rarely acknowledged, yet widely used qualitative analytic method within psychology. In this paper, we argue that it offers an accessible and theoretically flexible approach to analysing qualitative data. We outline what thematic analysis is, locating it in relation to other qualitative analytic methods that search for themes or patterns, and in relation to different epistemological and ontological positions. We then provide clear guidelines to those wanting to start thematic analysis, or conduct it in a more deliberate and rigorous way, and consider potential pitfalls in conducting thematic analysis. Finally, we outline the disadvantages and advantages of thematic analysis. We conclude by advocating thematic analysis as a useful and flexible method for qualitative research in and beyond psychology.",2006,110,75770,5318,0,0,0,0,0,0,1,0,0,0
67556c4f0cfdd1f09fff373768b03638f949be0d,"Chapter 3 deals with probability distributions, discrete and continuous densities, distribution functions, bivariate distributions, means, variances, covariance, correlation, and some random process material. Chapter 4 is a detailed study of the concept of utility including the psychological aspects, risk, attributes, rules for utilities, multidimensional utility, and normal form of analysis. Chapter 5 treats games and optimization, linear optimization, and mixed strategies. Entropy is the topic of Chapter 6 with sections devoted to entropy, disorder, information, Shannon’s theorem, demon’s roulette, Maxwell– Boltzmann distribution, Schrodinger’s nutshell, maximum entropy probability distributions, blackbodies, and Bose–Einstein distribution. Chapter 7 is standard statistical fare including transformations of random variables, characteristic functions, generating functions, and the classic limit theorems such as the central limit theorem and the laws of large numbers. Chapter 8 is about exchangeability and inference with sections on Bayesian techniques and classical inference. Partial exchangeability is also treated. Chapter 9 considers such things as order statistics, extreme value, intensity, hazard functions, and Poisson processes. Chapter 10 covers basic elements of risk and reliability, while Chapter 11 is devoted to curve fitting, regression, and Monte Carlo simulation. There is an ample number of exercises at the ends of the chapters with answers or comments on many of them in an appendix in the back of the book. Other appendices are on the common discrete and continuous distributions and mathematical aspects of integration.",2007,0,18913,4802,0,0,0,0,0,0,0,1,7,889
ec3d71a2fdd01968a6dc638ee261715a0f118c1e,"Summary: It is expected that emerging digital gene expression (DGE) technologies will overtake microarray technologies in the near future for many functional genomics applications. One of the fundamental data analysis tasks, especially for gene expression studies, involves determining whether there is evidence that counts for a transcript or exon are significantly different across experimental conditions. edgeR is a Bioconductor software package for examining differential expression of replicated count data. An overdispersed Poisson model is used to account for both biological and technical variability. Empirical Bayes methods are used to moderate the degree of overdispersion across transcripts, improving the reliability of inference. The methodology can be used even with the most minimal levels of replication, provided at least one phenotype or experimental condition is replicated. The software may have other applications beyond sequencing data, such as proteome peptide count data. Availability: The package is freely available under the LGPL licence from the Bioconductor web site (http://bioconductor.org). Contact: mrobinson@wehi.edu.au",2009,10,21553,1162,0,0,0,0,0,0,1,1,7,64
d17669e4f3f4dd3a180bde84dd54a508d0dc22f4,"A comprehensive, but simple-to-use software package for executing a range of standard numerical analysis and operations used in quantitative paleontology has been developed. The program, called PAST (PAleontological STatistics), runs on standard Windows computers and is available free of charge. PAST integrates spreadsheet-type data entry with univariate and multivariate statistics, curve fitting, timeseries analysis, data plotting, and simple phylogenetic analysis. Many of the functions are specific to paleontology and ecology, and these functions are not found in standard, more extensive, statistical packages. PAST also includes fourteen case studies (data files and exercises) illustrating use of the program for paleontological problems, making it a complete educational package for courses in quantitative methods.",2001,17,17969,3587,0,0,0,0,0,0,0,0,0,0
9529c25408dc86194d417aed73d49ae0e418f1be,"32.03 MB Free download Econometric Analysis of Cross Section and Panel Data book PDF, FB2, EPUB and MOBI. Read online Econometric Analysis of Cross Section and Panel Data which classified as Other that has 776 pages that contain constructive material with lovely reading experience. Reading online Econometric Analysis of Cross Section and Panel Data book will be provide using wonderful book reader and it's might gives you some access to identifying the book content before you download the book.",2002,0,21019,2368,0,0,0,0,0,0,0,3,0,4
89fe2ca0bc4ea3f53f5745de6a88e094b8734a2b,1 Introduction: Models and Model Building Section I Understanding and Preparing for Multivariate Analysis 2 Cleaning and Transforming Data 3 Factor Analysis Section II Analysis Using Dependece Techniques 4 Simple and Multiple Regression Analysis 5 Canonical correlation 6 Conjoint analysis 7 Multiple Discriminant Analysis and Logistic Regression 8 ANOVA and MANOVA Section III Analysis using Interdependence Techniques 9 Group data and Cluster Analysis 10 MDS and Correspondence Analysis Structural Equation Modeling 11 SEM: An Introduction 12 Application of SEM,2010,0,6831,1353,53,154,275,450,587,635,645,725,827,809
0ad5733eafb41274895bf1dce6b92ae8f3d68c60,,2004,0,18831,2817,1,3,6,2,10,713,1440,1290,1233,1117
0d6cf3cd3794bc31a4e5a8ded4d4ba83bb20f9b0,"BOOK REVIEW: Constructing grounded theory. A practical guide through qualitative analysis Kathy Charmaz, 2006, 208 pp. London: Sage. ISBN 2005928035",2006,0,10716,2252,0,0,0,1,365,666,939,1134,1328,847
7bd23e6ec32cb1507a385c21a21150e9c332682f,"genalex is a user-friendly cross-platform package that runs within Microsoft Excel, enabling population genetic analyses of codominant, haploid and binary data. Allele frequency-based analyses include heterozygosity, F statistics, Nei's genetic distance, population assignment, probabilities of identity and pairwise relatedness. Distance-based calculations include amova, principal coordinates analysis (PCA), Mantel tests, multivariate and 2D spatial autocorrelation and twogener. More than 20 different graphs summarize data and aid exploration. Sequence and genotype data can be imported from automated sequencers, and exported to other software. Initially designed as tool for teaching, genalex 6 now offers features for researchers as well. Documentation and the program are available at http://www.anu.edu.au/BoZo/GenAlEx/",2006,12,14558,3330,0,0,0,0,0,0,3,972,1332,1368
895860c6083736508d2541900cdf0960eb11592f,"The design, implementation, and capabilities of an extensible visualization system, UCSF Chimera, are discussed. Chimera is segmented into a core that provides basic services and visualization, and extensions that provide most higher level functionality. This architecture ensures that the extension mechanism satisfies the demands of outside developers who wish to incorporate new features. Two unusual extensions are presented: Multiscale, which adds the ability to visualize large‐scale molecular assemblies such as viral coats, and Collaboratory, which allows researchers to share a Chimera session interactively despite being at separate locales. Other extensions include Multalign Viewer, for showing multiple sequence alignments and associated structures; ViewDock, for screening docked ligand orientations; Movie, for replaying molecular dynamics trajectories; and Volume Viewer, for display and analysis of volumetric data. A discussion of the usage of Chimera in real‐world situations is given, along with anticipated future directions. Chimera includes full user documentation, is free to academic and nonprofit users, and is available for Microsoft Windows, Linux, Apple Mac OS X, SGI IRIX, and HP Tru64 Unix from http://www.cgl.ucsf.edu/chimera/. © 2004 Wiley Periodicals, Inc. J Comput Chem 25: 1605–1612, 2004",2004,70,28328,1713,0,0,0,0,1,0,0,0,0,0
e7c8aa2cb2223f17615c1b1ae3b33095466e95cc,"The two most commonly used methods to analyze data from real-time, quantitative PCR experiments are absolute quantification and relative quantification. Absolute quantification determines the input copy number, usually by relating the PCR signal to a standard curve. Relative quantification relates the PCR signal of the target transcript in a treatment group to that of another sample such as an untreated control. The 2(-Delta Delta C(T)) method is a convenient way to analyze the relative changes in gene expression from real-time quantitative PCR experiments. The purpose of this report is to present the derivation, assumptions, and applications of the 2(-Delta Delta C(T)) method. In addition, we present the derivation and applications of two variations of the 2(-Delta Delta C(T)) method that may be useful in the analysis of real-time, quantitative PCR data.",2001,21,115916,1656,0,0,0,0,0,0,0,0,1,0
05abdc87bcaf2963fd511672e64ab39d02239aaf,,2007,30,24491,2512,0,1,0,0,1,0,5,6,535,2032
2d6f573c36c5e2153b65859fb080523fc4d842d0,"We announce the release of the fourth version of MEGA software, which expands on the existing facilities for editing DNA sequence data from autosequencers, mining Web-databases, performing automatic and manual sequence alignment, analyzing sequence alignments to estimate evolutionary distances, inferring phylogenetic trees, and testing evolutionary hypotheses. Version 4 includes a unique facility to generate captions, written in figure legend format, in order to provide natural language descriptions of the models and methods used in the analyses. This facility aims to promote a better understanding of the underlying assumptions used in analyses, and of the results generated. Another new feature is the Maximum Composite Likelihood (MCL) method for estimating evolutionary distances between all pairs of sequences simultaneously, with and without incorporating rate variation among sites and substitution pattern heterogeneities among lineages. This MCL method also can be used to estimate transition/transversion bias and nucleotide substitution pattern without knowledge of the phylogenetic tree. This new version is a native 32-bit Windows application with multi-threading and multi-user supports, and it is also available to run in a Linux desktop environment (via the Wine compatibility layer) and on Intel-based Macintosh computers under the Parallels program. The current version of MEGA is available free of charge at (http://www.megasoftware.net).",2007,10,28423,6043,0,0,0,0,1,18,2034,2152,1667,1255
4e2f43dab69d690dc86422949e410ebf37f522d4,"Bayesian methods have garnered huge interest in cognitive science as an approach to models of cognition and perception. On the other hand, Bayesian methods for data analysis have not yet made much headway in cognitive science against the institutionalized inertia of 20th century null hypothesis significance testing (NHST). Ironically, specific Bayesian models of cognition and perception may not long endure the ravages of empirical verification, but generic Bayesian methods for data analysis will eventually dominate. It is time that Bayesian data analysis became the norm for empirical methods in cognitive science. This article reviews a fatal flaw of NHST and introduces the reader to some benefits of Bayesian data analysis. The article presents illustrative examples of multiple comparisons in Bayesian analysis of variance and Bayesian approaches to statistical power. Copyright © 2010 John Wiley & Sons, Ltd. For further resources related to this article, please visit the WIREs website.",2010,87,5662,709,296,287,323,345,347,434,424,416,498,498
57e7a7323f58a35f5e2cc33bf17d4ac9cdcafdd4,"DAVID bioinformatics resources consists of an integrated biological knowledgebase and analytic tools aimed at systematically extracting biological meaning from large gene/protein lists. This protocol explains how to use DAVID, a high-throughput and integrated data-mining environment, to analyze gene lists derived from high-throughput genomic experiments. The procedure first requires uploading a gene list containing any number of common gene identifiers followed by analysis using one or more text and pathway-mining tools such as gene functional classification, functional annotation chart or clustering and functional annotation table. By following this protocol, investigators are able to gain an in-depth understanding of the biological themes in lists of genes that are enriched in genome-scale studies.",2008,16,27514,2132,0,0,0,0,0,0,0,0,7,39
cad327e1e3a0799202cb40da5da51d7b0616b64e,"Arlequin ver 3.0 is a software package integrating several basic and advanced methods for population genetics data analysis, like the computation of standard genetic diversity indices, the estimation of allele and haplotype frequencies, tests of departure from linkage equilibrium, departure from selective neutrality and demographic equilibrium, estimation or parameters from past population expansions, and thorough analyses of population subdivision under the AMOVA framework. Arlequin 3 introduces a completely new graphical interface written in C++, a more robust semantic analysis of input files, and two new methods: a Bayesian estimation of gametic phase from multi-locus genotypes, and an estimation of the parameters of an instantaneous spatial expansion from DNA sequence polymorphism. Arlequin can handle several data types like DNA sequences, microsatellite data, or standard multi-locus genotypes. A Windows version of the software is freely available on http://cmpg.unibe.ch/software/arlequin3.",2007,148,12556,4438,1,1,21,1207,1437,1392,1211,1052,891,751
e09bb0025f4939a4bd233a70937584b4d7bdd0a7,"BackgroundThe evolutionary analysis of molecular sequence variation is a statistical enterprise. This is reflected in the increased use of probabilistic models for phylogenetic inference, multiple sequence alignment, and molecular population genetics. Here we present BEAST: a fast, flexible software architecture for Bayesian analysis of molecular sequences related by an evolutionary tree. A large number of popular stochastic models of sequence evolution are provided and tree-based models suitable for both within- and between-species sequence data are implemented.ResultsBEAST version 1.4.6 consists of 81000 lines of Java source code, 779 classes and 81 packages. It provides models for DNA and protein sequence evolution, highly parametric coalescent analysis, relaxed clock phylogenetics, non-contemporaneous sequence data, statistical alignment and a wide range of options for prior distributions. BEAST source code is object-oriented, modular in design and freely available at http://beast-mcmc.googlecode.com/ under the GNU LGPL license.ConclusionBEAST is a powerful and flexible evolutionary analysis package for molecular sequence variation. It also provides a resource for the further development of new models and statistical methods of evolutionary analysis.",2007,45,11140,3504,0,0,1,247,973,1270,1219,1114,1018,941
80935b370bac09ce615a002caabc30fbb26f029b,"With its theoretical basis firmly established in molecular evolutionary and population genetics, the comparative DNA and protein sequence analysis plays a central role in reconstructing the evolutionary histories of species and multigene families, estimating rates of molecular evolution, and inferring the nature and extent of selective forces shaping the evolution of genes and genomes. The scope of these investigations has now expanded greatly owing to the development of high-throughput sequencing techniques and novel statistical and computational methods. These methods require easy-to-use computer programs. One such effort has been to produce Molecular Evolutionary Genetics Analysis (MEGA) software, with its focus on facilitating the exploration and analysis of the DNA and protein sequence variation from an evolutionary perspective. Currently in its third major release, MEGA3 contains facilities for automatic and manual sequence alignment, web-based mining of databases, inference of the phylogenetic trees, estimation of evolutionary distances and testing evolutionary hypotheses. This paper provides an overview of the statistical methods, computational tools, and visual exploration modules for data input and the results obtainable in MEGA.",2004,73,12037,3302,1,0,26,1588,2150,1625,1243,879,678,475
4c97d9b9eb7c158e682844b394b42924af3c5b3f,"Interpretative phenomenological analysis (IPA) is an increasingly popular approach to qualitative inquiry. This handy text covers its theoretical foundations and provides a detailed guide to conducting IPA research. 
 
Extended worked examples from the authors' own studies in health, sexuality, psychological distress and identity illustrate the breadth and depth of IPA research. 
 
Each of the chapters also offers a guide to other good exemplars of IPA research in the designated area. The final section of the book considers how IPA connects with other contemporary qualitative approaches like discourse and narrative analysis and how it addresses issues to do with validity. The book is written in an accessible style and will be extremely useful to students and researchers in psychology and related disciplines in the health and social sciences.",2009,7,6197,1589,6,76,172,280,438,624,709,699,792,811
001c07aefcc186013184009e0c83847f28867e08,"ggplot2: Elegant Graphics for Data Analysis is a new addition to the UseR! series by Springer, probably the fastest expanding source of resources for computational statistics at the current moment. The books in this series are all linked with R, either presenting a new package developed by the own authors of the book or describing how to applying statistical techniques with the different packages available in R. ggplot2 is an implementation in R of The Grammar of Graphics (Wilkinson 2005) a systematic approach to the specification of statistical graphics that was introduced in a book previously reviewed in the Journal of Statistical Software by Cox (2007). This implementation has been developed by Hadley Wickham, who is also the author of the book reviewed here.",2010,1,4911,435,9,20,22,56,87,94,178,255,446,795
7ea9b1915072f2adff3762b59b7c7d79805fee8e,"If radiocarbon measurements are to be used at all for chronological purposes, we have to use statistical methods for calibration. The most widely used method of calibration can be seen as a simple application of Bayesian statistics, which uses both the information from the new measurement and information from the 14C calibration curve. In most dating applications, however, we have larger numbers of 14C measurements and we wish to relate those to events in the past. Bayesian statistics provides a coherent framework in which such analysis can be performed and is becoming a core element in many 14C dating projects. This article gives an overview of the main model components used in chronological analysis, their mathematical formulation, and examples of how such analyses can be performed using the latest version of the OxCal software (v4). Many such models can be put together, in a modular fashion, from simple elements, with defined constraints and groupings. In other cases, the commonly used ""uniform phase"" models might not be appropriate, and ramped, exponential, or normal distributions of events might be more useful. When considering analyses of these kinds, it is useful to be able run simulations on synthetic data. Methods for performing such tests are discussed here along with other methods of diagnosing possible problems with statistical models of this kind.",2009,69,4539,1446,11,103,201,275,402,450,446,453,577,449
87ccc438b0c73fcfdea48485fcdb091a8ecaa89c,"High-throughput sequencing assays such as RNA-Seq, ChIP-Seq or barcode counting provide quantitative readouts in the form of count data. To infer differential signal in such data correctly and with good statistical power, estimation of data variability throughout the dynamic range and a suitable error model are required. We propose a method based on the negative binomial distribution, with variance and mean linked by local regression and present an implementation, DESeq, as an R/Bioconductor package.",2010,80,9807,1096,9,65,225,483,806,957,981,1071,1172,1372
b9544a1bf4b02c6648dbd12702bc10c00e20e197,"Content analysis is a widely used qualitative research technique. Rather than being a single method, current applications of content analysis show three distinct approaches: conventional, directed, or summative. All three approaches are used to interpret meaning from the content of text data and, hence, adhere to the naturalistic paradigm. The major differences among the approaches are coding schemes, origins of codes, and threats to trustworthiness. In conventional content analysis, coding categories are derived directly from the text data. With a directed approach, analysis starts with a theory or relevant research findings as guidance for initial codes. A summative content analysis involves counting and comparisons, usually of keywords or content, followed by the interpretation of the underlying context. The authors delineate analytic procedures specific to each approach and techniques addressing trustworthiness with hypothetical examples drawn from the area of end-of-life care.",2005,57,24913,943,0,0,0,0,0,0,0,0,0,0
2fcf90089d9f95025e8953812a43f0db2de3af7c,,2009,0,10344,2663,0,0,262,430,655,922,1128,1232,1332,1349
d76bde423b71f1cb900b988311bd2d71b700d506,"The extent of heterogeneity in a meta-analysis partly determines the difficulty in drawing overall conclusions. This extent may be measured by estimating a between-study variance, but interpretation is then specific to a particular treatment effect metric. A test for the existence of heterogeneity exists, but depends on the number of studies in the meta-analysis. We develop measures of the impact of heterogeneity on a meta-analysis, from mathematical criteria, that are independent of the number of studies and the treatment effect metric. We derive and propose three suitable statistics: H is the square root of the chi2 heterogeneity statistic divided by its degrees of freedom; R is the ratio of the standard error of the underlying mean from a random effects meta-analysis to the standard error of a fixed effect meta-analytic estimate, and I2 is a transformation of (H) that describes the proportion of total variation in study estimates that is due to heterogeneity. We discuss interpretation, interval estimates and other properties of these measures and examine them in five example data sets showing different amounts of heterogeneity. We conclude that H and I2, which can usually be calculated for published meta-analyses, are particularly useful summaries of the impact of heterogeneity. One or both should be presented in published meta-analyses in preference to the test for heterogeneity.",2002,35,21386,493,0,0,0,0,1,0,1,0,1,1
fc448a7db5a2fac242705bd8e37ae1fc4a858643,"The human genome holds an extraordinary trove of information about human development, physiology, medicine and evolution. Here we report the results of an international collaboration to produce and make freely available a draft sequence of the human genome. We also present an initial analysis of the data, describing some of the insights that can be gleaned from the sequence.",2001,431,17459,430,5,1,4,2,1,2,8,504,764,774
1a77e19441f3a0e030998fb2d11d9dd774582403,"The techniques available for the interrogation and analysis of neuroimaging data have a large influence in determining the flexibility, sensitivity, and scope of neuroimaging experiments. The development of such methodologies has allowed investigators to address scientific questions that could not previously be answered and, as such, has become an important research area in its own right. In this paper, we present a review of the research carried out by the Analysis Group at the Oxford Centre for Functional MRI of the Brain (FMRIB). This research has focussed on the development of new methodologies for the analysis of both structural and functional magnetic resonance imaging data. The majority of the research laid out in this paper has been implemented as freely available software tools within FMRIB's Software Library (FSL).",2004,52,10646,1541,0,0,0,0,0,77,419,577,673,764
76ad159a2887b008e5a7335d124c148c13e65465,"We have developed a toolbox and graphic user interface, EEGLAB, running under the crossplatform MATLAB environment (The Mathworks, Inc.) for processing collections of single-trial and/or averaged EEG data of any number of channels. Available functions include EEG data, channel and event information importing, data visualization (scrolling, scalp map and dipole model plotting, plus multi-trial ERP-image plots), preprocessing (including artifact rejection, filtering, epoch selection, and averaging), independent component analysis (ICA) and time/frequency decompositions including channel and component cross-coherence supported by bootstrap statistical methods based on data resampling. EEGLAB functions are organized into three layers. Top-layer functions allow users to interact with the data through the graphic interface without needing to use MATLAB syntax. Menu options allow users to tune the behavior of EEGLAB to available memory. Middle-layer functions allow users to customize data processing using command history and interactive 'pop' functions. Experienced MATLAB users can use EEGLAB data structures and stand-alone signal processing functions to write custom and/or batch analysis scripts. Extensive function help and tutorial information are included. A 'plug-in' facility allows easy incorporation of new EEG modules into the main menu. EEGLAB is freely available (http://www.sccn.ucsd.edu/eeglab/) under the GNU public license for noncommercial use and open source development, together with sample data, user tutorial and extensive documentation.",2004,85,14460,1914,0,0,0,0,0,0,0,0,0,0
e250c4b0cc0180af9f47b97f3b9ff1727a2767aa,"New software, OLEX2, has been developed for the determination, visualization and analysis of molecular crystal structures. The software has a portable mouse-driven workflow-oriented and fully comprehensive graphical user interface for structure solution, refinement and report generation, as well as novel tools for structure analysis. OLEX2 seamlessly links all aspects of the structure solution, refinement and publication process and presents them in a single workflow-driven package, with the ultimate goal of producing an application which will be useful to both chemists and crystallographers.",2009,10,13162,496,0,0,0,0,0,0,3,653,1471,1660
42abddd227d653a0375d7d037ddb885f6c07f66f,"We present Model-based Analysis of ChIP-Seq data, MACS, which analyzes data generated by short read sequencers such as Solexa's Genome Analyzer. MACS empirically models the shift size of ChIP-Seq tags, and uses it to improve the spatial resolution of predicted binding sites. MACS also uses a dynamic Poisson distribution to effectively capture local biases in the genome, allowing for more robust predictions. MACS compares favorably to existing ChIP-Seq peak-finding algorithms, and is freely available.",2008,17,9866,1179,6,43,122,233,339,455,628,662,729,980
20aeb2357e9e215787c7e0d0acfe7a6b598c9103,"This book describes ggplot2, a new data visualization package for R that uses the insights from Leland Wilkisons Grammar of Graphics to create a powerful and flexible system for creating data graphics. With ggplot2, its easy to: produce handsome, publication-quality plots, with automatic legends created from the plot specification superpose multiple layers (points, lines, maps, tiles, box plots to name a few) from different data sources, with automatically adjusted common scales add customisable smoothers that use the powerful modelling capabilities of R, such as loess, linear models, generalised additive models and robust regression save any ggplot2 plot (or part thereof) for later modification or reuse create custom themes that capture in-house or journal style requirements, and that can easily be applied to multiple plots approach your graph from a visual perspective, thinking about how each component of the data is represented on the final plot. This book will be useful to everyone who has struggled with displaying their data in an informative and attractive way. You will need some basic knowledge of R (i.e. you should be able to get your data into R), but ggplot2 is a mini-language specifically tailored for producing graphics, and youll learn everything you need in the book. After reading this book youll be able to produce graphics customized precisely for your problems,and youll find it easy to get graphics out of your head and on to the screen or page.",2009,0,20904,1807,0,0,0,0,0,1,2,0,3,9
7a6142cfa79cc01ceced5e144bd0e01a0f241a74,,2009,43,7893,2014,377,456,500,626,706,655,723,661,657,644
94559c249d204110296c39ed4af2042cc4468e68,"The Karhunen-Lo eve basis functions, more frequently referred to as principal components or empirical orthogonal functions (EOFs), of the noise response of the climate system are an important tool for geophysical studies. Many researchers have used this tool to examine the geophysical and climatological phenomena. Perhaps more frequent use of EOFs in recent studies is in conjunction with the development of the signal detection and estimation methods of the background uctuations of a detection variable serve as an orthogonal basis set and are used to design optimal techniques for detecting and estimating signals. A detection and prediction approach is to design a lter or optimal weights for the signal to be detected. It has been reported that weighted averaging of data over the surface of the Earth improved the detectability of climatic changes (Hasselmann 1979; Stefanick 1981; Bell 1982). Since the signal-to-noise ratio (SNR) varies geographically, there exists an optimal geographical weighting of the signal which maximizes the SNR. The design of an optimal weighting function may require detailed knowledge on the natural uctuation of the climate system. A conceptually similar approach is to employ a particular pattern (or patterns) of climatic change for detection and prediction (e.g., Barnett and Hasselmann 1979; Hasselmann 1979). The patterns of interest (also called the predictors) may include the principal components (empirical orthogonal functions) (e. von Storch 1990) among others. This approach also requires complete knowledge of the natural variability of the climate system. To test and improve the detection and prediction techniques addressed above, a complete cross-spectral covariance matrix, or similarly, a complete set of the principal components of natural uctuations of the climate system for each frequency band of the spectrum is necessary. In reality, a reliable spectrum of observational covariance matrix is not available because observations are not suuciently long and sampling errors contaminate the observational records (Preisendorfer and Barnett 1977; North et al. 1982). Further, inadequate spatial coverage of observations may introduce bias. Therefore, the covariance matrix of the noise response is often estimated from a simple stochastic model. Kim and North (1991, 1992) examined the covariance matrix in terms of various second-moment statistics earlier. Examined here are the principal components of the covariance matrix of the surface temperature uctuations in a simple coupled climate model in comparison with observations. The principal components not only are an",2009,52,14117,1668,1,0,3,13,175,903,1082,1144,1134,1081
da7ab2f1b6278472f3671a7430c9a72bad07781f,"PAML, currently in version 4, is a package of programs for phylogenetic analyses of DNA and protein sequences using maximum likelihood (ML). The programs may be used to compare and test phylogenetic trees, but their main strengths lie in the rich repertoire of evolutionary models implemented, which can be used to estimate parameters in models of sequence evolution and to test interesting biological hypotheses. Uses of the programs include estimation of synonymous and nonsynonymous rates (d(N) and d(S)) between two protein-coding DNA sequences, inference of positive Darwinian selection through phylogenetic comparison of protein-coding genes, reconstruction of ancestral genes and proteins for molecular restoration studies of extinct life forms, combined analysis of heterogeneous data sets from multiple gene loci, and estimation of species divergence times incorporating uncertainties in fossil calibrations. This note discusses some of the major applications of the package, which includes example data sets to demonstrate their use. The package is written in ANSI C, and runs under Windows, Mac OSX, and UNIX systems. It is available at -- (http://abacus.gene.ucl.ac.uk/software/paml.html).",2007,203,9021,1777,10,131,298,412,471,583,614,666,638,749
d40ee5dd758c525dfb9932d726bb4e844b7b8478,"Receiver operating characteristics (ROC) graphs are useful for organizing classifiers and visualizing their performance. ROC graphs are commonly used in medical decision making, and in recent years have been used increasingly in machine learning and data mining research. Although ROC graphs are apparently simple, there are some common misconceptions and pitfalls when using them in practice. The purpose of this article is to serve as an introduction to ROC graphs and as a guide for using them in research.",2006,45,14314,1234,0,0,0,0,0,0,1,4,75,1122
215579acece24b34f6ab91fab62bac8ba7ccfe03,,2002,0,16249,1013,1,1,5,5,9,12,517,1114,1268,1194
c98386ddf2fe4973da42187a9e3c9167095acf4e,"During the past 30 years, meta-analysis has been an indispensable tool for revealing the hidden meaning of our research literatures. The four articles in this special section on meta-analysis illustrate some of the complexities entailed in meta-analysis methods. Although meta-analysis is a powerful tool for advancing cumulative knowledge, researchers can be confused by the complicated issues involved in the methodology. Each of these four articles contributes both to advancing this methodology and to the increasing complexities that can befuddle researchers. In these comments, the author attempts to clarify both of these aspects and provide a perspective on the methodological issues examined in these articles.",2008,114,15161,703,0,0,0,0,0,0,0,0,0,4
b6fbb3a44a8e946b4a231118a737a396517c83de,"AIM
This paper is a description of inductive and deductive content analysis.


BACKGROUND
Content analysis is a method that may be used with either qualitative or quantitative data and in an inductive or deductive way. Qualitative content analysis is commonly used in nursing studies but little has been published on the analysis process and many research books generally only provide a short description of this method.


DISCUSSION
When using content analysis, the aim was to build a model to describe the phenomenon in a conceptual form. Both inductive and deductive analysis processes are represented as three main phases: preparation, organizing and reporting. The preparation phase is similar in both approaches. The concepts are derived from the data in inductive content analysis. Deductive content analysis is used when the structure of analysis is operationalized on the basis of previous knowledge.


CONCLUSION
Inductive content analysis is used in cases where there are no previous studies dealing with the phenomenon or when it is fragmented. A deductive approach is useful if the general aim was to test a previous theory in a different situation or to compare categories at different time periods.",2008,65,11840,609,0,0,0,0,0,1,379,1016,1090,1290
39dae53515afb42664369c291ec6d1ce34d778bd,"BackgroundCorrelation networks are increasingly being used in bioinformatics applications. For example, weighted gene co-expression network analysis is a systems biology method for describing the correlation patterns among genes across microarray samples. Weighted correlation network analysis (WGCNA) can be used for finding clusters (modules) of highly correlated genes, for summarizing such clusters using the module eigengene or an intramodular hub gene, for relating modules to one another and to external sample traits (using eigengene network methodology), and for calculating module membership measures. Correlation networks facilitate network based gene screening methods that can be used to identify candidate biomarkers or therapeutic targets. These methods have been successfully applied in various biological contexts, e.g. cancer, mouse genetics, yeast genetics, and analysis of brain imaging data. While parts of the correlation network methodology have been described in separate publications, there is a need to provide a user-friendly, comprehensive, and consistent software implementation and an accompanying tutorial.ResultsThe WGCNA R software package is a comprehensive collection of R functions for performing various aspects of weighted correlation network analysis. The package includes functions for network construction, module detection, gene selection, calculations of topological properties, data simulation, visualization, and interfacing with external software. Along with the R package we also present R software tutorials. While the methods development was motivated by gene expression data, the underlying data mining approach can be applied to a variety of different settings.ConclusionThe WGCNA package provides R functions for weighted correlation network analysis, e.g. co-expression network analysis of gene expression data. The R package along with its source code and additional material are freely available at http://www.genetics.ucla.edu/labs/horvath/CoexpressionNetwork/Rpackages/WGCNA.",2008,51,9025,1051,2,9,29,60,112,163,263,361,592,783
0e2532c31c992ac0930998561932f198b467572d,"This article examines the function of documents as a data source in qualitative research and discusses document analysis procedure in the context of actual research experiences. Targeted to research novices, the article takes a nuts‐and‐bolts approach to document analysis. It describes the nature and forms of documents, outlines the advantages and limitations of document analysis, and offers specific examples of the use of documents in the research process. The application of document analysis to a grounded theory study is illustrated.",2009,34,4574,534,0,12,16,59,127,198,275,417,534,725
dd1b3a3793619cec8994cc7cca10e6dee656fb7b,"UNLABELLED
Research over the last few years has revealed significant haplotype structure in the human genome. The characterization of these patterns, particularly in the context of medical genetic association studies, is becoming a routine research activity. Haploview is a software package that provides computation of linkage disequilibrium statistics and population haplotype patterns from primary genotype data in a visually appealing and interactive interface.


AVAILABILITY
http://www.broad.mit.edu/mpg/haploview/


CONTACT
jcbarret@broad.mit.edu",2005,12,13390,1399,0,0,0,1,74,1111,1159,1137,1018,973
6fb968167f3c9c76d00d085a57b265cb912ad012,"Data Mining Methods and Models is the second volume of a three-book series on data mining authored by Larose. The following review was performed independently of LaRose’s other two books. Paraphrasing from the Preface, the goal of this book is to “explore the process of data mining from the point of view of model building.” Nevertheless, the reader will soon be aware that this book is not intended to provide a systematic or comprehensive coverage of various data mining algorithms. Instead, it considers supervised learning or predictive modeling only, and it walks the reader through the data mining process merely with a few selected modeling methods such as (generalized) linear modeling and the Bayesian approach. The book has seven chapters. Chapter 1 introduces dimension reduction, with a focus on principal components analysis (PCA) types of techniques. Chapters 2, 3, and 4 provide a detailed coverage of simple linear regression, multiple linear regression, and logistic regression, respectively. Chapter 5 introduces naive Bayes estimation and Bayesian networks. In Chapter 6, the basic idea of genetic algorithms is discussed. Finally, Chapter 7 presents a case study example of modeling response to direct mail marketing within the CRISP (crossindustry standard process) framework. This book is very easy to read, and this is absolutely the strength which many readers, especially those nonstatistically oriented ones, will greatly appreciate. Predictive modeling is perhaps the most technical part in a data mining process. The author has done an excellent job in making this difficult topic accessible to a broad audience. For example, I like the way in which Bayesian networks are introduced in Chapter 5. After the reader goes through a churn example on naive Bayes estimation in a step-by-step manner, Bayesian belief networks become easily understood as natural extensions. The overall style of the book is clear and patient. The main limitation of the book is its limited coverage. An inspired reader would expect to see a much more extended list of topics. Hastie, Tibishirani, and Friedman (2001) gave a full and more technical account of various data mining algorithms. The inclusion of genetic algorithms in Chapter 6 seems novel when compared to Hastie, Tibishirani, and Friedman (2001), but at the same time, a little unexpected as a separate chapter, since a genetic algorithm involves a stochastics search scheme, which is somewhat involved given the elementary nature of this text. Another noteworthy issue is that the author does not make an attempt to distinguish between conventional statistical analysis and data mining. I found a few errors. On Page 25, for example, it should be ai = 1, instead of ai = 1/4. Also, in the frame on the top of Page 211, it might have been “Posterior Odds,” instead of “Posterior Odds Ratio.” The book uses three different software packages to implement the ideas including SPSS with Clementine, Minitab, and WEKA, which might not be appealing. On the other hand, it is justifiable as it allows one to perform data mining with affordable costs. In summary, I recommend this fairly readable book for adoption in a graduate-level introductory course on data mining, especially when the students come from varied backgrounds.",2008,5,6081,1832,57,100,190,265,350,401,473,572,669,712
85dfac3a261fbdea3b4e1a6f3264c6384bbc4485,"Qualitative content analysis as described in published literature shows conflicting opinions and unsolved issues regarding meaning and use of concepts, procedures and interpretation. This paper provides an overview of important concepts (manifest and latent content, unit of analysis, meaning unit, condensation, abstraction, content area, code, category and theme) related to qualitative content analysis; illustrates the use of concepts related to the research procedure; and proposes measures to achieve trustworthiness (credibility, dependability and transferability) throughout the steps of the research procedure. Interpretation in qualitative content analysis is discussed in light of Watzlawick et al.'s [Pragmatics of Human Communication. A Study of Interactional Patterns, Pathologies and Paradoxes. W.W. Norton & Company, New York, London] theory of communication.",2004,58,14412,1104,0,0,0,0,0,0,0,0,0,4
d96faee1898de7a052115ecfe533a5b2fd1151c0,"This paper develops a new approach to the problem of testing the existence of a level relationship between a dependent variable and a set of regressors, when it is not known with certainty whether the underlying regressors are trend- or first-difference stationary. The proposed tests are based on standard F- and t-statistics used to test the significance of the lagged levels of the variables in a univariate equilibrium correction mechanism. The asymptotic distributions of these statistics are non-standard under the null hypothesis that there exists no level relationship, irrespective of whether the regressors are I(0) or I(1). Two sets of asymptotic critical values are provided: one when all regressors are purely I(1) and the other if they are all purely I(0). These two sets of critical values provide a band covering all possible classifications of the regressors into purely I(0), purely I(1) or mutually cointegrated. Accordingly, various bounds testing procedures are proposed. It is shown that the proposed tests are consistent, and their asymptotic distribution under the null and suitably defined local alternatives are derived. The empirical relevance of the bounds procedures is demonstrated by a re-examination of the earnings equation included in the UK Treasury macroeconometric model. Copyright © 2001 John Wiley & Sons, Ltd.",2001,46,11403,2343,0,0,0,0,0,0,0,0,0,2
a82d7e0dc7b2d3a1b159e0902bb9f3017788a786,"A comprehensive, but simple-to-use software package for executing a range of standard numerical analysis and operations used in quantitative paleontology has been developed. The program, called PAST (PAleontological STatistics), runs on standard Windows computers and is available free of charge. PAST integrates spreadsheet-type data entry with univariate and multivariate statistics, curve fitting, timeseries analysis, data plotting, and simple phylogenetic analysis. Many of the functions are specific to paleontology and ecology, and these functions are not found in standard, more extensive, statistical packages. PAST also includes fourteen case studies (data files and exercises) illustrating use of the program for paleontological problems, making it a complete educational package for courses in quantitative methods.",2001,31,10400,1798,0,0,0,0,0,0,0,0,0,3
39dfeda235027e1bed00ab33bcb2ad16831677f8,"Hypothesis-testing methods for multivariate data are needed to make rigorous probability statements about the effects of factors and their interactions in experiments. Analysis of variance is particularly powerful for the analysis of univariate data. The traditional multivariate analogues, however, are too stringent in their assumptions for most ecological multivariate data sets. Non-parametric methods, based on permutation tests, are preferable. This paper describes a new non-parametric method for multivariate analysis of variance, after McArdle and Anderson (in press). It is given here, with several applications in ecology, to provide an alternative and perhaps more intuitive formulation for ANOVA (based on sums of squared distances) to complement the description pro- vided by McArdle and Anderson (in press) for the analysis of any linear model. It is an improvement on previous non-parametric methods because it allows a direct additive partitioning of variation for complex models. It does this while maintaining the flexibility and lack of formal assumptions of other non-parametric methods. The test- statistic is a multivariate analogue to Fisher's F-ratio and is calculated directly from any symmetric distance or dissimilarity matrix. P-values are then obtained using permutations. Some examples of the method are given for tests involving several factors, including factorial and hierarchical (nested) designs and tests of interactions.",2001,127,10965,1444,0,0,0,0,0,0,0,0,0,158
21c41fcec6ac8a7f55c539ac199247f200633753,"Microarrays can measure the expression of thousands of genes to identify changes in expression between different biological states. Methods are needed to determine the significance of these changes while accounting for the enormous number of genes. We describe a method, Significance Analysis of Microarrays (SAM), that assigns a score to each gene on the basis of change in gene expression relative to the standard deviation of repeated measurements. For genes with scores greater than an adjustable threshold, SAM uses permutations of the repeated measurements to estimate the percentage of genes identified by chance, the false discovery rate (FDR). When the transcriptional response of human cells to ionizing radiation was measured by microarrays, SAM identified 34 genes that changed at least 1.5-fold with an estimated FDR of 12%, compared with FDRs of 60 and 84% by using conventional methods of analysis. Of the 34 genes, 19 were involved in cell cycle regulation and 3 in apoptosis. Surprisingly, four nucleotide excision repair genes were induced, suggesting that this repair pathway for UV-damaged DNA might play a previously unrecognized role in repairing DNA damaged by ionizing radiation.",2001,54,11566,1626,0,0,1,3,249,864,864,894,921,881
c8831d7d318b8d59f9b958d250a58f253f08bd8a,"This article is about a curious phenomenon. Suppose we have a data matrix, which is the superposition of a low-rank component and a sparse component. Can we recover each component individually? We prove that under some suitable assumptions, it is possible to recover both the low-rank and the sparse components exactly by solving a very convenient convex program called Principal Component Pursuit; among all feasible decompositions, simply minimize a weighted combination of the nuclear norm and of the ℓ1 norm. This suggests the possibility of a principled approach to robust principal component analysis since our methodology and results assert that one can recover the principal components of a data matrix even though a positive fraction of its entries are arbitrarily corrupted. This extends to the situation where a fraction of the entries are missing as well. We discuss an algorithm for solving this optimization problem, and present applications in the area of video surveillance, where our methodology allows for the detection of objects in a cluttered background, and in the area of face recognition, where it offers a principled way of removing shadows and specularities in images of faces.",2009,90,5547,1043,9,66,155,236,340,507,532,647,665,703
70b48fd1a0c3d9fef98600578308e1e033c0c67a,Supplementary Figure 1 Overview of the analysis pipeline. Supplementary Table 1 Details of conventionally raised and conventionalized mouse samples. Supplementary Discussion Expanded discussion of QIIME analyses presented in the main text; Sequencing of 16S rRNA gene amplicons; QIIME analysis notes; Expanded Figure 1 legend; Links to raw data and processed output from the runs with and without denoising.,2010,30,23951,2769,0,0,0,0,0,1,2,4,98,3004
e5136e9306bf1b0e3d4be0cea384ee9a969a44fa,"Thematic analysis is a poorly demarcated, rarely acknowledged, yet widely used qualitative analytic method within psychology. In this paper, we argue that it offers an accessible and theoretically flexible approach to analysing qualitative data. We outline what thematic analysis is, locating it in relation to other qualitative analytic methods that search for themes or patterns, and in relation to different epistemological and ontological positions. We then provide clear guidelines to those wanting to start thematic analysis, or conduct it in a more deliberate and rigorous way, and consider potential pitfalls in conducting thematic analysis. Finally, we outline the disadvantages and advantages of thematic analysis. We conclude by advocating thematic analysis as a useful and flexible method for qualitative research in and beyond psychology.",2006,110,75770,5318,0,0,0,0,0,0,1,0,0,0
67556c4f0cfdd1f09fff373768b03638f949be0d,"Chapter 3 deals with probability distributions, discrete and continuous densities, distribution functions, bivariate distributions, means, variances, covariance, correlation, and some random process material. Chapter 4 is a detailed study of the concept of utility including the psychological aspects, risk, attributes, rules for utilities, multidimensional utility, and normal form of analysis. Chapter 5 treats games and optimization, linear optimization, and mixed strategies. Entropy is the topic of Chapter 6 with sections devoted to entropy, disorder, information, Shannon’s theorem, demon’s roulette, Maxwell– Boltzmann distribution, Schrodinger’s nutshell, maximum entropy probability distributions, blackbodies, and Bose–Einstein distribution. Chapter 7 is standard statistical fare including transformations of random variables, characteristic functions, generating functions, and the classic limit theorems such as the central limit theorem and the laws of large numbers. Chapter 8 is about exchangeability and inference with sections on Bayesian techniques and classical inference. Partial exchangeability is also treated. Chapter 9 considers such things as order statistics, extreme value, intensity, hazard functions, and Poisson processes. Chapter 10 covers basic elements of risk and reliability, while Chapter 11 is devoted to curve fitting, regression, and Monte Carlo simulation. There is an ample number of exercises at the ends of the chapters with answers or comments on many of them in an appendix in the back of the book. Other appendices are on the common discrete and continuous distributions and mathematical aspects of integration.",2007,0,18913,4802,0,0,0,0,0,0,0,1,7,888
ec3d71a2fdd01968a6dc638ee261715a0f118c1e,"Summary: It is expected that emerging digital gene expression (DGE) technologies will overtake microarray technologies in the near future for many functional genomics applications. One of the fundamental data analysis tasks, especially for gene expression studies, involves determining whether there is evidence that counts for a transcript or exon are significantly different across experimental conditions. edgeR is a Bioconductor software package for examining differential expression of replicated count data. An overdispersed Poisson model is used to account for both biological and technical variability. Empirical Bayes methods are used to moderate the degree of overdispersion across transcripts, improving the reliability of inference. The methodology can be used even with the most minimal levels of replication, provided at least one phenotype or experimental condition is replicated. The software may have other applications beyond sequencing data, such as proteome peptide count data. Availability: The package is freely available under the LGPL licence from the Bioconductor web site (http://bioconductor.org). Contact: mrobinson@wehi.edu.au",2009,10,21553,1162,0,0,0,0,0,0,1,1,7,64
9529c25408dc86194d417aed73d49ae0e418f1be,"32.03 MB Free download Econometric Analysis of Cross Section and Panel Data book PDF, FB2, EPUB and MOBI. Read online Econometric Analysis of Cross Section and Panel Data which classified as Other that has 776 pages that contain constructive material with lovely reading experience. Reading online Econometric Analysis of Cross Section and Panel Data book will be provide using wonderful book reader and it's might gives you some access to identifying the book content before you download the book.",2002,0,21019,2368,0,0,0,0,0,0,0,3,0,4
d17669e4f3f4dd3a180bde84dd54a508d0dc22f4,"A comprehensive, but simple-to-use software package for executing a range of standard numerical analysis and operations used in quantitative paleontology has been developed. The program, called PAST (PAleontological STatistics), runs on standard Windows computers and is available free of charge. PAST integrates spreadsheet-type data entry with univariate and multivariate statistics, curve fitting, timeseries analysis, data plotting, and simple phylogenetic analysis. Many of the functions are specific to paleontology and ecology, and these functions are not found in standard, more extensive, statistical packages. PAST also includes fourteen case studies (data files and exercises) illustrating use of the program for paleontological problems, making it a complete educational package for courses in quantitative methods.",2001,17,17969,3587,0,0,0,0,0,0,0,0,0,0
89fe2ca0bc4ea3f53f5745de6a88e094b8734a2b,1 Introduction: Models and Model Building Section I Understanding and Preparing for Multivariate Analysis 2 Cleaning and Transforming Data 3 Factor Analysis Section II Analysis Using Dependece Techniques 4 Simple and Multiple Regression Analysis 5 Canonical correlation 6 Conjoint analysis 7 Multiple Discriminant Analysis and Logistic Regression 8 ANOVA and MANOVA Section III Analysis using Interdependence Techniques 9 Group data and Cluster Analysis 10 MDS and Correspondence Analysis Structural Equation Modeling 11 SEM: An Introduction 12 Application of SEM,2010,0,6831,1353,53,154,275,450,587,635,645,725,827,809
0ad5733eafb41274895bf1dce6b92ae8f3d68c60,,2004,0,18831,2817,1,3,6,2,10,713,1440,1290,1233,1117
0d6cf3cd3794bc31a4e5a8ded4d4ba83bb20f9b0,"BOOK REVIEW: Constructing grounded theory. A practical guide through qualitative analysis Kathy Charmaz, 2006, 208 pp. London: Sage. ISBN 2005928035",2006,0,10716,2252,0,0,0,1,365,666,939,1134,1328,847
7bd23e6ec32cb1507a385c21a21150e9c332682f,"genalex is a user-friendly cross-platform package that runs within Microsoft Excel, enabling population genetic analyses of codominant, haploid and binary data. Allele frequency-based analyses include heterozygosity, F statistics, Nei's genetic distance, population assignment, probabilities of identity and pairwise relatedness. Distance-based calculations include amova, principal coordinates analysis (PCA), Mantel tests, multivariate and 2D spatial autocorrelation and twogener. More than 20 different graphs summarize data and aid exploration. Sequence and genotype data can be imported from automated sequencers, and exported to other software. Initially designed as tool for teaching, genalex 6 now offers features for researchers as well. Documentation and the program are available at http://www.anu.edu.au/BoZo/GenAlEx/",2006,12,14558,3330,0,0,0,0,0,0,3,972,1332,1368
895860c6083736508d2541900cdf0960eb11592f,"The design, implementation, and capabilities of an extensible visualization system, UCSF Chimera, are discussed. Chimera is segmented into a core that provides basic services and visualization, and extensions that provide most higher level functionality. This architecture ensures that the extension mechanism satisfies the demands of outside developers who wish to incorporate new features. Two unusual extensions are presented: Multiscale, which adds the ability to visualize large‐scale molecular assemblies such as viral coats, and Collaboratory, which allows researchers to share a Chimera session interactively despite being at separate locales. Other extensions include Multalign Viewer, for showing multiple sequence alignments and associated structures; ViewDock, for screening docked ligand orientations; Movie, for replaying molecular dynamics trajectories; and Volume Viewer, for display and analysis of volumetric data. A discussion of the usage of Chimera in real‐world situations is given, along with anticipated future directions. Chimera includes full user documentation, is free to academic and nonprofit users, and is available for Microsoft Windows, Linux, Apple Mac OS X, SGI IRIX, and HP Tru64 Unix from http://www.cgl.ucsf.edu/chimera/. © 2004 Wiley Periodicals, Inc. J Comput Chem 25: 1605–1612, 2004",2004,70,28328,1713,0,0,0,0,1,0,0,0,0,0
e7c8aa2cb2223f17615c1b1ae3b33095466e95cc,"The two most commonly used methods to analyze data from real-time, quantitative PCR experiments are absolute quantification and relative quantification. Absolute quantification determines the input copy number, usually by relating the PCR signal to a standard curve. Relative quantification relates the PCR signal of the target transcript in a treatment group to that of another sample such as an untreated control. The 2(-Delta Delta C(T)) method is a convenient way to analyze the relative changes in gene expression from real-time quantitative PCR experiments. The purpose of this report is to present the derivation, assumptions, and applications of the 2(-Delta Delta C(T)) method. In addition, we present the derivation and applications of two variations of the 2(-Delta Delta C(T)) method that may be useful in the analysis of real-time, quantitative PCR data.",2001,21,115916,1656,0,0,0,0,0,0,0,0,1,0
05abdc87bcaf2963fd511672e64ab39d02239aaf,,2007,30,24491,2512,0,1,0,0,1,0,5,6,535,2032
2d6f573c36c5e2153b65859fb080523fc4d842d0,"We announce the release of the fourth version of MEGA software, which expands on the existing facilities for editing DNA sequence data from autosequencers, mining Web-databases, performing automatic and manual sequence alignment, analyzing sequence alignments to estimate evolutionary distances, inferring phylogenetic trees, and testing evolutionary hypotheses. Version 4 includes a unique facility to generate captions, written in figure legend format, in order to provide natural language descriptions of the models and methods used in the analyses. This facility aims to promote a better understanding of the underlying assumptions used in analyses, and of the results generated. Another new feature is the Maximum Composite Likelihood (MCL) method for estimating evolutionary distances between all pairs of sequences simultaneously, with and without incorporating rate variation among sites and substitution pattern heterogeneities among lineages. This MCL method also can be used to estimate transition/transversion bias and nucleotide substitution pattern without knowledge of the phylogenetic tree. This new version is a native 32-bit Windows application with multi-threading and multi-user supports, and it is also available to run in a Linux desktop environment (via the Wine compatibility layer) and on Intel-based Macintosh computers under the Parallels program. The current version of MEGA is available free of charge at (http://www.megasoftware.net).",2007,10,28423,6043,0,0,0,0,1,18,2034,2152,1667,1255
4e2f43dab69d690dc86422949e410ebf37f522d4,"Bayesian methods have garnered huge interest in cognitive science as an approach to models of cognition and perception. On the other hand, Bayesian methods for data analysis have not yet made much headway in cognitive science against the institutionalized inertia of 20th century null hypothesis significance testing (NHST). Ironically, specific Bayesian models of cognition and perception may not long endure the ravages of empirical verification, but generic Bayesian methods for data analysis will eventually dominate. It is time that Bayesian data analysis became the norm for empirical methods in cognitive science. This article reviews a fatal flaw of NHST and introduces the reader to some benefits of Bayesian data analysis. The article presents illustrative examples of multiple comparisons in Bayesian analysis of variance and Bayesian approaches to statistical power. Copyright © 2010 John Wiley & Sons, Ltd. For further resources related to this article, please visit the WIREs website.",2010,87,5662,709,296,287,323,345,347,434,424,416,498,498
57e7a7323f58a35f5e2cc33bf17d4ac9cdcafdd4,"DAVID bioinformatics resources consists of an integrated biological knowledgebase and analytic tools aimed at systematically extracting biological meaning from large gene/protein lists. This protocol explains how to use DAVID, a high-throughput and integrated data-mining environment, to analyze gene lists derived from high-throughput genomic experiments. The procedure first requires uploading a gene list containing any number of common gene identifiers followed by analysis using one or more text and pathway-mining tools such as gene functional classification, functional annotation chart or clustering and functional annotation table. By following this protocol, investigators are able to gain an in-depth understanding of the biological themes in lists of genes that are enriched in genome-scale studies.",2008,16,27514,2132,0,0,0,0,0,0,0,0,7,39
e09bb0025f4939a4bd233a70937584b4d7bdd0a7,"BackgroundThe evolutionary analysis of molecular sequence variation is a statistical enterprise. This is reflected in the increased use of probabilistic models for phylogenetic inference, multiple sequence alignment, and molecular population genetics. Here we present BEAST: a fast, flexible software architecture for Bayesian analysis of molecular sequences related by an evolutionary tree. A large number of popular stochastic models of sequence evolution are provided and tree-based models suitable for both within- and between-species sequence data are implemented.ResultsBEAST version 1.4.6 consists of 81000 lines of Java source code, 779 classes and 81 packages. It provides models for DNA and protein sequence evolution, highly parametric coalescent analysis, relaxed clock phylogenetics, non-contemporaneous sequence data, statistical alignment and a wide range of options for prior distributions. BEAST source code is object-oriented, modular in design and freely available at http://beast-mcmc.googlecode.com/ under the GNU LGPL license.ConclusionBEAST is a powerful and flexible evolutionary analysis package for molecular sequence variation. It also provides a resource for the further development of new models and statistical methods of evolutionary analysis.",2007,45,11140,3504,0,0,1,247,973,1270,1219,1114,1018,941
cad327e1e3a0799202cb40da5da51d7b0616b64e,"Arlequin ver 3.0 is a software package integrating several basic and advanced methods for population genetics data analysis, like the computation of standard genetic diversity indices, the estimation of allele and haplotype frequencies, tests of departure from linkage equilibrium, departure from selective neutrality and demographic equilibrium, estimation or parameters from past population expansions, and thorough analyses of population subdivision under the AMOVA framework. Arlequin 3 introduces a completely new graphical interface written in C++, a more robust semantic analysis of input files, and two new methods: a Bayesian estimation of gametic phase from multi-locus genotypes, and an estimation of the parameters of an instantaneous spatial expansion from DNA sequence polymorphism. Arlequin can handle several data types like DNA sequences, microsatellite data, or standard multi-locus genotypes. A Windows version of the software is freely available on http://cmpg.unibe.ch/software/arlequin3.",2007,148,12556,4438,1,1,21,1207,1437,1392,1211,1052,891,751
80935b370bac09ce615a002caabc30fbb26f029b,"With its theoretical basis firmly established in molecular evolutionary and population genetics, the comparative DNA and protein sequence analysis plays a central role in reconstructing the evolutionary histories of species and multigene families, estimating rates of molecular evolution, and inferring the nature and extent of selective forces shaping the evolution of genes and genomes. The scope of these investigations has now expanded greatly owing to the development of high-throughput sequencing techniques and novel statistical and computational methods. These methods require easy-to-use computer programs. One such effort has been to produce Molecular Evolutionary Genetics Analysis (MEGA) software, with its focus on facilitating the exploration and analysis of the DNA and protein sequence variation from an evolutionary perspective. Currently in its third major release, MEGA3 contains facilities for automatic and manual sequence alignment, web-based mining of databases, inference of the phylogenetic trees, estimation of evolutionary distances and testing evolutionary hypotheses. This paper provides an overview of the statistical methods, computational tools, and visual exploration modules for data input and the results obtainable in MEGA.",2004,73,12037,3302,1,0,26,1588,2150,1625,1243,879,678,475
4c97d9b9eb7c158e682844b394b42924af3c5b3f,"Interpretative phenomenological analysis (IPA) is an increasingly popular approach to qualitative inquiry. This handy text covers its theoretical foundations and provides a detailed guide to conducting IPA research. 
 
Extended worked examples from the authors' own studies in health, sexuality, psychological distress and identity illustrate the breadth and depth of IPA research. 
 
Each of the chapters also offers a guide to other good exemplars of IPA research in the designated area. The final section of the book considers how IPA connects with other contemporary qualitative approaches like discourse and narrative analysis and how it addresses issues to do with validity. The book is written in an accessible style and will be extremely useful to students and researchers in psychology and related disciplines in the health and social sciences.",2009,7,6197,1589,6,76,172,280,438,624,709,699,792,811
001c07aefcc186013184009e0c83847f28867e08,"ggplot2: Elegant Graphics for Data Analysis is a new addition to the UseR! series by Springer, probably the fastest expanding source of resources for computational statistics at the current moment. The books in this series are all linked with R, either presenting a new package developed by the own authors of the book or describing how to applying statistical techniques with the different packages available in R. ggplot2 is an implementation in R of The Grammar of Graphics (Wilkinson 2005) a systematic approach to the specification of statistical graphics that was introduced in a book previously reviewed in the Journal of Statistical Software by Cox (2007). This implementation has been developed by Hadley Wickham, who is also the author of the book reviewed here.",2010,1,4911,435,9,20,22,56,87,94,178,255,446,795
7ea9b1915072f2adff3762b59b7c7d79805fee8e,"If radiocarbon measurements are to be used at all for chronological purposes, we have to use statistical methods for calibration. The most widely used method of calibration can be seen as a simple application of Bayesian statistics, which uses both the information from the new measurement and information from the 14C calibration curve. In most dating applications, however, we have larger numbers of 14C measurements and we wish to relate those to events in the past. Bayesian statistics provides a coherent framework in which such analysis can be performed and is becoming a core element in many 14C dating projects. This article gives an overview of the main model components used in chronological analysis, their mathematical formulation, and examples of how such analyses can be performed using the latest version of the OxCal software (v4). Many such models can be put together, in a modular fashion, from simple elements, with defined constraints and groupings. In other cases, the commonly used ""uniform phase"" models might not be appropriate, and ramped, exponential, or normal distributions of events might be more useful. When considering analyses of these kinds, it is useful to be able run simulations on synthetic data. Methods for performing such tests are discussed here along with other methods of diagnosing possible problems with statistical models of this kind.",2009,69,4539,1446,11,103,201,275,402,450,446,453,577,449
87ccc438b0c73fcfdea48485fcdb091a8ecaa89c,"High-throughput sequencing assays such as RNA-Seq, ChIP-Seq or barcode counting provide quantitative readouts in the form of count data. To infer differential signal in such data correctly and with good statistical power, estimation of data variability throughout the dynamic range and a suitable error model are required. We propose a method based on the negative binomial distribution, with variance and mean linked by local regression and present an implementation, DESeq, as an R/Bioconductor package.",2010,80,9807,1096,9,65,225,483,806,957,981,1071,1172,1372
b9544a1bf4b02c6648dbd12702bc10c00e20e197,"Content analysis is a widely used qualitative research technique. Rather than being a single method, current applications of content analysis show three distinct approaches: conventional, directed, or summative. All three approaches are used to interpret meaning from the content of text data and, hence, adhere to the naturalistic paradigm. The major differences among the approaches are coding schemes, origins of codes, and threats to trustworthiness. In conventional content analysis, coding categories are derived directly from the text data. With a directed approach, analysis starts with a theory or relevant research findings as guidance for initial codes. A summative content analysis involves counting and comparisons, usually of keywords or content, followed by the interpretation of the underlying context. The authors delineate analytic procedures specific to each approach and techniques addressing trustworthiness with hypothetical examples drawn from the area of end-of-life care.",2005,57,24913,943,0,0,0,0,0,0,0,0,0,0
2fcf90089d9f95025e8953812a43f0db2de3af7c,,2009,0,10344,2663,0,0,262,430,655,922,1128,1232,1332,1349
d76bde423b71f1cb900b988311bd2d71b700d506,"The extent of heterogeneity in a meta-analysis partly determines the difficulty in drawing overall conclusions. This extent may be measured by estimating a between-study variance, but interpretation is then specific to a particular treatment effect metric. A test for the existence of heterogeneity exists, but depends on the number of studies in the meta-analysis. We develop measures of the impact of heterogeneity on a meta-analysis, from mathematical criteria, that are independent of the number of studies and the treatment effect metric. We derive and propose three suitable statistics: H is the square root of the chi2 heterogeneity statistic divided by its degrees of freedom; R is the ratio of the standard error of the underlying mean from a random effects meta-analysis to the standard error of a fixed effect meta-analytic estimate, and I2 is a transformation of (H) that describes the proportion of total variation in study estimates that is due to heterogeneity. We discuss interpretation, interval estimates and other properties of these measures and examine them in five example data sets showing different amounts of heterogeneity. We conclude that H and I2, which can usually be calculated for published meta-analyses, are particularly useful summaries of the impact of heterogeneity. One or both should be presented in published meta-analyses in preference to the test for heterogeneity.",2002,35,21386,493,0,0,0,0,1,0,1,0,1,1
fc448a7db5a2fac242705bd8e37ae1fc4a858643,"The human genome holds an extraordinary trove of information about human development, physiology, medicine and evolution. Here we report the results of an international collaboration to produce and make freely available a draft sequence of the human genome. We also present an initial analysis of the data, describing some of the insights that can be gleaned from the sequence.",2001,431,17459,430,5,1,4,2,1,2,8,504,764,774
76ad159a2887b008e5a7335d124c148c13e65465,"We have developed a toolbox and graphic user interface, EEGLAB, running under the crossplatform MATLAB environment (The Mathworks, Inc.) for processing collections of single-trial and/or averaged EEG data of any number of channels. Available functions include EEG data, channel and event information importing, data visualization (scrolling, scalp map and dipole model plotting, plus multi-trial ERP-image plots), preprocessing (including artifact rejection, filtering, epoch selection, and averaging), independent component analysis (ICA) and time/frequency decompositions including channel and component cross-coherence supported by bootstrap statistical methods based on data resampling. EEGLAB functions are organized into three layers. Top-layer functions allow users to interact with the data through the graphic interface without needing to use MATLAB syntax. Menu options allow users to tune the behavior of EEGLAB to available memory. Middle-layer functions allow users to customize data processing using command history and interactive 'pop' functions. Experienced MATLAB users can use EEGLAB data structures and stand-alone signal processing functions to write custom and/or batch analysis scripts. Extensive function help and tutorial information are included. A 'plug-in' facility allows easy incorporation of new EEG modules into the main menu. EEGLAB is freely available (http://www.sccn.ucsd.edu/eeglab/) under the GNU public license for noncommercial use and open source development, together with sample data, user tutorial and extensive documentation.",2004,85,14460,1914,0,0,0,0,0,0,0,0,0,0
1a77e19441f3a0e030998fb2d11d9dd774582403,"The techniques available for the interrogation and analysis of neuroimaging data have a large influence in determining the flexibility, sensitivity, and scope of neuroimaging experiments. The development of such methodologies has allowed investigators to address scientific questions that could not previously be answered and, as such, has become an important research area in its own right. In this paper, we present a review of the research carried out by the Analysis Group at the Oxford Centre for Functional MRI of the Brain (FMRIB). This research has focussed on the development of new methodologies for the analysis of both structural and functional magnetic resonance imaging data. The majority of the research laid out in this paper has been implemented as freely available software tools within FMRIB's Software Library (FSL).",2004,52,10646,1541,0,0,0,0,0,77,419,577,673,764
e250c4b0cc0180af9f47b97f3b9ff1727a2767aa,"New software, OLEX2, has been developed for the determination, visualization and analysis of molecular crystal structures. The software has a portable mouse-driven workflow-oriented and fully comprehensive graphical user interface for structure solution, refinement and report generation, as well as novel tools for structure analysis. OLEX2 seamlessly links all aspects of the structure solution, refinement and publication process and presents them in a single workflow-driven package, with the ultimate goal of producing an application which will be useful to both chemists and crystallographers.",2009,10,13162,496,0,0,0,0,0,0,3,653,1471,1660
42abddd227d653a0375d7d037ddb885f6c07f66f,"We present Model-based Analysis of ChIP-Seq data, MACS, which analyzes data generated by short read sequencers such as Solexa's Genome Analyzer. MACS empirically models the shift size of ChIP-Seq tags, and uses it to improve the spatial resolution of predicted binding sites. MACS also uses a dynamic Poisson distribution to effectively capture local biases in the genome, allowing for more robust predictions. MACS compares favorably to existing ChIP-Seq peak-finding algorithms, and is freely available.",2008,17,9866,1179,6,43,122,233,339,455,628,662,729,980
7a6142cfa79cc01ceced5e144bd0e01a0f241a74,,2009,43,7893,2014,377,456,500,626,706,655,723,661,657,644
94559c249d204110296c39ed4af2042cc4468e68,"The Karhunen-Lo eve basis functions, more frequently referred to as principal components or empirical orthogonal functions (EOFs), of the noise response of the climate system are an important tool for geophysical studies. Many researchers have used this tool to examine the geophysical and climatological phenomena. Perhaps more frequent use of EOFs in recent studies is in conjunction with the development of the signal detection and estimation methods of the background uctuations of a detection variable serve as an orthogonal basis set and are used to design optimal techniques for detecting and estimating signals. A detection and prediction approach is to design a lter or optimal weights for the signal to be detected. It has been reported that weighted averaging of data over the surface of the Earth improved the detectability of climatic changes (Hasselmann 1979; Stefanick 1981; Bell 1982). Since the signal-to-noise ratio (SNR) varies geographically, there exists an optimal geographical weighting of the signal which maximizes the SNR. The design of an optimal weighting function may require detailed knowledge on the natural uctuation of the climate system. A conceptually similar approach is to employ a particular pattern (or patterns) of climatic change for detection and prediction (e.g., Barnett and Hasselmann 1979; Hasselmann 1979). The patterns of interest (also called the predictors) may include the principal components (empirical orthogonal functions) (e. von Storch 1990) among others. This approach also requires complete knowledge of the natural variability of the climate system. To test and improve the detection and prediction techniques addressed above, a complete cross-spectral covariance matrix, or similarly, a complete set of the principal components of natural uctuations of the climate system for each frequency band of the spectrum is necessary. In reality, a reliable spectrum of observational covariance matrix is not available because observations are not suuciently long and sampling errors contaminate the observational records (Preisendorfer and Barnett 1977; North et al. 1982). Further, inadequate spatial coverage of observations may introduce bias. Therefore, the covariance matrix of the noise response is often estimated from a simple stochastic model. Kim and North (1991, 1992) examined the covariance matrix in terms of various second-moment statistics earlier. Examined here are the principal components of the covariance matrix of the surface temperature uctuations in a simple coupled climate model in comparison with observations. The principal components not only are an",2009,52,14117,1668,1,0,3,13,175,903,1082,1144,1134,1081
20aeb2357e9e215787c7e0d0acfe7a6b598c9103,"This book describes ggplot2, a new data visualization package for R that uses the insights from Leland Wilkisons Grammar of Graphics to create a powerful and flexible system for creating data graphics. With ggplot2, its easy to: produce handsome, publication-quality plots, with automatic legends created from the plot specification superpose multiple layers (points, lines, maps, tiles, box plots to name a few) from different data sources, with automatically adjusted common scales add customisable smoothers that use the powerful modelling capabilities of R, such as loess, linear models, generalised additive models and robust regression save any ggplot2 plot (or part thereof) for later modification or reuse create custom themes that capture in-house or journal style requirements, and that can easily be applied to multiple plots approach your graph from a visual perspective, thinking about how each component of the data is represented on the final plot. This book will be useful to everyone who has struggled with displaying their data in an informative and attractive way. You will need some basic knowledge of R (i.e. you should be able to get your data into R), but ggplot2 is a mini-language specifically tailored for producing graphics, and youll learn everything you need in the book. After reading this book youll be able to produce graphics customized precisely for your problems,and youll find it easy to get graphics out of your head and on to the screen or page.",2009,0,20904,1807,0,0,0,0,0,1,2,0,3,9
da7ab2f1b6278472f3671a7430c9a72bad07781f,"PAML, currently in version 4, is a package of programs for phylogenetic analyses of DNA and protein sequences using maximum likelihood (ML). The programs may be used to compare and test phylogenetic trees, but their main strengths lie in the rich repertoire of evolutionary models implemented, which can be used to estimate parameters in models of sequence evolution and to test interesting biological hypotheses. Uses of the programs include estimation of synonymous and nonsynonymous rates (d(N) and d(S)) between two protein-coding DNA sequences, inference of positive Darwinian selection through phylogenetic comparison of protein-coding genes, reconstruction of ancestral genes and proteins for molecular restoration studies of extinct life forms, combined analysis of heterogeneous data sets from multiple gene loci, and estimation of species divergence times incorporating uncertainties in fossil calibrations. This note discusses some of the major applications of the package, which includes example data sets to demonstrate their use. The package is written in ANSI C, and runs under Windows, Mac OSX, and UNIX systems. It is available at -- (http://abacus.gene.ucl.ac.uk/software/paml.html).",2007,203,9021,1777,10,131,298,412,471,583,614,666,638,749
d40ee5dd758c525dfb9932d726bb4e844b7b8478,"Receiver operating characteristics (ROC) graphs are useful for organizing classifiers and visualizing their performance. ROC graphs are commonly used in medical decision making, and in recent years have been used increasingly in machine learning and data mining research. Although ROC graphs are apparently simple, there are some common misconceptions and pitfalls when using them in practice. The purpose of this article is to serve as an introduction to ROC graphs and as a guide for using them in research.",2006,45,14314,1234,0,0,0,0,0,0,1,4,75,1122
c98386ddf2fe4973da42187a9e3c9167095acf4e,"During the past 30 years, meta-analysis has been an indispensable tool for revealing the hidden meaning of our research literatures. The four articles in this special section on meta-analysis illustrate some of the complexities entailed in meta-analysis methods. Although meta-analysis is a powerful tool for advancing cumulative knowledge, researchers can be confused by the complicated issues involved in the methodology. Each of these four articles contributes both to advancing this methodology and to the increasing complexities that can befuddle researchers. In these comments, the author attempts to clarify both of these aspects and provide a perspective on the methodological issues examined in these articles.",2008,114,15161,703,0,0,0,0,0,0,0,0,0,4
b6fbb3a44a8e946b4a231118a737a396517c83de,"AIM
This paper is a description of inductive and deductive content analysis.


BACKGROUND
Content analysis is a method that may be used with either qualitative or quantitative data and in an inductive or deductive way. Qualitative content analysis is commonly used in nursing studies but little has been published on the analysis process and many research books generally only provide a short description of this method.


DISCUSSION
When using content analysis, the aim was to build a model to describe the phenomenon in a conceptual form. Both inductive and deductive analysis processes are represented as three main phases: preparation, organizing and reporting. The preparation phase is similar in both approaches. The concepts are derived from the data in inductive content analysis. Deductive content analysis is used when the structure of analysis is operationalized on the basis of previous knowledge.


CONCLUSION
Inductive content analysis is used in cases where there are no previous studies dealing with the phenomenon or when it is fragmented. A deductive approach is useful if the general aim was to test a previous theory in a different situation or to compare categories at different time periods.",2008,65,11840,609,0,0,0,0,0,1,379,1016,1090,1290
39dae53515afb42664369c291ec6d1ce34d778bd,"BackgroundCorrelation networks are increasingly being used in bioinformatics applications. For example, weighted gene co-expression network analysis is a systems biology method for describing the correlation patterns among genes across microarray samples. Weighted correlation network analysis (WGCNA) can be used for finding clusters (modules) of highly correlated genes, for summarizing such clusters using the module eigengene or an intramodular hub gene, for relating modules to one another and to external sample traits (using eigengene network methodology), and for calculating module membership measures. Correlation networks facilitate network based gene screening methods that can be used to identify candidate biomarkers or therapeutic targets. These methods have been successfully applied in various biological contexts, e.g. cancer, mouse genetics, yeast genetics, and analysis of brain imaging data. While parts of the correlation network methodology have been described in separate publications, there is a need to provide a user-friendly, comprehensive, and consistent software implementation and an accompanying tutorial.ResultsThe WGCNA R software package is a comprehensive collection of R functions for performing various aspects of weighted correlation network analysis. The package includes functions for network construction, module detection, gene selection, calculations of topological properties, data simulation, visualization, and interfacing with external software. Along with the R package we also present R software tutorials. While the methods development was motivated by gene expression data, the underlying data mining approach can be applied to a variety of different settings.ConclusionThe WGCNA package provides R functions for weighted correlation network analysis, e.g. co-expression network analysis of gene expression data. The R package along with its source code and additional material are freely available at http://www.genetics.ucla.edu/labs/horvath/CoexpressionNetwork/Rpackages/WGCNA.",2008,51,9025,1051,2,9,29,60,112,163,263,361,592,783
0e2532c31c992ac0930998561932f198b467572d,"This article examines the function of documents as a data source in qualitative research and discusses document analysis procedure in the context of actual research experiences. Targeted to research novices, the article takes a nuts‐and‐bolts approach to document analysis. It describes the nature and forms of documents, outlines the advantages and limitations of document analysis, and offers specific examples of the use of documents in the research process. The application of document analysis to a grounded theory study is illustrated.",2009,34,4574,534,0,12,16,59,127,198,275,417,534,725
dd1b3a3793619cec8994cc7cca10e6dee656fb7b,"UNLABELLED
Research over the last few years has revealed significant haplotype structure in the human genome. The characterization of these patterns, particularly in the context of medical genetic association studies, is becoming a routine research activity. Haploview is a software package that provides computation of linkage disequilibrium statistics and population haplotype patterns from primary genotype data in a visually appealing and interactive interface.


AVAILABILITY
http://www.broad.mit.edu/mpg/haploview/


CONTACT
jcbarret@broad.mit.edu",2005,12,13390,1399,0,0,0,1,74,1111,1159,1137,1018,973
6fb968167f3c9c76d00d085a57b265cb912ad012,"Data Mining Methods and Models is the second volume of a three-book series on data mining authored by Larose. The following review was performed independently of LaRose’s other two books. Paraphrasing from the Preface, the goal of this book is to “explore the process of data mining from the point of view of model building.” Nevertheless, the reader will soon be aware that this book is not intended to provide a systematic or comprehensive coverage of various data mining algorithms. Instead, it considers supervised learning or predictive modeling only, and it walks the reader through the data mining process merely with a few selected modeling methods such as (generalized) linear modeling and the Bayesian approach. The book has seven chapters. Chapter 1 introduces dimension reduction, with a focus on principal components analysis (PCA) types of techniques. Chapters 2, 3, and 4 provide a detailed coverage of simple linear regression, multiple linear regression, and logistic regression, respectively. Chapter 5 introduces naive Bayes estimation and Bayesian networks. In Chapter 6, the basic idea of genetic algorithms is discussed. Finally, Chapter 7 presents a case study example of modeling response to direct mail marketing within the CRISP (crossindustry standard process) framework. This book is very easy to read, and this is absolutely the strength which many readers, especially those nonstatistically oriented ones, will greatly appreciate. Predictive modeling is perhaps the most technical part in a data mining process. The author has done an excellent job in making this difficult topic accessible to a broad audience. For example, I like the way in which Bayesian networks are introduced in Chapter 5. After the reader goes through a churn example on naive Bayes estimation in a step-by-step manner, Bayesian belief networks become easily understood as natural extensions. The overall style of the book is clear and patient. The main limitation of the book is its limited coverage. An inspired reader would expect to see a much more extended list of topics. Hastie, Tibishirani, and Friedman (2001) gave a full and more technical account of various data mining algorithms. The inclusion of genetic algorithms in Chapter 6 seems novel when compared to Hastie, Tibishirani, and Friedman (2001), but at the same time, a little unexpected as a separate chapter, since a genetic algorithm involves a stochastics search scheme, which is somewhat involved given the elementary nature of this text. Another noteworthy issue is that the author does not make an attempt to distinguish between conventional statistical analysis and data mining. I found a few errors. On Page 25, for example, it should be ai = 1, instead of ai = 1/4. Also, in the frame on the top of Page 211, it might have been “Posterior Odds,” instead of “Posterior Odds Ratio.” The book uses three different software packages to implement the ideas including SPSS with Clementine, Minitab, and WEKA, which might not be appealing. On the other hand, it is justifiable as it allows one to perform data mining with affordable costs. In summary, I recommend this fairly readable book for adoption in a graduate-level introductory course on data mining, especially when the students come from varied backgrounds.",2008,5,6081,1832,57,100,190,265,350,401,473,572,669,712
85dfac3a261fbdea3b4e1a6f3264c6384bbc4485,"Qualitative content analysis as described in published literature shows conflicting opinions and unsolved issues regarding meaning and use of concepts, procedures and interpretation. This paper provides an overview of important concepts (manifest and latent content, unit of analysis, meaning unit, condensation, abstraction, content area, code, category and theme) related to qualitative content analysis; illustrates the use of concepts related to the research procedure; and proposes measures to achieve trustworthiness (credibility, dependability and transferability) throughout the steps of the research procedure. Interpretation in qualitative content analysis is discussed in light of Watzlawick et al.'s [Pragmatics of Human Communication. A Study of Interactional Patterns, Pathologies and Paradoxes. W.W. Norton & Company, New York, London] theory of communication.",2004,58,14412,1104,0,0,0,0,0,0,0,0,0,4
d96faee1898de7a052115ecfe533a5b2fd1151c0,"This paper develops a new approach to the problem of testing the existence of a level relationship between a dependent variable and a set of regressors, when it is not known with certainty whether the underlying regressors are trend- or first-difference stationary. The proposed tests are based on standard F- and t-statistics used to test the significance of the lagged levels of the variables in a univariate equilibrium correction mechanism. The asymptotic distributions of these statistics are non-standard under the null hypothesis that there exists no level relationship, irrespective of whether the regressors are I(0) or I(1). Two sets of asymptotic critical values are provided: one when all regressors are purely I(1) and the other if they are all purely I(0). These two sets of critical values provide a band covering all possible classifications of the regressors into purely I(0), purely I(1) or mutually cointegrated. Accordingly, various bounds testing procedures are proposed. It is shown that the proposed tests are consistent, and their asymptotic distribution under the null and suitably defined local alternatives are derived. The empirical relevance of the bounds procedures is demonstrated by a re-examination of the earnings equation included in the UK Treasury macroeconometric model. Copyright © 2001 John Wiley & Sons, Ltd.",2001,46,11403,2343,0,0,0,0,0,0,0,0,0,2
21c41fcec6ac8a7f55c539ac199247f200633753,"Microarrays can measure the expression of thousands of genes to identify changes in expression between different biological states. Methods are needed to determine the significance of these changes while accounting for the enormous number of genes. We describe a method, Significance Analysis of Microarrays (SAM), that assigns a score to each gene on the basis of change in gene expression relative to the standard deviation of repeated measurements. For genes with scores greater than an adjustable threshold, SAM uses permutations of the repeated measurements to estimate the percentage of genes identified by chance, the false discovery rate (FDR). When the transcriptional response of human cells to ionizing radiation was measured by microarrays, SAM identified 34 genes that changed at least 1.5-fold with an estimated FDR of 12%, compared with FDRs of 60 and 84% by using conventional methods of analysis. Of the 34 genes, 19 were involved in cell cycle regulation and 3 in apoptosis. Surprisingly, four nucleotide excision repair genes were induced, suggesting that this repair pathway for UV-damaged DNA might play a previously unrecognized role in repairing DNA damaged by ionizing radiation.",2001,54,11566,1626,0,0,1,3,249,864,864,894,921,881
a82d7e0dc7b2d3a1b159e0902bb9f3017788a786,"A comprehensive, but simple-to-use software package for executing a range of standard numerical analysis and operations used in quantitative paleontology has been developed. The program, called PAST (PAleontological STatistics), runs on standard Windows computers and is available free of charge. PAST integrates spreadsheet-type data entry with univariate and multivariate statistics, curve fitting, timeseries analysis, data plotting, and simple phylogenetic analysis. Many of the functions are specific to paleontology and ecology, and these functions are not found in standard, more extensive, statistical packages. PAST also includes fourteen case studies (data files and exercises) illustrating use of the program for paleontological problems, making it a complete educational package for courses in quantitative methods.",2001,31,10400,1798,0,0,0,0,0,0,0,0,0,3
39dfeda235027e1bed00ab33bcb2ad16831677f8,"Hypothesis-testing methods for multivariate data are needed to make rigorous probability statements about the effects of factors and their interactions in experiments. Analysis of variance is particularly powerful for the analysis of univariate data. The traditional multivariate analogues, however, are too stringent in their assumptions for most ecological multivariate data sets. Non-parametric methods, based on permutation tests, are preferable. This paper describes a new non-parametric method for multivariate analysis of variance, after McArdle and Anderson (in press). It is given here, with several applications in ecology, to provide an alternative and perhaps more intuitive formulation for ANOVA (based on sums of squared distances) to complement the description pro- vided by McArdle and Anderson (in press) for the analysis of any linear model. It is an improvement on previous non-parametric methods because it allows a direct additive partitioning of variation for complex models. It does this while maintaining the flexibility and lack of formal assumptions of other non-parametric methods. The test- statistic is a multivariate analogue to Fisher's F-ratio and is calculated directly from any symmetric distance or dissimilarity matrix. P-values are then obtained using permutations. Some examples of the method are given for tests involving several factors, including factorial and hierarchical (nested) designs and tests of interactions.",2001,127,10965,1444,0,0,0,0,0,0,0,0,0,158
c8831d7d318b8d59f9b958d250a58f253f08bd8a,"This article is about a curious phenomenon. Suppose we have a data matrix, which is the superposition of a low-rank component and a sparse component. Can we recover each component individually? We prove that under some suitable assumptions, it is possible to recover both the low-rank and the sparse components exactly by solving a very convenient convex program called Principal Component Pursuit; among all feasible decompositions, simply minimize a weighted combination of the nuclear norm and of the ℓ1 norm. This suggests the possibility of a principled approach to robust principal component analysis since our methodology and results assert that one can recover the principal components of a data matrix even though a positive fraction of its entries are arbitrarily corrupted. This extends to the situation where a fraction of the entries are missing as well. We discuss an algorithm for solving this optimization problem, and present applications in the area of video surveillance, where our methodology allows for the detection of objects in a cluttered background, and in the area of face recognition, where it offers a principled way of removing shadows and specularities in images of faces.",2009,90,5547,1043,9,66,155,236,340,507,532,647,665,703
70b48fd1a0c3d9fef98600578308e1e033c0c67a,Supplementary Figure 1 Overview of the analysis pipeline. Supplementary Table 1 Details of conventionally raised and conventionalized mouse samples. Supplementary Discussion Expanded discussion of QIIME analyses presented in the main text; Sequencing of 16S rRNA gene amplicons; QIIME analysis notes; Expanded Figure 1 legend; Links to raw data and processed output from the runs with and without denoising.,2010,30,23951,2769,0,0,0,0,0,1,2,4,98,3004
e5136e9306bf1b0e3d4be0cea384ee9a969a44fa,"Thematic analysis is a poorly demarcated, rarely acknowledged, yet widely used qualitative analytic method within psychology. In this paper, we argue that it offers an accessible and theoretically flexible approach to analysing qualitative data. We outline what thematic analysis is, locating it in relation to other qualitative analytic methods that search for themes or patterns, and in relation to different epistemological and ontological positions. We then provide clear guidelines to those wanting to start thematic analysis, or conduct it in a more deliberate and rigorous way, and consider potential pitfalls in conducting thematic analysis. Finally, we outline the disadvantages and advantages of thematic analysis. We conclude by advocating thematic analysis as a useful and flexible method for qualitative research in and beyond psychology.",2006,110,75770,5318,0,0,0,0,0,0,1,0,0,0
67556c4f0cfdd1f09fff373768b03638f949be0d,"Chapter 3 deals with probability distributions, discrete and continuous densities, distribution functions, bivariate distributions, means, variances, covariance, correlation, and some random process material. Chapter 4 is a detailed study of the concept of utility including the psychological aspects, risk, attributes, rules for utilities, multidimensional utility, and normal form of analysis. Chapter 5 treats games and optimization, linear optimization, and mixed strategies. Entropy is the topic of Chapter 6 with sections devoted to entropy, disorder, information, Shannon’s theorem, demon’s roulette, Maxwell– Boltzmann distribution, Schrodinger’s nutshell, maximum entropy probability distributions, blackbodies, and Bose–Einstein distribution. Chapter 7 is standard statistical fare including transformations of random variables, characteristic functions, generating functions, and the classic limit theorems such as the central limit theorem and the laws of large numbers. Chapter 8 is about exchangeability and inference with sections on Bayesian techniques and classical inference. Partial exchangeability is also treated. Chapter 9 considers such things as order statistics, extreme value, intensity, hazard functions, and Poisson processes. Chapter 10 covers basic elements of risk and reliability, while Chapter 11 is devoted to curve fitting, regression, and Monte Carlo simulation. There is an ample number of exercises at the ends of the chapters with answers or comments on many of them in an appendix in the back of the book. Other appendices are on the common discrete and continuous distributions and mathematical aspects of integration.",2007,0,18914,4802,0,0,0,0,0,0,0,1,7,889
ec3d71a2fdd01968a6dc638ee261715a0f118c1e,"Summary: It is expected that emerging digital gene expression (DGE) technologies will overtake microarray technologies in the near future for many functional genomics applications. One of the fundamental data analysis tasks, especially for gene expression studies, involves determining whether there is evidence that counts for a transcript or exon are significantly different across experimental conditions. edgeR is a Bioconductor software package for examining differential expression of replicated count data. An overdispersed Poisson model is used to account for both biological and technical variability. Empirical Bayes methods are used to moderate the degree of overdispersion across transcripts, improving the reliability of inference. The methodology can be used even with the most minimal levels of replication, provided at least one phenotype or experimental condition is replicated. The software may have other applications beyond sequencing data, such as proteome peptide count data. Availability: The package is freely available under the LGPL licence from the Bioconductor web site (http://bioconductor.org). Contact: mrobinson@wehi.edu.au",2009,10,21553,1162,0,0,0,0,0,0,1,1,7,64
a2893118e14c29a23472b02249b4641b9971786b,"Although genomewide RNA expression analysis has become a routine tool in biomedical research, extracting biological insight from such information remains a major challenge. Here, we describe a powerful analytical method called Gene Set Enrichment Analysis (GSEA) for interpreting gene expression data. The method derives its power by focusing on gene sets, that is, groups of genes that share common biological function, chromosomal location, or regulation. We demonstrate how GSEA yields insights into several cancer-related data sets, including leukemia and lung cancer. Notably, where single-gene analysis finds little similarity between two independent studies of patient survival in lung cancer, GSEA reveals many biological pathways in common. The GSEA method is embodied in a freely available software package, together with an initial database of 1,325 biologically defined gene sets.",2005,85,26903,2908,0,0,0,0,0,0,0,0,0,0
d17669e4f3f4dd3a180bde84dd54a508d0dc22f4,"A comprehensive, but simple-to-use software package for executing a range of standard numerical analysis and operations used in quantitative paleontology has been developed. The program, called PAST (PAleontological STatistics), runs on standard Windows computers and is available free of charge. PAST integrates spreadsheet-type data entry with univariate and multivariate statistics, curve fitting, timeseries analysis, data plotting, and simple phylogenetic analysis. Many of the functions are specific to paleontology and ecology, and these functions are not found in standard, more extensive, statistical packages. PAST also includes fourteen case studies (data files and exercises) illustrating use of the program for paleontological problems, making it a complete educational package for courses in quantitative methods.",2001,17,17969,3587,0,0,0,0,0,0,0,0,0,0
9529c25408dc86194d417aed73d49ae0e418f1be,"32.03 MB Free download Econometric Analysis of Cross Section and Panel Data book PDF, FB2, EPUB and MOBI. Read online Econometric Analysis of Cross Section and Panel Data which classified as Other that has 776 pages that contain constructive material with lovely reading experience. Reading online Econometric Analysis of Cross Section and Panel Data book will be provide using wonderful book reader and it's might gives you some access to identifying the book content before you download the book.",2002,0,21019,2368,0,0,0,0,0,0,0,3,0,4
89fe2ca0bc4ea3f53f5745de6a88e094b8734a2b,1 Introduction: Models and Model Building Section I Understanding and Preparing for Multivariate Analysis 2 Cleaning and Transforming Data 3 Factor Analysis Section II Analysis Using Dependece Techniques 4 Simple and Multiple Regression Analysis 5 Canonical correlation 6 Conjoint analysis 7 Multiple Discriminant Analysis and Logistic Regression 8 ANOVA and MANOVA Section III Analysis using Interdependence Techniques 9 Group data and Cluster Analysis 10 MDS and Correspondence Analysis Structural Equation Modeling 11 SEM: An Introduction 12 Application of SEM,2010,0,6831,1353,53,154,275,450,587,635,645,725,827,809
0ad5733eafb41274895bf1dce6b92ae8f3d68c60,,2004,0,18831,2817,1,3,6,2,10,713,1440,1290,1233,1117
0d6cf3cd3794bc31a4e5a8ded4d4ba83bb20f9b0,"BOOK REVIEW: Constructing grounded theory. A practical guide through qualitative analysis Kathy Charmaz, 2006, 208 pp. London: Sage. ISBN 2005928035",2006,0,10716,2252,0,0,0,1,365,666,939,1134,1328,847
7bd23e6ec32cb1507a385c21a21150e9c332682f,"genalex is a user-friendly cross-platform package that runs within Microsoft Excel, enabling population genetic analyses of codominant, haploid and binary data. Allele frequency-based analyses include heterozygosity, F statistics, Nei's genetic distance, population assignment, probabilities of identity and pairwise relatedness. Distance-based calculations include amova, principal coordinates analysis (PCA), Mantel tests, multivariate and 2D spatial autocorrelation and twogener. More than 20 different graphs summarize data and aid exploration. Sequence and genotype data can be imported from automated sequencers, and exported to other software. Initially designed as tool for teaching, genalex 6 now offers features for researchers as well. Documentation and the program are available at http://www.anu.edu.au/BoZo/GenAlEx/",2006,12,14558,3330,0,0,0,0,0,0,3,972,1332,1368
895860c6083736508d2541900cdf0960eb11592f,"The design, implementation, and capabilities of an extensible visualization system, UCSF Chimera, are discussed. Chimera is segmented into a core that provides basic services and visualization, and extensions that provide most higher level functionality. This architecture ensures that the extension mechanism satisfies the demands of outside developers who wish to incorporate new features. Two unusual extensions are presented: Multiscale, which adds the ability to visualize large‐scale molecular assemblies such as viral coats, and Collaboratory, which allows researchers to share a Chimera session interactively despite being at separate locales. Other extensions include Multalign Viewer, for showing multiple sequence alignments and associated structures; ViewDock, for screening docked ligand orientations; Movie, for replaying molecular dynamics trajectories; and Volume Viewer, for display and analysis of volumetric data. A discussion of the usage of Chimera in real‐world situations is given, along with anticipated future directions. Chimera includes full user documentation, is free to academic and nonprofit users, and is available for Microsoft Windows, Linux, Apple Mac OS X, SGI IRIX, and HP Tru64 Unix from http://www.cgl.ucsf.edu/chimera/. © 2004 Wiley Periodicals, Inc. J Comput Chem 25: 1605–1612, 2004",2004,70,28328,1713,0,0,0,0,1,0,0,0,0,0
e7c8aa2cb2223f17615c1b1ae3b33095466e95cc,"The two most commonly used methods to analyze data from real-time, quantitative PCR experiments are absolute quantification and relative quantification. Absolute quantification determines the input copy number, usually by relating the PCR signal to a standard curve. Relative quantification relates the PCR signal of the target transcript in a treatment group to that of another sample such as an untreated control. The 2(-Delta Delta C(T)) method is a convenient way to analyze the relative changes in gene expression from real-time quantitative PCR experiments. The purpose of this report is to present the derivation, assumptions, and applications of the 2(-Delta Delta C(T)) method. In addition, we present the derivation and applications of two variations of the 2(-Delta Delta C(T)) method that may be useful in the analysis of real-time, quantitative PCR data.",2001,21,115917,1656,0,0,0,0,0,0,0,0,1,0
05abdc87bcaf2963fd511672e64ab39d02239aaf,,2007,30,24491,2512,0,1,0,0,1,0,5,6,535,2032
2d6f573c36c5e2153b65859fb080523fc4d842d0,"We announce the release of the fourth version of MEGA software, which expands on the existing facilities for editing DNA sequence data from autosequencers, mining Web-databases, performing automatic and manual sequence alignment, analyzing sequence alignments to estimate evolutionary distances, inferring phylogenetic trees, and testing evolutionary hypotheses. Version 4 includes a unique facility to generate captions, written in figure legend format, in order to provide natural language descriptions of the models and methods used in the analyses. This facility aims to promote a better understanding of the underlying assumptions used in analyses, and of the results generated. Another new feature is the Maximum Composite Likelihood (MCL) method for estimating evolutionary distances between all pairs of sequences simultaneously, with and without incorporating rate variation among sites and substitution pattern heterogeneities among lineages. This MCL method also can be used to estimate transition/transversion bias and nucleotide substitution pattern without knowledge of the phylogenetic tree. This new version is a native 32-bit Windows application with multi-threading and multi-user supports, and it is also available to run in a Linux desktop environment (via the Wine compatibility layer) and on Intel-based Macintosh computers under the Parallels program. The current version of MEGA is available free of charge at (http://www.megasoftware.net).",2007,10,28423,6043,0,0,0,0,1,18,2034,2152,1667,1255
4e2f43dab69d690dc86422949e410ebf37f522d4,"Bayesian methods have garnered huge interest in cognitive science as an approach to models of cognition and perception. On the other hand, Bayesian methods for data analysis have not yet made much headway in cognitive science against the institutionalized inertia of 20th century null hypothesis significance testing (NHST). Ironically, specific Bayesian models of cognition and perception may not long endure the ravages of empirical verification, but generic Bayesian methods for data analysis will eventually dominate. It is time that Bayesian data analysis became the norm for empirical methods in cognitive science. This article reviews a fatal flaw of NHST and introduces the reader to some benefits of Bayesian data analysis. The article presents illustrative examples of multiple comparisons in Bayesian analysis of variance and Bayesian approaches to statistical power. Copyright © 2010 John Wiley & Sons, Ltd. For further resources related to this article, please visit the WIREs website.",2010,87,5662,709,296,287,323,345,347,434,424,416,498,498
57e7a7323f58a35f5e2cc33bf17d4ac9cdcafdd4,"DAVID bioinformatics resources consists of an integrated biological knowledgebase and analytic tools aimed at systematically extracting biological meaning from large gene/protein lists. This protocol explains how to use DAVID, a high-throughput and integrated data-mining environment, to analyze gene lists derived from high-throughput genomic experiments. The procedure first requires uploading a gene list containing any number of common gene identifiers followed by analysis using one or more text and pathway-mining tools such as gene functional classification, functional annotation chart or clustering and functional annotation table. By following this protocol, investigators are able to gain an in-depth understanding of the biological themes in lists of genes that are enriched in genome-scale studies.",2008,16,27514,2132,0,0,0,0,0,0,0,0,7,39
cad327e1e3a0799202cb40da5da51d7b0616b64e,"Arlequin ver 3.0 is a software package integrating several basic and advanced methods for population genetics data analysis, like the computation of standard genetic diversity indices, the estimation of allele and haplotype frequencies, tests of departure from linkage equilibrium, departure from selective neutrality and demographic equilibrium, estimation or parameters from past population expansions, and thorough analyses of population subdivision under the AMOVA framework. Arlequin 3 introduces a completely new graphical interface written in C++, a more robust semantic analysis of input files, and two new methods: a Bayesian estimation of gametic phase from multi-locus genotypes, and an estimation of the parameters of an instantaneous spatial expansion from DNA sequence polymorphism. Arlequin can handle several data types like DNA sequences, microsatellite data, or standard multi-locus genotypes. A Windows version of the software is freely available on http://cmpg.unibe.ch/software/arlequin3.",2007,148,12556,4438,1,1,21,1207,1437,1392,1211,1052,891,751
e09bb0025f4939a4bd233a70937584b4d7bdd0a7,"BackgroundThe evolutionary analysis of molecular sequence variation is a statistical enterprise. This is reflected in the increased use of probabilistic models for phylogenetic inference, multiple sequence alignment, and molecular population genetics. Here we present BEAST: a fast, flexible software architecture for Bayesian analysis of molecular sequences related by an evolutionary tree. A large number of popular stochastic models of sequence evolution are provided and tree-based models suitable for both within- and between-species sequence data are implemented.ResultsBEAST version 1.4.6 consists of 81000 lines of Java source code, 779 classes and 81 packages. It provides models for DNA and protein sequence evolution, highly parametric coalescent analysis, relaxed clock phylogenetics, non-contemporaneous sequence data, statistical alignment and a wide range of options for prior distributions. BEAST source code is object-oriented, modular in design and freely available at http://beast-mcmc.googlecode.com/ under the GNU LGPL license.ConclusionBEAST is a powerful and flexible evolutionary analysis package for molecular sequence variation. It also provides a resource for the further development of new models and statistical methods of evolutionary analysis.",2007,45,11140,3504,0,0,1,247,973,1270,1219,1114,1018,941
80935b370bac09ce615a002caabc30fbb26f029b,"With its theoretical basis firmly established in molecular evolutionary and population genetics, the comparative DNA and protein sequence analysis plays a central role in reconstructing the evolutionary histories of species and multigene families, estimating rates of molecular evolution, and inferring the nature and extent of selective forces shaping the evolution of genes and genomes. The scope of these investigations has now expanded greatly owing to the development of high-throughput sequencing techniques and novel statistical and computational methods. These methods require easy-to-use computer programs. One such effort has been to produce Molecular Evolutionary Genetics Analysis (MEGA) software, with its focus on facilitating the exploration and analysis of the DNA and protein sequence variation from an evolutionary perspective. Currently in its third major release, MEGA3 contains facilities for automatic and manual sequence alignment, web-based mining of databases, inference of the phylogenetic trees, estimation of evolutionary distances and testing evolutionary hypotheses. This paper provides an overview of the statistical methods, computational tools, and visual exploration modules for data input and the results obtainable in MEGA.",2004,73,12037,3302,1,0,26,1588,2150,1625,1243,879,678,475
4c97d9b9eb7c158e682844b394b42924af3c5b3f,"Interpretative phenomenological analysis (IPA) is an increasingly popular approach to qualitative inquiry. This handy text covers its theoretical foundations and provides a detailed guide to conducting IPA research. 
 
Extended worked examples from the authors' own studies in health, sexuality, psychological distress and identity illustrate the breadth and depth of IPA research. 
 
Each of the chapters also offers a guide to other good exemplars of IPA research in the designated area. The final section of the book considers how IPA connects with other contemporary qualitative approaches like discourse and narrative analysis and how it addresses issues to do with validity. The book is written in an accessible style and will be extremely useful to students and researchers in psychology and related disciplines in the health and social sciences.",2009,7,6197,1589,6,76,172,280,438,624,709,699,792,811
001c07aefcc186013184009e0c83847f28867e08,"ggplot2: Elegant Graphics for Data Analysis is a new addition to the UseR! series by Springer, probably the fastest expanding source of resources for computational statistics at the current moment. The books in this series are all linked with R, either presenting a new package developed by the own authors of the book or describing how to applying statistical techniques with the different packages available in R. ggplot2 is an implementation in R of The Grammar of Graphics (Wilkinson 2005) a systematic approach to the specification of statistical graphics that was introduced in a book previously reviewed in the Journal of Statistical Software by Cox (2007). This implementation has been developed by Hadley Wickham, who is also the author of the book reviewed here.",2010,1,4911,435,9,20,22,56,87,94,178,255,446,795
7ea9b1915072f2adff3762b59b7c7d79805fee8e,"If radiocarbon measurements are to be used at all for chronological purposes, we have to use statistical methods for calibration. The most widely used method of calibration can be seen as a simple application of Bayesian statistics, which uses both the information from the new measurement and information from the 14C calibration curve. In most dating applications, however, we have larger numbers of 14C measurements and we wish to relate those to events in the past. Bayesian statistics provides a coherent framework in which such analysis can be performed and is becoming a core element in many 14C dating projects. This article gives an overview of the main model components used in chronological analysis, their mathematical formulation, and examples of how such analyses can be performed using the latest version of the OxCal software (v4). Many such models can be put together, in a modular fashion, from simple elements, with defined constraints and groupings. In other cases, the commonly used ""uniform phase"" models might not be appropriate, and ramped, exponential, or normal distributions of events might be more useful. When considering analyses of these kinds, it is useful to be able run simulations on synthetic data. Methods for performing such tests are discussed here along with other methods of diagnosing possible problems with statistical models of this kind.",2009,69,4539,1446,11,103,201,275,402,450,446,453,577,449
87ccc438b0c73fcfdea48485fcdb091a8ecaa89c,"High-throughput sequencing assays such as RNA-Seq, ChIP-Seq or barcode counting provide quantitative readouts in the form of count data. To infer differential signal in such data correctly and with good statistical power, estimation of data variability throughout the dynamic range and a suitable error model are required. We propose a method based on the negative binomial distribution, with variance and mean linked by local regression and present an implementation, DESeq, as an R/Bioconductor package.",2010,80,9807,1096,9,65,225,483,806,957,981,1071,1172,1372
b9544a1bf4b02c6648dbd12702bc10c00e20e197,"Content analysis is a widely used qualitative research technique. Rather than being a single method, current applications of content analysis show three distinct approaches: conventional, directed, or summative. All three approaches are used to interpret meaning from the content of text data and, hence, adhere to the naturalistic paradigm. The major differences among the approaches are coding schemes, origins of codes, and threats to trustworthiness. In conventional content analysis, coding categories are derived directly from the text data. With a directed approach, analysis starts with a theory or relevant research findings as guidance for initial codes. A summative content analysis involves counting and comparisons, usually of keywords or content, followed by the interpretation of the underlying context. The authors delineate analytic procedures specific to each approach and techniques addressing trustworthiness with hypothetical examples drawn from the area of end-of-life care.",2005,57,24913,943,0,0,0,0,0,0,0,0,0,0
2fcf90089d9f95025e8953812a43f0db2de3af7c,,2009,0,10344,2663,0,0,262,430,655,922,1128,1232,1332,1349
